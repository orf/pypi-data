{
    "0.0.1": {
        "info": {
            "author": "HaraAi",
            "author_email": "info@hara.ai",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/haraai/ParsiNorm",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "parsinorm",
            "package_url": "https://pypi.org/project/parsinorm/",
            "platform": null,
            "project_url": "https://pypi.org/project/parsinorm/",
            "project_urls": {
                "Homepage": "https://github.com/haraai/ParsiNorm"
            },
            "release_url": "https://pypi.org/project/parsinorm/0.0.1/",
            "requires_dist": [
                "num2fawords (==1.1)",
                "persian-tools (==0.0.10)",
                "urlextract (==1.4.0)",
                "nltk (==3.3)",
                "hazm (==0.7.0)"
            ],
            "requires_python": "",
            "summary": "Persain Text Pre-Proceesing Tool",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14065637,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6a0d56d5a1d89680623e9776936d4f2d",
                    "sha256": "c3506865eeebd39e2c829cd4065842a44d5f7b4f08e2439d5862effa35e066fc"
                },
                "downloads": -1,
                "filename": "parsinorm-0.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "6a0d56d5a1d89680623e9776936d4f2d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 29935,
                "upload_time": "2022-03-29T16:57:05",
                "upload_time_iso_8601": "2022-03-29T16:57:05.231478Z",
                "url": "https://files.pythonhosted.org/packages/80/3a/07490b5a14c1a83ec8d7ecc482dbbbec905fa03f6745215c169b02bf3f91/parsinorm-0.0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.2": {
        "info": {
            "author": "HaraAi",
            "author_email": "info@hara.ai",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/haraai/ParsiNorm",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "parsinorm",
            "package_url": "https://pypi.org/project/parsinorm/",
            "platform": null,
            "project_url": "https://pypi.org/project/parsinorm/",
            "project_urls": {
                "Homepage": "https://github.com/haraai/ParsiNorm"
            },
            "release_url": "https://pypi.org/project/parsinorm/0.0.2/",
            "requires_dist": [
                "num2fawords (==1.1)",
                "persian-tools (==0.0.10)",
                "urlextract (==1.4.0)",
                "nltk (==3.3)",
                "hazm (==0.7.0)"
            ],
            "requires_python": "",
            "summary": "Persain Text Pre-Proceesing Tool",
            "version": "0.0.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14065637,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9aa391ff124fdb402a1b5fc93f705705",
                    "sha256": "162572aae3b9a326d09a6348a3944a1d7fc178a945877484a0de05819d9baff6"
                },
                "downloads": -1,
                "filename": "parsinorm-0.0.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "9aa391ff124fdb402a1b5fc93f705705",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 30376,
                "upload_time": "2022-04-03T09:57:32",
                "upload_time_iso_8601": "2022-04-03T09:57:32.873123Z",
                "url": "https://files.pythonhosted.org/packages/e5/c3/78559c0674dea5a1103ba9117706fbf59dbb880685e821c96cbfe599c7bc/parsinorm-0.0.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.3": {
        "info": {
            "author": "HaraAi",
            "author_email": "info@hara.ai",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "<div dir='ltr' align='left'>\n\n# ParsiNorm\nThe normalization step is so essential to format unification in pure textual applications. However, for embedded language models in speech processing modules, normalization is not limited to format unification. Moreover, it has to convert each readable symbol, number, etc., to how they are pronounced. \n\n<h1>functionalities</h1>\n\n<h3> General Normalization</h3>\n\n+ Sentence tokenizer (you must add postagger.model to a folder named resources in where parsinorm is installed for example \"/home/yourComputerName/.anaconda3/lib/python3.8/site-packages/parsinorm/resources\")\n+ Word Tokenizer\n+ Normalizing persian and English characters \n+ Normalizing Numbers (Converting to unique perisan Number)\n+ Converting Persian, English, Arabic symbols to normalized characters\n+ Normalize Punctuations\n+ Removing emojis\n+ Converting HTML tags to characters and symbols\n+ Having unique floating point number\n+ Removing different comma between numbers\n+ Removing repeated punctuations\n+ convert semi sapce to null\n\n<h3> Speech Normalization</h3>\n\n+ Converting mail and url to how are pronounced\n+ Converting Date and Times to how they are pronounced\n+ Converting special numbers to how they are pronounced\n+ Converting English and Persian Abbrevations to how they are pronounced\n+ converting telephone numbers to how they are pronounced in Persian\n+ Converting currency to how they are read\n+ Converting some symbols to how they are read such as %, \u00b0, *, #, +, &, \u0394\n\n<h1>Usage</h1>\n\n```python\n>>> from parsinorm import Mail_url_cleaner \n>>> mail_url_cleaner  = Mail_url_cleaner ()\n>>> mail_url_cleaner.find_mails_clean(sentence=\"info@hara.ai\")\ninfo at hara dot ai\n\n>>> mail_url_cleaner.find_urls_clean(sentence=\"https://hara.ai/#services\")\nhttps do noghte slash slash hara dot ai\n\n>>> from parsinorm import Date_time_to_text\n>>> date_time_to_text = Date_time_to_text()\n>>> date_time_to_text.date_to_text(sentence='2021/10/27')\n\u0628\u06cc\u0633\u062a \u0648 \u0647\u0641\u062a\u0645 \u0627\u06a9\u062a\u0628\u0631 \u0633\u0627\u0644 \u062f\u0648 \u0647\u0632\u0627\u0631 \u0648 \u0628\u06cc\u0633\u062a \u0648 \u06cc\u06a9\n\n>>> date_time_to_text.time_to_text(sentence='22:57:11')\n\u0628\u06cc\u0633\u062a \u0648 \u062f\u0648 \u0648 \u067e\u0646\u062c\u0627\u0647 \u0648 \u0647\u0641\u062a \u062f\u0642\u06cc\u0642\u0647 \u0648  \u06cc\u0627\u0632\u062f\u0647 \u062b\u0627\u0646\u06cc\u0647\n\n>>> from parsinorm import General_normalization\n>>> general_normalization = General_normalization()\n>>> general_normalization.alphabet_correction(sentence='\ufed9\ufbd8\u0759\u0764\ufbae')\n\u06a9\u0648\u062f\u06a9\u06cc\n\n>>>general_normalization.semi_space_correction(sentence='\u06a9\u062a\u0627\u0628\\u200b\u062e\u0627\u0646\u0647')\n\u06a9\u062a\u0627\u0628\u062e\u0627\u0646\u0647\n\n>>> general_normalization.english_correction(sentence='na\u00efve')\nnaive\n\n>>> general_normalization.html_correction(sentence='&quot;')\n\"\n\n>>> general_normalization.arabic_correction(sentence='\ufdfa')\n\u0635\u0644\u06cc \u0627\u0644\u0644\u0647 \u0639\u0644\u06cc\u0647 \u0648 \u0633\u0644\u0645\n\n>>> general_normalization.punctuation_correction(sentence=\"\u2026\")\n...\n\n>>> general_normalization.specials_chars(sentence=\"\u2121\")\nTEL\n\n>>> general_normalization.remove_emojis(sentence='\ud83d\ude0a')\n\n\n>>> general_normalization.unique_floating_point(sentence='1\u060c2')\n\u06f1.\u06f2\n\n>>> general_normalization.remove_comma_between_numbers(sentence='1\u066c234')\n\u06f1\u06f2\u06f3\u06f4\n\n>>> general_normalization.number_correction(sentence=\"\u2464\")\n\u06f5\n\n>>> general_normalization.remove_not_desired_chars(sentence=\"^ Hi ~\")\n  Hi  \n\n>>> general_normalization.remove_repeated_punctuation(sentence=\"!!!!!\")\n!\n\n>>> from parsinorm import Telephone_number\n>>> telephone_number = Telephone_number()\n>>> telephone_number.find_phones_replace(sentence='\u062a\u0644\u0641\u0646 \u06f0\u06f2\u06f1\u06f3\u06f3\u06f4\u06f5\u06f6\u06f7\u06f8\u06f8')\n\u062a\u0644\u0641\u0646   \u0635\u0641\u0631  \u0628\u06cc\u0633\u062a \u0648 \u06cc\u06a9 \u0633\u06cc \u0648 \u0633\u0647 \u0686\u0647\u0644 \u0648 \u067e\u0646\u062c \u0634\u0635\u062a \u0648 \u0647\u0641\u062a \u0647\u0634\u062a\u0627\u062f \u0648 \u0647\u0634\u062a\n\n>>> from parsinorm import Abbreviation\n>>> abbreviation = Abbreviation()\n>>> abbreviation.replace_date_abbreviation(sentence=\".\u062f\u0631 \u0633\u0627\u0644 1400 \u0647.\u0634\")\n\u062f\u0631 \u0633\u0627\u0644 1400 \u0647\u062c\u0631\u06cc \u0634\u0645\u0633\u06cc\n\n>>> abbreviation.replace_persian_label_abbreviation(sentence='\u0627\u0645\u0627\u0645 \u0632\u0645\u0627\u0646 (\u0639\u062c)')\n\u0627\u0645\u0627\u0645 \u0632\u0645\u0627\u0646  \u0639\u062c\u0644 \u0627\u0644\u0644\u0647 \u062a\u0639\u0627\u0644\u06cc \u0641\u0631\u062c\u0647 \u0627\u0644\u0634\u0631\u06cc\u0641 \n\n>>> abbreviation.replace_law_abbreviation(sentence='\u062f\u0631 \u0642.\u0627 \u0622\u0645\u062f\u0647 \u0627\u0633\u062a')\n\u062f\u0631 \u0642\u0627\u0646\u0648\u0646 \u0627\u0633\u0627\u0633\u06cc \u0622\u0645\u062f\u0647 \u0627\u0633\u062a\n\n>>> abbreviation.replace_book_abbreviation(sentence='\u0628\u0647 \u06a9\u062a\u0627\u0628 \u0632\u06cc\u0631 \u0631.\u06a9 \u0645\u0631\u0627\u062c\u0639\u0647 \u06a9\u0646\u06cc\u062f')\n\u0628\u0647 \u06a9\u062a\u0627\u0628 \u0632\u06cc\u0631 \u0631\u062c\u0648\u0639 \u06a9\u0646\u06cc\u062f \u0645\u0631\u0627\u062c\u0639\u0647 \u06a9\u0646\u06cc\u062f\n\n>>> abbreviation.replace_other_abbreviation(sentence='\u062f\u0631 \u0642\u0627\u0646\u0648\u0646 \u062c.\u0627 \u0622\u0645\u062f\u0647 \u0627\u0633\u062a')\n\u062f\u0631 \u0642\u0627\u0646\u0648\u0646 \u062c\u0645\u0647\u0648\u0631\u06cc \u0627\u0633\u0644\u0627\u0645\u06cc \u0622\u0645\u062f\u0647 \u0627\u0633\u062a\n\n>>> abbreviation.replace_English_abbrevations(sentence='U.S.A')\n\u06cc\u0648 \u0627\u0633 \u0622\n\n>>> from parsinorm import TTS_normalization\n>>> TTS_normalization = TTS_normalization()\n>>> TTS_normalization.math_correction(sentence='\u215e')\n\u0647\u0641\u062a \u0647\u0634\u062a\u0645\n\n>>> TTS_normalization.replace_currency(sentence='\u06f3\u06f3$')\n\u06f3\u06f3 \u062f\u0644\u0627\u0631\n\n>>> TTS_normalization.replace_symbols(sentence='\u06f3\u06f3\u00b0')\n\u06f3\u06f3 \u062f\u0631\u062c\u0647 \n\n>>> from parsinorm import Special_numbers\n>>> special_numbers = Special_numbers()\n>>> special_numbers.convert_numbers_to_text(sentence='122')\n \u0635\u062f \u0648 \u0628\u06cc\u0633\u062a \u0648 \u062f\u0648\n\n>>> special_numbers.replace_national_code(sentence='0499370899')\n\u0635\u0641\u0631  \u0686\u0647\u0627\u0631   \u0646\u0647\u0635\u062f \u0648 \u0646\u0648\u062f \u0648 \u0633\u0647   \u0647\u0641\u062a\u0627\u062f   \u0647\u0634\u062a\u0635\u062f \u0648 \u0646\u0648\u062f \u0648 \u0646\u0647\n\n>>> special_numbers.replace_card_number(sentence='6037701689095443')\n\u0634\u0635\u062a   \u0633\u06cc \u0648 \u0647\u0641\u062a   \u0647\u0641\u062a\u0627\u062f   \u0634\u0627\u0646\u0632\u062f\u0647   \u0647\u0634\u062a\u0627\u062f \u0648 \u0646\u0647   \u0635\u0641\u0631  \u0646\u0647   \u067e\u0646\u062c\u0627\u0647 \u0648 \u0686\u0647\u0627\u0631   \u0686\u0647\u0644 \u0648 \u0633\u0647\n\n>>>special_numbers.replace_shaba(sentence='IR820540102680020817909002')\n \u0622\u06cc \u0622\u0631   \u0647\u0634\u062a\u0627\u062f \u0648 \u062f\u0648   \u0635\u0641\u0631  \u067e\u0646\u062c   \u0686\u0647\u0644   \u062f\u0647   \u0628\u06cc\u0633\u062a \u0648 \u0634\u0634   \u0647\u0634\u062a\u0627\u062f   \u0635\u0641\u0631  \u062f\u0648   \u0635\u0641\u0631  \u0647\u0634\u062a   \u0647\u0641\u062f\u0647   \u0646\u0648\u062f   \u0646\u0648\u062f   \u0635\u0641\u0631  \u062f\u0648 \n\n>>> from parsinorm import Tokenizer\n>>> tokenizer = Tokenizer()\n>>> tokenizer.sentence_tokenize('\u0627\u06cc\u0646 \u0645\u062b\u0627\u0644\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u06cc\u06a9 \u062c\u0645\u0644\u0647 \u0641\u0642\u0637 \u0628\u0631 \u0627\u0633\u0627\u0633 \u0639\u0644\u0627\u0626\u0645 \u0646\u06af\u0627\u0631\u0634\u06cc \u062c\u062f\u0627 \u0645\u06cc\u200c\u0634\u0648\u062f.',verb_seperator= False)\n['\u0627\u06cc\u0646 \u0645\u062b\u0627\u0644\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u06cc\u06a9 \u062c\u0645\u0644\u0647 \u0641\u0642\u0637 \u0628\u0631 \u0627\u0633\u0627\u0633 \u0639\u0644\u0627\u0626\u0645 \u0646\u06af\u0627\u0631\u0634\u06cc \u062c\u062f\u0627 \u0645\u06cc\u0634\u0648\u062f .']\n\n>>> tokenizer.sentence_tokenize('\u0627\u06cc\u0646 \u0645\u062b\u0627\u0644\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u06cc\u06a9 \u062c\u0645\u0644\u0647 \u0628\u0627 \u0641\u0639\u0644 \u062a\u0645\u0627\u0645 \u0634\u062f\u0647\u200c\u0627\u0633\u062a \u0648\u0644\u06cc \u0628\u0627 \u0646\u0642\u0637\u0647 \u062a\u0645\u0627\u0645 \u0646\u0634\u062f\u0647\u200c\u0627\u0633\u062a \u0628\u0647 \u0647\u0645\u06cc\u0646 \u062f\u0644\u06cc\u0644 \u0622\u0646 \u0631\u0627 \u0628\u0631 \u0627\u0633\u0627\u0633 \u0641\u0639\u0644 \u062c\u062f\u0627 \u0645\u06cc\u200c\u06a9\u0646\u06cc\u0645',verb_seperator= True)\n[' \u0627\u06cc\u0646 \u0645\u062b\u0627\u0644\u06cc \u0627\u0633\u062a',\n ' \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u06cc\u06a9 \u062c\u0645\u0644\u0647 \u0628\u0627 \u0641\u0639\u0644 \u062a\u0645\u0627\u0645 \u0634\u062f\u0647\\u200c\u0627\u0633\u062a',\n ' \u0648\u0644\u06cc \u0628\u0627 \u0646\u0642\u0637\u0647 \u062a\u0645\u0627\u0645 \u0646\u0634\u062f\u0647\\u200c\u0627\u0633\u062a',\n ' \u0628\u0647 \u0647\u0645\u06cc\u0646 \u062f\u0644\u06cc\u0644 \u0622\u0646 \u0631\u0627 \u0628\u0631 \u0627\u0633\u0627\u0633 \u0641\u0639\u0644 \u062c\u062f\u0627 \u0645\u06cc\\u200c\u06a9\u0646\u06cc\u0645']\n\n\n\n>>> tokenizer.word_tokenize('\u0645\u06cc\u200c\u062a\u0648\u0627\u0646\u06cc\u062f \u0627\u0632 \u0637\u0631\u06cc\u0642 \u0627\u06cc\u0646email \u0628\u0627 \u0645\u0627 \u062f\u0631 \u0627\u0631\u062a\u0628\u0627\u0637 \u0628\u0627\u0634\u06cc\u062f: info@hara.ai. \u0647\u0645\u0686\u0646\u06cc\u0646 \u0628\u0627 \u0647\u0634\u062a\u06af #hara \u0645\u0627 \u0631\u0627 \u062f\u0646\u0628\u0627\u0644 \u06a9\u0646\u06cc\u062f')\n['\u0645\u06cc\\u200c\u062a\u0648\u0627\u0646\u06cc\u062f',\n '\u0627\u0632',\n '\u0637\u0631\u06cc\u0642',\n '\u0627\u06cc\u0646',\n 'email',\n '\u0628\u0627',\n '\u0645\u0627',\n '\u062f\u0631',\n '\u0627\u0631\u062a\u0628\u0627\u0637',\n '\u0628\u0627\u0634\u06cc\u062f',\n ':',\n 'info@hara.ai',\n '.',\n '\u0647\u0645\u0686\u0646\u06cc\u0646',\n '\u0628\u0627',\n '\u0647\u0634\u062a\u06af',\n 'hara#',\n '\u0645\u0627',\n '\u0631\u0627',\n '\u062f\u0646\u0628\u0627\u0644',\n '\u06a9\u0646\u06cc\u062f']\n\n```\n\n\n<h1> Reference </h1>\n\nIf you use or discuss this normalization tool in your work, please cite our paper :\n\n```\n@inproceedings{oji2021parsinorm,\n  title={ParsiNorm: A Persian Toolkit for Speech Processing Normalization},\n  author={Oji, Romina and Razavi, Seyedeh Fatemeh and Dehsorkh, Sajjad Abdi and Hariri, Alireza and Asheri, Hadi and Hosseini, Reshad},\n  booktitle={2021 7th International Conference on Signal Processing and Intelligent Systems (ICSPIS)},\n  pages={1--5},\n  year={2021},\n  organization={IEEE}\n}\n```\n\n<h1> Contact </h1>\n\nIf you have any technical question regarding the dataset or publication, please\ncreate an issue in this repository.\n\n\n</div>\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/haraai/ParsiNorm",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "parsinorm",
            "package_url": "https://pypi.org/project/parsinorm/",
            "platform": null,
            "project_url": "https://pypi.org/project/parsinorm/",
            "project_urls": {
                "Homepage": "https://github.com/haraai/ParsiNorm"
            },
            "release_url": "https://pypi.org/project/parsinorm/0.0.3/",
            "requires_dist": [
                "num2fawords (==1.1)",
                "persian-tools (==0.0.10)",
                "urlextract (==1.4.0)",
                "nltk (==3.3)",
                "hazm (==0.7.0)"
            ],
            "requires_python": "",
            "summary": "Persain Text Pre-Proceesing Tool",
            "version": "0.0.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14065637,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "262597e08d7d161c0f6e4f5fb40c7645",
                    "sha256": "d3cf22bd31dc0abaa1c56bfa51e6e9d75fdcfc9f52cbe8f524574bf51173484b"
                },
                "downloads": -1,
                "filename": "parsinorm-0.0.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "262597e08d7d161c0f6e4f5fb40c7645",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 30378,
                "upload_time": "2022-06-08T05:54:35",
                "upload_time_iso_8601": "2022-06-08T05:54:35.066093Z",
                "url": "https://files.pythonhosted.org/packages/48/37/06343b4abf2341362ddebd5b0f468458046a309118be6e28d8b6413b7595/parsinorm-0.0.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1": {
        "info": {
            "author": "AIDynamicAction",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/x-rst",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/AIDynamicAction/rcognita",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rcognita",
            "package_url": "https://pypi.org/project/rcognita/",
            "platform": "",
            "project_url": "https://pypi.org/project/rcognita/",
            "project_urls": {
                "Homepage": "https://github.com/AIDynamicAction/rcognita"
            },
            "release_url": "https://pypi.org/project/rcognita/0.1/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "rcognita is a framework for hybrid agent-environment loop simulation, with a library of predictive and stabilizing reinforcement learning setups",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 11446891,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1200756cc5cecc85fac416a868356124",
                    "sha256": "51e85d0ec035e75cb8c125d0e05b2faca4d4a630a2b55b48283ffc84fd9ef893"
                },
                "downloads": -1,
                "filename": "rcognita-0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "1200756cc5cecc85fac416a868356124",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 39040,
                "upload_time": "2021-09-13T20:52:39",
                "upload_time_iso_8601": "2021-09-13T20:52:39.746894Z",
                "url": "https://files.pythonhosted.org/packages/e0/8a/6079df1a8499d4f7d933762cdd13ea6f115b19bdf4b2b71de8d17213c38c/rcognita-0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "AIDynamicAction",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/x-rst",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/AIDynamicAction/rcognita",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rcognita",
            "package_url": "https://pypi.org/project/rcognita/",
            "platform": "",
            "project_url": "https://pypi.org/project/rcognita/",
            "project_urls": {
                "Homepage": "https://github.com/AIDynamicAction/rcognita"
            },
            "release_url": "https://pypi.org/project/rcognita/0.1.1/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "rcognita is a framework for hybrid agent-environment loop simulation, with a library of predictive and stabilizing reinforcement learning setups",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 11446891,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c3b01463b252a46f2128c9a21aaf9390",
                    "sha256": "65edbd68768e0dd3ae2ca52148ecf47c49a96e86bddfde633386aedb41351b17"
                },
                "downloads": -1,
                "filename": "rcognita-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "c3b01463b252a46f2128c9a21aaf9390",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 38964,
                "upload_time": "2021-09-14T01:42:13",
                "upload_time_iso_8601": "2021-09-14T01:42:13.449373Z",
                "url": "https://files.pythonhosted.org/packages/9e/a6/c1aaf8e324d241e60c840b8495db63de2580ef6fc8e53e3365c5ab564c5f/rcognita-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "AIDynamicAction",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/x-rst",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/AIDynamicAction/rcognita",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rcognita",
            "package_url": "https://pypi.org/project/rcognita/",
            "platform": "",
            "project_url": "https://pypi.org/project/rcognita/",
            "project_urls": {
                "Homepage": "https://github.com/AIDynamicAction/rcognita"
            },
            "release_url": "https://pypi.org/project/rcognita/0.1.2/",
            "requires_dist": [
                "matplotlib (>=3.2.2)",
                "mpldatacursor-rcognita (==0.7.2)",
                "numpy (>=1.20.1)",
                "scipy (>=1.5.0)",
                "svgpath2mpl (==0.2.1)",
                "tabulate (==0.8.7)",
                "torch (>=1.6.0)",
                "systems (==0.1.0)",
                "shapely (==1.7.1)",
                "sippy-rcognita (==0.2.1) ; extra == 'sippy'"
            ],
            "requires_python": ">=3.6",
            "summary": "rcognita is a framework for hybrid agent-environment loop simulation, with a library of predictive and stabilizing reinforcement learning setups",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 11446891,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "79e7b5097405f01cf11b1adb8c2d2160",
                    "sha256": "8d5b2cbb7d9aa9cb68fcf6ae9d36e75de019a26867d14c981eaf5dc8e8425f7e"
                },
                "downloads": -1,
                "filename": "rcognita-0.1.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "79e7b5097405f01cf11b1adb8c2d2160",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 37407,
                "upload_time": "2021-09-14T12:00:04",
                "upload_time_iso_8601": "2021-09-14T12:00:04.552225Z",
                "url": "https://files.pythonhosted.org/packages/23/b0/d9a8bbab5c7abd767880562f56b4e966e94bc20e9ef716b2b785dec9e968/rcognita-0.1.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "866820cc2e301a0fd675abd3dc436d81",
                    "sha256": "16a324dc24d38a8c6ff55b0e4013265481b0061d5c395f0fe41edbcc6a67cd5e"
                },
                "downloads": -1,
                "filename": "rcognita-0.1.2.tar.gz",
                "has_sig": false,
                "md5_digest": "866820cc2e301a0fd675abd3dc436d81",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 38960,
                "upload_time": "2021-09-14T12:00:06",
                "upload_time_iso_8601": "2021-09-14T12:00:06.257879Z",
                "url": "https://files.pythonhosted.org/packages/5f/64/4d6e45ff0a750e4a062ac6d5b7dbbd1942b2c6aa7690e5055400bff4b829/rcognita-0.1.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1rc1": {
        "info": {
            "author": "AIDynamicAction",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/AIDynamicAction/rcognita/master/gfx/logo/rcognita-logo.png\" width=40% height=40% />\n</p>\n\n`rcognita` is a framework for hybrid agent-enviroment simultion.\nThe hybrid setting here means the actions are updated at discrete moments in time, whereas the environment dynamics are modelled time-continuous.\nA detailed documentation is available [here](https://aidynamicaction.github.io/rcognita/).\n\n## Example run with a mobile robot simulation\n\n<p align=\"center\">\n\t<img src=\"https://raw.githubusercontent.com/AIDynamicAction/rcognita/master/gfx/demo/3wheel_robot_exm_run.gif\" width=40% />\n</p>\n\n# Table of content\n\n- [Installation](#Installation)\n- [General description](#General-description)\n- [Usage](#Usage)\n  * [Settings](#Settings)\n  * [Advanced customization](#Advanced-customization)\n  * [Experimental things](#Experimental-things)\n- [Closing remarks](#Closing-remarks)\n\n# Installation\n\nRun in terminal:\n```\npip3 install rcognita\n```\n\nAlternatively one can install the package direcly form the master branch.\nThe following instruction is for Unix-based systems, assuming a terminal and Python3 interpreter.\n\n```\ngit clone https://github.com/AIDynamicAction/rcognita\ncd rcognita\npython3 setup.py install\n```\n\nNotice that your Python 3 interpreter might be called something else, say, just `python`\n\n# General description\n\n[To table of content](#Table-of-content)\n\n`rcognita` Python package is designed for hybrid simulation of agents and environments (generally speaking, not necessarily reinforcement learning agents).\nIts main idea is to have an explicit implementation of sampled controls with user-defined sampling time specification.\nThe package consists of several modules, namely, `controllers`, `loggers`, `models`, `simulator`, `systems`, `utilities`, `visuals` and a collection of main modules (presets) for each agent-environment configuration.\n\n[This flowchart](./flowcharts/rcognita-flowchart-RLstab.pdf) shows interaction of the core `rcognita` classes contained in the said modules (the latter are not shown on the diagram).\n\nThe main module is a preset, on the flowchart a 3-wheel robot.\nIt initializes the system (the environment), the controllers (the agents, e. g., a safe agent, a benchmarking agent, a reinforcement learning agent etc.), the visualization engine called animator, the logger and the simulator.\nThe latter is a multi-purpose device for simulating agent-environment loops of different types (specified by sys type).\n\nDepending on `sys_type`, the environment can either be described by a differential equation (including stochastic ones), a difference equation (for discrete-time systems), or by a probability distribution (for, e. g., Markov decision processes).\n\nThe parameter `dt` determines the maximal step size for the numerical solver in case of differential equations.\nThe main method of this class is `sim_step` which performs one solver step, whereas reset re-initializes the simulator after an episode.\n\nThe `Logger` class is an interface defining stubs of a print-to-console method print sim step, and print-to-file method log data row, respectively.\nConcrete loggers realize these methods.\n\nA similar class inheritance scheme is used in animator, and system.\nThe core data of animator\u2019s subclasses are `objects`, which include entities to be updated on the screen, and their parameters stored in `pars`.\n\nA concrete realization of a system interface must realize `sys_dyn`, which is the \u201cright-handside\u201d of the environment description, optionally disturbance dynamics via `disturb_dyn`, optionally controller dynamics (if the latter is, e. g., time-varying), and the output function `out`.\nThe method `receive_action` gets a control action and stores it.\nEverything is packed together in the `closed_loop_rhs` for the use in `Simulator`.\n\nFinally, the `controllers` module contains various agent types.\nOne of them is `CtrlRLStab` \u2013 the class of stabilizing reinforcement learning agents as shown in [this flowchart](./flowcharts/rcognita-flowchart-RLstab.pdf).\nNotice it contains an explicit specification of the sampling time.\nThe data `SafeCtrl` is required to specify the stabilizing constraints and also to initialize the optimizer inside the `actor_critic` method, which in turns fetches the cost function from the `actor_critic_cost` method.\nThe method `compute_action` essentially watches the internal clock and performs an action updates when a time sample has elapsed.\n\nAuxiliary modules of the package are `models` and `utilities` which provide auxiliary functions and data structures, such as neural networks.\n\n# Usage\n\n[To table of content](#Table-of-content)\n\nAfter the package is installed, you may just `python` run one of the presets found [here](./presets).\nThe naming concention is `main_ACRONYM`, where `ACRONYM` is actually related to the system (environment). \nYou may create your own by analogy.\n\n## Settings\n\n[To table of content](#Table-of-content)\n\nThese are made in a preset file.\nSome are more or less self-evident, like `is_log_data`.\nThe crucial ones are:\n\n* `dt`: [in seconds] controller sampling time. Relevant if the system itself is continuous as a physical process while the controller is digital\n* `Nactor`: number of prediction steps. `Nactor=1` means the controller is purely **data-driven** and doesn't use prediction. Say, stacked QL will turn into the usual SARSA (in VI form)\n* `pred_step_size`: [in seconds] determines how fine the resolution of the prediction horizon is. Larger `pred_step_size` will result in a larger effective horizon length\n* \n\nMiscellaneous settings:\n\n* `t0`, `t1`: start time and stop time of one episode (usually, `t0=0` and `t1` is the episode duration)\n* `atol, rtol`: sensitivity of the solver. The lower the values, the more accurate the simulation results are\n* `Nruns`: number of episodes. After an episode, the system is reset to the initial state, whereas all the learned parameters continue to get updated. This emulates multi-episode RL\n\n## Advanced customization\n\n[To table of content](#Table-of-content)\n\n* **Custom environments**: realize `system` interface in the `systems` module. You might need nominal controllers for that, as well as an animator, a logger etc.\n* **Custom running cost**: adjust `rcost` in controllers\n* **Custom AC method**: simplest way -- by adding a new mode and updating `_actor_cost`, `_critic_cost` and, possibly, `_actor`, `_critic`. For deep net AC structures, use, say, [PyTorch](https://pytorch.org/)\n* **Custom model estimator**: so far, the framework offers a state-space model structure. You may use any other one. In case of neural nets, use, e.g., [PyTorch](https://pytorch.org/)\n\n## Experimental things\n\n[To table of content](#Table-of-content)\n\nAn interface for dynamical controllers, which can be considered as extensions of the system state vector, is provided in `_ctrl_dyn` of the `systems` module.\nRL is usually understood as a static controller, i.e., a one which assigns actions directly to outputs.\nA dynamical controller does this indirectly, via an internal state as intermediate link. \nynamical controllers can overcome some limitations of static controllers.\n\nThe package was tested with online model estimation using [SIPPY](https://github.com/CPCLAB-UNIPI/SIPPY). So far, there is no straightforward way to install it (under Windows at least).\nThe functionality is implemented and enabled via `is_est_model`.\nRelated parameters can be found in the documentation of the `ctrl_opt_pred` class.\nUpdates to come.\n\n# Closing remarks\n\n[To table of content](#Table-of-content)\n\nPlease contact [me](mailto:p.osinenko@gmail.com) for any inquiries and don't forget to give me credit for usage of this code.\nIf you are interested in stacked Q-learning, kindly read the [paper](https://arxiv.org/abs/2007.03999).\n\n```\n@misc{rcognita00,\nauthor =   {Pavel Osinenko},\ntitle =    {Rcognita: a framework for hybrid agent-enviroment simultion},\nhowpublished = {\\url{https://github.com/AIDynamicAction/rcognita}},\nyear = {2020}\n}\n```\n\nOriginal author: P. Osinenko, 2020\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/AIDynamicAction/rcognita",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rcognita",
            "package_url": "https://pypi.org/project/rcognita/",
            "platform": "",
            "project_url": "https://pypi.org/project/rcognita/",
            "project_urls": {
                "Homepage": "https://github.com/AIDynamicAction/rcognita"
            },
            "release_url": "https://pypi.org/project/rcognita/0.1rc1/",
            "requires_dist": [
                "matplotlib (>=3.2.2)",
                "mpldatacursor (==0.7.1)",
                "numpy (>=1.20.1)",
                "scipy (>=1.5.0)",
                "svgpath2mpl (==0.2.1)",
                "tabulate (==0.8.7)",
                "torch (>=1.6.0)",
                "systems (==0.1.0)",
                "shapely (==1.7.1)"
            ],
            "requires_python": ">=3.6",
            "summary": "rcognita is a framework for hybrid agent-environment loop simulation, with a library of predictive and stabilizing reinforcement learning setups",
            "version": "0.1rc1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 11446891,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "da088170b7721ac4899beaa961081d74",
                    "sha256": "ce8cd55a55d669589447a7fb0cada1511761273f05e6f5ad161560d0ec5e8109"
                },
                "downloads": -1,
                "filename": "rcognita-0.1rc1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "da088170b7721ac4899beaa961081d74",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 33494,
                "upload_time": "2021-09-07T16:32:34",
                "upload_time_iso_8601": "2021-09-07T16:32:34.579457Z",
                "url": "https://files.pythonhosted.org/packages/67/52/860ba5459874f45991dc3ae11dc97150aa8cb45b5adaab3d6950c9ff467a/rcognita-0.1rc1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "998adad5e4af541a129c5e6f995b1872",
                    "sha256": "e44bfab3960e56201872142a62dd7402e1fe1b101af8faf929031dbca2021cb0"
                },
                "downloads": -1,
                "filename": "rcognita-0.1rc1.tar.gz",
                "has_sig": false,
                "md5_digest": "998adad5e4af541a129c5e6f995b1872",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 33277,
                "upload_time": "2021-09-07T16:32:36",
                "upload_time_iso_8601": "2021-09-07T16:32:36.625060Z",
                "url": "https://files.pythonhosted.org/packages/f0/64/47fde7e06096e574d63ee015970a4b1182db43680ebd7d78fd18565c4ca9/rcognita-0.1rc1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
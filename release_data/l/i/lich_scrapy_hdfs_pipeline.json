{
    "0.0.1": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 2 - Pre-Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: English",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3 :: Only",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description": "# lich_scrapy_hdfs_pipeline\n\nScrapy project auto generated by [os-scrapy-cookiecutter](https://github.com/cfhamlet/os-scrapy-cookiecutter). \n\n\n## Project\n\nThis scrapy project is a python package generated by os-scrapy-cookiecutter.\n\nYou can run it as normal scrapy project with scrapy commands.\n\nIt is also a python package, the scaffolds can be used for formatting, testing, installing.\n\n* lint\n  \n    ```\n    sh scripts/lint.sh\n    ```\n\n* test\n\n    ```\n    sh scripts/test.sh\n    ```\n\n* install\n\n    ```\n    python setup.py install\n    ```\n\n* example\n\n    You can run example spider:\n\n    ```\n    scrapy crawl example\n    ```\n\n* files\n\n    ```\n    .\n    \u251c\u2500\u2500 lich_scrapy_hdfs_pipeline # scrapy project          \n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 items.py\n    \u2502   \u251c\u2500\u2500 middlewares.py\n    \u2502   \u251c\u2500\u2500 pipelines.py\n    \u2502   \u251c\u2500\u2500 settings.py\n    \u2502   \u2514\u2500\u2500 spiders\n    \u2502       \u2514\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 LICENSE # license file\n    \u251c\u2500\u2500 MANIFEST.in # setup install package file\n    \u251c\u2500\u2500 pytest.ini # pytest config file\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 requirements\n    \u2502   \u251c\u2500\u2500 requirements-lint.txt # requirements of format tools used by scripts/lint.sh and tox\n    \u2502   \u251c\u2500\u2500 requirements-test.txt # requirements of test used by tox\n    \u2502   \u2514\u2500\u2500 requirements.txt # requirements of this project\n    \u251c\u2500\u2500 scrapy.cfg # scrapy project entrypoint file\n    \u251c\u2500\u2500 scripts\n    \u2502   \u251c\u2500\u2500 test.sh # run test \n    \u2502   \u2514\u2500\u2500 lint.sh # format the source file\n    \u251c\u2500\u2500 setup.cfg # setup tool config file\n    \u251c\u2500\u2500 setup.py # setup tool \n    \u251c\u2500\u2500 tests\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u2514\u2500\u2500 test_scrapy_check.py # unit test with scrapy check\n    \u2514\u2500\u2500 tox.ini # tox config file\n    ```\n\n## Install\n\n```\npython setup.py install\n```\n\n## Usage\n\n```\nscrapy -h\n```\n\n## Unit Tests\n\n```\nsh scripts/test.sh\n```\n\n## License\n\nMIT licensed.\n",
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "MIT License",
            "maintainer": "",
            "maintainer_email": "",
            "name": "lich_scrapy_hdfs_pipeline",
            "package_url": "https://pypi.org/project/lich_scrapy_hdfs_pipeline/",
            "platform": "",
            "project_url": "https://pypi.org/project/lich_scrapy_hdfs_pipeline/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/lich_scrapy_hdfs_pipeline/0.0.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Auto Generated by os-scrapy-cookiecutter",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 9518415,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b6b034fedff34d34b6bae1dac7620c4c",
                    "sha256": "8bfa68c870af3150230560b279a04738432ab28c65a5acc63159de9af2cb5ee0"
                },
                "downloads": -1,
                "filename": "lich_scrapy_hdfs_pipeline-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "b6b034fedff34d34b6bae1dac7620c4c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 7097,
                "upload_time": "2021-02-25T03:11:12",
                "upload_time_iso_8601": "2021-02-25T03:11:12.149018Z",
                "url": "https://files.pythonhosted.org/packages/d9/1d/5b25b9b34bf41d5e035ea98f12956b1ea7919f8a7c5a2f9636edf052e44c/lich_scrapy_hdfs_pipeline-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
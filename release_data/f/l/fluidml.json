{
    "0.1.0": {
        "info": {
            "author": "Rajkumar Ramamurthy, Lars Hillebrand",
            "author_email": "raj1514@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/fluidml/fluidml/",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/fluidml/fluidml/",
            "keywords": "pipelines,machine-learning,parallel,deep-learning",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "fluidml",
            "package_url": "https://pypi.org/project/fluidml/",
            "platform": "",
            "project_url": "https://pypi.org/project/fluidml/",
            "project_urls": {
                "Download": "https://github.com/fluidml/fluidml/",
                "Homepage": "https://github.com/fluidml/fluidml/"
            },
            "release_url": "https://pypi.org/project/fluidml/0.1.0/",
            "requires_dist": [
                "networkx",
                "datasets ; extra == 'examples'",
                "flair ; extra == 'examples'",
                "jupyterlab ; extra == 'examples'",
                "numpy ; extra == 'examples'",
                "pyyaml ; extra == 'examples'",
                "requests ; extra == 'examples'",
                "sklearn ; extra == 'examples'",
                "tokenizers ; extra == 'examples'",
                "torchtext ; extra == 'examples'",
                "torch ; extra == 'examples'",
                "tqdm ; extra == 'examples'",
                "mongoengine ; extra == 'mongo-store'",
                "rich ; extra == 'rich-logging'"
            ],
            "requires_python": ">=3.7",
            "summary": "FluidML is a lightweight framework for developing machine learning pipelines. Focus only on your tasks and not the boilerplate!",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10569607,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "aa87c2ab3ede3abd079a7190bf78ae63",
                    "sha256": "16baba6c6d5dab0fb9017f439b2a0b6ac1f83031d4239103961256535e2e1105"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "aa87c2ab3ede3abd079a7190bf78ae63",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 30476,
                "upload_time": "2021-02-02T22:48:05",
                "upload_time_iso_8601": "2021-02-02T22:48:05.852995Z",
                "url": "https://files.pythonhosted.org/packages/ff/fc/028d61f90e67a8bf1224526b5ade38298f09e793a9ffda6842c35f299146/fluidml-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "5e0dbd902c2ba717e8c730111a25952f",
                    "sha256": "2162e4967030f0b514656b1d007806b863ffc38827970d364a1fd3e2d1ddd9ac"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "5e0dbd902c2ba717e8c730111a25952f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 26252,
                "upload_time": "2021-02-02T22:48:07",
                "upload_time_iso_8601": "2021-02-02T22:48:07.236568Z",
                "url": "https://files.pythonhosted.org/packages/d2/d8/ae21a3a4f500bed6bee888334d88ce8ab0f9038ea7ef8bface0ec2c6ec43/fluidml-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "Rajkumar Ramamurthy, Lars Hillebrand",
            "author_email": "raj1514@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/fluidml/fluidml/",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/fluidml/fluidml/",
            "keywords": "pipelines,machine-learning,parallel,deep-learning",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "fluidml",
            "package_url": "https://pypi.org/project/fluidml/",
            "platform": "",
            "project_url": "https://pypi.org/project/fluidml/",
            "project_urls": {
                "Download": "https://github.com/fluidml/fluidml/",
                "Homepage": "https://github.com/fluidml/fluidml/"
            },
            "release_url": "https://pypi.org/project/fluidml/0.1.1/",
            "requires_dist": [
                "networkx",
                "datasets ; extra == 'examples'",
                "flair ; extra == 'examples'",
                "jupyterlab ; extra == 'examples'",
                "numpy ; extra == 'examples'",
                "pyyaml ; extra == 'examples'",
                "requests ; extra == 'examples'",
                "sklearn ; extra == 'examples'",
                "tokenizers ; extra == 'examples'",
                "torchtext ; extra == 'examples'",
                "torch ; extra == 'examples'",
                "tqdm ; extra == 'examples'",
                "mongoengine ; extra == 'mongo-store'",
                "rich ; extra == 'rich-logging'"
            ],
            "requires_python": ">=3.7",
            "summary": "FluidML is a lightweight framework for developing machine learning pipelines. Focus only on your tasks and not the boilerplate!",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10569607,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "757a355c4c59c7e5795cb59edb26f9d6",
                    "sha256": "4758d3229d838f7616728142abf63aad70418ef6992f2d137707ce77bd062568"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "757a355c4c59c7e5795cb59edb26f9d6",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 30560,
                "upload_time": "2021-02-02T23:33:52",
                "upload_time_iso_8601": "2021-02-02T23:33:52.316828Z",
                "url": "https://files.pythonhosted.org/packages/6a/f3/1bd01a551250bfc2b46ca9ed50053f640e95d31d66dfee35761dd596c416/fluidml-0.1.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "8b070731c38897c768141ee89b07a74e",
                    "sha256": "ff133dee77985f16c48ab6bb0a2aebca2aefd329e308fe65f2cb42a3f3eb408e"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "8b070731c38897c768141ee89b07a74e",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 26393,
                "upload_time": "2021-02-02T23:33:53",
                "upload_time_iso_8601": "2021-02-02T23:33:53.642256Z",
                "url": "https://files.pythonhosted.org/packages/10/4d/300d152ce752d6a144426483804dafcb7d67df5577e00b64915422c850ab/fluidml-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "Rajkumar Ramamurthy, Lars Hillebrand",
            "author_email": "raj1514@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/fluidml/fluidml/",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/fluidml/fluidml/",
            "keywords": "pipelines,machine-learning,parallel,deep-learning",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "fluidml",
            "package_url": "https://pypi.org/project/fluidml/",
            "platform": "",
            "project_url": "https://pypi.org/project/fluidml/",
            "project_urls": {
                "Download": "https://github.com/fluidml/fluidml/",
                "Homepage": "https://github.com/fluidml/fluidml/"
            },
            "release_url": "https://pypi.org/project/fluidml/0.1.2/",
            "requires_dist": [
                "networkx",
                "dataclasses ; python_version < \"3.7\"",
                "datasets ; extra == 'examples'",
                "flair ; extra == 'examples'",
                "jupyterlab ; extra == 'examples'",
                "numpy ; extra == 'examples'",
                "pyyaml ; extra == 'examples'",
                "requests ; extra == 'examples'",
                "sklearn ; extra == 'examples'",
                "tokenizers (>=0.10.1) ; extra == 'examples'",
                "torchtext ; extra == 'examples'",
                "torch ; extra == 'examples'",
                "tqdm ; extra == 'examples'",
                "mongoengine ; extra == 'mongo-store'",
                "rich ; extra == 'rich-logging'",
                "tblib ; extra == 'rich-logging'"
            ],
            "requires_python": ">=3.6",
            "summary": "FluidML is a lightweight framework for developing machine learning pipelines. Focus only on your tasks and not the boilerplate!",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10569607,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "fc41f2435c583c909e99f721f2f5234d",
                    "sha256": "7a54e9ba287f421639d23dee66a9ab025df9b2352f9ffbe0141934d354b46053"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "fc41f2435c583c909e99f721f2f5234d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 32971,
                "upload_time": "2021-02-17T21:24:26",
                "upload_time_iso_8601": "2021-02-17T21:24:26.299276Z",
                "url": "https://files.pythonhosted.org/packages/94/5c/ff7624422e00b3291007e572a73d4fac105685479f3a0c1841b59d72bc81/fluidml-0.1.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "5aa5b478fe0cbcac88ebd913ad5daa40",
                    "sha256": "66b7fceded90d46df3b93c7d2cb314d278c034edc0c5004adcd49f091a55af7a"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.2.tar.gz",
                "has_sig": false,
                "md5_digest": "5aa5b478fe0cbcac88ebd913ad5daa40",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 28662,
                "upload_time": "2021-02-17T21:24:27",
                "upload_time_iso_8601": "2021-02-17T21:24:27.362795Z",
                "url": "https://files.pythonhosted.org/packages/7b/17/ffe233a1c05f70b37ffcd7d313413d243b4594db00ff355a93c0c8196c1b/fluidml-0.1.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.3": {
        "info": {
            "author": "Rajkumar Ramamurthy, Lars Hillebrand",
            "author_email": "raj1514@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/fluidml/fluidml/",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/fluidml/fluidml/",
            "keywords": "pipelines,machine-learning,parallel,deep-learning",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "fluidml",
            "package_url": "https://pypi.org/project/fluidml/",
            "platform": "",
            "project_url": "https://pypi.org/project/fluidml/",
            "project_urls": {
                "Download": "https://github.com/fluidml/fluidml/",
                "Homepage": "https://github.com/fluidml/fluidml/"
            },
            "release_url": "https://pypi.org/project/fluidml/0.1.3/",
            "requires_dist": [
                "networkx",
                "dataclasses ; python_version < \"3.7\"",
                "datasets ; extra == 'examples'",
                "flair ; extra == 'examples'",
                "jupyterlab ; extra == 'examples'",
                "numpy ; extra == 'examples'",
                "pyyaml ; extra == 'examples'",
                "requests ; extra == 'examples'",
                "sklearn ; extra == 'examples'",
                "tokenizers (>=0.10.1) ; extra == 'examples'",
                "torchtext (>=0.8.1) ; extra == 'examples'",
                "torch ; extra == 'examples'",
                "tqdm ; extra == 'examples'",
                "mongoengine ; extra == 'mongo-store'",
                "rich ; extra == 'rich-logging'",
                "tblib ; extra == 'rich-logging'"
            ],
            "requires_python": ">=3.6",
            "summary": "FluidML is a lightweight framework for developing machine learning pipelines. Focus only on your tasks and not the boilerplate!",
            "version": "0.1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10569607,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1301bdfaff779810d7d72f8eff08b29e",
                    "sha256": "042e27a9b90150ae8e883d5ca37fee2ee82a38ac57249e84dff4b36ea4577d2f"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1301bdfaff779810d7d72f8eff08b29e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 34015,
                "upload_time": "2021-02-20T18:59:55",
                "upload_time_iso_8601": "2021-02-20T18:59:55.753155Z",
                "url": "https://files.pythonhosted.org/packages/8f/ed/02999c635c25293de730e563b40ddb5d103702bcad414bd0138a140e3577/fluidml-0.1.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "ae8aeb8a5e4cca40d69a5716fd9ac9f5",
                    "sha256": "5d1b983ad6d9614e3a4b9c69dac5da467c5da9904051bbd5043f5e6802afbdd2"
                },
                "downloads": -1,
                "filename": "fluidml-0.1.3.tar.gz",
                "has_sig": false,
                "md5_digest": "ae8aeb8a5e4cca40d69a5716fd9ac9f5",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 30281,
                "upload_time": "2021-02-20T18:59:56",
                "upload_time_iso_8601": "2021-02-20T18:59:56.940511Z",
                "url": "https://files.pythonhosted.org/packages/87/2d/32d536330f0aafcf51378ba85722f1e6fc3bce924f340cbf3dd1f59fb157/fluidml-0.1.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.2.0": {
        "info": {
            "author": "Rajkumar Ramamurthy, Lars Hillebrand",
            "author_email": "raj1514@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "<div align=\"center\">\n<img src=\"logo/fluid_ml_logo.png\" width=\"400px\">\n\n_Develop ML pipelines fluently with no boilerplate code. Focus only on your tasks and not the boilerplate!_\n\n---\n\n<p align=\"center\">\n  <a href=\"#key-features\">Key Features</a> \u2022\n  <a href=\"#getting-started\">Getting Started</a> \u2022\n  <a href=\"#examples\">Examples</a> \u2022\n  <a href=\"#citation\">Citation</a>\n</p>\n\n[![Python 3.6](https://img.shields.io/badge/python-3.6+-blue.svg)](https://www.python.org/downloads/release/python-360/)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![CircleCI](https://circleci.com/gh/fluidml/fluidml/tree/main.svg?style=shield)](https://circleci.com/gh/fluidml/fluidml/tree/main)\n[![codecov](https://codecov.io/gh/fluidml/fluidml/branch/main/graph/badge.svg?token=XG4UDWF8RE)](https://codecov.io/gh/fluidml/fluidml)\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](https://github.com/fluidml/fluidml/blob/main/CODE_OF_CONDUCT.md)\n\n</div>\n\n---\n\n**FluidML** is a lightweight framework for developing machine learning pipelines.\n\n<div align=\"center\">\n<img src=\"logo/fluidml_example.gif\" width=\"70%\" />\n</div>\n\nDeveloping machine learning models is a challenging process, with a wide range of sub-tasks: data collection, pre-processing, model development, hyper-parameter tuning and deployment. Each of these tasks is iterative in nature and requires lot of iterations to get it right with good performance.\n\nDue to this, each task is generally developed sequentially, with artifacts from one task being fed as inputs to the subsequent tasks. For instance, raw datasets are first cleaned, pre-processed, featurized and stored as iterable datasets (on disk), which are then used for model training. However, this type of development can become messy and un-maintenable quickly for several reasons:\n\n- pipeline code may be split across multiple scripts whose dependencies are not modeled explicitly\n- each of this task contains boilerplate code to collect results from previous tasks (eg: reading from disk)\n- hard to keep track of task artifacts and their different versions\n- hyper-parameter tuning adds further complexity and boilerplate code\n\n## Key Features\n\nFluidML provides following functionalities out-of-the-box:\n\n- **Task Graphs** - Create ML pipelines or task graph using simple APIs\n- **Results Forwarding** - Results from tasks are automatically forwarded to downstream tasks based on dependencies\n- **Parallel Processing** - Execute the task graph parallely with multi-processing\n- **Grid Search** - Extend the task graph by enabling grid search on tasks with just one line of code\n- **Result Caching** - Task results are cached in a results store (eg: Local File Store or a MongoDB Store) and made available for subsequent runs without executing the tasks again and again\n- **Flexibility** - Provides full control on your task implementations. You are free to choose any framework of your choice (Sklearn, TensorFlow, Pytorch, Keras, or any of your favorite library)\n\n---\n\n## Getting Started\n\n### Installation\n\n#### 1. From Pip\nSimply execute:  \n```bash\n$ pip install fluidml\n```\n\n#### 2. From Source\n1. Clone the repository,\n2. Navigate into the cloned directory (contains the setup.py file),\n3. Execute `$ pip install .`\n\n**Note:** To run demo examples, execute `$ pip install fluidml[examples]` (Pip) or `$ pip install .[examples]` (Source) to install the additional requirements.\n\n### Minimal Example\n\nThis minimal toy example showcases how to get started with FluidML.\nFor real machine learning examples, check the \"Examples\" section below.\n\n#### 1. Basic imports\n\nFirst, we import necessary classes from FluidML.\n\n```Python\nfrom fluidml import Task, Flow, Swarm\nfrom fluidml.common import Resource\nfrom fluidml.flow import GridTaskSpec, TaskSpec\nfrom fluidml.storage import MongoDBStore, LocalFileStore, ResultsStore\nfrom fluidml.visualization import visualize_graph_in_console\n```\n\n#### 2. Define Tasks\n\nNext, we define some toy machine learning tasks. A Task can be implemented as a function or as a class inheriting from our `Task` class.\n\nIn case of the class approach, each task should implement the `run()` method, which takes some inputs and performs the desired functionality. These inputs are actually the results from predecessor tasks and are automatically forwarded by FluidML based on registered task dependencies. If the task has any hyper-parameters, they can be defined as arguments in the constructor. Additionally, within each task, users have access to methods and attributes like `self.save()` and `self.resource` to save its result and access task resources (more on that later).\n\n```Python\nclass MyTask(Task):\n    def __init__(self, kwarg_1, kwarg_2):\n        ...\n    def run(self, result_1, result2):\n        ...\n```\n\nor\n\n```Python\ndef my_task(result_1, result_2, kwarg_1, kwarg_2, task: Task):\n    ...\n```\n\nIn the case of defining the task as callable, an extra task object is provided to the task,\nwhich makes important internal attributes and functions like `task.save()` and `task.resource` available to the user.\n\nBelow, we define standard machine learning tasks such as dataset preparation, pre-processing, featurization and model training using Task classes.\nNotice that:\n\n- Each task is implemented individually and it's clear what the inputs are (check arguments of `run()` method)\n- Each task saves its results using `self.save(...)` by providing the object to be saved and a unique name for it. This unique name corresponds to input names in successor task definitions.\n\n```Python\nclass DatasetFetchTask(Task):\n    def run(self):\n        ...\n        # For InMemoryStore (default) and MongoDBStore type_ is NOT required\n        # For LocalFileStore type_ IS required               \n        self.save(obj=data_fetch_result, name='data_fetch_result', type_='json')\n\n\nclass PreProcessTask(Task):\n    def __init__(self, pre_processing_steps: List[str]):\n        super().__init__()\n        self._pre_processing_steps = pre_processing_steps\n\n    def run(self, data_fetch_result):\n        ...\n        self.save(obj=pre_process_result, name='pre_process_result')\n\n\nclass TFIDFFeaturizeTask(Task):\n    def __init__(self, min_df: int, max_features: int):\n        super().__init__()\n        self._min_df = min_df\n        self._max_features = max_features\n\n    def run(self, pre_process_result):\n        ...\n        self.save(obj=tfidf_featurize_result, name='tfidf_featurize_result')\n\n\nclass GloveFeaturizeTask(Task):\n    def run(self, pre_process_result):\n        ...\n        self.save(obj=glove_featurize_result, name='glove_featurize_result')\n\n\nclass TrainTask(Task):\n    def __init__(self, max_iter: int, balanced: str):\n        super().__init__()\n        self._max_iter = max_iter\n        self._class_weight = \"balanced\" if balanced else None\n\n    def run(self, tfidf_featurize_result, glove_featurize_result):\n        ...\n        self.save(obj=train_result, name='train_result')\n\n\nclass EvaluateTask(Task):\n    def run(self, train_result):\n        ...\n        self.save(obj=evaluate_result, name='evaluate_result')\n```\n\n#### 3. Task Specifications\n\nNext, we can create the defined tasks with their specifications. \nWe now only write their specifications, later these are used to create real instances of tasks by FluidML.\nFor each Task specification, we also add a list of result names that the corresponding task _publishes_. \nEach published result object will be considered when results are automatically collected for a successor task.\n\nNote: The `config` argument holds the configuration of the task (ie. hyper-parameters). \nIt has to be a dictionary (possibly nested), which is `json` serializable. \nThat means a `TypeError` is thrown if the dictionary contains objects, e.g. an `np.array`, that cannot be serialized by Python's json encoder.\n\nAdditionally, if there are other parameters to the task, including objects of non-standard types (eg. models, tensors, files, etc), they can be passed using `additional_kwargs` argument.\n\n\n```Python\ndataset_fetch_task = TaskSpec(task=DatasetFetchTask, publishes=['data_fetch_result'])\npre_process_task = TaskSpec(task=PreProcessTask,\n                            config={\n                                \"pre_processing_steps\": [\"lower_case\", \"remove_punct\"]},\n                            publishes=['pre_process_result'])\nfeaturize_task_1 = TaskSpec(task=GloveFeaturizeTask,\n                            publishes=['glove_featurize_result'])\nfeaturize_task_2 = TaskSpec(task=TFIDFFeaturizeTask, config={\"min_df\": 5, \"max_features\": 1000},\n                            publishes=['tfidf_featurize_result'])\ntrain_task = TaskSpec(task=TrainTask, config={\"max_iter\": 50, \"balanced\": True},\n                      publishes=['train_result'])\nevaluate_task = TaskSpec(task=EvaluateTask, publishes=['evaluate_result'])\n```\n\n#### 4. Registering task dependencies\n\nHere we create the task graph by registering dependencies between the tasks. In particular, for each task specifier, you can register a list of predecessor tasks using the `requires()` method.\n\n```Python\npre_process_task.requires(dataset_fetch_task)\nfeaturize_task_1.requires(pre_process_task)\nfeaturize_task_2.requires(pre_process_task)\ntrain_task.requires([dataset_fetch_task, featurize_task_1, featurize_task_2])\nevaluate_task.requires([dataset_fetch_task, featurize_task_1, featurize_task_2, train_task])\n```\n\n#### 5. [optional] Define and instantiate Resources to share across all Tasks\n\nAdditionally, you can pass a list of resources (eg. GPU devices) that are made available to the workers, which forward them to the corresponding tasks.\nYou just have to create your own Resource dataclass, which inherits from our `Resource` interface. In this dataclass you can define all resources, e.g. the cuda device, which automatically is made available to all tasks through the `self.resource` or `task.resource` attribute.\n\n```python\n@dataclass\nclass TaskResource(Resource):\n    device: str\n```\n\nLet's assume our resources consist of a list of cuda device ids, e.g. `['cuda:0', 'cuda:1', 'cuda:0', 'cuda:1']`, and we set `num_workers=4`.\nThen we can create our list of resources object with a simple list comprehension:\n\n```python\n# create list of resources\nresources = [TaskResource(device=devices[i]) for i in range(num_workers)]\n```\n\n#### 6. [optional] Results Store/Caching\n\nBy default, results of tasks are stored in an `InMemoryStore`, which might be impractical for large datasets/models. \nAlso, the results are not persistent. To have persistent storage, FluidML provides two fully implemented `ResultsStore` namely `LocalFileStore` and `MongoDBStore`.\n\nAdditionally, users can provide their own results store to `Swarm` by inheriting from `ResultsStore` class and implementing `load()`, `save()` and `delete()`. \nNote these methods rely on task name and its config parameters, which act as lookup-key for results. \nIn this way, tasks are skipped by FluidML when task results are already available for the given config. \nBut users can override and force execute tasks by passing `force` parameter to the `Flow`.\n\n```Python\nclass MyResultsStore(ResultsStore):\n    def load(self, name: str, task_name: str, task_unique_config: Dict, **kwargs) -> Optional[Any]:\n        \"\"\" Query method to load an object based on its name, task_name and task_config if it exists \"\"\"\n        raise NotImplementedError\n\n    def save(self, obj: Any, name: str, type_: str, task_name: str, task_unique_config: Dict, **kwargs):\n        \"\"\" Method to save/update any artifact \"\"\"\n        raise NotImplementedError\n\n    def delete(self, name: str, task_name: str, task_unique_config: Dict):\n        \"\"\" Method to delete any artifact \"\"\"\n        raise NotImplementedError\n```\n\nWe can instantiate for example a `LocalFileStore`\n\n```python\nresults_store = LocalFileStore(base_dir='/some/dir')\n```\n\nand pass it in the next step to `Swarm` to enable persistent results storing.\n\n#### 7. [optional] Configure Logging\n\nFluidML internally utilizes Python's `logging` library. However, we refrain from configuring a logger object with handlers\nand formatters since each user has different logging needs and preferences. Hence, if you want to use FluidML's logging\ncapability, you just have to do the configuration yourself. For convenience, we provide a simple utility function which\nconfigures a visually appealing logger (using a specific handler from the [rich](https://github.com/willmcgugan/rich) library).\n\n```python\nfrom fluidml.common.logging import configure_logging\nconfigure_logging()\n```\n\n**Note**: If you want to use logging in your application (e.g. within FluidML Tasks) but want to disable all FluidML internal logging messages you can\nsimply call\n\n```python\nlogging.getLogger('fluidml').propagate = False\n```\n\n#### 8. Run tasks using Flow and Swarm\n\nNow that we have all the tasks specified, we can just run the task graph. \nFor that, we have to create an instance of the`Swarm` class, by specifying a number of workers (`n_dolphins` :wink:).\nIf `n_dolphin` is not set, it defaults internally to the number of CPU's available to the machine.\nAdditionally, we can provide one of our persistent result stores (defaults to `InMemoryStore` if no store is provided).\n\nNext, we create an instance of the `Flow` class which will construct the task graph via the `create()` method. \nFinally, we run the pipeline by calling `flow.run()`. Internally, `Swarm` executes the graph in parallel while considering the registered dependencies.\n\n```Python\ntasks = [dataset_fetch_task, pre_process_task, featurize_task_1,\n         featurize_task_2, train_task, evaluate_task]\n\nwith Swarm(n_dolphins=2,                        # optional (defaults to number of CPU's)\n           resources=resources,                 # optional\n           return_results=True,                 # optional\n           results_store=results_store,         # optional\n           ) as swarm:\n    flow = Flow(swarm=swarm)\n    flow.create(task_specs=tasks)\n\n    # optional graph visualization\n    visualize_graph_in_console(graph=flow.task_spec_graph,\n                               use_pager=True,    # optional (defaults to True)\n                               use_unicode=False  # optional (defaults to False)\n                               )\n    results = flow.run(force=None)\n```\n**Note 1**: After calling `flow.create()` we have access to the created task specifier graph via `flow.task_spec_graph`. \nThis constructed graph can be rendered on the console using fluidML's visualization routine `visualize_graph_in_console(graph=flow.task_spec_graph)`. \nThe default arguments `use_pager=True` and `use_unicode=False` will render the graph in ascii within a pager for horizontal scralling support. \nIf `use_pager=False` the graph is simply printed and if `use_unicode=True` a visually more appealing unicode character set is used for console rendering. \nNote not every console supports unicode characters.\n\n\nSee below the visualization of the task specifier graph from our example:\n\n<div align=\"center\">\n<img src=\"logo/task_spec_graph.png\" width=\"500px\">\n</div>\n\n**Note 2**: We can provide a `force='all'` to the `run` method in order to force execute all tasks in the pipeline regardless of previously saved results.\nAlternatively, `force` can take a concrete task name or a list of task names as argument. \nIf all successor tasks of a provided task name should also be force execute you simply write `force='PreProcessTask+'`. \nThe \"+\" registers all successor tasks for force execution as well.\n\n**Note 3**: If the `InMemoryStore` is used, results of all the tasks are always returned by `flow.run()`, so that the user can store them manually. \nFor the other shipped storages the user has the option to return or not return results (`return_results=True/False`). \nTask results can be accessed via task names, e.g. `results[\"EvaluationTask\"]`. \nOur shipped result stores can be utilized to fetch specific task results from the returned result dictionary at any point via `results_store.load()`.\n\n### Grid Search\n\nUsers can easily enable grid search for their tasks with just one line of code. \nTo enable grid search on a particular task, we just have to wrap it with `GridTaskSpec` instead of `TaskSpec` and specify hyper-parameters in the grid search config argument `gs_config` as follows:\n\n```Python\ntrain_task = GridTaskSpec(task=TrainTask,\n                          gs_config={\"max_iter\": [50, 100],\n                                     \"balanced\": [True, False],\n                                     \"layers\": [[50, 100, 50]]},\n                          gs_expansion_method='product'  # or 'zip'\n                          )\n```\n\nThat's it! Internally, Flow expands this task into 4 tasks with provided cross product combinations of `max_iter` and `balanced`. \nAlternatively, one can select `zip` as the expansion method, which would result in 2 expanded tasks, with the respective `max_iter` and `balanced` combinations of `(50, True), (100, False)`. \nGenerally, all values of type `List` will be unpacked to form grid search combinations. \n\nAdditional task parameters can be provided via `additional_kwargs` argument. However, note that these parameters are not subject to grid search expansion. \n\nThe expanded task graph object is available via `flow.task_graph` after calling `flow.create()`. \nAs before, we can again visualize the expanded task graph in the console via `visualize_graph_in_console(graph=flow.task_graph)`.\n\n<div align=\"center\">\n<img src=\"logo/task_graph.png\">\n</div>\n\nNote: Since we use Python's `json` module to serialize the provided configs, we don't distinguish between types `List` and `Tuple`. \nIn fact, tuples are internally converted to lists, and thus get expanded in the same way as described above.\n\nIf a list itself is an argument and should not be expanded, it has to be wrapped again in a list. \nThat is why `layers` is not considered for different grid search realizations. \nFurther, any successor tasks (for instance, evaluate task) in the task graph will also be automatically expanded. \nTherefore, in our example, we would have 4 evaluate tasks, each one corresponding to the 4 train tasks.\n\nRunning a complete machine learning pipeline usually yields trained models for many grid search parameter combinations.\nA common goal is then to automatically determine the best hyper-parameter setup and the best performing model.\nFluidML enables just that by providing a `reduce=True` argument to the `TaskSpec` class. Hence, to automatically \ncompare the 4 evaluate tasks and select the best performing model, we implement an additional `ModelSelectionTask`\nwhich gets wrapped by our `TaskSpec` class.\n\n```Python\nclass ModelSelectionTask(Task):\n    def run(self, reduced_results: List[Dict[str, Dict]]):\n        # from all trained models/hyper-parameter combinations, determine the best performing model\n        ...\n\nmodel_selection_task = TaskSpec(task=ModelSelectionTask, reduce=True, expects=['evaluate_result'])\n\nmodel_selection_task.requires(evaluate_task)\n```\n\nThe important `reduce=True` argument enables that a single `ModelSelectionTask` instance gets the reduced results\nfrom all grid search expanded predecessor tasks. \n\n**Note**: When specifying a `reduce` task one can explicitly provide the expected inputs as list of strings to the `expects` argument of `TaskSpec`.\nThe expected inputs will be retrieved from the predecessor tasks and packed in a special `reduced_results` argument (the only input to the task's `run` method).\nIf `expects` is not provided all published predecessor task results will be retrieved and packed in `reduced_results`.\nIt is a list of dictionaries where each dictionary holds the results and config of one specific grid search parameter combination. For example:\n\n```Python\nreduced_results = [\n    {'result': {'result_name_1': result_1,\n                'result_name_2': result_2},\n     'config': {...}  # first unique parameter combination config\n     },\n    {'result': {'result_name_1': result_1,\n                'result_name_2': result_2},\n     'config': {...}  # second unique parameter combination config\n     }\n]\n```\n\n---\n\n## Examples\n\nFor real machine learning pipelines including grid search implemented with FluidML, check our\nJupyter Notebook tutorials:\n\n- [Transformer based Sequence to Sequence Translation (PyTorch)](https://github.com/fluidml/fluidml/blob/main/examples/pytorch_transformer_seq2seq_translation/transformer_seq2seq_translation.ipynb)\n- [Multi-class Text Classification (Sklearn)](https://github.com/fluidml/fluidml/blob/main/examples/sklearn_text_classification/sklearn_text_classification.ipynb)\n\n---\n\n## Citation\n\n```\n@article{fluid_ml,\n  title = {FluidML - a lightweight framework for developing machine learning pipelines},\n  author = {Ramamurthy, Rajkumar and Hillebrand, Lars},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/fluidml/fluidml}},\n}\n```\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/fluidml/fluidml/",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/fluidml/fluidml/",
            "keywords": "pipelines,machine-learning,parallel,deep-learning",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "fluidml",
            "package_url": "https://pypi.org/project/fluidml/",
            "platform": "",
            "project_url": "https://pypi.org/project/fluidml/",
            "project_urls": {
                "Download": "https://github.com/fluidml/fluidml/",
                "Homepage": "https://github.com/fluidml/fluidml/"
            },
            "release_url": "https://pypi.org/project/fluidml/0.2.0/",
            "requires_dist": [
                "bokeh",
                "grandalf",
                "networkx",
                "rich",
                "tblib",
                "dataclasses ; python_version < \"3.7\"",
                "datasets ; extra == 'examples'",
                "flair ; extra == 'examples'",
                "jupyterlab ; extra == 'examples'",
                "numpy ; extra == 'examples'",
                "pyyaml ; extra == 'examples'",
                "requests ; extra == 'examples'",
                "sklearn ; extra == 'examples'",
                "tokenizers (>=0.10.1) ; extra == 'examples'",
                "torchtext (>=0.8.1) ; extra == 'examples'",
                "torch ; extra == 'examples'",
                "tqdm ; extra == 'examples'",
                "mongoengine ; extra == 'mongo-store'"
            ],
            "requires_python": ">=3.6",
            "summary": "FluidML is a lightweight framework for developing machine learning pipelines. Focus only on your tasks and not the boilerplate!",
            "version": "0.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10569607,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "99ddc430e8cbb0a74f5fd0130220238f",
                    "sha256": "b7d47fd722b7be71253de1bd2f5f90dc49119f6f2953e7b03bb68562ec497adb"
                },
                "downloads": -1,
                "filename": "fluidml-0.2.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "99ddc430e8cbb0a74f5fd0130220238f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 45850,
                "upload_time": "2021-06-06T12:28:25",
                "upload_time_iso_8601": "2021-06-06T12:28:25.120047Z",
                "url": "https://files.pythonhosted.org/packages/1a/6f/0a209768012a225ea96767c01b4284de5efe6da00bdfb3448752e6ff2dfe/fluidml-0.2.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "0120de1fa9d30960f35c8875a0275433",
                    "sha256": "78fc7ff8b0309054c8a293dad32e21a6ab46c21cac7834529ee048a0e6141b6a"
                },
                "downloads": -1,
                "filename": "fluidml-0.2.0.tar.gz",
                "has_sig": false,
                "md5_digest": "0120de1fa9d30960f35c8875a0275433",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 41335,
                "upload_time": "2021-06-06T12:28:26",
                "upload_time_iso_8601": "2021-06-06T12:28:26.277060Z",
                "url": "https://files.pythonhosted.org/packages/3e/f3/9887526a1f9592589353670133cbaaf3dc1ac637cfd03f238ab2b030e197/fluidml-0.2.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
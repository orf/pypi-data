{
    "0.1.0": {
        "info": {
            "author": "carefree0910",
            "author_email": "syameimaru_kurumi@pku.edu.cn",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/carefree0910/carefree-ml/archive/v0.1.0.tar.gz",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/carefree0910/carefree-ml",
            "keywords": "python machine-learning numpy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "carefree-ml",
            "package_url": "https://pypi.org/project/carefree-ml/",
            "platform": "",
            "project_url": "https://pypi.org/project/carefree-ml/",
            "project_urls": {
                "Download": "https://github.com/carefree0910/carefree-ml/archive/v0.1.0.tar.gz",
                "Homepage": "https://github.com/carefree0910/carefree-ml"
            },
            "release_url": "https://pypi.org/project/carefree-ml/0.1.0/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Machine Learning algorithms implemented with numpy",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14146927,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f88b2fc79ed2f8d82fd40161b59c86c8",
                    "sha256": "5bee0a23b9db9b93fd8148bb48d033ef2ae46f19dd869ccec0fa0a3bae72395d"
                },
                "downloads": -1,
                "filename": "carefree-ml-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "f88b2fc79ed2f8d82fd40161b59c86c8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 27319,
                "upload_time": "2020-06-23T13:50:13",
                "upload_time_iso_8601": "2020-06-23T13:50:13.034535Z",
                "url": "https://files.pythonhosted.org/packages/7f/da/34b50df829d576c5166816416a49cedd9fb5c63e23fd4d3288730a748025/carefree-ml-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "carefree0910",
            "author_email": "syameimaru_kurumi@pku.edu.cn",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/carefree0910/carefree-ml/archive/v0.1.1.tar.gz",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/carefree0910/carefree-ml",
            "keywords": "python machine-learning numpy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "carefree-ml",
            "package_url": "https://pypi.org/project/carefree-ml/",
            "platform": "",
            "project_url": "https://pypi.org/project/carefree-ml/",
            "project_urls": {
                "Download": "https://github.com/carefree0910/carefree-ml/archive/v0.1.1.tar.gz",
                "Homepage": "https://github.com/carefree0910/carefree-ml"
            },
            "release_url": "https://pypi.org/project/carefree-ml/0.1.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Machine Learning algorithms implemented with numpy",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14146927,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "374828de1e6452fb146f2893162846d2",
                    "sha256": "e9cdb532f247d2b925d8e71b2c5f6cb05af0053599741fcece8a34ae190311f8"
                },
                "downloads": -1,
                "filename": "carefree-ml-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "374828de1e6452fb146f2893162846d2",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 26982,
                "upload_time": "2020-12-12T08:29:35",
                "upload_time_iso_8601": "2020-12-12T08:29:35.310097Z",
                "url": "https://files.pythonhosted.org/packages/7a/5a/cb6cfe7fc0e2d1758d4137cce16f45ce9311e1986abd254539f38febc6fe/carefree-ml-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2.1": {
        "info": {
            "author": "carefree0910",
            "author_email": "syameimaru.saki@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/carefree0910/carefree-ml/archive/v0.1.2.1.tar.gz",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/carefree0910/carefree-ml",
            "keywords": "python machine-learning numpy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "carefree-ml",
            "package_url": "https://pypi.org/project/carefree-ml/",
            "platform": null,
            "project_url": "https://pypi.org/project/carefree-ml/",
            "project_urls": {
                "Download": "https://github.com/carefree0910/carefree-ml/archive/v0.1.2.1.tar.gz",
                "Homepage": "https://github.com/carefree0910/carefree-ml"
            },
            "release_url": "https://pypi.org/project/carefree-ml/0.1.2.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Machine Learning algorithms implemented with numpy",
            "version": "0.1.2.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14146927,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e0bc16fdc4261043de7d050e7c9bd301",
                    "sha256": "649e6f3fb7961a5a41749d4cb8cc0f4e559c180b2a477e5591818c53c54a2da8"
                },
                "downloads": -1,
                "filename": "carefree-ml-0.1.2.1.tar.gz",
                "has_sig": false,
                "md5_digest": "e0bc16fdc4261043de7d050e7c9bd301",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 52418,
                "upload_time": "2022-06-15T11:44:07",
                "upload_time_iso_8601": "2022-06-15T11:44:07.174242Z",
                "url": "https://files.pythonhosted.org/packages/61/79/b2509f82fab85c6cae3e8ef5d45d93eb751dfd04c634ac04015abf01a447/carefree-ml-0.1.2.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.3": {
        "info": {
            "author": "carefree0910",
            "author_email": "syameimaru.saki@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "# carefree-ml\r\n\r\n`carefree-ml` implemented Machine Learning algorithms with numpy, mainly for educational use\r\n\r\n\r\n## Installation\r\n\r\n`carefree-ml` requires Python 3.8 or higher.\r\n\r\n```bash\r\npip install carefree-ml\r\n```\r\n\r\nor\r\n\r\n```bash\r\ngit clone https://github.com/carefree0910/carefree-ml.git\r\ncd carefree-ml\r\npip install -e .\r\n```\r\n\r\n\r\n## Basic Usage\r\n\r\nSee `tests/usages/basic.py` for more example\r\n\r\n```python\r\nfrom cfml import *\r\nfrom cfdata.tabular import TabularDataset\r\n\r\n# fetch dataset\r\nboston = TabularDataset.boston()\r\n# make a model\r\nlr = Base.make(\"linear_regression\")\r\n# fit the model\r\nlr.fit(*boston.xy)\r\n# plot loss curve\r\nlr.plot_loss_curve()\r\n# make predictions\r\npredictions = lr.predict(boston.x)\r\n```\r\n\r\n...or use methods chaining\r\n\r\n```python\r\nimport os\r\nfrom cfml import *\r\nfrom cfdata.tabular import *\r\n\r\n# fetch dataset\r\nprices_file = os.path.join(\"tests\", \"datasets\", \"prices.txt\")\r\nprices = TabularData(task_type=TaskTypes.REGRESSION).read(prices_file).to_dataset()\r\n# one liner\r\nBase.make(\"linear_regression\").fit(*prices.xy).visualize1d(*prices.xy).plot_loss_curve()\r\n```\r\n\r\n\r\n## Supported Algorithms\r\n\r\n+ 1-dimensional polynomial fit (`np.polyfit`)\r\n+ Linear Models (Linear Regression, Logistic Regression, Linear SVC, Linear SVR)\r\n+ Naive Bayes (Multinomial NB, Gaussian NB)\r\n+ Support Vector Machine (SVC, SVR)\r\n+ Fully Connected Neural Network (FCNN-clf, FCNN-reg)\r\n\r\n\r\n## Roadmap\r\n\r\nIt's up to you! Issues are welcomed :)\r\n\r\n\r\n## Q & A\r\n\r\n+ I used Google Translate to help me translate Chinese to English\r\n\r\n### Why carefree-ml?\r\n\r\n**\u4e3a\u4ec0\u4e48\u9009\u62e9\u4f7f\u7528\uff08\u6216\u501f\u9274\uff09`carefree-ml`\uff1f**\r\n\r\nWhy shall we choose to use (or learn from) `carefree-ml`?\r\n\r\n**`carefree-ml` \u5176\u5b9e\u6e90\u4e8e\u6211\u4e00\u76f4\u4ee5\u6765\u672a\u7adf\u7684\u4e24\u4e2a\u5fc3\u613f**\r\n\r\n+ **\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5230\u5e95\u53ef\u4ee5\u7b80\u5316\u6210\u4ec0\u4e48\u6837**\r\n+ **\u63a2\u7d22\u5404\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u95f4\u7684\u5171\u6027\u7a76\u7adf\u6709\u591a\u5c11**\r\n\r\n`carefree-ml` actually stems from my two unfinished wishes\r\n\r\n+ Explore how machine learning algorithms can be simplified\r\n+ Explore commonality among various machine learning algorithms\r\n\r\n**\u5982\u679c\u4f60\u6070\u597d\u6709\u8fd9\u4e2a\u7591\u60d1\uff0c\u53c8\u6216\u662f\u60f3\u6559\u5bfc\u5176\u4ed6\u4eba\u8fd9\u65b9\u9762\u7684\u76f4\u89c2\uff0c\u90a3\u4e48 `carefree-ml` \u53ef\u80fd\u5c31\u4f1a\u6bd4\u8f83\u9002\u5408\u4f60\u3002\u4f46\u662f\uff0c\u5982\u679c\u4f60\u5bf9\u673a\u5668\u5b66\u4e60\u6709\u7740\u66f4\u9ad8\u7684\u8ffd\u6c42\uff0c\u5bf9\u5404\u79cd\u7f8e\u5999\u7684\u6027\u8d28\u6709\u7740\u63a2\u7d22\u7684\u6b32\u671b\uff0c\u90a3\u4e48 `carefree-ml` \u53cd\u800c\u53ef\u80fd\u4f1a\u6fc0\u6012\u4f60\uff0c\u56e0\u4e3a\u5b83\u7701\u7565\u4e86\u5f88\u591a\u524d\u4eba\u7814\u7a76\u51fa\u6765\u7684\u7ed3\u6676**\r\n\r\nIf you happen to have these doubts, or willing to teach others about some intuitions, then `carefree-ml` may be suitable for you. However, if you have a higher pursuit of machine learning and desire to explore more wonderful properties from machine learning, then `carefree-ml` may irritate you, because it omits many of them\r\n\r\n**\u9996\u5148\uff0c\u6211\u4eec\u77e5\u9053\uff0c\u673a\u5668\u5b66\u4e60\uff08\u4ee5\u53ca\u73b0\u5728\u5927\u884c\u5176\u9053\u7684\u6df1\u5ea6\u5b66\u4e60\uff09\u7b97\u6cd5\uff0c\u5f88\u591a\u65f6\u5019\u90fd\u53ef\u4ee5\u8f6c\u5316\u4e3a\u65e0\u7ea6\u675f\u6700\u4f18\u5316\u95ee\u9898\uff1b\u5982\u679c\u4e0d\u8003\u8651\u4e00\u4e9b\u7279\u6b8a\u6027\u8d28\uff08\u7a00\u758f\u6027\uff0c\u6536\u655b\u901f\u5ea6\u7b49\uff09\u7684\u8bdd\uff0c\u68af\u5ea6\u4e0b\u964d\u6cd5\u53ef\u4ee5\u8bf4\u662f\u4e00\u79cd\u4e07\u91d1\u6cb9\u7684\u65b9\u6cd5**\r\n\r\nFirst of all, we know that machine learning (and deep learning) algorithms can often be transformed into unconstrained optimization problems. If some special properties (sparseness, convergence speed, etc.) are not considered, the gradient descent based methods can be the most widely use\r\n\r\n**\u56e0\u6b64\uff0c`carefree-ml` \u5b9e\u73b0\u7684\u7b2c\u4e00\u5927\u6a21\u5757\uff0c\u5c31\u662f\u4e00\u5957\u7b80\u5355\u7684\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u6846\u67b6\uff0c\u65e8\u5728\u7528\u8f83\u5c11\u7684\u4ee3\u7801\u53bb handle \u5927\u90e8\u5206\u60c5\u51b5\uff1b\u5728\u5b9e\u73b0\u4e00\u4e2a\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u65f6\uff0c\u4e5f\u4f1a\u4f18\u5148\u8003\u8651\u91c7\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u53bb\u5b9e\u73b0\uff08\u8fd9\u5176\u5b9e\u5c31\u662f `carefree-ml` \u6240\u505a\u7684\u6700\u5927\u7684\u7b80\u5316\u4e86\uff0c\u4e0b\u9762\u7684\u4f8b\u5b50\u5c31\u8bf4\u660e\u4e86\u8fd9\u4e00\u70b9\uff09**\r\n\r\nTherefore, the first major module implemented by `carefree-ml` is a simple gradient descent optimization framework, which is designed to handle most cases with less code. After that, when implementing a machine learning algorithm in `carefree-ml`, gradient descent based methods will also be considered first (this is actually the biggest simplification done by `carefree-ml`, the following example of `LinearRegression` illustrates this)\r\n\r\n**\u90a3\u4e48\uff0c\u5728\u8fd9\u79cd\u601d\u60f3\u4e0b\uff0c\u6211\u4eec\u662f\u5982\u4f55\u5b9e\u73b0 `LinearRegression` \u548c `LogisticRegression` \u7684\u5462\uff1f\u9996\u5148\u6211\u4eec\u53ef\u80fd\u90fd\u77e5\u9053\uff1a**\r\n\r\n+ **\u4e24\u8005\u90fd\u662f `\u7ebf\u6027\u6a21\u578b`**\r\n+ **\u524d\u8005\u505a\u7684\u662f `\u56de\u5f52` \u95ee\u9898\uff0c\u540e\u8005\u505a\u7684\u662f `\u5206\u7c7b` \u95ee\u9898**\r\n+ **\u540e\u8005\u5728\u8f93\u51fa\u65f6\u4f7f\u7528\u4e86 `sigmoid` \u6fc0\u6d3b\u51fd\u6570**\r\n\r\nSo, under this idea, how do we implement `LinearRegression` and` LogisticRegression`? First of all we may all know that:\r\n\r\n+ Both of them are `Linear Models`\r\n+ The former deals with `regression` problems, while the latter deals with `classification` problems\r\n+ The latter used `sigmoid` function to output the probability predictions\r\n\r\n**\u4f46\u662f\u6709\u4e00\u70b9\u6211\u4eec\u53ef\u80fd\u4e4b\u524d\u6ca1\u6ce8\u610f\u5230\uff1a**\r\n\r\n+ **\u5982\u679c\u524d\u8005\u4f7f\u7528 `mse` \u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u540e\u8005\u4f7f\u7528 `cross_entropy` \u4f5c\u4e3a\u635f\u5931\u51fd\u6570\uff0c\u90a3\u4e48\u5b83\u4eec\u53c2\u6570\u7684\u68af\u5ea6\u5c06\u4f1a\u51e0\u4e4e\u662f\u4e00\u6a21\u4e00\u6837\u7684\uff08\u53ea\u5dee\u4e00\u4e2a\u500d\u6570\uff09**\r\n\r\nBut there's one thing that we might not have noticed before:\r\n\r\n+ If we use `mse` loss in `LinearRegression` and use `cross_entropy` loss in `LogisticRegression`, then thier parameters' gradients will be almost identical (except for a multiple factor)\r\n\r\n**\u90a3\u4e48\uff0c\u65e2\u7136\u5b83\u4eec\u5982\u6b64\u76f8\u4f3c\uff0c\u5dee\u5f02\u70b9\u4ec5\u5728\u4e8e\u51e0\u4e2a\u5c0f\u90e8\u5206\uff0c\u5b83\u4eec\u7684\u5b9e\u73b0\u4e5f\u5e94\u8be5\u5f88\u50cf\u624d\u5bf9\u3002\u6240\u4ee5\uff0c\u5728 `carefree-ml` \u4e2d\uff0c\u5b83\u4eec\u7684\u5b9e\u73b0\u7684\u4e3b\u4f53\u5c06\u5206\u522b\u662f\uff1a**\r\n\r\nSince they are so similar and the differences are only in a few small parts, their implementation should be very similar as well. Therefore, in `carefree-ml`, the main part of their implementations will be as follows:\r\n\r\n```python\r\nclass LinearRegression(LinearRegressorMixin, RegressorBase):\r\n    def __init__(self):\r\n        self._w = self._b = None\r\n```\r\n\r\n```python\r\nclass LogisticRegression(LinearBinaryClassifierMixin, ClassifierBase):\r\n    def __init__(self):\r\n        self._w = self._b = None\r\n        self._sigmoid = Activations(\"sigmoid\")\r\n\r\n    def _predict_normalized(self, x_normalized):\r\n        affine = super()._predict_normalized(x_normalized)\r\n        return self._sigmoid(affine)\r\n```\r\n\r\n**\u8fd9\u91cc\u7684\u8bbe\u8ba1\uff0c\u5176\u5b9e\u5c31\u4f53\u73b0\u4e86 `carefree-ml` \u60f3\u5c06\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u201c\u7b80\u5316\u201d\u7684\u601d\u60f3\u3002\u56e0\u4e3a\u6211\u4eec\u77e5\u9053\uff0c`mse` loss \u4e0b\u7684 `LinearRegression` \u662f\u6709\u663e\u5f0f\u89e3\u7684\uff08\u56e0\u4e3a\u5c31\u662f\u4e00\u4e2a\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff09\uff0c\u4f46\u662f\u6211\u4eec\u4ecd\u7136\u7528\u68af\u5ea6\u4e0b\u964d\u53bb\u6c42\u89e3\u5b83\uff0c\u56e0\u4e3a\u8fd9\u6837\u5b83\u5c06\u4f1a\u4e0e `LogisticRegression` \u5171\u4eab\u5927\u90e8\u5206\u4ee3\u7801**\r\n\r\nThe design here actually embodies the idea that `carefree-ml` wants to *simplify* machine learning algorithms. Because we know that `LinearRegression` under` mse` loss has an explicit solution (because it's simply a Least Squares problem), but we still use gradient descent to solve it because in this case it will share most of its code with `LogisticRegression`'s code\r\n\r\n**\u5f53\u7136\uff0c\u8fd9\u79cd\u7b80\u5316\uff08\u5c06\u8bb8\u591a\u7b97\u6cd5\u90fd\u5f52\u7ed3\u4e3a\u65e0\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u5e76\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u6c42\u89e3\uff09\u5e76\u4e0d\u662f\u5168\u662f\u574f\u5904\uff0c\u6bd4\u5982\u6211\u4eec\u5b8c\u5168\u53ef\u4ee5\u5728\u4ee3\u7801\u51e0\u4e4e\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\u53bb\u6c42\u89e3 `l1` loss\u3001\u6216\u8005\u5176\u5b83\u5f62\u5f62\u8272\u8272\u7684 loss \u4e0b\u7684 `LinearRegression`**\r\n\r\nOf course, this simplification (reducing many algorithms to unconstrained optimization problems and solving them by gradient descent) has its advantage too. For example, we can solve `l1` loss or other losses in `LinearRegression` under the premise that the corresponding training codes will be almost unchanged\r\n\r\n**\u518d\u6bd4\u5982\u8bf4 `svm`\u3002\u867d\u7136\u652f\u6301\u5411\u91cf\u5206\u7c7b\u548c\u652f\u6301\u5411\u91cf\u56de\u5f52\u770b\u4e0a\u53bb\u662f\u975e\u5e38\u4e0d\u4e00\u6837\u7684\u4e24\u79cd\u7b97\u6cd5\uff0c\u4f46\u662f\u62bd\u4e1d\u5265\u8327\u4e4b\u540e\uff0c\u5982\u679c\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\u53bb\u6c42\u89e3\uff0c\u5c31\u4f1a\u53d1\u73b0\u5176\u5b9e\u5927\u90e8\u5206\u4ee3\u7801\u4ecd\u7136\u662f\u5171\u4eab\u7684\uff0c\u8fd9\u4e5f\u6070\u597d\u8f85\u8bc1\u4e86\u4e3a\u4f55\u5b83\u4eec\u540c\u5c5e `svm` \u7684\u8303\u7574\uff1a**\r\n\r\nAnother example is `svm`. Although support vector classification and support vector regression seem to be very different algorithms, but after pulling the cocoon, if you use gradient descent based methods to solve them, you will find that most of the codes are still shared. This also justifies why they belong to the same category - `svm`:\r\n\r\n```python\r\nclass CoreSVCMixin:\r\n    @staticmethod\r\n    def _preprocess_data(x, y):\r\n        y_svm = y.copy()\r\n        y_svm[y_svm == 0] = -1\r\n        return x, y_svm\r\n\r\n    @staticmethod\r\n    def get_diffs(y_batch, predictions):\r\n        return {\"diff\": 1. - y_batch * predictions, \"delta_coeff\": -y_batch}\r\n\r\nclass SVCMixin(BinaryClassifierMixin, SVMMixin, metaclass=ABCMeta):\r\n    def predict_prob(self, x):\r\n        affine = self.predict_raw(x)\r\n        sigmoid = Activations.sigmoid(np.clip(affine, -2., 2.) * 5.)\r\n        return np.hstack([1. - sigmoid, sigmoid])\r\n```\r\n\r\n```python\r\nclass CoreSVRMixin:\r\n    def get_diffs(self, y_batch, predictions):\r\n        raw_diff = predictions - y_batch\r\n        l1_diff = np.abs(raw_diff)\r\n        if self.eps <= 0.:\r\n            tube_diff = l1_diff\r\n        else:\r\n            tube_diff = l1_diff - self.eps\r\n        return {\"diff\": tube_diff, \"delta_coeff\": np.sign(raw_diff)}\r\n\r\nclass SVRMixin(SVMMixin, metaclass=ABCMeta):\r\n    def predict(self, x):\r\n        return self.predict_raw(x)\r\n```\r\n\r\n**\u7136\u540e\u771f\u6b63\u5b9e\u73b0 `svm` \u7b97\u6cd5\u65f6\uff0c\u5c31\u53ea\u9700\u7ee7\u627f\u4e0d\u540c\u7684\u7c7b\u5373\u53ef\uff1a**\r\n\r\nAfter these, when you actually implement the `svm` algorithms, you only need to inherit different classes:\r\n\r\n```python\r\nclass SVC(CoreSVCMixin, SVCMixin, ClassifierBase):\r\n    def __init__(self,\r\n                 kernel: str = \"rbf\"):\r\n        self._kernel = Kernel(kernel)\r\n```\r\n\r\n```python\r\nclass SVR(CoreSVRMixin, SVRMixin, RegressorBase):\r\n    def __init__(self,\r\n                 eps: float = 0.,\r\n                 kernel: str = \"rbf\"):\r\n        self._eps = eps\r\n        self._kernel = Kernel(kernel)\r\n```\r\n\r\n> **\u5f53\u7136\u4e86\uff0c\u771f\u6b63\u7684\u6838\u5fc3\u4ee3\u7801\uff08`SVMMixin`\uff09\u8fd8\u662f\u8981\u5199\u4e00\u5199\u7684**\r\n>\r\n> Of course, the real core codes (`SVMMixin`) still have to be written\r\n\r\n**\u6b64\u5916\uff0c\u9664\u4e86\u76f8\u4f3c\u7b97\u6cd5\u95f4\u7684\u4ee3\u7801\u5171\u4eab\uff0c`carefree-ml` \u8fd8\u81f4\u529b\u4e8e\u5e38\u89c1\u5de5\u7a0b\u529f\u80fd\u4e0a\u7684\u4ee3\u7801\u5171\u4eab\u3002\u6bd4\u5982\u8bf4\uff0c\u6211\u4eec\u4e00\u822c\u53ef\u80fd\u9700\u8981\uff1a**\r\n\r\n+ **\u5bf9\u8f93\u5165\u7684\u7279\u5f81\u8fdb\u884c\u89c4\u8303\u5316\u5904\u7406\uff08normalization\uff09**\r\n+ **\u5728\u56de\u5f52\u95ee\u9898\u4e2d\u5bf9\u6807\u7b7e\u8fdb\u884c normalization**\r\n+ **\u5728\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\u901a\u8fc7 roc curve \u4ee5\u53ca\u5177\u4f53\u7684 metric \u6765\u6311\u9009\u51fa\u6700\u4f18\u5206\u7c7b\u9608\u503c**\r\n\r\nIn addition, besides code sharing between similar algorithms, `carefree-ml` is also dedicated to sharing codes on common engineering functions. For example, we may generally need:\r\n\r\n+ Normalize the input features\r\n+ Normalize the labels in regression problems\r\n+ Utilize roc curve to find the best threshold of specific metric in binary classification problems\r\n\r\n**\u8fd9\u4e9b\u5de5\u7a0b\u4e0a\u7684\u4e1c\u897f\uff0c\u4e5f\u662f\u7406\u5e94\u8fdb\u884c\u4ee3\u7801\u5171\u4eab\u7684\u3002\u56e0\u6b64\uff0c`carefree-ml` \u786e\u5b9e\u5728 `cfml.models.mixins` \u4e2d\uff0c\u5b9e\u73b0\u4e86  `NormalizeMixin` \u548c `BinaryClassifierMixin`\uff0c\u7528\u4e8e\u5b9e\u73b0\u8fd9\u4e9b\u53ef\u80fd\u88ab\u5e7f\u6cdb\u8fd0\u7528\u7684\u529f\u80fd**\r\n\r\nThese engineering functions are also supposed to share codes. Therefore, `carefree-ml` implements ` NormalizeMixin` and `BinaryClassifierMixin` in `cfml.models.mixins` for these functions that may be widely used\r\n\r\n\r\n### What can carefree-ml do?\r\n\r\n**`carefree-ml` \u80fd\u505a\u5230\u4ec0\u4e48\uff1f**\r\n\r\nWhat can `carefree-ml` do? \r\n\r\n**\u9996\u5148\uff0c\u6700\u8fd1\u5176\u5b9e\u6709\u5f88\u591a\u7528 `numpy` \u5b9e\u73b0\u6d77\u91cf\u7b97\u6cd5\u7684 repo\uff0c\u6240\u4ee5\u5355\u5355\u7528 `numpy` \u6765\u4f5c\u4e3a\u5356\u70b9\u662f\u4e0d\u5408\u9002\u7684\u3002\u6211\u4e2a\u4eba\u8ba4\u4e3a\u7684\u8bdd\uff0c`carefree-ml` \u4e4b\u6240\u4ee5\u8fd8\u7b97\u6709\u4e9b\u7279\u8272\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u5982\u4e0b\u4e09\u70b9\uff1a**\r\n\r\n+ **\u5b9e\u73b0\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u3001\u6cdb\u7528\u6027\u6bd4\u8f83\u597d\u7684\u68af\u5ea6\u4e0b\u964d\u6846\u67b6**\r\n+ **\u6bd4\u8d77\u6a21\u578b\u7684\u6027\u80fd\uff0c\u66f4\u6ce8\u91cd\u4e8e\u8ba9\u7b97\u6cd5\u95f4\u5171\u4eab\u903b\u8f91\u3001\u4ee3\u7801\uff1b\u6b63\u56e0\u6b64\uff0c\u603b\u4ee3\u7801\u91cf\u4f1a\u6bd4\u8f83\u5c11**\r\n+ **\u5373\u4f7f\u5728\u7b2c\u4e8c\u70b9\u7684\u201c\u684e\u688f\u201d\u4e0b\uff0c\u5728\u5c0f\u7684\u3001\u6bd4\u8f83\u7b80\u5355\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u65e0\u8bba\u662f\u901f\u5ea6\u8fd8\u662f\u6027\u80fd\uff0c\u90fd\u662f\u53ef\u4ee5\u9524\u6389 `scikit-learn` \u7684\u53cb\u5546\u4ea7\u54c1\u7684**\r\n\r\nFirst of all, there are actually a lot of repos that use `numpy` to implement massive algorithms recently, so it is not appropriate to use` numpy` as a selling point. In my personal opinion, the reason why `carefree-ml` is still special are shown as follows:\r\n\r\n+ Implemented a lightweight gradient descent framework which can be used in a wide range of problems\r\n+ Compared with the performance of the model, it focused more on the sharing of logic and codes between algorithms. Therefore, the total amount of code will be less\r\n+ Even under the 'shackles' of the second point, on small and relatively simple datasets, it can beat `scikit-learn` in either speed or performance to some extend\r\n\r\n**\u6d4b\u8bd5\u65b9\u5f0f\uff08\u5305\u62ec\u4e86\u5b89\u88c5\u6b65\u9aa4\uff09\uff1a**\r\n\r\nHere's how you can test it (included installation procedures)\r\n\r\n```bash\r\ngit clone https://github.com/carefree0910/carefree-ml.git\r\ncd carefree-ml\r\npip install -e .\r\ncd tests/unittests\r\npython test_all.py\r\n```\r\n\r\n**\u5728\u8f93\u51fa\u4e2d\u968f\u4fbf\u622a\u51e0\u7ec4\u6570\u636e\u5427\uff1a**\r\n\r\nHere's some fragments from the outputs:\r\n\r\n```text\r\n~~~  [ info ] timing for    cfml_fcnn     : 0.310764\r\n~~~  [ info ] timing for   sklearn_fcnn   : 0.549960\r\n==========================================================\r\n|             cfml_fcnn  |    mae     |  2.682794  |  <-  \r\n|          sklearn_fcnn  |    mae     |  3.969561  |\r\n----------------------------------------------------------\r\n===========================================================\r\n|             cfml_fcnn  |    mse     |  15.635315  |  <-  \r\n|          sklearn_fcnn  |    mse     |  30.890426  |\r\n-----------------------------------------------------------\r\n```\r\n\r\n```text\r\n~~~  [ info ] timing for     cfml_lr      : 0.039881\r\n~~~  [ info ] timing for    sklearn_lr    : 0.654799\r\n==========================================================\r\n|               cfml_lr  |    auc     |  0.996287  |  <-  \r\n|            sklearn_lr  |    auc     |  0.994675  |\r\n----------------------------------------------------------\r\n==========================================================\r\n|               cfml_lr  |    acc     |  0.980668  |  <-  \r\n|            sklearn_lr  |    acc     |  0.957821  |\r\n----------------------------------------------------------\r\n```\r\n\r\n```text\r\n# gaussian naive bayes\r\n~~~  [ info ] timing for     cfml_gnb     : 0.000000\r\n~~~  [ info ] timing for   sklearn_gnb    : 0.001028\r\n# multinomial naive bayes\r\n~~~  [ info ] timing for     cfml_mnb     : 0.003990\r\n~~~  [ info ] timing for   sklearn_mnb    : 0.007011\r\n```\r\n\r\n```text\r\n~~~  [ info ] timing for     cfml_svc     : 0.207024\r\n~~~  [ info ] timing for    cfml_l_svc    : 0.023937\r\n~~~  [ info ] timing for    sklearn_lr    : 0.571722\r\n~~~  [ info ] timing for   sklearn_svc    : 0.007978\r\n~~~  [ info ] timing for  sklearn_l_svc   : 0.148603\r\n==========================================================\r\n|            cfml_l_svc  |    auc     |  0.996300  |\r\n|              cfml_svc  |    auc     |  1.000000  |  <-  \r\n|            sklearn_lr  |    auc     |  0.994675  |\r\n----------------------------------------------------------\r\n==========================================================\r\n|            cfml_l_svc  |    acc     |  0.985940  |\r\n|              cfml_svc  |    acc     |  1.000000  |  <-  \r\n|         sklearn_l_svc  |    acc     |  0.848858  |\r\n|            sklearn_lr  |    acc     |  0.957821  |\r\n|           sklearn_svc  |    acc     |  0.922671  |\r\n----------------------------------------------------------\r\n```\r\n\r\n```text\r\n~~~  [ info ] timing for     cfml_svr     : 0.090758\r\n~~~  [ info ] timing for    cfml_l_svr    : 0.027925\r\n~~~  [ info ] timing for   sklearn_svr    : 0.008012\r\n~~~  [ info ] timing for  sklearn_l_svr   : 0.165730\r\n==========================================================\r\n|            cfml_l_svr  |    mae     |  3.107422  |  <-  \r\n|              cfml_svr  |    mae     |  5.106989  |\r\n|         sklearn_l_svr  |    mae     |  4.654314  |\r\n|           sklearn_svr  |    mae     |  5.259882  |\r\n----------------------------------------------------------\r\n===========================================================\r\n|            cfml_l_svr  |    mse     |  24.503884  |  <-  \r\n|              cfml_svr  |    mse     |  66.583145  |\r\n|         sklearn_l_svr  |    mse     |  39.598211  |\r\n|           sklearn_svr  |    mse     |  66.818898  |\r\n-----------------------------------------------------------\r\n```\r\n\r\n**\u5f53\u7136\u4e86\uff0c\u5439\u662f\u8fd9\u4e48\u5439\uff0c\u6700\u540e\u6211\u4eec\u8fd8\u662f\u5f97\u8d1f\u8d23\u4efb\u5730\u8bf4\u4e00\u53e5\uff1a\u4ece\u5b9e\u7528\u6027\u3001\u6cdb\u5316\u6027\u6765\u8bf4\uff0c`scikit-learn` \u80af\u5b9a\u662f\u540a\u6253 `carefree-ml` \u7684\uff08\u6bd4\u5982 `carefree-ml` \u5b8c\u5168\u4e0d\u652f\u6301\u7a00\u758f\u6570\u636e\uff09\u3002\u4f46\u662f\uff0c\u6b63\u5982\u6211\u4e00\u5f00\u59cb\u6240\u8bf4\uff0c`carefree-ml` \u53ea\u662f\u60f3\u63a2\u7d22\u201c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5230\u5e95\u53ef\u4ee5\u7b80\u5316\u6210\u4ec0\u4e48\u6837\u201d\u7684\u4ea7\u7269\uff0c\u6240\u4ee5\u5728\u7b80\u5355\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u62df\u5408\u80fd\u529b\u3001\u62df\u5408\u901f\u5ea6\u8d85\u8fc7 `scikit-learn` \u5176\u5b9e\u4e5f\u5e76\u4e0d\u5947\u602a**\r\n\r\nOf course, in the end we still have to say something responsibly: from the perspective of practical use and generalization, `scikit-learn` will beat ` carefree-ml` by all means (for short, `carefree-ml` does not support sparse data). However, as I said at the beginning, `carefree-ml` focus on exploring *how machine learning algorithms can be simplified*. So it is not surprising that `carefree-ml` can exceed `scikit-learn` on small & simple datasets in fitting capacity & fitting speed.\r\n\r\n> **\u6ce8\uff1a\u4e0a\u8ff0\u5b9e\u9a8c\u7ed3\u679c\u90fd\u662f\u8bad\u7ec3\u96c6\u4e0a\u7684\u7ed3\u679c\uff0c\u6240\u4ee5\u53ea\u80fd\u53cd\u6620\u62df\u5408\u80fd\u529b\uff0c\u4e0d\u80fd\u53cd\u6620\u6cdb\u5316\u80fd\u529b**\r\n>\r\n> Notice that the above experimental results are the results on the training set, so it can only reflect the fitting capacity, not the generalization capacity\r\n\r\n\r\n### How can I utilize carefree-ml?\r\n\r\n**\u6211\u80fd\u600e\u4e48\u4f7f\u7528 `carefree-ml`\uff1f**\r\n\r\nHow can I utilize `carefree-ml`?\r\n\r\n**\u4ece\u5b9e\u7528\u6027\u89d2\u5ea6\u6765\u770b\uff0c\u4e5f\u8bb8 `carefree-ml` \u5b9e\u73b0\u7684\u90a3\u5957\u7b80\u6613\u68af\u5ea6\u4e0b\u964d\u6846\u67b6\uff0c\u662f\u76f8\u5bf9\u800c\u8a00\u6700\u5b9e\u7528\u7684\u3002\u4f46\u5373\u4fbf\u662f\u5b83\uff0c\u4e5f\u4f1a\u88ab `pytorch` \u8f7b\u677e\u540a\u9524**\r\n\r\nFrom a practical point of view, perhaps the lightweight gradient descent framework implemented by `carefree-ml` is relatively the most useful tool. But even it will be easily defeated and replaced by `pytorch`\r\n\r\n**\u6240\u4ee5\uff0c\u6b63\u5982\u6211\u5f00\u5934\u6240\u8bf4\uff0cmainly for educational use\uff0c\u53ef\u80fd\u6559\u80b2\u610f\u4e49\u4f1a\u5927\u4e8e\u5b9e\u7528\u610f\u4e49\u3002\u867d\u7136\u672c\u4eba\u5b66\u672f\u80fd\u529b\u4e0d\u548b\u5730\uff0c\u4f46\u662f\u6bd5\u7adf\u8be5 repo \u7684\u521d\u8877\u5e94\u8be5\u5f88\u5c11\u641e\u5b66\u672f\u7684\u4f1a\u770b\u5f97\u8d77\u5e76\u52a0\u4ee5\u7814\u7a76\uff0c\u6240\u4ee5\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c`carefree-ml` \u4e5f\u8bb8\u80fd\u7ed9\u4f60\u5e26\u6765\u4e00\u4e9b\u65b0\u7684\u4f53\u4f1a**\r\n\r\nSo, as I said at the beginning, `carefree-ml` is mainly for educational use, so the meaning of education may be greater than the practical meaning. Although my academic ability is not good at all, the original intention of this repo might not be worthy of academic researching. So from this perspective, `carefree-ml` may give you some new sights\r\n\r\n\r\n## License\r\n\r\n`carefree-ml` is MIT licensed, as found in the [`LICENSE`](https://github.com/carefree0910/carefree-ml/blob/master/LICENSE) file.\r\n\r\n---\r\n\r\n\r\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/carefree0910/carefree-ml/archive/v0.1.3.tar.gz",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/carefree0910/carefree-ml",
            "keywords": "python machine-learning numpy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "carefree-ml",
            "package_url": "https://pypi.org/project/carefree-ml/",
            "platform": null,
            "project_url": "https://pypi.org/project/carefree-ml/",
            "project_urls": {
                "Download": "https://github.com/carefree0910/carefree-ml/archive/v0.1.3.tar.gz",
                "Homepage": "https://github.com/carefree0910/carefree-ml"
            },
            "release_url": "https://pypi.org/project/carefree-ml/0.1.3/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Machine Learning algorithms implemented with numpy",
            "version": "0.1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14146927,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "cc29d583d0121040adc9eaa9a20f4f60",
                    "sha256": "f0cd8ae5a84767248f64fed7667ce5ba7e03f035a6f65edc7f517dde3f1f2aa1"
                },
                "downloads": -1,
                "filename": "carefree-ml-0.1.3.tar.gz",
                "has_sig": false,
                "md5_digest": "cc29d583d0121040adc9eaa9a20f4f60",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 52422,
                "upload_time": "2022-06-16T03:07:15",
                "upload_time_iso_8601": "2022-06-16T03:07:15.770791Z",
                "url": "https://files.pythonhosted.org/packages/3f/f3/bdb062b8193b83476d791a17d62f4d8bf42b2f8c1a5d3110acaf8c90e17d/carefree-ml-0.1.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
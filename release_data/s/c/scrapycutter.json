{
    "0.1": {
        "info": {
            "author": "Diogo Neves",
            "author_email": "diogooncastro1@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://gitlab.internal.b2w.io/team/a-tech/crawler-template",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "scrapycutter",
            "package_url": "https://pypi.org/project/scrapycutter/",
            "platform": "",
            "project_url": "https://pypi.org/project/scrapycutter/",
            "project_urls": {
                "Homepage": "http://gitlab.internal.b2w.io/team/a-tech/crawler-template"
            },
            "release_url": "https://pypi.org/project/scrapycutter/0.1/",
            "requires_dist": [
                "cookiecutter",
                "scrapy",
                "scrapy-rotated-proxy",
                "bigquery"
            ],
            "requires_python": ">=3.6",
            "summary": "Template para nossos projetos com base no cookiecutter",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10829510,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "de0e5658779d59cd0dcbba78617a67db",
                    "sha256": "c23bca14d0ebcd1813f0c38c384a4a010bcbd43a468afd797dc6ae7a9c79a29a"
                },
                "downloads": -1,
                "filename": "scrapycutter-0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "de0e5658779d59cd0dcbba78617a67db",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 3204,
                "upload_time": "2021-07-05T22:12:18",
                "upload_time_iso_8601": "2021-07-05T22:12:18.848615Z",
                "url": "https://files.pythonhosted.org/packages/87/6f/20a7927fc38c77488caf3dc334173f4edfc9d9a376d9eaea7e4aa2d39520/scrapycutter-0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "Diogo Neves",
            "author_email": "diogooncastro1@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "# Template padr\u00e3o de crawler para projetos da B2W\n\n## Pr\u00e9-requisitos\n- Python >= 3.6\n- scrapycutter (`pip install scrapycutter`)\n- Acesso ao nosso Gitlab\n\n## Como usar\nDepois de ter todo o necess\u00e1rio visto acima, ent\u00e3o basta apenas executar o comando\n- `scrapycutter revolution` que o comando nos permitir\u00e1 fazer as configura\u00e7\u00f5es b\u00e1sicas para o projeto Revolution\n  - OBS: O template foi criado de forma que seja poss\u00edvel adicionar novas funcionalidades ou templates de projetos facilmente, para nossa comodidade.\n\nCaso prefira, tamb\u00e9m temos outras duas maneiras de criar o template, a partir do c\u00f3digo fonte:\n- Primeiramente lembrando que \u00e9 necess\u00e1rio estar com a VPN  ativa no momento que realizar o comando acima para que funcione corretamente.\n- Fazer clone para sua m\u00e1quina permitindo que seja poss\u00edvel executar esse comando localmente:\n  - `git clone git@gitlab.internal.b2w.io:team/a-tech/crawler-template.git`\n  - `cookiecutter crawler-template`\n- Tamb\u00e9m podemos usar a forma mais pr\u00e1tica, que \u00e9 referenciando esse reposit\u00f3rio da seguinte forma:\n  - `cookiecutter git+http://gitlab.internal.b2w.io/team/a-tech/crawler-template.git`\n  - Basta apenas inserir esse comando referenciando esse reposit\u00f3rio de template, digitar o usu\u00e1rio e senha do gitlab da empresa (j\u00e1 que funciona como se fosse um `git clone`) que as op\u00e7\u00f5es ser\u00e3o mostradas para criar o template do projeto da forma que bem entender;\n\n# OBS:\nPor motivos de seguran\u00e7a o arquivo B2W.json n\u00e3o \u00e9 gerado junto com o template, \u00e9 o \u00fanico arquivo necess\u00e1rio de ser adicionado assim que o template \u00e9 gerado.\n\n### ToDo\n- ~Investigar como gerar o template diretamente do nosso reposit\u00f3rio  privado do Gitlab, atualmente isso ainda n\u00e3o \u00e9 poss\u00edvel;~ (Resolvido)\n- Melhorar dinamismo de como o template \u00e9 gerado, talvez adicionando novos campos que possam ser configurados;\n- ~Fazer com que se torne um pacote Python, para que seja ainda mais simples de executar.~ (Feito)\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "http://gitlab.internal.b2w.io/team/a-tech/crawler-template",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "scrapycutter",
            "package_url": "https://pypi.org/project/scrapycutter/",
            "platform": "",
            "project_url": "https://pypi.org/project/scrapycutter/",
            "project_urls": {
                "Homepage": "http://gitlab.internal.b2w.io/team/a-tech/crawler-template"
            },
            "release_url": "https://pypi.org/project/scrapycutter/0.1.2/",
            "requires_dist": [
                "cookiecutter",
                "scrapy",
                "scrapy-rotated-proxy",
                "bigquery"
            ],
            "requires_python": ">=3.6",
            "summary": "Template para nossos projetos com base no cookiecutter",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10829510,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d3e35e166174bcf28c67f9824f819cce",
                    "sha256": "f606c895fef0a664796e06546b08bb6da91845eca3254974dd57ac284b62eef6"
                },
                "downloads": -1,
                "filename": "scrapycutter-0.1.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d3e35e166174bcf28c67f9824f819cce",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 3387,
                "upload_time": "2021-07-05T22:19:41",
                "upload_time_iso_8601": "2021-07-05T22:19:41.059669Z",
                "url": "https://files.pythonhosted.org/packages/38/12/da0df5079436c49b1e49735bf2e3c516e3a6cb97db36749607537eb751c8/scrapycutter-0.1.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
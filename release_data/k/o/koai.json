{
    "0.0.1.1": {
        "info": {
            "author": "Eddie",
            "author_email": "hkjeo13@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Developers",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "## KoAI; Korean AI Project. \ud55c\uad6d\uc5b4\ub97c \uc704\ud55c \uc778\uacf5\uc9c0\ub2a5 \ud504\ub85c\uc81d\ud2b8\n\n\n```\n$ pip install koai\n```\n\n\n\n\n## FineTuning\n\n\ud5c8\uae45\ud398\uc774\uc2a4 \ud5c8\ube0c(huggingface-hub) \ub610\ub294 \ud5c8\uae45\ud398\uc774\uc2a4 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \ud1b5\ud574 \ub85c\ub4dc \uac00\ub2a5\ud55c \ub85c\uceec \ud30c\uc77c\uc744, klue \ubca4\uce58 \ub9c8\ud06c\uc5d0 \ub300\ud558\uc5ec \ud14c\uc2a4\ud2b8\ud558\ub294 \uc608\uc2dc\uc785\ub2c8\ub2e4.\n\n```\nfrom koai import finetune\n\n# finetuning and evaluating on klue-sts dataset\nfinetune(\n    task_name=\"klue-sts\", \n    model_name_or_path=\"klue/bert-base\", \n    do_train=True, \n    do_eval=True, \n    num_train_epochs=5, \n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_strategy=\"epoch\"\n)\n\n# finetuning and evaluating on all klue dataset (except 'wos')\n# if \"finetune_model_across_the_tasks\" is True, the model train all the tasks in KLUE\n# but it is false(default is false), finetuning the language model individually.  \nfinetune(\n    \"klue\", \n    \"klue/bert-base\", \n    do_train=True, \n    do_eval=True, \n    num_train_epochs=5, \n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    logging_strategy=\"epoch\"\n)\n```\n- task_name: str, \uacfc\uc81c\uc758 \uc774\ub984\uc744 \uc124\uc815\ud569\ub2c8\ub2e4(klue \uc804\uccb4\ub97c \ud14c\uc2a4\ud2b8 \ud558\ub824\uba74, \"klue\". \ud2b9\uc815 \ud14c\uc2a4\ud06c\ub97c \uc120\ud0dd\ud558\ub824\uba74 \"klue-mrc\"\uc640 \uac19\uc774 \uc785\ub825\ud574\uc8fc\uc138\uc694. \"mrc\"\uc640 \uac19\uc740 \ud558\uc704 \ud14c\uc2a4\ud06c \uc774\ub984\uc740 \ud5c8\uae45\ud398\uc774\uc2a4 \ud5c8\ube0c\ub97c \ub530\ub985\ub2c8\ub2e4.)\n\n- model_name_or_path: str, \ubaa8\ub378\uc758 \ud5c8\uae45\ud398\uc774\uc2a4 \ud5c8\ube0c \uc774\ub984 \ub610\ub294 \ub85c\uceec \uacbd\ub85c\ub97c \uc785\ub825\ud574 \uc8fc\uc138\uc694.\n\n- remove_columns: bool = True, \ub370\uc774\ud130 \ub85c\ub4dc \ud6c4 \ubaa8\ub378 \uc785\ub825\uc744 \uc704\ud55c \ud504\ub85c\uc138\uc2a4 \uc644\ub8cc \ud6c4 \uae30\uc874 \uceec\ub7fc \uc774\ub984\uc744 \uc0ad\uc81c\ud560\uc9c0 \uc5ec\ubd80\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n- custom_task_infolist: Optional[List[TaskInfo]] = None, \uc9c1\uc811 TaskInfo \ud074\ub798\uc2a4\ub97c \uc124\uc815\ud558\uace0 \uc774\ub97c \ub9ac\uc2a4\ud2b8 \uc548\uc5d0 \ub123\uc5b4 \ubca4\uce58\ub9c8\ud06c \ud14c\uc2a4\ud2b8\ub97c \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n- max_source_length: int = 512, \uc785\ub825 \ud14d\uc2a4\ud2b8\uc758 \ucd5c\ub300 \uae38\uc774\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n- max_target_length: Optional[int] = None, (\ub9cc\uc57d \uc788\ub2e4\uba74) \ucd9c\ub825 \ud14d\uc2a4\ud2b8\uc758 \ucd5c\ub300 \uae38\uc774\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n- padding: str = \"longest\", padding\uc758 \ubc29\ubc95\uc744 \uc124\uc815\ud569\ub2c8\ub2e4(`transformers.PretrainedTokenizerBase.__call__`\uc758 'padding'\uc778\uc790\uc640 \ub3d9\uc77c\ud569\ub2c8\ub2e4).\n\n- save_model: bool = False, \ubaa8\ub378\uc744 \ub0b4\ubd80\uc5d0 \uc800\uc7a5\ud560 \uc9c0 \uc5ec\ubd80\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n- return_models: bool = False, \ud568\uc218\uac00 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \ubc18\ud658\ud560\uc9c0 \uc5ec\ubd80\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n- output_dir: str = \"runs/\", (save_model=True\uc77c \ub54c), \uc800\uc7a5\ud560 \ub514\ub809\ud1a0\ub9ac\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n- finetune_model_across_the_tasks: bool = False, \ubaa8\ub378\uc744 \uc785\ub825 \ubc1b\uc740 \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud574\uc11c \uc870\uc815 \ud559\uc2b5 \uc2dc, \ucd08\uae30\ud654 \ud560\uc9c0\ub97c \uc124\uc815\ud569\ub2c8\ub2e4(True\uba74 \ud558\ub098\uc758 \ubaa8\ub378\uc774 \uc5ec\ub7ec \ubca4\uce58\ub9c8\ud06c\uc5d0 \ub300\ud558\uc5ec \ud559\uc2b5\ud569\ub2c8\ub2e4).\n\n- add_sp_tokens_to_unused:bool, \uacfc\uc81c\uc5d0\uc11c special_token \uc744 unused \ud1a0\ud070\uacfc \ub300\uce58\ud560 \uc9c0\ub97c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n(\uadf8 \ubc16\uc5d0 \ud5c8\uae45\ud398\uc774\uc2a4\uc758 transformers.TrainingArguments \uc758 \ubaa8\ub4e0 \uc778\uc790\ub97c \uc785\ub825\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.)\n\n\n## Available Tasks\n- GLUE(except \"glue-mnli_matched\",\"glue-mnli_mismatched\", and \"glue-ax\")\n- KLUE(except \"klue-wos\")\n\n## Issue\n\n-  \ud604\uc7ac \uac1c\ubc1c \uc911\uc5d0 \uc788\ub294 \ud504\ub85c\uc81d\ud2b8\uc785\ub2c8\ub2e4. \ud5a5\ud6c4 \ubca4\uce58\ub9c8\ud06c\uac00 \ucd94\uac00\ub420 \uc608\uc815\uc785\ub2c8\ub2e4.\n-  \uc18c\uc2a4\uc758 \ub9ce\uc740 \ubd80\ubd84\ub4e4\uc774, https://github.com/huggingface/transformers/ \ub97c \ucc38\uace0 \ubc0f \uc778\uc6a9\ud558\uc5ec \uc81c\uc791\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/hkjeon13/koai",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "koai",
            "package_url": "https://pypi.org/project/koai/",
            "platform": null,
            "project_url": "https://pypi.org/project/koai/",
            "project_urls": {
                "Homepage": "https://github.com/hkjeon13/koai"
            },
            "release_url": "https://pypi.org/project/koai/0.0.1.1/",
            "requires_dist": [
                "transformers",
                "datasets",
                "seqeval",
                "nltk",
                "rouge-score",
                "evaluate"
            ],
            "requires_python": ">=3",
            "summary": "Korean AI Project",
            "version": "0.0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15896885,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c4af29efa2ee976917a86c3b258f6de9",
                    "sha256": "2c5f9ac81b13056fa052f7b67aff656899da14c6db40f2c99c315e14bd32cf00"
                },
                "downloads": -1,
                "filename": "koai-0.0.1.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "c4af29efa2ee976917a86c3b258f6de9",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 24023,
                "upload_time": "2022-11-26T11:18:21",
                "upload_time_iso_8601": "2022-11-26T11:18:21.614518Z",
                "url": "https://files.pythonhosted.org/packages/91/cb/408ed47f1e6cbf4353bc9b1d4ccdc5c046d1413dacfefe737b7bd6c6ed0c/koai-0.0.1.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1.0": {
        "info": {
            "author": "Ross Patterson",
            "author_email": "me@rpatterson.net",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 4 - Beta",
                "Environment :: Console",
                "Intended Audience :: Developers",
                "Intended Audience :: System Administrators",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: English",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Topic :: Utilities"
            ],
            "description": "########################################################################################\nfeed-archiver\n########################################################################################\nArchive the full contents of RSS/Atom syndication feeds including enclosures and assets.\n****************************************************************************************\n\n.. image:: https://github.com/rpatterson/feed-archiver/workflows/Run%20linter,%20tests%20and,%20and%20release/badge.svg\n\nThe ``$ feed-archiver`` command aims to archive RSS/Atom feeds as fully as possible in\nsuch a way that the archive can serve (at least) 2 use cases:\n\n#. `Mirror of Feed Enclosures and Assets`_\n\n    A mirror of the archived feeds that can be in turn served onto onto feed\n    clients/subscribers (such as podcatchers).  For example, you can subscribe to the\n    archived feed from your podcatcher app on your phone with auto-download and\n    auto-delete of podcast episodes while archiving those same episodes on your HTPC\n    server with large enough storage to keep all episodes.  The archived version of the\n    feed will also reflect the earliest form of feed XML, item XML, enclosures, and\n    assets that the archive downloaded and as such can be used to reflect the original\n    version to clients even as the remote feed changes over time.\n\n#. `Ingest Feed Enclosures Into Media Libraries`_\n\n    An alternate hierarchy of feed item enclosures better suited for ingestion into\n    other media software, such as media library servers.  For example, your podcast\n    episodes can also be made available in your `Jellyfin`_/Emby/Plex library.\n\n********************\nDetailed Description\n********************\n\nMirror of Feed Enclosures and Assets\n====================================\n\nTo serve use case #1, ``feed-archiver`` downloads enclosures and external assets\n(e.g. feed and item logos specified as URLs in the feed XMLs) to the archive's local\nfilesystem, adjusts the URLs of the downloaded items in the feed XML, and saves the feed\nXML into the archive as well.  This makes the local archive filesystem suitable for\nserving to feed clients/subscribers using a simple static site server such as `nginx`_.\n\nAll URLs are transformed into file-system paths that are as readable as possible while\navoiding special characters that may cause issues with common file-systems.\nSpecifically, special characters are ``%xx`` escaped using `Python's\nurllib.parse.quote`_ function.  Note that this will double-escape any\n``%xx`` escapes in the remote URL:\n\n  ``.../foo?bar=qux%2Fbaz#corge`` -> ``.../foo%3Fbar=qux%252Fbaz#corge``\n\nThen the URL is converted to a corresponding filesystem path:\n\n  ``https://foo-username:secret@grault.example.com/feeds/garply.rss`` ->\n  ``./https/foo-username%3Asecret@grault.example.com/feeds/garply.rss``\n\nAssuming the archived feeds are all hosted via HTTPS/TLS from an `nginx server_name`_ of\n``feeds.example.com``, then subscribing to the archived feed in a syndication client,\nsuch as a pod-catcher app can be done by transforming the URL like so:\n\n  ``https://foo-username:secret@grault.example.com/feeds/garply.rss`` ->\n  ``https://feeds.example.com/https/foo-username%3Asecret@grault.example.com/feeds/garply.rss``\n\nIOW, it's as close as possible to simply prepending your archives host name to the feed\nURL.\n\nAs feeds change over time, ``feed-archiver`` preserves the earliest form of feed content\nas much as possible.  If a feed item is changed in a subsequent retrieval of the feed,\nthe remote item XML is preserved instead of updating to the newer XML.  More\nspecifically, items will be ignored on subsequent retrievals of the same feed if they\nhave the same ``guid``/``id`` as items that have previously been archived for that feed.\n\nIngest Feed Enclosures Into Media Libraries\n===========================================\n\nTo serve use case #2, ``feed-archiver`` links the downloaded feed item enclosures into\nan alternate hierarchy based on feed item metadata that better reflects the\nshow-with-episodes nature of most feeds, such as podcasts, with media enclosures.  What\nfeed item metadata is used and how it's used to assemble the media library path\nenclosures are linked into is configurable on a per-feed basis.  This can be used, for\nexample, simply to make your podcasts accessible from your media library software.  In a\nmore complex example, it can be used to link episodes from a podcast about a TV series\nas `external alternative audio tracks`_ next to the corresponding TV episode video file.\nMultiple linking paths can be configured such that feed item enclosures can be ingested\nin multiple locations in media libraries.\n\nBecause syndication feeds may have a number of different ways to correspond to library\nmedia, this functionality needs to be highly configurable and in order to be highly\nconfigurable it is more complex to customize to a specific goal.  As such, using this\nfeature requires using `a link path plugin`_, or the skill level of a junior developer,\nor someone who is comfortable reading and interpreting technical documentation, or\nre-using example configurations known to work by others.\n\n\n************\nInstallation\n************\n\nInstall using any tool for installing standard Python 3 distributions such as `pip`_::\n\n  $ sudo pip3 install feed-archiver\n\n\n*****\nUsage\n*****\n\nCreate a ``./.feed-archiver.yml`` YAML file in a directory to serve as the root\ndirectory for all feeds to be archived.  The YAML file must have a top-level\n``defaults`` key whose value is an object defining default or global options.  In\nparticular, the ``base-url`` key in that section whose value must be a string which\ndefines the external base URL at which the archive is served to clients and is used to\nassemble absolute URLs where relative URLs can't be used.  The file must also have a\ntop-level ``feeds`` key whose value is an array or list of objects defining the remote\nfeeds to archive in this directory.  Each feed object must contain a ``remote-url`` key\nwhose value is a string that contains the URL of an individual feed to archive.  In the\nsimplest form, this can just be a file like so::\n\n  defaults:\n    base-url: \"https://feeds.example.com\"\n  feeds:\n    - remote-url:\n\t\"https://foo-username:secret@grault.example.com/feeds/garply.rss?bar=qux%2Fbaz#corge\"\n  ...\n\nThen simple run the ``$ feed-archiver`` command in that directory to update the archive\nfrom the current version of the feeds::\n\n  $ cd \"/var/www/html/feeds/\"\n  $ feed-archiver\n  INFO:Retrieving feed URL: https://foo-username:secret@grault.example.com/feeds/garply.rss\n  ...\n\nSee also the command-line help for details on options and arguments::\n\n  $ usage: feed-archiver [-h] [archive-dir...]\n\n  Archive the full contents of RSS/Atom syndication feeds including enclosures and\n  assets.\n\n  positional arguments:\n    archive-dir  filesystem path to the root of an archive of feeds (default: ./)\n\n  optional arguments:\n    -h, --help  show this help message and exit\n\n  ...\n\nTo link feed items into an `alternate hierarchy`_, such as in a media library, add a\n``link-paths`` key to the feed configuration whose value is an list/array of objects\neach defining one alternative path to link to the feed item enclosure.  Any\n``link-paths`` defined in the top-level ``defaults`` key will be used for all feeds.\nConfiguration to be shared across multiple ``link-paths`` configurations may be placed\nin the corresponding ``defaults`` / ``plugins`` / ``link-paths`` / ``{plugin_name}``\nobject.  The actual linking of enclosures is delegated to `plugins`_.\n\n\n*******\nPlugins\n*******\n\nHow feed item enclosures are linked into a media library is delegated to plugins or\nadd-ons.  Specifically, the ``plugin`` key in a ``link-paths`` configuration must be a\nstring which is the name of `a Python entry point`_ registered in the\n``feedarchiver.linkpaths`` group.  The entry point object reference must point to a\n``feedarchiver.linkpaths.LinkPathPlugin`` subclass which accepts the following arguments\nwhen instantiated:\n\n#. ``parent=dict``\n\n   The ``feedarchiver.archive.Archive`` if the plugin is configured in ``defaults`` for\n   all feeds or the ``feedarchiver.feed.ArchiveFeed`` if defined for a specific feed.\n\n#. ``config=dict``\n\n   The Python dictionary object from the de-serialized archive configuration YAML for\n   this specific link path configuration.\n\nand whose instances must be callable and accept the following arguments when called:\n\n#. ``archive_feed=feedarchiver.feed.ArchiveFeed``\n\n   The object ``feedarchiver`` uses internally to represent an individual feed in the\n   archive.\n\n#. ``feed_elem=xml.etree.ElementTree.Element``\n\n   The `Python XML element object`_ representing the whole feed.  For RSS this is the\n   ``<channel>`` child element while for Atom this is the root ``<feed>`` element.\n\n#. ``item_elem=xml.etree.ElementTree.Element``\n\n   The `Python XML element object`_ representing the specific feed item.\n\n#. ``url_result=lxml.TODO``\n\n   The `lmxl special string object`_ that contains the URL of the specific enclosure.\n   Can be used to access the specific enclosure element.\n\n#. ``basename=str``\n\n  The best guess at the most correct file basename, including the suffix or extension,\n  for the given enclosure.  This suffix takes into account the suffix from the enclosure\n  URL, the ``Content-Type`` header of the response to the enclosure URL request, and\n  finally the value of any ``type`` attribute of the enclosure element XML.\n\n#. ``match=re.Match``\n\n   The `Python regular expression match object`_ if the ``match-pattern`` matched the\n   string expanded from the `Python format string`_ in the ``match-string`` key.\n   Particularly useful to designate `regular expression groups`_ in the\n   ``match-pattern`` and then use the parts of ``match-string`` that matched those\n   groups in the format ``template``.  If the ``match-pattern`` doesn't match then the\n   enclosure will not be linked.  If no ``match-string`` is provided a default is used\n   combining the feed title, item title, and enclosure basename with extension::\n\n     {feed_elem.find('title').text.strip()}/{item_elem.find('title').text.strip()}/{basename}\n\nIf the plugin returns a value, it must be a list of strings and will be used as the\ntarget paths at which to link the enclosure.  Relative paths are resolved against the\narchive root.  These paths are not escaped, so if escaping is needed it must be a part\nof the plugin configuration.  Here's an example ``link-paths`` definition::\n\n  defaults:\n    base-url: \"https://feeds.example.com\"\n    plugins:\n      link-paths:\n        sonarr:\n          url: \"http://localhost:8989\"\n          api-key: \"????????????????????????????????\"\n    link-paths:\n      # Link all feed item enclosures into the media library under the podcasts directory\n      - template: \"/media/Library/Music/Podcasts/{feed_elem.find('title').text.strip()}/{item_elem.find('title').text.strip()})/{basename}\"\n  feeds:\n    - remote-url:\n\t\"https://foo-username:secret@grault.example.com/feeds/garply.rss?bar=qux%2Fbaz#corge\"\n      link-paths:\n\t# This particular feed is a podcast about a TV series/show.  Link enclosures\n\t# from feed items about an individual episode next to the episode video file as\n\t# an external audio track using a non-default plugin.\n\t- plugin: \"sonarr\"\n\t  match-string: \"{item_elem.find('title').text.strip()}\"\n\t  match-pattern: \"(?P<item_title>.+) \\\\((?P<series_title>.+) (?P<season_number>[0-9])(?P<episode_numbers>[0-9]+[0-9Ee& -]*)\\\\)\"\n\t  stem-append: \"-garply\"\n  ...\n\nDefault Template Plugin\n=======================\n\nIf no ``plugin`` key is specified, the ``template`` plugin is used.  The link\npath config may include the ``template`` key containing a `Python format string`_ which\nwill be expanded to determine where the feed item enclosure should be linked to.  The\ndefault ``template`` is::\n\n  ./Feeds/{feed_elem.find('title').text.strip()}/{item_elem.find('title').text.strip()}/{basename}\n\nThe format strings may reference any of `the arguments passed into link path plugins`_.\n\nSonarr TV Series Plugin\n=======================\n\nThe ``sonarr`` plugin uses values from the link path configuration and/or the ``match``\ngroups to lookup a TV series/show managed by `Sonarr`_, then lookup an episode video\nfile that corresponds to the feed item enclosure/content, and link the enclosure/content\nnext to that video file.  The ``link-paths`` configuration or ``match`` groups must\ncontain:\n\n- ``url`` and ``api-key`` used to `connect to the Sonarr API`_\n- ``series_id`` or ``series_title`` used to `look up the TV show/series`_, note that\n  using ``series_id`` saves on Sonarr API request per update\n- ``season_number`` used to `lookup the episode file`_\n- ``episode_numbers`` used to `lookup the episode file`_, plural to support\n  multi-episode files\n\nThey may also include:\n\n- ``stem-append`` containing a string to append to the episode file stem before the\n  enclosure/content suffix/extension\n\n\n.. _alternate hierarchy: `Ingest Feed Enclosures Into Media Libraries`_\n.. _a link path plugin: `Plugins`_\n.. _the arguments passed into link path plugins: `Plugins`_\n\n.. _pip: https://pip.pypa.io/en/stable/installing/\n.. _a Python entry point:\n   https://packaging.python.org/en/latest/specifications/entry-points/#data-model\n.. _Python format string: https://docs.python.org/3/library/string.html#formatstrings\n.. _Python regular expression match object:\n   https://docs.python.org/3/library/re.html#match-objects\n.. _regular expression groups: https://docs.python.org/3/library/re.html#index-17\n.. _Python's urllib.parse.quote:\n   https://docs.python.org/3/library/urllib.parse.html#urllib.parse.quote\n.. _Python XML element object:\n    https://docs.python.org/3/library/xml.etree.elementtree.html#element-objects\n.. _lmxl special string object: https://lxml.de/xpathxslt.html#xpath-return-values\n\n.. _nginx: https://nginx.org/en/docs/\n.. _nginx server_name: https://www.nginx.com/resources/wiki/start/topics/examples/server_blocks/\n\n.. _Jellyfin: https://jellyfin.org/\n.. _external alternative audio tracks:\n   https://jellyfin.org/docs/general/server/media/external-audio-files.html\n.. _Sonarr: https://sonarr.tv\n.. _connect to the Sonarr API: https://github.com/Sonarr/Sonarr/wiki/API#url\n.. _look up the TV show/series: https://github.com/Sonarr/Sonarr/wiki/Series#getid\n.. _lookup the episode file: https://github.com/Sonarr/Sonarr/wiki/Episode#get\n",
            "description_content_type": "text/x-rst",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/rpatterson/feed-archiver",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "feed-archiver",
            "package_url": "https://pypi.org/project/feed-archiver/",
            "platform": null,
            "project_url": "https://pypi.org/project/feed-archiver/",
            "project_urls": {
                "Homepage": "https://github.com/rpatterson/feed-archiver"
            },
            "release_url": "https://pypi.org/project/feed-archiver/0.1.0/",
            "requires_dist": [
                "pyyaml",
                "lxml",
                "requests",
                "requests-toolbelt",
                "user-agent",
                "arrapi",
                "tenacity",
                "importlib-metadata ; python_version < \"3.10\"",
                "requests-mock ; extra == 'devel'",
                "tox ; extra == 'devel'",
                "pytest ; extra == 'devel'",
                "pytest-subtests ; extra == 'devel'",
                "pre-commit ; extra == 'devel'",
                "coverage ; extra == 'devel'",
                "flake8 ; extra == 'devel'",
                "autoflake ; extra == 'devel'",
                "autopep8 ; extra == 'devel'",
                "flake8-black ; extra == 'devel'",
                "rstcheck ; extra == 'devel'",
                "pip-tools ; extra == 'devel'",
                "pylint ; extra == 'devel'",
                "lxml-stubs ; extra == 'devel'",
                "types-requests ; extra == 'devel'"
            ],
            "requires_python": ">=3.9",
            "summary": "Archive the full contents of RSS/Atom syndication feeds including enclosures and assets.",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15680143,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3e9691bb04ce16e483cb59c1ad86011b",
                    "sha256": "c5ba47b282268b7aff986d1aa8a9be0d788fda508f6b6f69d74f2d36fa9bbe77"
                },
                "downloads": -1,
                "filename": "feed_archiver-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3e9691bb04ce16e483cb59c1ad86011b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9",
                "size": 46016,
                "upload_time": "2022-11-07T03:54:56",
                "upload_time_iso_8601": "2022-11-07T03:54:56.238415Z",
                "url": "https://files.pythonhosted.org/packages/61/4b/06f174a016feec520524b9237ef79d646c57dc6d29d2651cc355b66eb22f/feed_archiver-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "c8835fd6f0a59b673b0503ad9656e956",
                    "sha256": "16121969c4add09d873b5e34e719b85cf845a30cbe13c1207c9503c3bb648dc9"
                },
                "downloads": -1,
                "filename": "feed-archiver-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "c8835fd6f0a59b673b0503ad9656e956",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9",
                "size": 322527,
                "upload_time": "2022-11-07T03:54:58",
                "upload_time_iso_8601": "2022-11-07T03:54:58.195784Z",
                "url": "https://files.pythonhosted.org/packages/9e/a1/71c08c99be6771fb65002ecb212dcd58c4eeb47fefbf7464abeb869051c8/feed-archiver-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
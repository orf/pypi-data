{
    "0.1": {
        "info": {
            "author": "Wannaphong Phatthiyaphaibun",
            "author_email": "wannaphong@yahoo.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: Apache Software License",
                "Programming Language :: Python :: 3",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Text Processing",
                "Topic :: Text Processing :: General",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description": "# LEKCut\n<a href=\"https://pypi.python.org/pypi/lekcut\"><img alt=\"pypi\" src=\"https://img.shields.io/pypi/v/lekcut.svg\"/></a>\n\nLEKCut (\u0e40\u0e25\u0e47\u0e01 \u0e04\u0e31\u0e14) is a Thai tokenization library that ports the deep learning model to the onnx model.\n\n## Install\n\n> pip install lekcut\n\n## How to use\n\n```python\nfrom lekcut import word_tokenize\nword_tokenize(\"\u0e17\u0e14\u0e2a\u0e2d\u0e1a\u0e01\u0e32\u0e23\u0e15\u0e31\u0e14\u0e04\u0e33\")\n# output: ['\u0e17\u0e14\u0e2a\u0e2d\u0e1a', '\u0e01\u0e32\u0e23', '\u0e15\u0e31\u0e14', '\u0e04\u0e33']\n```\n\n**API**\n\n```python\nword_tokenize(text: str, model: str=\"deepcut\", path: str=\"default\") -> List[str]\n```\n\n## Model\n- ```deepcut``` - We ported deepcut model from tensorflow.keras to ONNX model. The model and code come from [Deepcut's Github](https://github.com/rkcosmos/deepcut). The model is [here](https://github.com/PyThaiNLP/LEKCut/blob/main/lekcut/model/deepcut.onnx).\n\n### Load custom model\n\nIf you has trained custom your model from deepcut or other that LEKCut support, You can load the custom model by ```path``` in ```word_tokenize``` after porting your model.\n\n- How to train custom model ith your dataset by deepcut - [Notebook](https://github.com/rkcosmos/deepcut/blob/master/notebooks/training.ipynb) (Needs to update ```deepcut/train.py``` before train model)\n\n## How to porting model?\n\nSee ```notebooks/```\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/PyThaiNLP/LEKCut",
            "keywords": "thai,NLP,natural language processing,text analytics,text processing,localization,computational linguistics,Thai language",
            "license": "Apache Software License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "LEKCut",
            "package_url": "https://pypi.org/project/LEKCut/",
            "platform": null,
            "project_url": "https://pypi.org/project/LEKCut/",
            "project_urls": {
                "Bug Reports": "https://github.com/PyThaiNLP/LEKCut/issues",
                "Homepage": "https://github.com/PyThaiNLP/LEKCut",
                "Source": "https://github.com/PyThaiNLP/LEKCut"
            },
            "release_url": "https://pypi.org/project/LEKCut/0.1/",
            "requires_dist": [
                "numpy",
                "onnxruntime",
                "onnx"
            ],
            "requires_python": ">=3.6",
            "summary": "LEKCut (\u0e40\u0e25\u0e47\u0e01 \u0e04\u0e31\u0e14) is a Thai tokenization library that ports the deep learning model to the onnx model.",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15567230,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d2c1c55b9fed0fe2972cdcd5391232c5",
                    "sha256": "b7e503b2816486b5998e4f0024f04ba197af131f3afd604c294be6b30060579b"
                },
                "downloads": -1,
                "filename": "LEKCut-0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d2c1c55b9fed0fe2972cdcd5391232c5",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 2002802,
                "upload_time": "2022-10-28T16:17:19",
                "upload_time_iso_8601": "2022-10-28T16:17:19.386140Z",
                "url": "https://files.pythonhosted.org/packages/1c/94/d39131588e28e5e5c85554423d41dd7715438eb3dbd42bd92a91c52a0d7a/LEKCut-0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "835e552eb25772900d7fa26420a94819",
                    "sha256": "1fbb200e129c204252369001ffcadea0e37c9871a6aa71a7819e49f1cbb973ba"
                },
                "downloads": -1,
                "filename": "LEKCut-0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "835e552eb25772900d7fa26420a94819",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 2003873,
                "upload_time": "2022-10-28T16:17:21",
                "upload_time_iso_8601": "2022-10-28T16:17:21.529365Z",
                "url": "https://files.pythonhosted.org/packages/fd/89/5853548acf1f39ac4554caa27e19a547becb68b7a0aa39fc36cc91b3a5af/LEKCut-0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
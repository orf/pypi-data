{
    "0.0.12": {
        "info": {
            "author": "Robel Equbasilassie",
            "author_email": "robiki4life@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/robikieq/ethiopian_language_toolkit.git",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "etltk",
            "package_url": "https://pypi.org/project/etltk/",
            "platform": null,
            "project_url": "https://pypi.org/project/etltk/",
            "project_urls": {
                "Homepage": "https://github.com/robikieq/ethiopian_language_toolkit.git"
            },
            "release_url": "https://pypi.org/project/etltk/0.0.12/",
            "requires_dist": [
                "1.7.0 ; extra == 'emoji_'",
                "Emoji ; extra == 'emoji_'",
                "0.0.21 ; extra == 'textsearch_'",
                "TextSearch ; extra == 'textsearch_'"
            ],
            "requires_python": ">=3.6",
            "summary": "Ethiopian Language NLP Toolkit",
            "version": "0.0.12",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13829097,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7035635243bad7748c5edc250fa00e1a",
                    "sha256": "bff40842ad0aac3e4798f166587d666323848612cc6894170c0d8875853fba67"
                },
                "downloads": -1,
                "filename": "etltk-0.0.12-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7035635243bad7748c5edc250fa00e1a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19603,
                "upload_time": "2022-04-22T17:11:20",
                "upload_time_iso_8601": "2022-04-22T17:11:20.864693Z",
                "url": "https://files.pythonhosted.org/packages/ab/65/a356d1705405a4e932b3dc5b1121342f7278b4462154cb82676ee1b4fc76/etltk-0.0.12-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "4649ee0fd69aa2f8dee303e3b2c88af8",
                    "sha256": "7d4aaa6fa563ea020723b74d0436a2ae18693757ec86247e4297a5f8bb6cc9e3"
                },
                "downloads": -1,
                "filename": "etltk-0.0.12.tar.gz",
                "has_sig": false,
                "md5_digest": "4649ee0fd69aa2f8dee303e3b2c88af8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 19830,
                "upload_time": "2022-04-22T17:11:22",
                "upload_time_iso_8601": "2022-04-22T17:11:22.636895Z",
                "url": "https://files.pythonhosted.org/packages/dc/76/a3410ca4b7a00acd6061b1d3aea6d67c27630a56ded998e0b13f1edfa179/etltk-0.0.12.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.14": {
        "info": {
            "author": "Robel Equbasilassie",
            "author_email": "robiki4life@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/robikieq/ethiopian_language_toolkit.git",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "etltk",
            "package_url": "https://pypi.org/project/etltk/",
            "platform": null,
            "project_url": "https://pypi.org/project/etltk/",
            "project_urls": {
                "Homepage": "https://github.com/robikieq/ethiopian_language_toolkit.git"
            },
            "release_url": "https://pypi.org/project/etltk/0.0.14/",
            "requires_dist": [
                "1.7.0 ; extra == 'emoji_'",
                "Emoji ; extra == 'emoji_'",
                "0.0.21 ; extra == 'textsearch_'",
                "TextSearch ; extra == 'textsearch_'"
            ],
            "requires_python": ">=3.6",
            "summary": "Ethiopian Language NLP Toolkit",
            "version": "0.0.14",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13829097,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "8e1934c9b16bed4fd244964c6b900d45",
                    "sha256": "cbfe3f541c0369666a4c6a4b0c8428591f4ba18515cc3ad9dc43b2e88d66e466"
                },
                "downloads": -1,
                "filename": "etltk-0.0.14-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "8e1934c9b16bed4fd244964c6b900d45",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19621,
                "upload_time": "2022-04-23T12:20:48",
                "upload_time_iso_8601": "2022-04-23T12:20:48.723708Z",
                "url": "https://files.pythonhosted.org/packages/7d/ca/06809a1050af363588416beed3beebcbff0dd5656392324d576f265fea0f/etltk-0.0.14-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "5ba197c2d63d4efd4d4fc2d04437bd83",
                    "sha256": "fcbfa241c14bb6cef0549f397d0e016304ac17251ff8fa0beaf9725d72e769cb"
                },
                "downloads": -1,
                "filename": "etltk-0.0.14.tar.gz",
                "has_sig": false,
                "md5_digest": "5ba197c2d63d4efd4d4fc2d04437bd83",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 19477,
                "upload_time": "2022-04-23T12:20:51",
                "upload_time_iso_8601": "2022-04-23T12:20:51.536263Z",
                "url": "https://files.pythonhosted.org/packages/5d/89/8adfd716d8aeca90d999405204b0fb5203442ad07d5378ec697d9b22ee17/etltk-0.0.14.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.18": {
        "info": {
            "author": "Robel Equbasilassie",
            "author_email": "robiki4life@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/robikieq/ethiopian_language_toolkit.git",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "etltk",
            "package_url": "https://pypi.org/project/etltk/",
            "platform": null,
            "project_url": "https://pypi.org/project/etltk/",
            "project_urls": {
                "Homepage": "https://github.com/robikieq/ethiopian_language_toolkit.git"
            },
            "release_url": "https://pypi.org/project/etltk/0.0.18/",
            "requires_dist": [
                "textsearch (==0.0.21)",
                "emoji (==1.7.0)"
            ],
            "requires_python": ">=3.6",
            "summary": "Ethiopian Language NLP Toolkit",
            "version": "0.0.18",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13829097,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "723253a551dbbdd60f0b3e04e4393971",
                    "sha256": "5ab1949eab98eeeb38167504e83255014c9823a5f6b16be7bf542d87329c9b26"
                },
                "downloads": -1,
                "filename": "etltk-0.0.18-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "723253a551dbbdd60f0b3e04e4393971",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19583,
                "upload_time": "2022-04-25T10:49:59",
                "upload_time_iso_8601": "2022-04-25T10:49:59.543032Z",
                "url": "https://files.pythonhosted.org/packages/39/30/f0dcbdce731250c24f4977b8b2f14bdca0e6bbde93ba547dd96320a1574a/etltk-0.0.18-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "21f9227848c727d9d25c91f3a7d06f3d",
                    "sha256": "4682da5507d5852cac3c1a061c0c110879b00a628f8f3514d7f79404c03a5f6a"
                },
                "downloads": -1,
                "filename": "etltk-0.0.18.tar.gz",
                "has_sig": false,
                "md5_digest": "21f9227848c727d9d25c91f3a7d06f3d",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 19449,
                "upload_time": "2022-04-25T10:50:03",
                "upload_time_iso_8601": "2022-04-25T10:50:03.376881Z",
                "url": "https://files.pythonhosted.org/packages/94/fc/ccb48fedecd1fa0ad86b87bc06f73dad1be58c2a916d1a7031ed7fa02bf7/etltk-0.0.18.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.20": {
        "info": {
            "author": "Robel Equbasilassie",
            "author_email": "robiki4life@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/robikieq/ethiopian_language_toolkit.git",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "etltk",
            "package_url": "https://pypi.org/project/etltk/",
            "platform": null,
            "project_url": "https://pypi.org/project/etltk/",
            "project_urls": {
                "Homepage": "https://github.com/robikieq/ethiopian_language_toolkit.git"
            },
            "release_url": "https://pypi.org/project/etltk/0.0.20/",
            "requires_dist": [
                "textsearch (>=0.0.21)",
                "emoji (>=1.7.0)"
            ],
            "requires_python": ">=3.6",
            "summary": "Ethiopian Language NLP Toolkit",
            "version": "0.0.20",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13829097,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "2f34873b01c1bcfcb5dd4fe68291d578",
                    "sha256": "e431195a3bef69702b87dd1adef92d999d13ef07ec2a7162a1882523dbde67c1"
                },
                "downloads": -1,
                "filename": "etltk-0.0.20-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "2f34873b01c1bcfcb5dd4fe68291d578",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 19695,
                "upload_time": "2022-04-27T08:10:22",
                "upload_time_iso_8601": "2022-04-27T08:10:22.487051Z",
                "url": "https://files.pythonhosted.org/packages/87/b4/989a42f0af525257c28d1f1a5bebec3623a8291437152904822f6a342f95/etltk-0.0.20-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "4a9b38f7106035a215b8800479f88eae",
                    "sha256": "ed29371e25fe9eaf04799394e139205138a7fa8d9b519bdb9a03d090a6f75cc9"
                },
                "downloads": -1,
                "filename": "etltk-0.0.20.tar.gz",
                "has_sig": false,
                "md5_digest": "4a9b38f7106035a215b8800479f88eae",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 19556,
                "upload_time": "2022-04-27T08:10:28",
                "upload_time_iso_8601": "2022-04-27T08:10:28.107525Z",
                "url": "https://files.pythonhosted.org/packages/8f/db/b2fdb600efc69886d5bea7a6199760bcac3b33630edd99e648f5a5cf05e2/etltk-0.0.20.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.22": {
        "info": {
            "author": "Robel Equbasilassie",
            "author_email": "robiki4life@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "# Ethiopian Language Toolkit (etltk)\n\n- The Ethiopian Natural Language Toolkit (ETLTK) project aimed to develop a suite of open source Natural Language Processing modules for the Ethiopian languages.\n- The Ethiopian Language Toolkit (ETLTK) is built using python language and takes inspiration from `spacy` and `nltk` libraries.\n\n## Installation\n\n### pip\n\n- **etltk** supports Python 3.6 or later. We recommend that you install etltk via `pip`, the Python package manager. To install, simply run:\n\n  ```python\n    pip install etltk\n  ```\n\n### From Source\n\n- Alternatively, you can also install from source via ethiopian_language_toolkit\u2019s git repository, which will give you more flexibility in developing on top of etltk. For this option, run\n\n  ```python\n    git clone https://github.com/robikieq/ethiopian_language_toolkit.git\n    \n    cd ethiopian_language_toolkit\n    \n    pip install -e .\n  ```\n\n## Documentation\n\nhttps://etltk.netlify.app/\n\n## Usage\n\n1. Amharic text preprocessing with Amharic document\n    - Preprocessing amharic text is very simple: you can simply pass the text to the `Amharic` document and access all annotations from the returned Amharic document object:\n\n    ```python\n      from etltk import Amharic\n\n      sample_text = \"\"\"\n        \u121a\u12eb\u12dd\u12eb 14\u1363 2014 \u12d3.\u121d \ud83e\udd17 \u1260\u12a0\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 /Artificial Intelligence/ \u12a0\u1201\u1295 \u12ab\u1208\u1260\u1275 \u12dd\u1245\u1270\u129b \u12f0\u1228\u1303 \u12c8\u12f0 \u120b\u1240 \u12f0\u1228\u1303 \u1208\u121b\u12f5\u1228\u1235\u1363 \u1203\u1308\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u12d3\u1208\u121d \u1270\u12f0\u122b\u123d \u1208\u121b\u12f5\u1228\u130d\u1363 \u12a0\u1308\u122b\u12ca \u12a0\u1245\u121d\u1295 \u1208\u121b\u1233\u12f0\u130d \u12a5\u1293 \u1270\u1320\u1243\u121a \u1208\u1218\u1206\u1295 \u1260\u130b\u122b \u12a0\u1265\u122e \u1218\u1235\u122b\u1271 \u12a5\u1305\u130d \u1320\u1243\u121a \u1290\u12cd\u1361\u1361\n\n        \u1260\u121b\u123d\u1295 \u12d3\u1235\u1270\u121d\u122e (Machine Learning) \u12a0\u121b\u12ab\u129d\u1290\u1275 \u12e8\u133d\u1201\u134d \u1293\u1219\u1293\u12ce\u127d \u1260\u12a0\u122d\u1272\u134a\u123b\u120d \u12a2\u1295\u1270\u1208\u1300\u1295\u1235 \u1225\u122d\u12d3\u1275 \u1208\u121b\u1230\u120d\u1320\u1295\u1363 \u12e8\u133d\u1201\u134d \u12f3\u1273\u1295 \u1218\u1230\u1265\u1230\u1265 \u12a5\u1293 \u121b\u12f0\u122b\u1300\u1275\u1364 \u12e8\u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d\u1295 /Natural Language Processing Tools/ \u1260\u1218\u1320\u1240\u121d \u12e8\u133d\u1201\u134d \u12f3\u1273\u1295 \u1355\u122e\u1230\u1235 \u121b\u12f5\u1228\u130d \u1270\u1240\u12f3\u121a \u12a5\u1293 \u1218\u1230\u1228\u1273\u12ca \u1309\u12f3\u12ed \u1290\u12cd\u1362\n      \"\"\"\n  \n      # Annotating Amharic document\n      doc = Amharic(sample_text)\n\n      # print the `clean` text:\n      print(doc)\n      \n      # output: Amharic(\"\u121a\u12eb\u12dd\u12eb \u12d3\u1218\u1270 \u121d\u1205\u1228\u1275 \u1260\u12a0\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 \u12a0\u1201\u1295 \u12ab\u1208\u1260\u1275 \u12dd\u1245\u1270\u129b \u12f0\u1228\u1303 \u12c8\u12f0 \u120b\u1240 \u12f0\u1228\u1303 \u1208\u121b\u12f5\u1228\u1235 \u1200\u1308\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u12a0\u1208\u121d \u1270\u12f0\u122b\u123d \u1208\u121b\u12f5\u1228\u130d \u12a0\u1308\u122b\u12ca \u12a0\u1245\u121d\u1295 \u1208\u121b\u1233\u12f0\u130d \u12a5\u1293 \u1270\u1320\u1243\u121a \u1208\u1218\u1206\u1295 \u1260\u130b\u122b \u12a0\u1265\u122e \u1218\u1235\u122b\u1271 \u12a5\u1305\u130d \u1320\u1243\u121a \u1290\u12cd \u1260\u121b\u123d\u1295 \u12a0\u1235\u1270\u121d\u122e \u12a0\u121b\u12ab\u129d\u1290\u1275 \u12e8\u1345\u1201\u134d \u1293\u1219\u1293\u12ce\u127d \u1260\u12a0\u122d\u1272\u134a\u123b\u120d \u12a2\u1295\u1270\u1208\u1300\u1295\u1235 \u1235\u122d\u12a0\u1275 \u1208\u121b\u1230\u120d\u1320\u1295 \u12e8\u1345\u1201\u134d \u12f3\u1273\u1295 \u1218\u1230\u1265\u1230\u1265 \u12a5\u1293 \u121b\u12f0\u122b\u1300\u1275 \u12e8\u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d\u1295 \u1260\u1218\u1320\u1240\u121d \u12e8\u1345\u1201\u134d \u12f3\u1273\u1295 \u1355\u122e\u1230\u1235 \u121b\u12f5\u1228\u130d \u1270\u1240\u12f3\u121a \u12a5\u1293 \u1218\u1230\u1228\u1273\u12ca \u1309\u12f3\u12ed \u1290\u12cd\")\n    ```\n\n     - Here is a another example of performing text cleaning on a piece of plaintext using `clean_amharic` function:\n\n    ```python\n    from etltk.lang.am import (\n      preprocessing,\n      clean_amharic\n    )\n\n    sample_text = \"\"\"\n      \u121a\u12eb\u12dd\u12eb 14\u1363 2014 \u12d3.\u121d \ud83e\udd17 \u1260\u12a0\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 /Artificial Intelligence/ \u12a0\u1201\u1295 \u12ab\u1208\u1260\u1275 \u12dd\u1245\u1270\u129b \u12f0\u1228\u1303 \u12c8\u12f0 \u120b\u1240 \u12f0\u1228\u1303 \u1208\u121b\u12f5\u1228\u1235\u1363 \u1203\u1308\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u12d3\u1208\u121d \u1270\u12f0\u122b\u123d \u1208\u121b\u12f5\u1228\u130d\u1363 \u12a0\u1308\u122b\u12ca \u12a0\u1245\u121d\u1295 \u1208\u121b\u1233\u12f0\u130d \u12a5\u1293 \u1270\u1320\u1243\u121a \u1208\u1218\u1206\u1295 \u1260\u130b\u122b \u12a0\u1265\u122e \u1218\u1235\u122b\u1271 \u12a5\u1305\u130d \u1320\u1243\u121a \u1290\u12cd\u1361\u1361\n\n      \u1260\u121b\u123d\u1295 \u12d3\u1235\u1270\u121d\u122e (Machine Learning) \u12a0\u121b\u12ab\u129d\u1290\u1275 \u12e8\u133d\u1201\u134d \u1293\u1219\u1293\u12ce\u127d \u1260\u12a0\u122d\u1272\u134a\u123b\u120d \u12a2\u1295\u1270\u1208\u1300\u1295\u1235 \u1225\u122d\u12d3\u1275 \u1208\u121b\u1230\u120d\u1320\u1295\u1363 \u12e8\u133d\u1201\u134d \u12f3\u1273\u1295 \u1218\u1230\u1265\u1230\u1265 \u12a5\u1293 \u121b\u12f0\u122b\u1300\u1275\u1364 \u12e8\u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d\u1295 /Natural Language Processing Tools/ \u1260\u1218\u1320\u1240\u121d \u12e8\u133d\u1201\u134d \u12f3\u1273\u1295 \u1355\u122e\u1230\u1235 \u121b\u12f5\u1228\u130d \u1270\u1240\u12f3\u121a \u12a5\u1293 \u1218\u1230\u1228\u1273\u12ca \u1309\u12f3\u12ed \u1290\u12cd\u1362\n    \"\"\"\n\n    # Define a custom preprocessor pipeline\n    custom_pipeline = [\n      preprocessing.remove_emojis, \n      preprocessing.remove_digits,\n      preprocessing.remove_ethiopic_punct,\n      preprocessing.remove_english_chars, \n      preprocessing.remove_punct\n    ]\n    \n    # `clean_amharic` function takes a custom pipeline, if not uses the default pipeline\n    cleaned = clean_amharic(input_text, abbrev=False, pipeline=custom_pipeline)\n\n    # print the `clean` text:\n    print(cleaned)\n    # output: \u121a\u12eb\u12dd\u12eb \u12d3\u1218\u1270 \u121d\u1205\u1228\u1275 \u1260\u12a0\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 \u12a0\u1201\u1295 \u12ab\u1208\u1260\u1275 \u12dd\u1245\u1270\u129b \u12f0\u1228\u1303 \u12c8\u12f0 \u120b\u1240 \u12f0\u1228\u1303 \u1208\u121b\u12f5\u1228\u1235 \u1200\u1308\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u12a0\u1208\u121d \u1270\u12f0\u122b\u123d \u1208\u121b\u12f5\u1228\u130d \u12a0\u1308\u122b\u12ca \u12a0\u1245\u121d\u1295 \u1208\u121b\u1233\u12f0\u130d \u12a5\u1293 \u1270\u1320\u1243\u121a \u1208\u1218\u1206\u1295 \u1260\u130b\u122b \u12a0\u1265\u122e \u1218\u1235\u122b\u1271 \u12a5\u1305\u130d \u1320\u1243\u121a \u1290\u12cd \u1260\u121b\u123d\u1295 \u12a0\u1235\u1270\u121d\u122e \u12a0\u121b\u12ab\u129d\u1290\u1275 \u12e8\u1345\u1201\u134d \u1293\u1219\u1293\u12ce\u127d \u1260\u12a0\u122d\u1272\u134a\u123b\u120d \u12a2\u1295\u1270\u1208\u1300\u1295\u1235 \u1235\u122d\u12a0\u1275 \u1208\u121b\u1230\u120d\u1320\u1295 \u12e8\u1345\u1201\u134d \u12f3\u1273\u1295 \u1218\u1230\u1265\u1230\u1265 \u12a5\u1293 \u121b\u12f0\u122b\u1300\u1275 \u12e8\u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d\u1295 \u1260\u1218\u1320\u1240\u121d \u12e8\u1345\u1201\u134d \u12f3\u1273\u1295 \u1355\u122e\u1230\u1235 \u121b\u12f5\u1228\u130d \u1270\u1240\u12f3\u121a \u12a5\u1293 \u1218\u1230\u1228\u1273\u12ca \u1309\u12f3\u12ed \u1290\u12cd\n    ```\n\n2. Tokenization - Sentence\n    - Here is a simple example of performing sentence tokenization on a piece of plaintext using Amharic document:\n    - Within Amharic document, annotations are further stored in `Sentences`\n\n    ```python\n    from etltk import Amharic\n\n    sample_text = \"\"\"\n      \u12e8\u121b\u123d\u1295 \u1208\u122d\u1292\u1295\u130d \u1235\u120d\u1270-\u1240\u1218\u122e\u127d  (Algorithms) \u1260\u1218\u1320\u1240\u121d \u124b\u1295\u124b\u12ce\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12a5\u1293 \u1218\u1228\u12f3\u1275\u1363 \u12e8\u133d\u1201\u134d \u12ed\u12d8\u1276\u127d\u1295 \u1218\u1208\u12e8\u1275\u1363 \u12e8\u124b\u1295\u124b\u1295 \u1218\u12cb\u1245\u122d \u1218\u1270\u1295\u1270\u1295 \u12e8\u121a\u12eb\u1235\u127d\u1209 \u12e8\u1203\u1308\u122a\u129b \u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d (NLP tools) \u1363 \u1235\u120d\u1270-\u1240\u1218\u122e\u127d \u12a5\u1293 \u121e\u12f4\u120e\u127d\u1295 \u121b\u12d8\u130b\u1300\u1275 \u1270\u1308\u1262 \u1290\u12cd\u1362 \u1260\u12da\u1205\u121d \u1218\u1230\u1228\u1275 \u12a0\u121b\u122d\u129b\u1363 \u12a0\u134b\u1295 \u12a6\u122e\u121e\u1363 \u1236\u121b\u120a\u129b \u12a5\u1293 \u1275\u130d\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u121b\u123d\u1295 \u12e8\u121b\u1235\u1270\u121b\u122d \u1202\u12f0\u1275\u1295 \u1240\u120b\u120d\u1293 \u12e8\u1270\u1240\u120b\u1270\u134d \u12a5\u1295\u12f2\u1206\u1295 \u12eb\u1235\u127d\u120b\u120d\u1361\u1361\n    \"\"\"\n\n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `Sentence` in a document:\n    print(doc.sentences)\n    # output: [Sentence(\"\u12e8\u121b\u123d\u1295 \u1208\u122d\u1292\u1295\u130d \u1235\u120d\u1270\u1240\u1218\u122e\u127d \u1260\u1218\u1320\u1240\u121d \u124b\u1295\u124b\u12ce\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12a5\u1293 \u1218\u1228\u12f3\u1275 \u12e8\u1345\u1201\u134d \u12ed\u12d8\u1276\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12e8\u124b\u1295\u124b\u1295 \u1218\u12cb\u1245\u122d \u1218\u1270\u1295\u1270\u1295 \u12e8\u121a\u12eb\u1235\u127d\u1209 \u12e8\u1200\u1308\u122a\u129b \u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d \u1235\u120d\u1270\u1240\u1218\u122e\u127d \u12a5\u1293 \u121e\u12f4\u120e\u127d\u1295 \u121b\u12d8\u130b\u1300\u1275 \u1270\u1308\u1262 \u1290\u12cd\"), Sentence(\"\u1260\u12da\u1205\u121d \u1218\u1230\u1228\u1275 \u12a0\u121b\u122d\u129b \u12a0\u134b\u1295 \u12a6\u122e\u121e \u1236\u121b\u120a\u129b \u12a5\u1293 \u1275\u130d\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u121b\u123d\u1295 \u12e8\u121b\u1235\u1270\u121b\u122d \u1202\u12f0\u1275\u1295 \u1240\u120b\u120d\u1293 \u12e8\u1270\u1240\u120b\u1270\u134d \u12a5\u1295\u12f2\u1206\u1295 \u12eb\u1235\u127d\u120b\u120d\")]\n    ```\n\n    - Here is another example of performing sentence tokenization on a piece of plaintext using `sentence_tokenize` function:\n\n    ```python\n    from etltk.tokenize.am import sent_tokenize\n\n    sample_text = \"\"\"\n      \u12e8\u121b\u123d\u1295 \u1208\u122d\u1292\u1295\u130d \u1235\u120d\u1270-\u1240\u1218\u122e\u127d  (Algorithms) \u1260\u1218\u1320\u1240\u121d \u124b\u1295\u124b\u12ce\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12a5\u1293 \u1218\u1228\u12f3\u1275\u1363 \u12e8\u133d\u1201\u134d \u12ed\u12d8\u1276\u127d\u1295 \u1218\u1208\u12e8\u1275\u1363 \u12e8\u124b\u1295\u124b\u1295 \u1218\u12cb\u1245\u122d \u1218\u1270\u1295\u1270\u1295 \u12e8\u121a\u12eb\u1235\u127d\u1209 \u12e8\u1203\u1308\u122a\u129b \u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d (NLP tools) \u1363 \u1235\u120d\u1270-\u1240\u1218\u122e\u127d \u12a5\u1293 \u121e\u12f4\u120e\u127d\u1295 \u121b\u12d8\u130b\u1300\u1275 \u1270\u1308\u1262 \u1290\u12cd\u1362 \u1260\u12da\u1205\u121d \u1218\u1230\u1228\u1275 \u12a0\u121b\u122d\u129b\u1363 \u12a0\u134b\u1295 \u12a6\u122e\u121e\u1363 \u1236\u121b\u120a\u129b \u12a5\u1293 \u1275\u130d\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u121b\u123d\u1295 \u12e8\u121b\u1235\u1270\u121b\u122d \u1202\u12f0\u1275\u1295 \u1240\u120b\u120d\u1293 \u12e8\u1270\u1240\u120b\u1270\u134d \u12a5\u1295\u12f2\u1206\u1295 \u12eb\u1235\u127d\u120b\u120d\u1361\u1361\n    \"\"\"\n\n    # Annotating a Document\n    sentences = sent_tokenize(sample_text)\n\n    # print all list of sentence:\n    print(sentences)\n    # output: ['\u12e8\u121b\u123d\u1295 \u1208\u122d\u1292\u1295\u130d \u1235\u120d\u1270\u1240\u1218\u122e\u127d \u1260\u1218\u1320\u1240\u121d \u124b\u1295\u124b\u12ce\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12a5\u1293 \u1218\u1228\u12f3\u1275 \u12e8\u1345\u1201\u134d \u12ed\u12d8\u1276\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12e8\u124b\u1295\u124b\u1295 \u1218\u12cb\u1245\u122d \u1218\u1270\u1295\u1270\u1295 \u12e8\u121a\u12eb\u1235\u127d\u1209 \u12e8\u1200\u1308\u122a\u129b \u1293\u1279\u122b\u120d \u120b\u1295\u1309\u12cc\u1305 \u1355\u122e\u1230\u1232\u1295\u130d \u1271\u120e\u127d \u1235\u120d\u1270\u1240\u1218\u122e\u127d \u12a5\u1293 \u121e\u12f4\u120e\u127d\u1295 \u121b\u12d8\u130b\u1300\u1275 \u1270\u1308\u1262 \u1290\u12cd', '\u1260\u12da\u1205\u121d \u1218\u1230\u1228\u1275 \u12a0\u121b\u122d\u129b \u12a0\u134b\u1295 \u12a6\u122e\u121e \u1236\u121b\u120a\u129b \u12a5\u1293 \u1275\u130d\u122d\u129b \u124b\u1295\u124b\u12ce\u127d\u1295 \u1208\u121b\u123d\u1295 \u12e8\u121b\u1235\u1270\u121b\u122d \u1202\u12f0\u1275\u1295 \u1240\u120b\u120d\u1293 \u12e8\u1270\u1240\u120b\u1270\u134d \u12a5\u1295\u12f2\u1206\u1295 \u12eb\u1235\u127d\u120b\u120d']\n\n3. Tokenization - Word\n    - Here is a simple example of performing word tokenization on a piece of plaintext using AmharicDocument:\n    - Within Amharic focument, annotations are further stored in `Words`.\n\n    ```python\n    from etltk import AmharicDocument\n\n    sample_text = \"\"\"\n      \u201c\u1270\u1228\u129b\u1363 \u1270\u1228\u129b!\u201d \u12a0\u1208 \u1290\u122d\u1231\u1362 \u12c8\u12ed\u12d8\u122e\n      \u1273\u122a\u12b3\u1363 \u201c\u12a0\u1264\u1275!\u201d \u1265\u1208\u12cd \u12e8\u1201\u1208\u1275\n      \u12d3\u1218\u1275 \u120d\u1303\u1278\u12cd\u1295 \u12ed\u12d8\u12cd \u1308\u1261\u1362\n      \u201c\u121d\u1291\u1295 \u1290\u12cd \u12eb\u1218\u1218\u12cd?\u201d \u12f6\u12ad\u1270\u122f\n      \u1320\u12e8\u1241\u1362 \u201c\u12a0\u12eb\u12e9\u1275\u121d! \u1340\u1309\u1229 \u1233\u1235\u1277\u120d\u1364\n      \u1206\u12f1 \u1270\u1290\u134d\u1277\u120d\u1364 \u12f5\u12f1\u121d \u12ed\u12f0\u121b\u120d\u201d\n      \u12a0\u1209 \u12c8\u12ed\u12d8\u122e \u1273\u122a\u12b3\u1362 \u12f6\u12ad\u1270\u122f\u121d\u1363\n      \u201c\u1260\u1323\u121d \u12eb\u1233\u12dd\u1293\u120d\u1364 \u12a5\u1295\u12f0\u12da\u1205\n      \u12eb\u12f0\u1228\u1308\u12cd \u12e8\u1270\u1218\u1323\u1320\u1290 \u121d\u130d\u1265 \u12a0\u1208\u121b\u130d\u1298\u1271 \u1290\u12cd\u1362 \u12a0\u1201\u1295\u121d \u12c8\u1270\u1275\u1363\n      \u12a5\u1295\u1241\u120b\u120d\u1363 \u121b\u122d\u1363 \u12a0\u1275\u12ad\u120d\u1275\u1293 \u134d\u122b\u134d\u122c \u12ed\u1218\u130d\u1261\u1275\u1364 \u1276\u120e \u12ed\u123b\u1208\u12cb\u120d\u1364\n      \u1208\u12a0\u1201\u1291 \u130d\u1295 \u1218\u12f5\u1283\u1292\u1275 \u12a0\u12dd\u1208\u1273\u1208\u1201\u201d \u1260\u121b\u1208\u1275 \u12a0\u1235\u1228\u12f7\u1278\u12cd\u1362 \u12c8\u12ed\u12d8\u122e\n      \u1273\u122a\u12b3\u121d \u201c\u12c8\u12ed \u12a0\u1208\u121b\u12c8\u1245! \u120d\u1304\u1295 \u1260\u121d\u130d\u1265 \u12a5\u1325\u1228\u1275 \u1308\u12f5\u12ec\u12cd \u1290\u1260\u122d\"\n      \u1260\u121b\u1208\u1275 \u12a0\u1208\u1240\u1231\u1362\n\n      \"\"\"\n    \n    # Annotating Amharic Text\n    doc = Amharic(sample_text)\n\n    # print all list of `AmharicWord` in a document:\n    print(doc.words)\n    # output: ['\u1270\u1228\u129b', '\u1270\u1228\u129b', '\u12a0\u1208', '\u1290\u122d\u1231', '\u12c8\u12ed\u12d8\u122e', '\u1273\u122a\u12b3', '\u12a0\u1264\u1275', '\u1265\u1208\u12cd', '\u12e8\u1201\u1208\u1275', '\u12a0\u1218\u1275', '\u120d\u1303\u1278\u12cd\u1295', '\u12ed\u12d8\u12cd', '\u1308\u1261', '\u121d\u1291\u1295', '\u1290\u12cd', '\u12eb\u1218\u1218\u12cd', '\u12f6\u12ad\u1270\u122f', '\u1320\u12e8\u1241', '\u12a0\u12eb\u12e9\u1275\u121d', '\u1340\u1309\u1229', '\u1233\u1235\u1277\u120d', '\u1206\u12f1', '\u1270\u1290\u134d\u1277\u120d', '\u12f5\u12f1\u121d', '\u12ed\u12f0\u121b\u120d', '\u12a0\u1209', '\u12c8\u12ed\u12d8\u122e', '\u1273\u122a\u12b3', '\u12f6\u12ad\u1270\u122f\u121d', '\u1260\u1323\u121d', '\u12eb\u1233\u12dd\u1293\u120d', '\u12a5\u1295\u12f0\u12da\u1205', '\u12eb\u12f0\u1228\u1308\u12cd', '\u12e8\u1270\u1218\u1323\u1320\u1290', '\u121d\u130d\u1265', '\u12a0\u1208\u121b\u130d\u1298\u1271', '\u1290\u12cd', '\u12a0\u1201\u1295\u121d', '\u12c8\u1270\u1275', '\u12a5\u1295\u1241\u120b\u120d', '\u121b\u122d', '\u12a0\u1275\u12ad\u120d\u1275\u1293', '\u134d\u122b\u134d\u122c', '\u12ed\u1218\u130d\u1261\u1275', '\u1276\u120e', '\u12ed\u123b\u1208\u12cb\u120d', '\u1208\u12a0\u1201\u1291', '\u130d\u1295', '\u1218\u12f5\u1200\u1292\u1275', '\u12a0\u12dd\u1208\u1273\u1208\u1201', '\u1260\u121b\u1208\u1275', '\u12a0\u1235\u1228\u12f7\u1278\u12cd', '\u12c8\u12ed\u12d8\u122e', '\u1273\u122a\u12b3\u121d', '\u12c8\u12ed', '\u12a0\u1208\u121b\u12c8\u1245', '\u120d\u1304\u1295', '\u1260\u121d\u130d\u1265', '\u12a5\u1325\u1228\u1275', '\u1308\u12f5\u12ec\u12cd', '\u1290\u1260\u122d', '\u1260\u121b\u1208\u1275', '\u12a0\u1208\u1240\u1231']\n    ```\n\n    - Here is another example of performing word tokenization on a piece of plaintext using `word_tokenize` function:\n\n    ```python\n    from etltk.tokenize.am import word_tokenize\n\n    sample_text = \"\"\"\n      \u201c\u1270\u1228\u129b\u1363 \u1270\u1228\u129b!\u201d \u12a0\u1208 \u1290\u122d\u1231\u1362 \u12c8\u12ed\u12d8\u122e\n      \u1273\u122a\u12b3\u1363 \u201c\u12a0\u1264\u1275!\u201d \u1265\u1208\u12cd \u12e8\u1201\u1208\u1275\n      \u12d3\u1218\u1275 \u120d\u1303\u1278\u12cd\u1295 \u12ed\u12d8\u12cd \u1308\u1261\u1362\n      \u201c\u121d\u1291\u1295 \u1290\u12cd \u12eb\u1218\u1218\u12cd?\u201d \u12f6\u12ad\u1270\u122f\n      \u1320\u12e8\u1241\u1362 \u201c\u12a0\u12eb\u12e9\u1275\u121d! \u1340\u1309\u1229 \u1233\u1235\u1277\u120d\u1364\n      \u1206\u12f1 \u1270\u1290\u134d\u1277\u120d\u1364 \u12f5\u12f1\u121d \u12ed\u12f0\u121b\u120d\u201d\n      \u12a0\u1209 \u12c8\u12ed\u12d8\u122e \u1273\u122a\u12b3\u1362 \u12f6\u12ad\u1270\u122f\u121d\u1363\n      \u201c\u1260\u1323\u121d \u12eb\u1233\u12dd\u1293\u120d\u1364 \u12a5\u1295\u12f0\u12da\u1205\n      \u12eb\u12f0\u1228\u1308\u12cd \u12e8\u1270\u1218\u1323\u1320\u1290 \u121d\u130d\u1265 \u12a0\u1208\u121b\u130d\u1298\u1271 \u1290\u12cd\u1362 \u12a0\u1201\u1295\u121d \u12c8\u1270\u1275\u1363\n      \u12a5\u1295\u1241\u120b\u120d\u1363 \u121b\u122d\u1363 \u12a0\u1275\u12ad\u120d\u1275\u1293 \u134d\u122b\u134d\u122c \u12ed\u1218\u130d\u1261\u1275\u1364 \u1276\u120e \u12ed\u123b\u1208\u12cb\u120d\u1364\n      \u1208\u12a0\u1201\u1291 \u130d\u1295 \u1218\u12f5\u1283\u1292\u1275 \u12a0\u12dd\u1208\u1273\u1208\u1201\u201d \u1260\u121b\u1208\u1275 \u12a0\u1235\u1228\u12f7\u1278\u12cd\u1362 \u12c8\u12ed\u12d8\u122e\n      \u1273\u122a\u12b3\u121d \u201c\u12c8\u12ed \u12a0\u1208\u121b\u12c8\u1245! \u120d\u1304\u1295 \u1260\u121d\u130d\u1265 \u12a5\u1325\u1228\u1275 \u1308\u12f5\u12ec\u12cd \u1290\u1260\u122d\"\n      \u1260\u121b\u1208\u1275 \u12a0\u1208\u1240\u1231\u1362\n\n    \"\"\"\n      \n    # word tokenization\n    words = word_tokenize(sample_text)\n\n    # print all list of word:\n    print(words)\n    # output: ['\u1270\u1228\u129b', '\u1270\u1228\u129b', '\u12a0\u1208', '\u1290\u122d\u1231', '\u12c8\u12ed\u12d8\u122e', '\u1273\u122a\u12b3', '\u12a0\u1264\u1275', '\u1265\u1208\u12cd', '\u12e8\u1201\u1208\u1275', '\u12a0\u1218\u1275', '\u120d\u1303\u1278\u12cd\u1295', '\u12ed\u12d8\u12cd', '\u1308\u1261', '\u121d\u1291\u1295', '\u1290\u12cd', '\u12eb\u1218\u1218\u12cd', '\u12f6\u12ad\u1270\u122f', '\u1320\u12e8\u1241', '\u12a0\u12eb\u12e9\u1275\u121d', '\u1340\u1309\u1229', '\u1233\u1235\u1277\u120d', '\u1206\u12f1', '\u1270\u1290\u134d\u1277\u120d', '\u12f5\u12f1\u121d', '\u12ed\u12f0\u121b\u120d', '\u12a0\u1209', '\u12c8\u12ed\u12d8\u122e', '\u1273\u122a\u12b3', '\u12f6\u12ad\u1270\u122f\u121d', '\u1260\u1323\u121d', '\u12eb\u1233\u12dd\u1293\u120d', '\u12a5\u1295\u12f0\u12da\u1205', '\u12eb\u12f0\u1228\u1308\u12cd', '\u12e8\u1270\u1218\u1323\u1320\u1290', '\u121d\u130d\u1265', '\u12a0\u1208\u121b\u130d\u1298\u1271', '\u1290\u12cd', '\u12a0\u1201\u1295\u121d', '\u12c8\u1270\u1275', '\u12a5\u1295\u1241\u120b\u120d', '\u121b\u122d', '\u12a0\u1275\u12ad\u120d\u1275\u1293', '\u134d\u122b\u134d\u122c', '\u12ed\u1218\u130d\u1261\u1275', '\u1276\u120e', '\u12ed\u123b\u1208\u12cb\u120d', '\u1208\u12a0\u1201\u1291', '\u130d\u1295', '\u1218\u12f5\u1200\u1292\u1275', '\u12a0\u12dd\u1208\u1273\u1208\u1201', '\u1260\u121b\u1208\u1275', '\u12a0\u1235\u1228\u12f7\u1278\u12cd', '\u12c8\u12ed\u12d8\u122e', '\u1273\u122a\u12b3\u121d', '\u12c8\u12ed', '\u12a0\u1208\u121b\u12c8\u1245', '\u120d\u1304\u1295', '\u1260\u121d\u130d\u1265', '\u12a5\u1325\u1228\u1275', '\u1308\u12f5\u12ec\u12cd', '\u1290\u1260\u122d', '\u1260\u121b\u1208\u1275', '\u12a0\u1208\u1240\u1231']\n\n4. Normalization\n    1. Character Level Normalization such as \"`\u1338`\u1200\u12ed\" and \"`\u1340`\u1210\u12ed\"\n    2. Labialized Character Normalzation such as \"\u121e\u120d`\u1271\u12cb`\u120d\" to \"\u121e\u120d`\u1277`\u120d\"\n    3. Short Form Expansion such as \"`\u12a0.\u12a0`\" to \"`\u12a0\u12f2\u1235 \u12a0\u1260\u1263`\"\n    4. Punctuation Normalization such as `::` to `\u1362`\n\n    - Here is a simple example of performing normalization on a piece of plaintext using `normalize` function:\n\n    ```python\n    from etltk.lang.am import normalize\n\n    sample_text = \"\"\"\n      \u121a\u12eb\u12dd\u12eb 14\u1363 2014 \u12d3.\u121d \u1260\u12d3\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 \u12e8\u12cd\u12ed\u12ed\u1275 \u1218\u12f5\u1228\u12ad \u120b\u12ed\n      \u12e8\u1203\u1308\u122d\u129b \u124b\u1295\u124b\u12ce\u127d \u1275\u122d\u1309\u121d \u12a0\u1308\u120d\u130d\u120e\u1275\u1363 \n      \u127b\u1275\u1266\u1275 (\u12e8\u12cd\u12ed\u12ed\u1275 \u1218\u1208\u12cb\u12c8\u132b \u122e\u1266\u1275): \n      \u12e8\u1345\u1201\u134d \u1230\u1290\u12f6\u127d \u1208\u1218\u1208\u12e8\u1275\u1363 \u12e8\u1243\u120b\u1275 \u1275\u12ad\u12ad\u1208\u129b\u1290\u1275\u1295 \u1208\u121b\u1228\u130b\u1308\u1325\u1363 \n      \u1260\u124b\u1295\u124b\u1295 \u1215\u130d\u130b\u1275 \u1218\u1220\u1228\u1275 \u133d\u1211\u134e\u127d\u1295 \u1208\u121b\u12cb\u1240\u122d \u12a5\u1293 \u1208\u1218\u1218\u1235\u1228\u1275\u1363 \n      \u1228\u1305\u121d \u133d\u1201\u134e\u127d\u1295 \u1208\u121b\u1233\u1320\u122d\u1363 \u12a0\u1295\u12b3\u122d \u1309\u12f3\u12ee\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12c8\u12ed\u121d \u1325\u1245\u120d \u1203\u1233\u1265 \u1208\u121b\u12cd\u1323\u1275\u1363 \n      \u1295\u130d\u130d\u122d\u1295 \u12c8\u12f0 \u133d\u1201\u134d \u1208\u1218\u1240\u12e8\u122d \u12e8\u121a\u12eb\u1235\u127d\u1209 \u1218\u1270\u130d\u1260\u122a\u12eb\u12ce\u127d\u1295 \u121b\u120d\u121b\u1275 \u12a0\u1235\u1228\u120b\u130a\u1290\u1271 \u1270\u1308\u120d\u1339\u12cb\u120d::\n    \"\"\"\n\n    # normalization\n    normalized_text = normalize(sample_text)\n\n    # The following example shows how to print all normalized in a document:\n    print(normalized_text)\n    # output: \u121a\u12eb\u12dd\u12eb 14\u1363 2014 \u12a0\u1218\u1270 \u121d\u1205\u1228\u1275 \u1260\u12a0\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 \u12e8\u12cd\u12ed\u12ed\u1275 \u1218\u12f5\u1228\u12ad \u120b\u12ed\n    # \u12e8\u1200\u1308\u122d\u129b \u124b\u1295\u124b\u12ce\u127d \u1275\u122d\u1309\u121d \u12a0\u1308\u120d\u130d\u120e\u1275\u1363 \n    # \u127b\u1275\u1266\u1275 (\u12e8\u12cd\u12ed\u12ed\u1275 \u1218\u1208\u12cb\u12c8\u132b \u122e\u1266\u1275)\u1361 \n    # \u12e8\u1345\u1201\u134d \u1230\u1290\u12f6\u127d \u1208\u1218\u1208\u12e8\u1275\u1363 \u12e8\u1243\u120b\u1275 \u1275\u12ad\u12ad\u1208\u129b\u1290\u1275\u1295 \u1208\u121b\u1228\u130b\u1308\u1325\u1363 \n    # \u1260\u124b\u1295\u124b\u1295 \u1205\u130d\u130b\u1275 \u1218\u1230\u1228\u1275 \u1345\u1201\u134e\u127d\u1295 \u1208\u121b\u12cb\u1240\u122d \u12a5\u1293 \u1208\u1218\u1218\u1235\u1228\u1275\u1363 \n    # \u1228\u1305\u121d \u1345\u1201\u134e\u127d\u1295 \u1208\u121b\u1233\u1320\u122d\u1363 \u12a0\u1295\u12b3\u122d \u1309\u12f3\u12ee\u127d\u1295 \u1218\u1208\u12e8\u1275 \u12c8\u12ed\u121d \u1325\u1245\u120d \u1200\u1233\u1265 \u1208\u121b\u12cd\u1323\u1275\u1363 \n    # \u1295\u130d\u130d\u122d\u1295 \u12c8\u12f0 \u1345\u1201\u134d \u1208\u1218\u1240\u12e8\u122d \u12e8\u121a\u12eb\u1235\u127d\u1209 \u1218\u1270\u130d\u1260\u122a\u12eb\u12ce\u127d\u1295 \u121b\u120d\u121b\u1275 \u12a0\u1235\u1228\u120b\u130a\u1290\u1271 \u1270\u1308\u120d\u133f\u120d\u1362 \"\"\"\n    ```\n\n    - Here is another example of performing normalization on a piece of plaintext using `normalize_char`, `normalize_punct`, `normalize_labialized`, `normalize_shortened` function:\n\n    ```python\n    from etltk.lang.am.normalizer import ( \n      normalize_labialized, \n      normalize_shortened,\n      normalize_punct,\n      normalize_char\n    )\n\n    # normalize labialized \n    normalized_text = normalize_labialized(\"\u1295\u130d\u130d\u122d\u1295 \u12c8\u12f0 \u133d\u1201\u134d \u1208\u1218\u1240\u12e8\u122d \u12e8\u121a\u12eb\u1235\u127d\u1209 \u1218\u1270\u130d\u1260\u122a\u12eb\u12ce\u127d\u1295 \u121b\u120d\u121b\u1275 \u12a0\u1235\u1228\u120b\u130a\u1290\u1271 \u1270\u1308\u120d\u1339\u12cb\u120d\")\n    print(normalized_text)\n    # output: \u1295\u130d\u130d\u122d\u1295 \u12c8\u12f0 \u1345\u1201\u134d \u1208\u1218\u1240\u12e8\u122d \u12e8\u121a\u12eb\u1235\u127d\u1209 \u1218\u1270\u130d\u1260\u122a\u12eb\u12ce\u127d\u1295 \u121b\u120d\u121b\u1275 \u12a0\u1235\u1228\u120b\u130a\u1290\u1271 \u1270\u1308\u120d\u133f\u120d\n\n    # normalize short forms\n    normalized_text = normalize_shortened(\"\u121a\u12eb\u12dd\u12eb 14\u1363 2014 \u12d3.\u121d \u1260\u12d3\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 \u12e8\u12cd\u12ed\u12ed\u1275 \u1218\u12f5\u1228\u12ad\")\n    print(normalized_text)\n    # output: \u121a\u12eb\u12dd\u12eb 14\u1363 2014 \u12d3\u1218\u1270 \u121d\u1205\u1228\u1275 \u1260\u12a0\u1308\u122d \u12f0\u1228\u1303 \u12e8\u1230\u12cd \u1230\u122b\u123d \u12a0\u1235\u1270\u12cd\u120e\u1275 \u12e8\u12cd\u12ed\u12ed\u1275 \u1218\u12f5\u1228\u12ad\n\n    # normalize punctuation\n    normalized_text = normalize_punct(\"\u1218\u1270\u130d\u1260\u122a\u12eb\u12ce\u127d\u1295 \u121b\u120d\u121b\u1275 \u12a0\u1235\u1228\u120b\u130a\u1290\u1271 \u1270\u1308\u120d\u1339\u12cb\u120d::\")\n    print(normalized_text)\n    # output: \u1218\u1270\u130d\u1260\u122a\u12eb\u12ce\u127d\u1295 \u121b\u120d\u121b\u1275 \u12a0\u1235\u1228\u120b\u130a\u1290\u1271 \u1270\u1308\u120d\u133f\u120d\u1362\n\n    # normalize characters\n    normalized_text = normalize_char(\"\u1260\u124b\u1295\u124b\u12c9 \u1215\u130d\u130b\u1275 \u1218\u1220\u1228\u1275 \u133d\u1211\u134e\u127d\u1295 \u121b\u12cb\u1240\u122d \u12a5\u1293 \u1218\u1218\u1225\u1228\u1275\")\n    print(normalized_text)\n    # output: \u1260\u124b\u1295\u124b\u12c9 \u1205\u130d\u130b\u1275 \u1218\u1230\u1228\u1275 \u1345\u1201\u134e\u127d\u1295 \u121b\u12cb\u1240\u122d \u12a5\u1293 \u1218\u1218\u1235\u1228\u1275\n\n## Features\n\n- Text preprocessing functions.\n\n    ``` python\n    from etltk.lang.am import preprocessing\n    ```\n\n    | Function | Description |\n    -----------|-------------|\n    | remove_whitespaces | Remove extra spaces, tabs, and new lines from a text string\n    | remove_links | Remove URLs from a text string\n    | remove_tags | Remove HTML tags from a text string\n    | remove_emojis | Remove emojis from a text string\n    | remove_email | Remove email adresses from a text string\n    | remove_digits | Remove all digits from a text string\n    | remove_english_chars | Remove ascii characters from a text string\n    | remove_arabic_chars | Remove arabic characters and numerals from a text string\n    | remove_chinese_chars | Remove chinese characters from a text string\n    | remove_ethiopic_digits | Remove all ethiopic digits from a text string\n    | remove_ethiopic_punct | Remove ethiopic punctuations from a text string\n    | remove_non_ethiopic | Remove non ethioipc characters from a text string\n    | remove_stopwords | Remove stop words\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/robikieq/ethiopian_language_toolkit.git",
            "keywords": "['nlp','ethiopic','amharic','tokenizing','preprocessing','text-analytics']",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "etltk",
            "package_url": "https://pypi.org/project/etltk/",
            "platform": null,
            "project_url": "https://pypi.org/project/etltk/",
            "project_urls": {
                "Homepage": "https://github.com/robikieq/ethiopian_language_toolkit.git"
            },
            "release_url": "https://pypi.org/project/etltk/0.0.22/",
            "requires_dist": [
                "textsearch (>=0.0.21)",
                "emoji (>=1.7.0)"
            ],
            "requires_python": ">=3.6",
            "summary": "Ethiopian Language NLP Toolkit",
            "version": "0.0.22",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13829097,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d16683b9e49641986e2373ded82d2c6a",
                    "sha256": "f5b992a01df2259daa7e1785b85d0b62ba831a52db8da8c91594d8569b0a2f37"
                },
                "downloads": -1,
                "filename": "etltk-0.0.22-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d16683b9e49641986e2373ded82d2c6a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 20570,
                "upload_time": "2022-05-16T11:59:28",
                "upload_time_iso_8601": "2022-05-16T11:59:28.788842Z",
                "url": "https://files.pythonhosted.org/packages/9f/a6/6977be39cc33c57de7d5240b7070513677048fb3f204694c42f4e6c8cbd8/etltk-0.0.22-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "c76905439832e4131d244bf34549074e",
                    "sha256": "3e1992b8fa42ba50e457b601e973126a723327d36f4730da98c132409bee966e"
                },
                "downloads": -1,
                "filename": "etltk-0.0.22.tar.gz",
                "has_sig": false,
                "md5_digest": "c76905439832e4131d244bf34549074e",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 20618,
                "upload_time": "2022-05-16T11:59:34",
                "upload_time_iso_8601": "2022-05-16T11:59:34.390018Z",
                "url": "https://files.pythonhosted.org/packages/f4/7e/e7bb001647397f49fbffe01a0638db011542447fb8d85917c9d7af3163d4/etltk-0.0.22.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
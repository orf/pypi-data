{
    "0.2.0": {
        "info": {
            "author": "VDuchauffour",
            "author_email": "vincent.duchauffour@proton.me",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3 :: Only",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Documentation :: Sphinx",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Information Analysis",
                "Topic :: Software Development :: Libraries :: Python Modules",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description": "<h1 align=\"center\">Transformers visualizer</h1>\n<p align=\"center\">Explain your \ud83e\udd17 transformers without effort!</p>\n<h1 align=\"center\"></h1>\n\n<p align=\"center\">\n    <a href=\"https://opensource.org/licenses/Apache-2.0\">\n        <img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\"/>\n    </a>\n</p>\n\nTransformers visualizer is a python package designed to work with \ud83e\udd17 [transformers](https://huggingface.co/docs/transformers/index) package. Given a <code>model</code> and a <code>tokenizer</code>, this package supports multiple ways to explain your model by plotting its internal behavior.\n\nThis package is mostly based on the [Captum][Captum] tutorials [[1]][captum_part1] [[2]][Captum_part2].\n\n## Installation\n\n```python\npip install transformers-visualizer\n```\n\n## Quickstart\n\nLet's define a model, a tokenizer and a text input for the following examples.\n\n```python\nfrom transformers import AutoModel, AutoTokenizer\n\nmodel_name = \"bert-base-uncased\"\nmodel = AutoModel.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntext = \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder.\"\n```\n\n<details><summary>Attention matrices</summary>\n<p align=\"center\">Plot attention matrices of a specific layer</p>\n\n```python\nfrom transformers_visualizer import TokenToTokenAttentions\n\nvisualizer = TokenToTokenAttentions(model, tokenizer)\nvisualizer(text)\n```\n\nInstead of using `__call__` function, you can use the `compute` method. Both work in place, `compute` method allows chaining method.\n\n`plot` method accept a layer index as parameter to specify which part of your model you want to plot. By default, the last layer is plotted.\n\n```python\nimport matplotlib.pyplot as plt\n\nvisualizer.plot(layer_index = 6)\nplt.savefig(\"token_to_token.jpg\")\n```\n\n<p align=\"center\">\n    <img alt=\"token to token\" src=\"images/token_to_token.jpg\" />\n</p>\n\n<p align=\"center\">Plot attention matrices normalized on head axis</p>\n\nYou can specify the `order` used in `torch.linalg.norm` in `__call__` and `compute` methods. By default, it's a L2 norm.\n\n```python\nfrom transformers_visualizer import TokenToTokenNormalizedAttentions\n\nvisualizer = TokenToTokenNormalizedAttentions(model, tokenizer)\nvisualizer.compute(text).plot()\n```\n\n<p align=\"center\">\n    <img alt=\"normalized token to token\"src=\"images/token_to_token_normalized.jpg\" />\n</p>\n\n</details>\n\n## Upcoming features\n\n- [ ] Adding an option to specify head/layer indices to plot.\n- [ ] Adding other plotting backends such as Plotly, Bokeh, Altair.\n- [ ] Implement other visualizers such as [vector norm](https://arxiv.org/pdf/2004.10102.pdf).\n\n## References\n\n- [[1]][captum_part1] Captum's BERT example part 1\n- [[2]][captum_part2] Captum's BERT example part 2\n\n\n## Acknowledgements\n\n- [Transformers Interpret](https://github.com/cdpierse/transformers-interpret) for the idea of this project.\n\n[Captum]: https://captum.ai/\n[captum_part1]: https://captum.ai/tutorials/Bert_SQUAD_Interpret\n[Captum_part2]: https://captum.ai/tutorials/Bert_SQUAD_Interpret2",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/VDuchauffour/transformers-visualizer",
            "keywords": "machine learning,natural language processing,nlp,explainability,transformers,model interpretability",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "transformers-visualizer",
            "package_url": "https://pypi.org/project/transformers-visualizer/",
            "platform": null,
            "project_url": "https://pypi.org/project/transformers-visualizer/",
            "project_urls": {
                "Homepage": "https://github.com/VDuchauffour/transformers-visualizer",
                "Repository": "https://github.com/VDuchauffour/transformers-visualizer"
            },
            "release_url": "https://pypi.org/project/transformers-visualizer/0.2.0/",
            "requires_dist": [
                "captum (>=0.5.0)",
                "transformers (>=4.0.0)",
                "matplotlib (>=3.5)",
                "torchtyping (>=0.1.4)"
            ],
            "requires_python": ">=3.8,<4.0",
            "summary": "Explain your \ud83e\udd17 transformers without effort! Display the internal behavior of your model.",
            "version": "0.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16162158,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "72b40428e05c5d52af237f12d05fb4e3",
                    "sha256": "21c7e9136edd3469ac6167f5b21a77c663800abb0d74e7cfdf06f74191039bbb"
                },
                "downloads": -1,
                "filename": "transformers_visualizer-0.2.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "72b40428e05c5d52af237f12d05fb4e3",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8,<4.0",
                "size": 15711,
                "upload_time": "2022-12-20T14:42:55",
                "upload_time_iso_8601": "2022-12-20T14:42:55.177111Z",
                "url": "https://files.pythonhosted.org/packages/cd/b7/23c3a5301672dbdb01f6f7d4259d109f78ae74b27588c6553cdb496c27cb/transformers_visualizer-0.2.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "4c52eceb5790cc04268523dfd34ef95c",
                    "sha256": "a8f07924b64032b0f4ff62ed74f38a4cd8586374a34ec0ff8c41c748f12f0012"
                },
                "downloads": -1,
                "filename": "transformers_visualizer-0.2.0.tar.gz",
                "has_sig": false,
                "md5_digest": "4c52eceb5790cc04268523dfd34ef95c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8,<4.0",
                "size": 14463,
                "upload_time": "2022-12-20T14:42:56",
                "upload_time_iso_8601": "2022-12-20T14:42:56.882257Z",
                "url": "https://files.pythonhosted.org/packages/ff/76/74ffee8ce155d7a95a19e7c494308184de42a7f58d8d986cbd4bd9264ee6/transformers_visualizer-0.2.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
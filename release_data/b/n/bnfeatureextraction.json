{
    "0.1": {
        "info": {
            "author": "Karigor",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "BnFeatureExtraction",
            "package_url": "https://pypi.org/project/BnFeatureExtraction/",
            "platform": "",
            "project_url": "https://pypi.org/project/BnFeatureExtraction/",
            "project_urls": {
                "Homepage": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction"
            },
            "release_url": "https://pypi.org/project/BnFeatureExtraction/0.1/",
            "requires_dist": [
                "scipy",
                "gensim",
                "numpy",
                "matplotlib",
                "scikit-learn",
                "glove-python"
            ],
            "requires_python": "",
            "summary": "",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7499871,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "4bb931816e075ba0d9470f07182015aa",
                    "sha256": "017335c6c32398af313bf3a3e2897cda01cdbe1c2d40b3eb662a58cf0358f6ab"
                },
                "downloads": -1,
                "filename": "BnFeatureExtraction-0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "4bb931816e075ba0d9470f07182015aa",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 173461,
                "upload_time": "2020-06-01T05:56:33",
                "upload_time_iso_8601": "2020-06-01T05:56:33.198196Z",
                "url": "https://files.pythonhosted.org/packages/1f/d9/a0b980dccdee5f4a507b3e4f79f813773f1a34f0be6b7be13d9dbee77e71/BnFeatureExtraction-0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.2": {
        "info": {
            "author": "Karigor",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "BnFeatureExtraction",
            "package_url": "https://pypi.org/project/BnFeatureExtraction/",
            "platform": "",
            "project_url": "https://pypi.org/project/BnFeatureExtraction/",
            "project_urls": {
                "Homepage": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction"
            },
            "release_url": "https://pypi.org/project/BnFeatureExtraction/0.2/",
            "requires_dist": [
                "scipy",
                "gensim",
                "numpy",
                "matplotlib",
                "scikit-learn",
                "glove-python"
            ],
            "requires_python": "",
            "summary": "",
            "version": "0.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7499871,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "8e36000db39ad05c8455f07bdf926737",
                    "sha256": "b4d98d355708179e1fe65bbe065725eed548678a9c5c6405be371ae79ebfbab8"
                },
                "downloads": -1,
                "filename": "BnFeatureExtraction-0.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "8e36000db39ad05c8455f07bdf926737",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 167889,
                "upload_time": "2020-06-01T06:08:39",
                "upload_time_iso_8601": "2020-06-01T06:08:39.511552Z",
                "url": "https://files.pythonhosted.org/packages/51/cd/a2e69391f004ee37109a5f1fd63618606b2538d18d41b740b1a1b6b0555f/BnFeatureExtraction-0.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3": {
        "info": {
            "author": "Kowsher Ahmed, Avishek Das",
            "author_email": "ahmedshuvo969@gmail.com, avishek.das.ayan@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "# Bangla Feature Extractor(BnFeatureExtraction)\n\nBnFeatureExtraction is a Bangla Natural Language Processing based feature extractor.\n\n\n### Feature Extraction\n\n  1. [CountVectorizer](#1-countvectorizer)\n  2. [HashVectorizer](#2-hashvectorizer)\n  3. [TfIdf](#3-tfidf)\n  4. [Word Embedding](#4-word-embedding)\n      * [Word2Vec](#word2vec)\n      * [FastText](#fasttext)\n\t  * [GloVe](#glove)\n\n## Installation\n```\npip install BnFeatureExtraction\n```\n## Example\n### 1. CountVectorizer\n  - Fit n Transform\n  - Transform\n  - Get Wordset\n\n**Fit n Transform**\n```py\nfrom BnFeatureExtraction import CountVectorizer\nct = CountVectorizer()\nX = ct.fit_transform(X) # X is the word features\n```\nOutput:\n```\nthe countVectorized matrix form of given features\n```\n\n**Transform**\n```py\nfrom BnFeatureExtraction import CountVectorizer\nct = CountVectorizer()\nget_mat = ct.transform(\"\u09b0\u09be\u09b9\u09be\u09a4\")\n```\nOutput:\n```\nthe countVectorized matrix form of given word\n```\n\n**Get Wordset**\n```py\nfrom BnFeatureExtraction import CountVectorizer\nct = CountVectorizer()\nct.get_wordSet()\n```\nOutput:\n```\nget the raw wordset used in training model\n```\n\n### 2. HashVectorizer\n  - Fit n Transform\n  - Transform\n```py\nfrom BnFeatureExtraction import HashVectorizer\ncorpus = [\n'\u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09a6\u09c7\u09b6 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6', '\u0986\u09ae\u09be\u09b0 \u09ac\u09be\u0982\u09b2\u09be'\n]\nVectorizer = HashVectorizer()\nn_features = 8\nX = Vectorizer.fit_transform(corpus, n_features)\ncorpus_t = [\"\u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09a6\u09c7\u09b6 \u0985\u09a8\u09c7\u0995 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0\"]\nXf = Vectorizer.transform(corpus_t)\n\nprint(X.shape, Xf.shape)\nprint(\"=====================================\")\nprint(X)\nprint(\"=====================================\")\nprint(Xf)\n```\nOutput:\n```\n(2, 8) (1, 8)\n=====================================\n  (0, 7)\t-1.0\n  (1, 7)\t-1.0\n=====================================\n  (0, 0)\t0.5773502691896258\n  (0, 2)\t0.5773502691896258\n  (0, 7)\t-0.5773502691896258\n```\n\n**Get Wordset**\n\n\n### 3. TfIdf\n  - Fit n Transform\n  - Transform\n  - Coefficients\n\n **Fit n Transform**\n```py\nfrom BnFeatureExtraction import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\", \"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"]\nmatrix1 = k.fit_transform(doc)\nprint(matrix1)\n```\nOutput:\n```\n[[0.150515 0.150515 0.       0.      ]\n [0.       0.       0.150515 0.150515]]\n\n```\n\n**Transform**\n```py\nfrom BnFeatureExtraction import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0986\u09b9\u09ae\u09c7\u09a6 \u09b8\u09c1\u09ae\u09a8\", \"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0995\u09b0\u09bf\u09ae\"]\nmatrix2 = k.transform(doc)\nprint(matrix2)\n```\nOutput: \n```\n[[0.150515 0.       0.       0.      ]\n [0.       0.150515 0.       0.      ]]\n```\n**Coefficients**\n```py\nfrom BnFeatureExtraction import TfIdfVectorizer\nk = TfIdfVectorizer()\ndoc = [\"\u0995\u09be\u0993\u099b\u09be\u09b0 \u0986\u09b9\u09ae\u09c7\u09a6\", \"\u09b6\u09c1\u09ad \u09b9\u09be\u0987\u09a6\u09be\u09b0\"]\nk.fit_transform(doc)\nwordset, idf = k.coefficients()\nprint(wordset)\n#Output: ['\u0986\u09b9\u09ae\u09c7\u09a6', '\u0995\u09be\u0993\u099b\u09be\u09b0', '\u09b9\u09be\u0987\u09a6\u09be\u09b0', '\u09b6\u09c1\u09ad']\n\nprint(idf)\n'''\nOutput: \n{'\u0986\u09b9\u09ae\u09c7\u09a6': 0.3010299956639812, '\u0995\u09be\u0993\u099b\u09be\u09b0': 0.3010299956639812, '\u09b9\u09be\u0987\u09a6\u09be\u09b0': 0.3010299956639812, '\u09b6\u09c1\u09ad': 0.3010299956639812}\n'''\n\n```\n\n### 4. Word Embedding\n- ### Word2Vec\n    - Training\n    - Get Word Vector\n    - Get Similarity\n    - Get n Similar Words\n    - Get Middle Word\n    - Get Odd Words\n    - Get Similarity Plot\n\n**Training**\n```py\nfrom BnFeatureExtraction import BN_Word2Vec\n#Training Against Sentences\nw2v = BN_Word2Vec(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'],['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'],['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be']])\nw2v.train()\n\n#Training Against one Text Corpus\nw2v = BN_Word2Vec(corpus_file=\"path_to_corpus.txt\")\nw2v.train()\n\n#Training Against Multiple corpuses\n'''\n    path\n      ->corpus\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nw2v = BN_Word2Vec(corpus_path=\"path/corpus\")\nw2v.train(epochs=25)\n\n\n#Training Against a Dataframe Column\nw2v = BN_Word2Vec(df= news_data['text_content'])\nw2v.train(epochs=25)\n```\nAfter training is done the model \"w2v_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you use any pretrained model, specify it while initializing BN_Word2Vec() . Otherwise no model_name is needed.**\n\n**Get Word Vector**\n```py\nfrom BnFeatureExtraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_wordVector('\u0986\u09ae\u09be\u09b0')\n```\n\n**Get Similarity**\n```py\nfrom BnFeatureExtraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_similarity('\u09a2\u09be\u0995\u09be', '\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0')\n```\nOutput: \n```\n67.457879\n```\n\n**Get n Similar Words**\n```py\nfrom BnFeatureExtraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n```\nOutput: \n```\n[('\u09b8\u09c7\u09a4\u09c1\u09b0', 0.5857524275779724),\n ('\u09ae\u09c1\u09b2\u09ab\u09ce\u0997\u099e\u09cd\u099c', 0.5773632526397705),\n ('\u09ae\u09b9\u09be\u09a8\u09a8\u09cd\u09a6\u09be', 0.5634652376174927),\n (\"'\u09aa\u09a6\u09cd\u09ae\u09be\", 0.5617109537124634),\n ('\u0997\u09cb\u09ae\u09a4\u09c0', 0.5605217218399048),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.5547558069229126),\n ('\u09a4\u09c1\u09b2\u09b8\u09c0\u0997\u0999\u09cd\u0997\u09be', 0.5274507999420166),\n ('\u09a8\u09a6\u09c0\u09b0', 0.5232067704200745),\n ('\u09b8\u09c7\u09a4\u09c1', 0.5225246548652649),\n ('\u09b8\u09c7\u09a4\u09c1\u09a4\u09c7', 0.5192927718162537)]\n```\n\n**Get Middle Word**\n\nGet the probability distribution of the center word given words list.\n```py\nfrom BnFeatureExtraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_outputWord(['\u09a2\u09be\u0995\u09be\u09df', '\u09ae\u09c3\u09a4\u09cd\u09af\u09c1'], n=2)\n```\nOutput:\n```\n[(\"\u09b9\u09df\u09c7\u099b\u09c7\u0964',\", 0.05880642), ('\u09b6\u09cd\u09b0\u09ae\u09bf\u0995\u09c7\u09b0', 0.05639163)]\n```\n\n**Get Odd Words**\n\nGet the most unmatched word out from given words list\n```py\nfrom BnFeatureExtraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n```\nOutput: \n```\n'\u0986\u0995\u09be\u09b6' \n```\n\n**Get Similarity Plot**\n\nCreates a barplot of similar words with their probability \n\n```py\nfrom BnFeatureExtraction import BN_Word2Vec \nw2v = BN_Word2Vec(model_name='give the model name here')\nw2v.get_similarity_plot('\u099a\u09be\u0989\u09b2', 5)\n```\n\n- ### FastText\n    - Training\n    - Get Word Vector\n    - Get Similarity\n    - Get n Similar Words\n    - Get Middle Word\n    - Get Odd Words\n\n\n**Training**\n```py\nfrom BnFeatureExtraction import BN_FastText\n#Training Against Sentences\nft = ft = BN_FastText(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'] ])\nft.train()\n\n#Training Against one Text Corpus\nft = BN_FastText(corpus_file=\"path to data or txt file\")\nft.train()\n\n#Training Against Multiple Corpuses\n'''\n    path\n      ->Corpus\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nft = BN_FastText(corpus_path=\"path/Corpus\")\nft.train(epochs=25)\n\n#Training Against a Dataframe Column\nft = BN_FastText(df= news_data['text_content'])\nft.train(epochs=25)\n\n```\nAfter training is done the model \"ft_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you don't want to train instead use a pretrained model, specify it while initializing BN_FastText() . Otherwise no model_name is needed.**\n\n**Get Word Vector**\n```py\nfrom BnFeatureExtraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_wordVector('\u0986\u09ae\u09be\u09b0')\n```\n\n**Get Similarity**\n```py\nfrom BnFeatureExtraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_similarity('\u09a2\u09be\u0995\u09be', '\u09b0\u09be\u099c\u09a7\u09be\u09a8\u09c0')\n```\nOutput:\n```\n70.56821120\n```\n\n**Get n Similar Words**\n```py\nfrom BnFeatureExtraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n```\n\nOutput: \n```\n[('\u09aa\u09a6\u09cd\u09ae\u09be\u09df', 0.8103810548782349),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.794012725353241),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09a8\u09a6\u09c0\u09b0', 0.7747839689254761),\n ('\u09aa\u09a6\u09cd\u09ae\u09be-\u09ae\u09c7\u0998\u09a8\u09be\u09b0', 0.7573559284210205),\n ('\u09aa\u09a6\u09cd\u09ae\u09be.', 0.7470568418502808),\n ('\u2018\u09aa\u09a6\u09cd\u09ae\u09be', 0.7413997650146484),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b8\u09c7\u09a4\u09c1\u09b0', 0.716225266456604),\n ('\u09aa\u09a6\u09cd\u09ae', 0.7154797315597534),\n ('\u09aa\u09a6\u09cd\u09ae\u09b9\u09c7\u09ae', 0.6881639361381531),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09ac\u09a4', 0.6682782173156738)]\n```\n\n**Get Odd Words**\n\nGet the most unmatched word out from given words list\n```py\nfrom BnFeatureExtraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_oddWords(['\u099a\u09be\u09b2', '\u09a1\u09be\u09b2', '\u099a\u09bf\u09a8\u09bf', '\u0986\u0995\u09be\u09b6'])\n```\nOutput:\n```\n'\u0986\u0995\u09be\u09b6' \n```\n\n**Get Similarity Plot**\n\nCreates a barplot of similar words with their probability \n\n```py\nfrom BnFeatureExtraction import BN_FastText \nft = BN_FastText(model_name='give the model name here')\nft.get_similarity_plot('\u099a\u09be\u0989\u09b2', 5)\n```\n\n- ### GloVe\n    - Training\n    - Get n Similar Words\n\n\n**Training**\n```py\nfrom BnFeatureExtraction import BN_GloVe\n#Training Against Sentences\nglv = BN_GloVe(sentences=[['\u0986\u09ae\u09be\u09b0', '\u09aa\u09cd\u09b0\u09bf\u09df', '\u099c\u09a8\u09cd\u09ae\u09ad\u09c2\u09ae\u09bf'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'], ['\u09ac\u09be\u0982\u09b2\u09be', '\u0986\u09ae\u09be\u09b0', '\u09ae\u09be\u09a4\u09c3\u09ad\u09be\u09b7\u09be'] ])\nglv.train()\n\n#Training Against one Text Corpus\nglv = BN_GloVe(corpus_file=\"path_to_corpus.txt\")\nglv.train()\n\n#Training Against Multiple Corpuses\n'''\n    path\n      ->Corpus\n        ->1.txt\n        ->2.txt\n        ->3.txt\n'''\nglv = BN_GloVe(corpus_path=\"path/corpus\")\nglv.train(epochs=25)\n\n#Training Against a Dataframe Column\nglv = BN_GloVe(df= news_data['text_content'])\nglv.train(epochs=25)\n\n\n```\nAfter training is done the model \"glove_model\"  along with it's supportive vector files will be saved to current directory.\n\n**If you don't want to train instead use a pretrained model, specify it while initializing BN_FastText() . Otherwise no model_name is needed.**\n\n\n**Get n Similar Words**\n```py\nfrom BnFeatureExtraction import BN_GloVe \nglv = BN_GloVe(model_name='give the model name here')\nglv.get_n_similarWord(['\u09aa\u09a6\u09cd\u09ae\u09be'], n=10)\n```\n\nOutput: \n```\n[('\u09aa\u09a6\u09cd\u09ae\u09be\u09df', 0.8103810548782349),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b0', 0.794012725353241),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09a8\u09a6\u09c0\u09b0', 0.7747839689254761),\n ('\u09aa\u09a6\u09cd\u09ae\u09be-\u09ae\u09c7\u0998\u09a8\u09be\u09b0', 0.7573559284210205),\n ('\u09aa\u09a6\u09cd\u09ae\u09be.', 0.7470568418502808),\n ('\u2018\u09aa\u09a6\u09cd\u09ae\u09be', 0.7413997650146484),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09b8\u09c7\u09a4\u09c1\u09b0', 0.716225266456604),\n ('\u09aa\u09a6\u09cd\u09ae', 0.7154797315597534),\n ('\u09aa\u09a6\u09cd\u09ae\u09b9\u09c7\u09ae', 0.6881639361381531),\n ('\u09aa\u09a6\u09cd\u09ae\u09be\u09ac\u09a4', 0.6682782173156738)]\n```\n\n\n\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "BnFeatureExtraction",
            "package_url": "https://pypi.org/project/BnFeatureExtraction/",
            "platform": "",
            "project_url": "https://pypi.org/project/BnFeatureExtraction/",
            "project_urls": {
                "Homepage": "https://github.com/Kowsher/Bangla-NLP/tree/master/Bangla%20Feature%20Extraction"
            },
            "release_url": "https://pypi.org/project/BnFeatureExtraction/0.3/",
            "requires_dist": [
                "scipy",
                "gensim",
                "numpy",
                "matplotlib",
                "scikit-learn",
                "glove-python"
            ],
            "requires_python": "",
            "summary": "",
            "version": "0.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7499871,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c636153cfeaa9298bcbd2e797e1095fb",
                    "sha256": "67bcae21609a3e3aa8e02e3256f420fc4b6dd5c1ec8e7c7bcbdc8cd5bfee67c7"
                },
                "downloads": -1,
                "filename": "BnFeatureExtraction-0.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "c636153cfeaa9298bcbd2e797e1095fb",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 167995,
                "upload_time": "2020-06-17T19:22:42",
                "upload_time_iso_8601": "2020-06-17T19:22:42.692672Z",
                "url": "https://files.pythonhosted.org/packages/31/90/b581cd19461380402148e351fbb82f9d1808104990372fa6d1de19a9d7ff/BnFeatureExtraction-0.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
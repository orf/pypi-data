{
    "1.0.0": {
        "info": {
            "author": "Jhon Freddy Puentes",
            "author_email": "jfredypuentes@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 2 - Pre-Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering",
                "Topic :: Software Development"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/jfreddypuentes/spanlp",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spanlp",
            "package_url": "https://pypi.org/project/spanlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/spanlp/",
            "project_urls": {
                "Homepage": "https://github.com/jfreddypuentes/spanlp"
            },
            "release_url": "https://pypi.org/project/spanlp/1.0.0/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "A fast, robust Python library to check for profanity or offensive language in Spanish strings.It contains all the rude words of Spanish-speaking countries (Argentina, Bolivia, Chile, Colombia, Costa Rica, Cuba, Ecuador, El Salvador, Espa\u00f1a, Guatemala, Guinea Ecuatorial, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, Puerto Rico, Dominicana, Uruguay, Venezuela)",
            "version": "1.0.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10261377,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b151a264689cdf8b40d0467fb0931992",
                    "sha256": "4d344181b9eaf9563896f5bad98a95562868b4d8a4edaf8425a127f24ab36453"
                },
                "downloads": -1,
                "filename": "spanlp-1.0.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b151a264689cdf8b40d0467fb0931992",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 38909,
                "upload_time": "2021-02-18T02:29:35",
                "upload_time_iso_8601": "2021-02-18T02:29:35.785944Z",
                "url": "https://files.pythonhosted.org/packages/02/3a/4f76daf1ffe12c71adefd008b9c91229a582dc62ebe3b6841c9d510ea449/spanlp-1.0.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "3b007c0c69465ba90274ff5e26ff8656",
                    "sha256": "6cf77034a917f6e11014760ba79fb72bf31efd82460f5591bf26b5a73c27b23e"
                },
                "downloads": -1,
                "filename": "spanlp-1.0.0.tar.gz",
                "has_sig": false,
                "md5_digest": "3b007c0c69465ba90274ff5e26ff8656",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 34809,
                "upload_time": "2021-02-18T02:29:37",
                "upload_time_iso_8601": "2021-02-18T02:29:37.977583Z",
                "url": "https://files.pythonhosted.org/packages/98/44/8a654ddba936c70dba99734828819f74368b5c5b255d9700f197c2eeb3b9/spanlp-1.0.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.0.1": {
        "info": {
            "author": "Jhon Freddy Puentes",
            "author_email": "jfredypuentes@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering",
                "Topic :: Software Development"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/jfreddypuentes/spanlp",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spanlp",
            "package_url": "https://pypi.org/project/spanlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/spanlp/",
            "project_urls": {
                "Homepage": "https://github.com/jfreddypuentes/spanlp"
            },
            "release_url": "https://pypi.org/project/spanlp/1.0.1/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "A fast, robust Python library to check for profanity or offensive language in Spanish strings.It contains all the rude words of Spanish-speaking countries (Argentina, Bolivia, Chile, Colombia, Costa Rica, Cuba, Ecuador, El Salvador, Espa\u00f1a, Guatemala, Guinea Ecuatorial, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, Puerto Rico, Dominicana, Uruguay, Venezuela)",
            "version": "1.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10261377,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3ce53f56db05810947eb2febadaa6721",
                    "sha256": "1407c5b983082d9ae5dc5b4c77c7733490983c9aa7395be4f5cd1fd7bed92bfc"
                },
                "downloads": -1,
                "filename": "spanlp-1.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3ce53f56db05810947eb2febadaa6721",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 38829,
                "upload_time": "2021-02-18T02:40:14",
                "upload_time_iso_8601": "2021-02-18T02:40:14.799910Z",
                "url": "https://files.pythonhosted.org/packages/19/88/0da0c74c575ad04e84663578c3ac72633e7326f110c7362360110bd1f9b7/spanlp-1.0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "7b5ea0a5d739d5caf29a8e9f6e418506",
                    "sha256": "3041a27c640b3a1dcaae62ba20de295447aa5a684cb87894adf95d057522f6d4"
                },
                "downloads": -1,
                "filename": "spanlp-1.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "7b5ea0a5d739d5caf29a8e9f6e418506",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 34668,
                "upload_time": "2021-02-18T02:40:18",
                "upload_time_iso_8601": "2021-02-18T02:40:18.186231Z",
                "url": "https://files.pythonhosted.org/packages/3f/95/a17ab1317bc8f125cde0e5565fbeaca1b96f2e921b28d51babd723ca77b0/spanlp-1.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.1.0": {
        "info": {
            "author": "Jhon Freddy Puentes",
            "author_email": "jfredypuentes@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering",
                "Topic :: Software Development"
            ],
            "description": "<h1 align=\"center\">spanlp</h1>\n\n<p align=\"center\">\n  <br>\n  <i>spanlp es una librer\u00eda escrita en Python para detectar, censurar  y limpiar groser\u00edas, <br>\n      vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en <strong>Espa\u00f1ol</strong>.\n    </i>\n  <br>\n\n  <p align=\"center\">\n    <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/version-v1.1.0-green\"/>\n    </a>\n    <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/status-stable-blue\"/>\n    </a>\n  <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/release-v1.1.0-brightgreen\"/>\n    </a>\n    <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/test--pypi-v0.0.7-yellow\"/>\n    </a>\n  <a href=\"https://test.pypi.org/project/spanlp/\">\n      <img src=\"https://img.shields.io/badge/license-MIT-brightgreen\"/>\n    </a>\n  </p>\n\n  <p align=\"center\">\n    <img alt=\"GitHub Repo stars\" src=\"https://img.shields.io/github/stars/jfreddypuentes/spanlp?style=social\">\n  </p>\n</p>\n\n<hr>\n\n## Indice\n- [Indice](#indice)\n- [Sobre la librer\u00eda](#sobre-la-librer\u00eda)\n- [Casos de uso](#casos-de-uso)\n- [Status Desarrollo](#status-desarrollo)\n- [Instalaci\u00f3n](#instalaci\u00f3n)\n- [Funcionamiento](#funcionamiento)\n  - [Uso b\u00e1sico](#uso-basico)\n  - [Uso avanzado](#uso-avanzado)\n  - [Pre-procesamiento de datos](#preprocesamiento-de-texto)\n- [Beta Testing](#beta-testing)\n- [Reportar un bug](#reportar-un-bug)\n- [Contribuidorxs](#contribuidorxs)\n- [Contacto](#contacto)\n\n<hr>\n\n## Sobre la librer\u00eda\nspanlp es una librer\u00eda escrita en Python para detecci\u00f3n de groser\u00edas, vulgaridades, palabras de odio, racismo, xenofobia y bullying en textos escritos en Espa\u00f1ol. Puedes usar la librer\u00eda y aplicarla a palabras de cualquiera de los m\u00e1s de **20 paises** de habla hispana.\n\nIncluye:\n1. Argentina \ud83c\udde6\ud83c\uddf7\n2. Bolivia \ud83c\udde7\ud83c\uddf4\n3. Chile \ud83c\udde8\ud83c\uddf1\n4. Colombia \ud83c\udde8\ud83c\uddf4\n5. Costa Rica \ud83c\udde8\ud83c\uddf7\n6. Cuba \ud83c\udde8\ud83c\uddfa\n7. Ecuador \ud83c\uddea\ud83c\udde8\n8. El Salvador \ud83c\uddf8\ud83c\uddfb\n9. Espa\u00f1a \ud83c\uddea\ud83c\uddf8\n10. Guatemala \ud83c\uddec\ud83c\uddf9\n11. Guinea Ecuatorial \ud83c\uddec\ud83c\uddf6\n12. Honduras \ud83c\udded\ud83c\uddf3\n13. M\u00e9xico \ud83c\uddf2\ud83c\uddfd\n14. Nicaragua \ud83c\uddf3\ud83c\uddee\n15. Panam\u00e1 \ud83c\uddf5\ud83c\udde6\n16. Paraguay \ud83c\uddf5\ud83c\uddfe\n17. Per\u00fa \ud83c\uddf5\ud83c\uddea\n18. Puerto Rico \ud83c\uddf5\ud83c\uddf7\n19. Rep\u00fablica Dominicana \ud83c\udde9\ud83c\uddf4\n20. Uruguay \ud83c\uddfa\ud83c\uddfe\n21. Venezuela \ud83c\uddfb\ud83c\uddea\n\n## Casos de uso\n* Censurar vulgaridades en un texto.\n* Detectar y censurar vulgaridades en una sala de chat en linea.\n* Encontrar y censurar frases y palabras de odio, racismo, xenofia, bullying. (Se deben incluir como par\u00e1metros)\n* Censurar comentarios groseros o insultos en alg\u00fan blog o aplicaci\u00f3n web o sitio web.\n* Censurar malas palabras en un sistema de recolecci\u00f3n de opiniones, sugerencias, quejas y reclamos.\n* Limpiar textos antes de ser publicados.\n* Detectar y eliminar vulgaridades en textos que ser\u00e1n leidos y/o vistos por ni\u00f1os.\n* Limpiar una base de datos con mucho texto.\n\n## Status Desarrollo\n\n| Funcionalidad                     | Desarrollo |   Pruebas   | Release  |\n|-----------------------------------|------------|-------------|-----------\n| Soporte de tokens con n\u00fameros     |     \u2713      |      \u2713      | v0.0.5   |  \n| Estrategias de limpieza de datos  |     \u2713      |      \u2713      | v0.0.5   |\n| Completar dataset                 |     \u2713      |      \u2713      | v1.0.1   |\n| Hamming                           |     \u2713      |      \u2713      | v1.0.2   |\n| Levenstein                        |     \u2713      |      \u2713      | v1.1.0   |\n| Bag distance                      |     -      |             |    -     |\n| Sorensen-Dice coefficient         |     -      |             |    -     |\n| Tversky index                     |     -      |             |    -     |\n| Overlap index                     |     -      |             |    -     |\n| Tanimoto distance                 |     -      |             |    -     |\n| Ampliaci\u00f3n datasets               |  Progreso  |      -      |    -     |\n\n\n## Instalaci\u00f3n\nPara instalar la \u00faltima versi\u00f3n use:\n```console\npip install spanlp\n```\n\nPara instalar una versi\u00f3n espec\u00edfica use (por ejemplo):\n```\npip install spanlp==1.1.0\n```\n\n## Funcionamiento\nLos algoritmos y modulos se personalizan de forma din\u00e1mica y muy flexible. Veamos algunos usos.\n\n### Uso b\u00e1sico\n\nValidar si una palabra o frase contiene o no una palabrota:\n```python\nfrom spanlp.palabrota import Palabrota\npalabrota = Palabrota()\nprint(palabrota.contains_palabrota(\"Hola huevon c\u00f3mo est\u00e1?\"))\n# salida: True\n```\n\n```python\nfrom spanlp.palabrota import Palabrota\npalabrota = Palabrota()\nprint(palabrota.contains_palabrota(\"Hola a todos \u00bfc\u00f3mo est\u00e1n?\"))\n# salida: False\n```\n\nCensurar una frase con los par\u00e1metros por defecto:\n\n```python\nfrom spanlp.palabrota import Palabrota\n\npalabrota = Palabrota()\nprint(palabrota.censor(\"Hola huevon c\u00f3mo est\u00e1?\"))\n\n# salida: Hola !$%#@! c\u00f3mo est\u00e1?\n```\n\nCensurar la misma frase, configurando car\u00e1cteres propios\n\n```python\nfrom spanlp.palabrota import Palabrota\n\npalabrota = Palabrota(censor_char=\"*\")\nprint(palabrota.censor(\"Hola huevon como est\u00e1?\"))\n\n# salida: Hola ****** c\u00f3mo est\u00e1?\n```\n\nCensurar otra frase, configurando car\u00e1cteres propios y pa\u00eds\n\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.COLOMBIA, Country.VENEZUELA])\nprint(palabrota.censor(\"Hola huevon marico c\u00f3mo est\u00e1?\"))\n\n# salida: Hola @@@@@@ @@@@@@ c\u00f3mo est\u00e1?\n```\n\nCensuremos la misma frase pero solo con el pa\u00eds de Venezuela\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.VENEZUELA])\nprint(palabrota.censor(\"Hola huevon marico c\u00f3mo est\u00e1?\"))\n\n# salida: Hola huevon @@@@@@ c\u00f3mo est\u00e1?\n```\n\nCensuremos la misma frase pero incluyendo \"huevon\" al vocabulario de Venezuela\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.VENEZUELA], include=[\"huevon\"])\nprint(palabrota.censor(\"Hola huevon marico c\u00f3mo est\u00e1?\"))\n\n# salida: Hola @@@@@@ @@@@@@ c\u00f3mo est\u00e1?\n```\n\nCensuremos la misma frase incluyendo \"huevon\" al vocabulario de Venezuela y excluyendo \"marico\"\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"@\", countries=[Country.VENEZUELA], include=[\"huevon\"], exclude=[\"marico\"])\nprint(palabrota.censor(\"Hola huevon marico c\u00f3mo est\u00e1?\"))\n\n# salida: Hola huevon marico c\u00f3mo est\u00e1?\n```\n\nCensuremos la misma frase incluyendo \"\"Hola\" y \"huevon\" al vocabulario de Venezuela y excluyendo \"marico\"\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\n\npalabrota = Palabrota(censor_char=\"-\", countries=[Country.VENEZUELA], include=[\"huevon\"], exclude=[\"marico\"])\nprint(palabrota.censor(\"Hola huevon marico c\u00f3mo est\u00e1?\"))\n\n# salida: ---- ---- marico c\u00f3mo est\u00e1?\n```\n\n### Uso Avanzado\nEl uso avanzado incluye usar metricas de distancia y similitud para encontrar, comparar, censurar palabras.\nEstas son las metricas usadas a la fecha:\n1. [ES-Indice de Jaccard](https://es.wikipedia.org/wiki/%C3%8Dndice_Jaccard) ([EN-Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index))\n2. [ES-Similitud del coseno](https://es.wikipedia.org/wiki/Similitud_coseno) ([EN-Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity))\n3. [ES-Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Levenshtein)([EN-Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance))\n4. [ES-Damerau-Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Damerau-Levenshtein)([EN-Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance))\n\nCensuremos la frase usando Cosine Similarity \n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import CosineSimilarity\n\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=CosineSimilarity())\nprint(palabrota.censor(\"Hola huevo maric c\u00f3mo est\u00e1?\"))\n\n# salida: Hola huevo ***** c\u00f3mo est\u00e1?\n```\nA pesar de que \"maric\" no est\u00e1 en el dataset, al algoritmo la censur\u00f3 dado que por la m\u00e9trica de distancia es muy similar. \n\n\nCensuremos la frase usando **Cosine Similarity** manipulando los par\u00e1metros\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import CosineSimilarity\n\n# Indicamos que tenga en cuenta palabras similares en al menos 30% y que normalice los datos (poner en minusculas, remover acentos)\ncosine = CosineSimilarity(0.9, normalize=True) \npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=cosine)\nprint(palabrota.censor(\"Hola huevon MARIC c\u00f3mo est\u00e1?\"))\n\n# salida: hola huevon ***** **** esta? => Censur\u00f3 \"como\" porque en el dataset est\u00e1 \"cono\" y son similares en m\u00e1s del 90%\n```\n\nCensuremos la frase usando **JaccardIndex** con los par\u00e1metros por defecto\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=JaccardIndex())\nprint(palabrota.censor(\"Hola huevo maric c\u00f3mo est\u00e1?\"))\n\n# salida: Hola huevo ***** c\u00f3mo est\u00e1?\n```\nEl indice de Jaccard usa por defecto los siguientes par\u00e1metros:\n* `threshold=0.8` - Indica que censurar\u00e1 palabras con una similitud del 80% o m\u00e1s.\n* `normalize=False` - False indica que no pasar\u00e1 el texto a minuscula y no remover\u00e1 acentos.\n* `n_gram=2` - Usa 2 subsecuencias de la palabra. (Ver [N-grama](https://es.wikipedia.org/wiki/N-grama))\n\nCensuremos la frase usando **JaccardIndex** y modifiquemos los par\u00e1metros\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.9, normalize=True, n_gram=1)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c\u00f3mo vamos?\"))\n\n# salida: hola huevon ****** **** vamos?\n```\n\nAhora, sin normalizar los datos\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.9, normalize=False, n_gram=1)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c\u00f3mo vamos?\"))\n\n# salida: Hola huevon ****** c\u00f3mo vamos? => \"moco\" y \"c\u00f3mo\" ahora son muy diferentes.\n```\n\nAhora, bajemos el `threshold` a `0.6`\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.6, normalize=False, n_gram=1)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c\u00f3mo vamos?\"))\n\n# salida: Hola ****** ****** c\u00f3mo vamos? => Ha censurado una palabra m\u00e1s.\n```\n\nAumentemos la cantidad de `n_gram` a `3` con el `threshold=0.7` y con `normalize=False`\n```python\nfrom spanlp.palabrota import Palabrota\nfrom spanlp.domain.countries import Country\nfrom spanlp.domain.strategies import JaccardIndex\n\njaccard = JaccardIndex(threshold=0.7, normalize=False, n_gram=3)\npalabrota = Palabrota(censor_char=\"*\", countries=[Country.VENEZUELA], distance_metric=jaccard)\nprint(palabrota.censor(\"Hola huevon marica c\u00f3mo vamos?\"))\n\n# salida: Hola huevon marica c\u00f3mo vamos? => No censur\u00f3 nada.\n```\n\n## Preprocesamiento de texto\nSiempre ser\u00e1 necesario limpiar los datos antes de empezar a trabajar. Aqui te presento la clase `Preprocessing` y las 28 estrat\u00e9gias de limpieza de datos.\n\n\u00bfCuantas estrategias hay y cuales son?\n\nSon 28 algoritmos y son:\n\n1. `TextToLower` **input**: \"HOLA QUE M\u00c1S?\" **output:** \"hola que m\u00e1s?\"\n2. `TextToUpper` **input:** \"hola \u00bfc\u00f3mo est\u00e1n?\" **output:** \"HOLA \u00bfC\u00d3MO EST\u00c1N?\"\n3. `RemoveUnicodeCharacters` **input:** \"hola \u00e7como \u00aavan?\" **output:** \"hola como van\"  ([Unicode characters](https://www.rapidtables.com/code/text/unicode-characters.html))\n4. `NumbersToVowelsInLowerCase` **input:** \"h0l4 qu3 t4l?\" **ouput:** \"hola que tal?\"\n5. `NumbersToVowelsInUpperCase` **input:** \"H0l4 c0m0 v4n?\" **output:** \"HOlA cOmO vAn?\"\n6. `NumbersToConsonantsInLowerCase` **input:** \"C0m0 e574n? 8i3n?\" **output:** \"Como estan? bien?\"\n7. `NumbersToConsonantsInUpperCase` **input:** \"C0m0 e574n? 8i3n?\" **output:** \"COMO ESTAN? BIEN?\"\n8. `RemoveExtraSpaces` **input:** \"Hola   como est\u00e1n?   \" **output:** \"Hola como est\u00e1n?\"\n9. `RemoveUserMentions` **input:** \"Hola @channel como van?\" **output:** \"CHola como van?\"\n10. `RemoveUrls`  **input:** \"Revisen este recurso https://github.com/jfreddypuentes/spanlp\" **output:** \"Revisen este recurso \"\n11. `RemoveHashtags` **input:** \"Hola #equipo bienvenidos\" **output:** \"Hola  bienvenidos\"\n12. `RemoveTicks` **input:** \"Hola, que' m\u00e1s'\" **output:** \"Hola, que m\u00e1s\"\n13. `RemoveBackTicks` **input:** \"Hola, que` m\u00e1s`\" **output:** \"Hola, que m\u00e1s\"\n14. `RemovePunctuation`  **input:** \"Mensaje...,con, puntos\" **output:** \"Mensaje con puntos\"\n15. `RemoveNumbers` **input:** \"Hay 12 patacones  y 20 yucas\" **output:** \"Hay patacones y yucas\"\n16. `RemoveAccents` **input:** \"La canci\u00f3n es una sensaci\u00f3n\" **output:** \"La cancion es una sensacion\"\n17. `RemoveStopWords` **input:** \"La canci\u00f3n y la letra es buena\" **output:** \"canci\u00f3n letra buena\"\n18. `RemoveArticles` **input:** \"La canci\u00f3n y la letra es buena\" **output:** \"canci\u00f3n y letra es buena\"\n19. `RemoveEmoticons` **input:** \"Hola ;) como est\u00e1s? XD\" **output:** \"Hola como est\u00e1s?\"\n20. `RemovePronouns` **input:** \"Yo pienso que ella deber\u00eda ser como \u00e9l\" **output:** \"pienso que deber\u00eda ser como\"\n21. `RemoveAdverbs` **input:** \"muchos a\u00f1os despues frente al peloton de fusilamiento lentamente recordaba...\" **output:** \"muchos a\u00f1os frente al peloton de fusilamiento recordaba...\"\n22. `RemoveConjunctions` **input:** \"y entonces estaba programando aunque con sue\u00f1o pero concentrado creando esta libreria\" **output:** \"entonces estaba programando con sue\u00f1o concentrado creando esta libreria\"\n23. `RemovePrepositions` **input:** \"ante todo es mejor cuidar a la naturaleza mediante buenas acciones. entre todos podemos.\" **output:** \"todo es mejor cuidar la naturaleza buenas acciones. todos podemos.\"\n24. `RemoveAdjectives` **input:** \"la voz era tenebrosa y la noche estaba fria y oscura hasta que de pronto algo luminoso apareci\u00f3 y\" **output:** \"la voz era y la noche estaba y hasta que de pronto algo apareci\u00f3 y\"\n25. `RemoveHtmlTags` **input:** \"Hola <strong>USUARIO</strong> que tal?\" **output:** \"Hola USUARIO que tal?\"\n26. `RemoveEmailAddress` **input:** \"Hola Pepito, el correo es contacto@domain.com\" **output:** \"Hola Pepito, el correo es \"\n27. `ExpandAbbreviations` **input:** \"pero xq tengo es3 si yo estaba bn en clase, ahora me duelen to2 los musculos\" **output:** \"pero por que tengo estres si yo estaba bien en clase, ahora me duelen todos los musculos\"\n28. `RemoveAbbreviations` **input:** \"xfa pongase el tapabocas pq me da es3 verlo sin eso. to2 debemos cuidarnos. chas gracias. salu2\" **output:** \"pongase el tapabocas me da verlo sin eso. debemos cuidarnos. gracias.\"\n\n\nLa nueva clase `Preprocessing` implementa de manera flexible y din\u00e1mica cualquier estrategia de limpieza de una manera muy simple. Se puede aplicar dentro de una metrica de distancia como `JaccardIndex` o `CosineSimilarity` para darle m\u00e1s poder a la busqueda, dismunir el riesgo de no encontrar las palabras a censurar y aumentar la posibilidad de censurar las palabras que son por el hecho de estar limpias.\n\n\nVeamos algunos ejemplos:\n\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nstrategies = [TextToLower()] # Defino mis estrategias de limpieza o pre-procesamiento\ndata = \"ESTARE EN MINUSCULA\" # Tengo mis datos\nresult = Preprocessing(data=data, clean_strategies=strategies).clean() # Invoco a Preprocessing\nprint(result)\n\n# salida: estare en minuscula\n```\n\nTambien se puede as\u00ed:\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nstrategies = [TextToLower()]\ndata = \"ESTARE EN MINUSCULA\" \nresult = Preprocessing().clean(data=data, clean_strategies=strategies) # Envio los datos y las estragias al clean()\nprint(result)\n\n# salida: estare en minuscula\n```\n\nY tambien as\u00ed:\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nstrategies = [TextToLower()]\ndata = \"ESTARE EN MINUSCULA\"\npreprocessor = Preprocessing(data=data, clean_strategies=strategies)\nresult = preprocessor.clean()\nprint(result)\n\n# salida: estare en minuscula\n```\n\nY as\u00ed:\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower\n\nresult = Preprocessing(data=\"ESTARE EN MINUSCULA\", clean_strategies=[TextToLower()]).clean()\nprint(result)\n\n# salida: estare en minuscula\n```\n\n**\u00bfC\u00f3mo aplico una estrategia para que pre-preprocese mis datos dentro de la m\u00e9trica de distancia?**\n\n\nAplicar la metrica de distancia con una estrategia de pre-procesado:\n```python\nfrom spanlp.domain.strategies import JaccardIndex, TextToLower\n\nstrategies = [TextToLower()]\njaccard_index = JaccardIndex(normalize=True, clean_strategies=strategies)\nresult = jaccard_index.calculate(\"HOLA\", \"hola\")\n\nprint(result)\n\n# salida: 1\n```\n\nUsar la m\u00e9trica como interface para ejecutar la estrategia:\n\n```python\nfrom spanlp.domain.strategies import JaccardIndex, TextToLower\n\nstrategies = [TextToLower()]\njaccard_index = JaccardIndex(normalize=True, clean_strategies=strategies)\nresult = jaccard_index.normalize(\"HOLA ME VOY A NORMALIZAR A MINUSCULA\")\n\nprint(result)\n\n# salida: hola me voy a normalizar a minuscula\n```\n\n**Usar varias estrategias de limpieza de datos**\nNota: Las estrategias se ejecutan en el orden enviado en la lista. Recomiendo analizar primero como desea que funcione: Si primero elimina espacios extras y despues elimina signos de puntuaci\u00f3n y luego stop words etc.. esto depender\u00e1 de su necesidad concreta; Por lo que se pueden obtener diferentes resultados si cambia el orden de las estrategias.\n\nEnviando varias estrategias para limpiar mis datos:\n\n```python\nfrom spanlp.domain.strategies import Preprocessing, TextToLower, RemoveUserMentions, RemovePunctuation\n\nstrategies = [RemoveUserMentions(), TextToLower(), RemovePunctuation()]\ntweet = \"Hola @jhon, si viste que @freddy va a lanzar una nueva libreria Python para NLP?\"\ncleaned = Preprocessing().clean(data=tweet, clean_strategies=strategies)\n\nprint(cleaned)\n\n#salida: hola  si viste que  va a lanzar una nueva libreria python para nlp\n```\n\n**Limpiemos emoticones, pronombres y pasemos a minuscula**\n\n```python\nfrom spanlp.domain.strategies import Preprocessing, RemoveEmoticons, TextToLower, RemovePronouns\n\nstrategies = [RemoveEmoticons(), TextToLower(), RemovePronouns()]\nmessage = \"Segun ella Los emoticones <3 :) :D ;) son muy usados y esta rosa tambien @}->--\"\ncleaned = Preprocessing().clean(data=message, clean_strategies=strategies)\n\nprint(cleaned)\n\n# salida: segun los emoticones son muy usados y esta rosa tambien\n```\n\n\n## Testing\n\u00bfEres tester? \u00bfquieres automatizar pruebas? o \u00bfsimplemente aprender del open source y de las pruebas? Aventurate ya y ayudame a mejorar este proyecto!\nA continuaci\u00f3n encontrar\u00e1s algunas pautas para implementar pruebas exitosas que permitar\u00e1n encontrar posibles errores y mejoras.\n\n### 1. \u00bfPor donde empezar?\n* Instalar python.\n* Instalar la librer\u00eda. Esto lo logras ejecutando en la terminal el comando: `pip install -i https://test.pypi.org/simple/ spanlp`\n* Abre un nuevo script de python, importa la librer\u00eda y empieza a experimentar.\n\n### 2. \u00bfQu\u00e9 tipos de pruebas puedo realizar?\nExcelente pregunta! no hay limite para la creatividad; As\u00ed que haz todas las pruebas que quieras e imagines. Sin embargo, aqu\u00ed te dejo algunas pautas:\n\n* **Pruebas de caja negra** => Una vez instales la librer\u00eda y hayas leido la documentaci\u00f3n; Trata de usarla sin preocuparte como funciona o como obtuvo el resultado (Las pruebas no se hacen en base al c\u00f3digo, sino a la interfaz); Eso si, valida que la salida o el resultado sea el que esperas. Te puedes guiar (pero no mucho) de las pruebas unitarias que est\u00e1n en: `/spanlp/tests/test_palabrota.py`\n\n* **Pruebas de caja blanca** => Si quieres vez como funciona la libreria, estas pruebas son las tuyas. Intenta entender la estructura, los algoritmos y flujos. Una vez los comprendas, \"a dar palo\", trata de quebar o romper la l\u00f3gica, observa y encuentra si hay posibles formas de hacer que falle, prueba diferentes parametros, flujos, tipos de datos. Haz que falle, haz que se ponga lento! y me cuentas. ;)\n\n* **Pruebas de carga y stress** => Si lo tuyo son las pruebas de requisitos no funcionales, te invito a que sigas estos pasos para estresar la libreria y medir que tan escalable es frente a procesos de alta carga, mide la velocidad y que tan bien se comparta con miles o millones de hilos usandola al tiempo.\n\nSigue estos pasos:\n\n1. Crear una API Rest s\u00faper simple. Crea el siguiente script y ll\u00e1malo `server.py` \n\n```console\npip install flask\n```\n\n```python\nfrom flask_cors import CORS, cross_origin\nfrom flask import request\nfrom flask import json\n\nfrom spanlp.palabrota import Palabrota\n\napp = Flask(__name__)\ncors = CORS(app)\n\n@app.route('/api/v1/nlp/text/censor', methods = ['POST'])\n@cross_origin()\ndef censor():\n    try:\n        body = request.json     \n        in_message = body['message']\n\n        if in_message and len(str(in_message).strip()):\n            palabrota = Palabrota()\n            censored = palabrota.censor(in_message)\n            response = {\n                \"success\": True,\n                \"message\": \"OK\",\n                \"error_code\": 0,\n                \"data\": {\n                    'message': in_message,\n                    'censored': censored\n                }\n            }\n            return response\n        else:\n            return {\n                \"success\": False,\n                \"message\": \"Bad Request - message is required\",\n                \"error_code\": 400,\n                \"data\": {}\n            }\n    except Exception as e:\n        return {\n            \"success\": False,\n            \"message\": \"Internal Server Error - \"+str(e),\n            \"error_code\": 500,\n            \"data\": {}\n        }\n\n\nif __name__ == '__main__':\n    app.run(host='127.0.0.1', port=8080, debug=True)\n```\n\n\n```\npython server.py\n```\n\ny listo!! \n\n\n2. Consume la API desde alg\u00fan cliente http como [Postman](https://www.postman.com/), [Insomnia](https://insomnia.rest/download/) y/o [SOAP UI](https://www.soapui.org/). Tambien puedes usar alguna herramienta como [Apache JMeter](https://jmeter.apache.org/); o tambien puedes crear un script python con muchos hilos que consuma la API.\n\n\n### 3. \u00bfquieres escibrir unit tests y ejecutarlo de forma autom\u00e1tica?\nClona el repositorio en tu m\u00e1quina, abre el proyecto en tu editor favorito, ve al archivo `/spanlp/tests/test_palabrota.py` y empieza a escribir tus propios tests unitarios. Escribe cuantos quieras.\nUna vez tengas los tests listos, ejecuta el siguiente comando en la raiz del proyecto (`/spanlp/`):\n\n```console\npytest -ra\n```\n\no tambien el comando:\n\n```\npython -m pytest\n```\n\nEsto ejecutar\u00e1 de forma autom\u00e1tica todas las pruebas programadas e indicar\u00e1 si alg\u00fan test fall\u00f3.\n\n\n## Reportar un bug\nSi encuentras alg\u00fan problema (por muy m\u00ednimo que sea) reportalo [aqu\u00ed](https://github.com/jfreddypuentes/spanlp/issues/new). Solo necesitar\u00e1s poner t\u00edtulo y describir la falla y aportar\u00e1 un mont\u00f3n a que este proyecto mejore su calidad.\n\n\n## Contacto\n\u00bfAlguna duda? escribeme por email:  [jfredypuentes@gmail.com](mailto:jfredypuentes@gmail.com)\n\nCuentame en ([@jfreddypuentes](https://twitter.com/jfreddypuentes)) \u00bfqu\u00e9 te parece est\u00e1 librer\u00eda? \u00bfc\u00f3mo la est\u00e1s usando? \u00bfQu\u00e9 le mejorar\u00edas?\n\n<br>\n\n## Contribuidorxs\n* [@vivianamarquez](https://github.com/vivianamarquez) en Github, [@vivmarquez](https://twitter.com/vivmarquez) en Twitter (Data Scientist) - Contribuci\u00f3n al dise\u00f1o y funcionalidades de la librer\u00eda.\n* [@normacalamartinez](https://github.com/normacalamartinez) en Github (BI Developer) - Contribuci\u00f3n al dataset de vulgaridades por pa\u00eds de habla hispana.\n\n<br>\n\n\n**Hecho con \u2764\ufe0f\ufe0f de Colombia para el mundo.**\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/jfreddypuentes/spanlp",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "spanlp",
            "package_url": "https://pypi.org/project/spanlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/spanlp/",
            "project_urls": {
                "Homepage": "https://github.com/jfreddypuentes/spanlp"
            },
            "release_url": "https://pypi.org/project/spanlp/1.1.0/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "A fast, robust Python library to check for profanity or offensive language in Spanish strings.It contains all the rude words of Spanish-speaking countries (Argentina, Bolivia, Chile, Colombia, Costa Rica, Cuba, Ecuador, El Salvador, Espa\u00f1a, Guatemala, Guinea Ecuatorial, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, Puerto Rico, Dominicana, Uruguay, Venezuela)",
            "version": "1.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10261377,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "382b61e4c13d16fd6978a0eb50300db8",
                    "sha256": "253c1c45ab5befb5e9ca4f165af34b5b315799d694c65f98120ff42dc7ed2741"
                },
                "downloads": -1,
                "filename": "spanlp-1.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "382b61e4c13d16fd6978a0eb50300db8",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 40517,
                "upload_time": "2021-05-05T03:32:27",
                "upload_time_iso_8601": "2021-05-05T03:32:27.066301Z",
                "url": "https://files.pythonhosted.org/packages/64/60/29d9f8c2fc2cbb221238c76e62dc14d25bdfaa0fe62ead0d7c60a5541984/spanlp-1.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "5c427ee7c3992cf16a0fb2f9f11c5121",
                    "sha256": "7d566a5110024df60b320782c72776826d51971099e7d3fc750d00d2550a503b"
                },
                "downloads": -1,
                "filename": "spanlp-1.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "5c427ee7c3992cf16a0fb2f9f11c5121",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 37156,
                "upload_time": "2021-05-05T03:32:31",
                "upload_time_iso_8601": "2021-05-05T03:32:31.056256Z",
                "url": "https://files.pythonhosted.org/packages/4e/05/3b46a448579e4f0fd21f3c7d6627048b919b03fe0721a0f3f7e6ea1f4321/spanlp-1.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.0.1": {
        "info": {
            "author": "Leandro von Werra",
            "author_email": "leandro.vonwerra@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: Apache Software License",
                "Natural Language :: English",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/lvwerra/trl",
            "keywords": "ppo,transformers,huggingface,gpt2,language modeling",
            "license": "Apache Software License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "trl",
            "package_url": "https://pypi.org/project/trl/",
            "platform": "",
            "project_url": "https://pypi.org/project/trl/",
            "project_urls": {
                "Homepage": "https://github.com/lvwerra/trl"
            },
            "release_url": "https://pypi.org/project/trl/0.0.1/",
            "requires_dist": [
                "torch (>=1.4.0)",
                "transformers (>=2.6.0)",
                "numpy (>=1.18.2)"
            ],
            "requires_python": ">=3.6",
            "summary": "A Pytorch implementation of Proximal Policy Optimization for transfomer language models.",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13822896,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "93ca6cc38f69d2a65f4400f98074b974",
                    "sha256": "b54d350c8df35488796c1bd140a45dd0572fa48ea1f149224cdde051a7ed5f23"
                },
                "downloads": -1,
                "filename": "trl-0.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "93ca6cc38f69d2a65f4400f98074b974",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 15206,
                "upload_time": "2020-03-30T16:50:54",
                "upload_time_iso_8601": "2020-03-30T16:50:54.322733Z",
                "url": "https://files.pythonhosted.org/packages/34/68/7e87337e5d91252fa86ecb53a3aa3122a5db7e3a426a26f4902223b78a36/trl-0.0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "bae932f404ea569bf08225712770c04a",
                    "sha256": "3519f5aac2e9f40166914f4db9aa895b2852d503e1ae2cf5aace857ac3c96119"
                },
                "downloads": -1,
                "filename": "trl-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "bae932f404ea569bf08225712770c04a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 18442,
                "upload_time": "2020-03-30T16:50:58",
                "upload_time_iso_8601": "2020-03-30T16:50:58.050613Z",
                "url": "https://files.pythonhosted.org/packages/22/73/00cb0c46f1023979d4ed85c8777a84b663b5265a0a4ffb279d745fec7035/trl-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.2": {
        "info": {
            "author": "Leandro von Werra",
            "author_email": "leandro.vonwerra@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: Apache Software License",
                "Natural Language :: English",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/lvwerra/trl",
            "keywords": "ppo,transformers,huggingface,gpt2,language modeling",
            "license": "Apache Software License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "trl",
            "package_url": "https://pypi.org/project/trl/",
            "platform": "",
            "project_url": "https://pypi.org/project/trl/",
            "project_urls": {
                "Homepage": "https://github.com/lvwerra/trl"
            },
            "release_url": "https://pypi.org/project/trl/0.0.2/",
            "requires_dist": [
                "torch (>=1.4.0)",
                "transformers (==2.6.0)",
                "numpy (>=1.18.2)"
            ],
            "requires_python": ">=3.6",
            "summary": "A Pytorch implementation of Proximal Policy Optimization for transfomer language models.",
            "version": "0.0.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13822896,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "88a582ef39161239bfde12da463659b1",
                    "sha256": "2f0e6458b359cc073d652e38cf4b5b827db208a076989a484422e01011b05c68"
                },
                "downloads": -1,
                "filename": "trl-0.0.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "88a582ef39161239bfde12da463659b1",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 15234,
                "upload_time": "2020-07-17T09:55:06",
                "upload_time_iso_8601": "2020-07-17T09:55:06.809991Z",
                "url": "https://files.pythonhosted.org/packages/ea/b5/179e2a8b33cdd78b76ee8df03a7235bc38f9de37c1d88f312fd2c1dee9a0/trl-0.0.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "24c9284ec0dc82eeb3c208f4378e63f1",
                    "sha256": "6b6d12020025e8ac4099c49a4a55e2d100f432c9310c59b38e67f5152cc0bbb9"
                },
                "downloads": -1,
                "filename": "trl-0.0.2.tar.gz",
                "has_sig": false,
                "md5_digest": "24c9284ec0dc82eeb3c208f4378e63f1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 17922,
                "upload_time": "2020-07-17T09:55:08",
                "upload_time_iso_8601": "2020-07-17T09:55:08.142350Z",
                "url": "https://files.pythonhosted.org/packages/c6/ef/d8030a3e44fd0fc83b50e4a97d8ef9f60976a69d4b06d2b3b642577ee300/trl-0.0.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.3": {
        "info": {
            "author": "Leandro von Werra",
            "author_email": "leandro.vonwerra@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: Apache Software License",
                "Natural Language :: English",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/lvwerra/trl",
            "keywords": "ppo,transformers,huggingface,gpt2,language modeling",
            "license": "Apache Software License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "trl",
            "package_url": "https://pypi.org/project/trl/",
            "platform": "",
            "project_url": "https://pypi.org/project/trl/",
            "project_urls": {
                "Homepage": "https://github.com/lvwerra/trl"
            },
            "release_url": "https://pypi.org/project/trl/0.0.3/",
            "requires_dist": [
                "torch (>=1.4.0)",
                "transformers (==4.3.2)",
                "numpy (>=1.18.2)"
            ],
            "requires_python": ">=3.6",
            "summary": "A Pytorch implementation of Proximal Policy Optimization for transfomer language models.",
            "version": "0.0.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13822896,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "2b1420055bac370fde868323667ca55d",
                    "sha256": "15af543cc31b8829b0bb1fe2e14cf802d7b4e439e1bed85ac88847310b0d57a7"
                },
                "downloads": -1,
                "filename": "trl-0.0.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "2b1420055bac370fde868323667ca55d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 15228,
                "upload_time": "2021-02-28T12:27:43",
                "upload_time_iso_8601": "2021-02-28T12:27:43.669910Z",
                "url": "https://files.pythonhosted.org/packages/ba/f2/dc3a0ec63353526f8a5acc14c99b5d9aaa93bbb87281fc417a0bce270ecb/trl-0.0.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "3e1d2c9dcd8bb659a80280965088b095",
                    "sha256": "897ffd6553481f50465baa22a3fba5f0afc3225fc0f667c8d283bd8e5753bc70"
                },
                "downloads": -1,
                "filename": "trl-0.0.3.tar.gz",
                "has_sig": false,
                "md5_digest": "3e1d2c9dcd8bb659a80280965088b095",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 18558,
                "upload_time": "2021-02-28T12:27:44",
                "upload_time_iso_8601": "2021-02-28T12:27:44.663070Z",
                "url": "https://files.pythonhosted.org/packages/2d/e5/a0aca0a105c7a991330b178ff4128154b5c594a6ba7108f73cea381635e8/trl-0.0.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.0": {
        "info": {
            "author": "Leandro von Werra",
            "author_email": "leandro.vonwerra@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: Apache Software License",
                "Natural Language :: English",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8"
            ],
            "description": "# Welcome to Transformer Reinforcement Learning (trl)\n> Train transformer language models with reinforcement learning.\n\n\n## What is it?\nWith `trl` you can train transformer language models with Proximal Policy Optimization (PPO). The library is built on top of the [`transformer`](https://github.com/huggingface/transformers) library by  \ud83e\udd17 Hugging Face. Therefore, pre-trained language models can be directly loaded via `transformers`. At this point only decoder architectures such as GTP2 are implemented.\n\n**Highlights:**\n- PPOTrainer: A PPO trainer for language models that just needs (query, response, reward) triplets to optimise the language model.\n- GPT2 model with a value head: A transformer model with an additional scalar output for each token which can be used as a value function in reinforcement learning.\n- Example: Train GPT2 to generate positive movie reviews with a BERT sentiment classifier.\n\n## How it works\nFine-tuning a language model via PPO consists of roughly three steps:\n\n1. **Rollout**: The language model generates a response or continuation based on query which could be the start of a sentence.\n2. **Evaluation**: The query and response are evaluated with a function, model, human feedback or some combination of them. The important thing is that this process should yield a scalar value for each query/response pair.\n3. **Optimization**: This is the most complex part. In the optimisation step the query/response pairs are used to calculate the log-probabilities of the tokens in the sequences. This is done with the model that is trained and and a reference model, which is usually the pre-trained model before fine-tuning. The KL-divergence between the two outputs is used as an additional reward signal to make sure the generated responses don't deviate to far from the reference language model. The active language model is then trained with PPO.\n\nThis process is illustrated in the sketch below:\n\n\n<div style=\"text-align: center\">\n<img src=\"nbs/images/trl_overview.png\" width=\"800\">\n<p style=\"text-align: center;\"> <b>Figure:</b> Sketch of the workflow. </p>\n</div>\n\n## Installation\n\n### Python package\nInstall the library with pip:\n```bash\npip install trl\n```\n\n### From source\nIf you want to run the examples in the repository a few additional libraries are required. Clone the repository and install it with pip:\n```bash\ngit clone https://github.com/lvwerra/trl.git\ncd tlr/\npip install -r requirements.txt\n```\n### Jupyter notebooks\n\nIf you run Jupyter notebooks you might need to run the following:\n```bash\njupyter nbextension enable --py --sys-prefix widgetsnbextension\n```\n\nFor Jupyterlab additionally this command:\n\n```bash\njupyter labextension install @jupyter-widgets/jupyterlab-manager\n```\n\n## How to use\n\n### Example\nThis is a basic example on how to use the library. Based on a query the language model creates a response which is then evaluated. The evaluation could be a human in the loop or another model's output.\n\n```\n# imports\nimport torch\nfrom transformers import GPT2Tokenizer\nfrom trl.gpt2 import GPT2HeadWithValueModel, respond_to_batch\nfrom trl.ppo import PPOTrainer\n\n# get models\ngpt2_model = GPT2HeadWithValueModel.from_pretrained('gpt2')\ngpt2_model_ref = GPT2HeadWithValueModel.from_pretrained('gpt2')\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\n# initialize trainer\nppo_config = {'batch_size': 1, 'forward_batch_size': 1}\nppo_trainer = PPOTrainer(gpt2_model, gpt2_model_ref, gpt2_tokenizer, **ppo_config)\n\n# encode a query\nquery_txt = \"This morning I went to the \"\nquery_tensor = gpt2_tokenizer.encode(query_txt, return_tensors=\"pt\")\n\n# get model response\nresponse_tensor  = respond_to_batch(gpt2_model, query_tensor)\nresponse_txt = gpt2_tokenizer.decode(response_tensor[0,:])\n\n# define a reward for response\n# (this could be any reward such as human feedback or output from another model)\nreward = [torch.tensor(1.0)]\n\n# train model with ppo\ntrain_stats = ppo_trainer.step([query_tensor[0]], [response_tensor[0]], reward)\n```\n\n### Advanced example: IMDB sentiment\nFor a detailed example check out the notebook `04-gpt2-sentiment-ppo-training.ipynb`, where GPT2 is fine-tuned to generate positive movie reviews. An few examples from the language models before and after optimisation are given below:\n\n<div style=\"text-align: center\">\n<img src=\"nbs/images/table_imdb_preview.png\" width=\"800\">\n<p style=\"text-align: center;\"> <b>Figure:</b> A few review continuations before and after optimisation. </p>\n</div>\n\n\n## Notebooks\nThis library is built with `nbdev` and as such all the library code as well as examples are in Jupyter notebooks. The following list gives an overview:\n\n- `index.ipynb`: Generates the README and the overview page.\n- `00-core.ipynb`: Contains the utility functions used throughout the library and examples.\n- `01-gpt2-with-value-head.ipynb`: Implementation of a `transformer` compatible GPT2 model with an additional value head as well as a function to generate sequences.\n- `02-ppo.ipynb`: Implementation of the PPOTrainer used to train language models.\n- `03-bert-imdb-training.ipynb`: Training of DistilBERT to classify sentiment on the IMDB dataset.\n- `04-gpt2-sentiment-ppo-training.ipynb`: Fine-tune GPT2 with the BERT sentiment classifier to produce positive movie reviews.\n\nCurrently using `trl==0.0.3`:\n- `05-gpt2-sentiment-control.ipynb`: Fine-tune GPT2 with the BERT sentiment classifier to produce movie reviews with controlled sentiment.\n\n## References\n\n### Proximal Policy Optimisation\nThe PPO implementation largely follows the structure introduced in the paper **\"Fine-Tuning Language Models from Human Preferences\"** by D. Ziegler et al. \\[[paper](https://arxiv.org/pdf/1909.08593.pdf), [code](https://github.com/openai/lm-human-preferences)].\n\n### Language models\nThe language models utilize the `transformers` library by \ud83e\udd17 Hugging Face.\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/lvwerra/trl",
            "keywords": "ppo,transformers,huggingface,gpt2,language modeling",
            "license": "Apache Software License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "trl",
            "package_url": "https://pypi.org/project/trl/",
            "platform": null,
            "project_url": "https://pypi.org/project/trl/",
            "project_urls": {
                "Homepage": "https://github.com/lvwerra/trl"
            },
            "release_url": "https://pypi.org/project/trl/0.1.0/",
            "requires_dist": [
                "torch (>=1.4.0)",
                "transformers (==4.3.2)",
                "numpy (>=1.18.2)"
            ],
            "requires_python": ">=3.6",
            "summary": "A Pytorch implementation of Proximal Policy Optimization for transfomer language models.",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13822896,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "54276fbcb506b4d93950accc57c9f91e",
                    "sha256": "fd5561834d893b50f0f0d911c7d0ee8af7fb55ce70dc7146c9199528eeba709c"
                },
                "downloads": -1,
                "filename": "trl-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "54276fbcb506b4d93950accc57c9f91e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 16089,
                "upload_time": "2022-05-15T16:35:03",
                "upload_time_iso_8601": "2022-05-15T16:35:03.389149Z",
                "url": "https://files.pythonhosted.org/packages/35/3f/c5206628502a779bfca10c0e013df9835f9f39f11c22d77d942b1a499a66/trl-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "28cba188ffb3cda8e9d5a386a4ac5bde",
                    "sha256": "b349cee7bab56efbbaa41eaac4e0aedb59bf90c27f13cccb41f690ae15414120"
                },
                "downloads": -1,
                "filename": "trl-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "28cba188ffb3cda8e9d5a386a4ac5bde",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 19077,
                "upload_time": "2022-05-15T16:35:06",
                "upload_time_iso_8601": "2022-05-15T16:35:06.031623Z",
                "url": "https://files.pythonhosted.org/packages/a0/59/f4c62757fa9cfb3a314fecaa6d99b7ae24f64fdd786d1f0f2ac94088e08e/trl-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1.4": {
        "info": {
            "author": "wengsongxiu",
            "author_email": "wengsongxiu@mastercom.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/me/myproject",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "sk-nlp",
            "package_url": "https://pypi.org/project/sk-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/sk-nlp/",
            "project_urls": {
                "Homepage": "https://github.com/me/myproject"
            },
            "release_url": "https://pypi.org/project/sk-nlp/0.1.4/",
            "requires_dist": [
                "numpy",
                "scipy",
                "tensorflow-gpu",
                "bert4keras",
                "sk-common"
            ],
            "requires_python": ">=3.6.0",
            "summary": "nlp kit.",
            "version": "0.1.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10896260,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "cba9830d6eda3561171e4f0bc4c05dc4",
                    "sha256": "bca1586aa3cb999d2e57b9e4d4243526098e0f5a2d4eb516b773277763419f60"
                },
                "downloads": -1,
                "filename": "sk_nlp-0.1.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "cba9830d6eda3561171e4f0bc4c05dc4",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6.0",
                "size": 318226,
                "upload_time": "2021-06-29T03:16:24",
                "upload_time_iso_8601": "2021-06-29T03:16:24.607435Z",
                "url": "https://files.pythonhosted.org/packages/9b/d3/ee9229898486be62ccc556fe630645e3e63586b6137755c8cccd3d1a469f/sk_nlp-0.1.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.5": {
        "info": {
            "author": "wengsongxiu",
            "author_email": "wengsongxiu@mastercom.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/me/myproject",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "sk-nlp",
            "package_url": "https://pypi.org/project/sk-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/sk-nlp/",
            "project_urls": {
                "Homepage": "https://github.com/me/myproject"
            },
            "release_url": "https://pypi.org/project/sk-nlp/0.1.5/",
            "requires_dist": [
                "numpy",
                "scipy",
                "tensorflow-gpu",
                "bert4keras",
                "sk-common"
            ],
            "requires_python": ">=3.6.0",
            "summary": "nlp kit.",
            "version": "0.1.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10896260,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "eea466bb0be7e0721d52fcc89cd1a727",
                    "sha256": "b38309d51a1cb6a300fdc393e429211dc6d0586cdf1733f4e567629528c17a0e"
                },
                "downloads": -1,
                "filename": "sk_nlp-0.1.5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "eea466bb0be7e0721d52fcc89cd1a727",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6.0",
                "size": 318476,
                "upload_time": "2021-07-13T09:44:32",
                "upload_time_iso_8601": "2021-07-13T09:44:32.245881Z",
                "url": "https://files.pythonhosted.org/packages/34/d5/4f195b088bccede9995f3584760080185a5babffa98fe875ecea7dd63743/sk_nlp-0.1.5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.6": {
        "info": {
            "author": "wengsongxiu",
            "author_email": "wengsongxiu@mastercom.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/me/myproject",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "sk-nlp",
            "package_url": "https://pypi.org/project/sk-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/sk-nlp/",
            "project_urls": {
                "Homepage": "https://github.com/me/myproject"
            },
            "release_url": "https://pypi.org/project/sk-nlp/0.1.6/",
            "requires_dist": [
                "numpy",
                "scipy",
                "tensorflow-gpu",
                "bert4keras",
                "sk-common"
            ],
            "requires_python": ">=3.6.0",
            "summary": "nlp kit.",
            "version": "0.1.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10896260,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a7ee50f8d686328a73d37a99e394b171",
                    "sha256": "33d47e74dfbd2cf21537316ffecd57d164862d025a0e8fbb1bbc3c93904259d9"
                },
                "downloads": -1,
                "filename": "sk_nlp-0.1.6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "a7ee50f8d686328a73d37a99e394b171",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6.0",
                "size": 318478,
                "upload_time": "2021-07-13T10:24:14",
                "upload_time_iso_8601": "2021-07-13T10:24:14.399278Z",
                "url": "https://files.pythonhosted.org/packages/79/a1/dd43a021fc73f556785116304ef97d190592c7dc8f25185f3fd9fe7802a2/sk_nlp-0.1.6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.7": {
        "info": {
            "author": "wengsongxiu",
            "author_email": "wengsongxiu@mastercom.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/me/myproject",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "sk-nlp",
            "package_url": "https://pypi.org/project/sk-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/sk-nlp/",
            "project_urls": {
                "Homepage": "https://github.com/me/myproject"
            },
            "release_url": "https://pypi.org/project/sk-nlp/0.1.7/",
            "requires_dist": [
                "numpy",
                "scipy",
                "tensorflow-gpu",
                "bert4keras",
                "sk-common"
            ],
            "requires_python": ">=3.6.0",
            "summary": "nlp kit.",
            "version": "0.1.7",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10896260,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "15119c203c8a16035ca516c1e70e4d72",
                    "sha256": "49b21a5bb38e02441e74664ac20e341e8f4fe44014cae6b4db45afe8c58c543c"
                },
                "downloads": -1,
                "filename": "sk_nlp-0.1.7-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "15119c203c8a16035ca516c1e70e4d72",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6.0",
                "size": 318476,
                "upload_time": "2021-07-13T10:28:03",
                "upload_time_iso_8601": "2021-07-13T10:28:03.985386Z",
                "url": "https://files.pythonhosted.org/packages/bb/07/3aeff9e4e42b76c89a080a9a88e65ad91b9918412ff4241907a106c59e70/sk_nlp-0.1.7-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.8": {
        "info": {
            "author": "wengsongxiu",
            "author_email": "wengsongxiu@mastercom.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/me/myproject",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "sk-nlp",
            "package_url": "https://pypi.org/project/sk-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/sk-nlp/",
            "project_urls": {
                "Homepage": "https://github.com/me/myproject"
            },
            "release_url": "https://pypi.org/project/sk-nlp/0.1.8/",
            "requires_dist": [
                "numpy",
                "scipy",
                "tensorflow-gpu",
                "bert4keras",
                "sk-common"
            ],
            "requires_python": ">=3.6.0",
            "summary": "nlp kit.",
            "version": "0.1.8",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10896260,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c66139ef8f5868e20652967c523591ae",
                    "sha256": "68188fafdb18fafe0dbed219b894d201c1b785397339eafedd78bff3e6c86a7c"
                },
                "downloads": -1,
                "filename": "sk_nlp-0.1.8-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "c66139ef8f5868e20652967c523591ae",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6.0",
                "size": 317640,
                "upload_time": "2021-07-13T10:31:15",
                "upload_time_iso_8601": "2021-07-13T10:31:15.215336Z",
                "url": "https://files.pythonhosted.org/packages/d0/33/bbf5c557cc0ad06735ff67b4c1b069f432ef00443621c491ca780538a4cd/sk_nlp-0.1.8-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.9": {
        "info": {
            "author": "wengsongxiu",
            "author_email": "wengsongxiu@mastercom.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description": "\n# sk-nlp\n\n[![Travis](https://travis-ci.org/CyberZHG/keras-transformer.svg)](https://travis-ci.org/CyberZHG/keras-transformer)\n[![Coverage](https://coveralls.io/repos/github/CyberZHG/keras-transformer/badge.svg?branch=master)](https://coveralls.io/github/CyberZHG/keras-transformer)\n\n![](https://img.shields.io/badge/keras-tensorflow-blue.svg)\n![](https://img.shields.io/badge/keras-tf.keras-blue.svg)\n![](https://img.shields.io/badge/keras-tf.keras/eager-blue.svg)\n![](https://img.shields.io/badge/keras-tf.keras/2.0_beta-blue.svg)\n\n\n\n\ud83d\udce6 \u9879\u76ee\u4ecb\u7ecd (for humans)\n=======================\n\n\u8fd9\u4e2a\u7b2c\u4e09\u65b9\u4ed3\u5e93\u662f\u7531\u6df1\u5733\u5e02\u540d\u901a\u79d1\u6280\u80a1\u4efd\u6709\u9650\u516c\u53f8AI\u56e2\u961f\u63d0\u4f9b\u7684\u3002\u56e2\u961f\u81f4\u529b\u4e8e\u4e3aNLP\u9886\u57df\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7a33\u5b9a\u53ef\u9760\uff0c \u529f\u80fd\u5b8c\u5584\u7684NLP\u5e38\u89c1\u64cd\u4f5c\u3002\n\n\nInstallation\n-----\n\n```bash\ncd your_project\npip install sk-nlp\n```\n\n# Content\n* sk_nlp package\n\n    * <a href='#sk_nlp.nlp_feature_extract package'>sk_nlp.nlp_feature_extract package</a>\n\n      * <a href='#sk_nlp.nlp_feature_extract.feature module'>sk_nlp.nlp_feature_extract.feature module</a>\n\n      * <a href='#sk_nlp.nlp_feature_extract.text_filter module'>sk_nlp.nlp_feature_extract.text_filter module</a>\n\n      * <a href='#sk_nlp.nlp_feature_extract.tokenizer module'>sk_nlp.nlp_feature_extract.tokenizer module</a>\n\n    * <a href='#sk_nlp.nlp_feature_embedding package'>sk_nlp.nlp_feature_embedding package</a>\n\n      * <a href='#sk_nlp.nlp_feature_embedding.bert module'>sk_nlp.nlp_feature_embedding.bert module</a>\n\n      * <a href='#sk_nlp.nlp_feature_embedding.similarity module'>sk_nlp.nlp_feature_embedding.similarity module</a>\n\n      * <a href='#sk_nlp.nlp_feature_embedding.w2v module'>sk_nlp.nlp_feature_embedding.w2v module</a>\n\n<div id=\"sk_nlp.nlp_feature_extract package\">\nsk_nlp.nlp_feature_extract package\n\n\n<div id=\"sk_nlp.nlp_feature_extract.feature module\">\nsk_nlp.nlp_feature_extract.feature module\n\n0 \u4f7f\u7528ac\u81ea\u52a8\u673a\u7edf\u8ba1\u7ed9\u5b9a\u7684\u8bcd\u8bed\u7684\u8bcd\u9891 1 \u83b7\u53d6tf-idf\u7279\u5f81\n\nclass sk_nlp.nlp_feature_extract.feature.CountByAC(pattern_list=[])\n\n   Bases: \"object\"\n\n   \u57fa\u4e8eac\u81ea\u52a8\u673a\u6765\u7edf\u8ba1\u6a21\u5f0f\u4e32\n\n   Parameters:\n      **pattern_list** -- \u5339\u914d\u7684\u6a21\u5f0f\u4e32\u5217\u8868\n\n   build_tree(pattern_list)\n\n      \u6784\u5efa\u6a21\u5f0f\u4e32\u524d\u7f00\u6811\n\n      Parameters:\n         **pattern_list** -- \u6a21\u5f0f\u4e32\u5217\u8868\n\n   count(sentence)\n\n      \u7edf\u8ba1sentence\u4e2d\u5173\u4e8e\u7ed9\u5b9a\u7684\u6a21\u5f0f\u4e32\u7684\u9891\u7387\n\n      Parameters:\n         **sentence** -- \u53e5\u5b50\n\n      Returns:\n         word_count \u6bcf\u4e2a\u5173\u952e\u8bcd\u5bf9\u5e94\u7684\u9891\u7387\n\n      >>> ac = CountByAC(['\u6770\u4f26\u7684\u4e03', '\u5468\u6770\u4f26\u7684', '\u4e03\u91cc\u9999'])\n      >>> result = ac.count('\u5468\u6770\u4f26\u7684\u4e03\u91cc\u9999\u4e03\u91cc\u9999')\n      >>> print(result)\n      {'\u5468\u6770\u4f26\u7684': 1, '\u6770\u4f26\u7684\u4e03': 1, '\u4e03\u91cc\u9999': 2}\n\nclass sk_nlp.nlp_feature_extract.feature.KeyWordExtract\n\n   Bases: \"object\"\n\n   \u5173\u952e\u8bcd\u62bd\u53d6\u7b97\u6cd5\uff0c\u57fa\u4e8etf-idf\n\n   get_tf_idf(sentence_list, model_file)\n\n      \u52a0\u8f7dtf-idf\u6a21\u578b\uff0c\u8fd4\u56desentence_list\u5bf9\u5e94\u7684\u7279\u5f81\u548c\u6a21\u578b\n\n      Parameters:\n         * **sentence_list** -- \u53e5\u5b50\u5217\u8868\uff08\u5206\u8bcd\u540e\uff09\n\n         * **model_file** -- tf-idf\u6a21\u578b\u6587\u4ef6\n\n      Returns:\n         tf_idf_model(\u6a21\u578b\u5b9e\u4f8b), tfidf_feature(sentence_list\u5bf9\u5e94\u7684tf-\n         idf\u7279\u5f81)\n\n      >>> tf_idf_model, tfidf_feature = kwe.get_tf_idf(['\u6770\u4f26 \u662f \u53f0\u6e7e \u6b4c\u624b', '\u4e03\u91cc\u9999 \u662f \u6770\u4f26 \u521b\u4f5c'], file_conf.tf_idf_file_path)\n      >>> print(tfidf_feature)\n        (0, 4)        0.6316672017376245\n        (0, 3)        0.4494364165239821\n        (0, 2)        0.6316672017376245\n        (1, 3)        0.4494364165239821\n        (1, 1)        0.6316672017376245\n        (1, 0)        0.6316672017376245\n\n   get_topk_keywords(data_list, topk=200)\n\n      \u5f97\u5230topk\u4e2a\u5173\u952e\u8bcd\n\n      Parameters:\n         * **data_list** -- \u53e5\u5b50\u5217\u8868\uff08\u5206\u8bcd\u540e\uff09\n\n         * **topk** -- tf-idf\u91cd\u8981\u5ea6\u6392\u5e8f\u540e\u524dtopk\n\n      Returns:\n         keywords\n\n      >>> keywords = kwe.get_topk_keywords(['\u6770\u4f26 \u662f \u53f0\u6e7e \u6b4c\u624b', '\u4e03\u91cc\u9999 \u662f \u6770\u4f26 \u521b\u4f5c'], topk=1)\n      >>> print(keywords)\n      [['\u6b4c\u624b']['\u521b\u4f5c']]\n\n   train_tf_idf(sentence_list, model_file, ngram_range=(1, 1))\n\n      \u8bad\u7ec3tf-idf\u6a21\u578b\uff0c\u4fdd\u5b58\u6a21\u578b\uff0c\u8fd4\u56de\u6a21\u578b\u548c\u7279\u5f81\n\n      Parameters:\n         * **sentence_list** -- \u53e5\u5b50\u5217\u8868\uff08\u5206\u8bcd\u540e\uff09\n\n         * **model_file** -- tf-idf\u6a21\u578b\u4fdd\u5b58\u6587\u4ef6\n\n      Returns:\n         tf_idf_model, tfidf_feature\n</div>\n<div id=\"sk_nlp.nlp_feature_extract.text_filter module\">\nsk_nlp.nlp_feature_extract.text_filter module\n\n\n\u654f\u611f\u8bcd\u6c47\u8fc7\u6ee4\u6a21\u5757\uff0c\u5171\u5b9e\u73b0\u4e863\u4e2a\u7c7b\uff1aNaiveFilter\uff0cBSFilter\uff0cDFAFilter\n\nclass sk_nlp.nlp_feature_extract.text_filter.BSFilter\n\n   Bases: \"object\"\n\n   \u5bbd\u5ea6\u4f18\u5148\u904d\u5386\u7684\u65b9\u5f0f\u8fc7\u6ee4\n\n   add(keyword)\n\n      \u65b0\u589e\u4e00\u4e2a\u654f\u611f\u8bcd\n\n      :param keyword:\u654f\u611f\u8bcd :return:\u65e0\n\n   filter(message, repl='*')\n\n      \u8fc7\u6ee4\u6389\u654f\u611f\u8bcd\n\n      Parameters:\n         * **message** -- \u539f\u59cb\u7684\u8f93\u5165\u53e5\u5b50\n\n         * **repl** -- \u654f\u611f\u8bcd\u6c47\u88ab\u66ff\u6362\u6210\u7684\u5b57\u7b26\n\n      Returns:\n         message \u5c4f\u853d\u6389\u654f\u611f\u8bcd\u6c47\u7684\u53e5\u5b50\n\n      >>> f = BSFilter()\n      >>> question = \"\u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u5417\"\n      >>> filter_question = f.filter(question)\n      >>> print(question, filter_question)\n      \u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u5417 *\u662f\u4e2d\u56fd\u7684\u5417\n\n   parse(path)\n\n      \u52a0\u8f7d\u654f\u611f\u8bcd\u6c47\u8868\n\n      Parameters:\n         **path** -- \u8def\u5f84\u4e3a/sk-nlp/data/dirty_word.txt\n\n      Returns:\nclass sk_nlp.nlp_feature_extract.text_filter.DFAFilter\n\n   Bases: \"object\"\n\n   DFA\u5373Deterministic Finite Automaton\uff0c\u4e5f\u5c31\u662f\u786e\u5b9a\u6709\u7a77\u81ea\u52a8\u673a\u3002 \u7b97\u6cd5\u6838\n   \u5fc3\u662f\u5efa\u7acb\u4e86\u4ee5\u654f\u611f\u8bcd\u4e3a\u57fa\u7840\u7684\u8bb8\u591a\u654f\u611f\u8bcd\u6811\n\n   add(keyword)\n\n      \u65b0\u589e\u4e00\u4e2a\u654f\u611f\u8bcd\n\n      :param keyword:\u654f\u611f\u8bcd :return:\u65e0\n\n   detect(message)\n\n      \u5224\u65admessage\u662f\u5426\u5305\u542b\u654f\u611f\u8bcd\u6c47\n\n      :param message:\u7528\u6237\u8f93\u5165\u7684\u53e5\u5b50 :return: True/False\n\n   filter(message, repl='*')\n\n      \u8fc7\u6ee4\u6389\u654f\u611f\u8bcd\n\n      Parameters:\n         * **message** -- \u539f\u59cb\u7684\u8f93\u5165\u53e5\u5b50\n\n         * **repl** -- \u654f\u611f\u8bcd\u6c47\u88ab\u66ff\u6362\u6210\u7684\u5b57\u7b26\n\n      Returns:\n         message \u5c4f\u853d\u6389\u654f\u611f\u8bcd\u6c47\u7684\u53e5\u5b50\n\n      >>> f = DFAFilter()\n      >>> question = \"\u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u5417\"\n      >>> filter_question = f.filter(question)\n      >>> print(question, filter_question)\n      \u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u5417 *\u662f\u4e2d\u56fd\u7684\u5417\n\n   parse(path)\n\n      \u52a0\u8f7d\u654f\u611f\u8bcd\u6c47\u8868\n\n      Parameters:\n         **path** -- \u8def\u5f84\u4e3a/sk-nlp/data/dirty_word.txt\n\n      Returns:\nclass sk_nlp.nlp_feature_extract.text_filter.NaiveFilter\n\n   Bases: \"object\"\n\n   \u666e\u901a\u7684\u8fc7\u6ee4\u65b9\u5f0f\uff1a\u4f7f\u7528\u96c6\u5408\u7684\u65b9\u5f0f\u8fc7\u6ee4\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u8ddf\u96c6\u5408\u7684\u5927\u5c0f\u6709\u5173\n\n   filter(message, repl='*')\n\n      \u8fc7\u6ee4\u6389\u654f\u611f\u8bcd\n\n      Parameters:\n         * **message** -- \u539f\u59cb\u7684\u8f93\u5165\u53e5\u5b50\n\n         * **repl** -- \u654f\u611f\u8bcd\u6c47\u88ab\u66ff\u6362\u6210\u7684\u5b57\u7b26\n\n      Returns:\n         message\uff1a\u5c4f\u853d\u6389\u654f\u611f\u8bcd\u6c47\u7684\u53e5\u5b50\n\n      >>> f = NaiveFilter()\n      >>> question = \"\u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u5417\"\n      >>> filter_question = f.filter(question)\n      >>> print(question, filter_question)\n      \u53f0\u6e7e\u662f\u4e2d\u56fd\u7684\u5417 *\u662f\u4e2d\u56fd\u7684\u5417\n\n   parse(path)\n\n      \u52a0\u8f7d\u654f\u611f\u8bcd\u6c47\u8868\n\n      Parameters:\n         **path** -- \u8def\u5f84\u4e3a/sk-nlp/data/dirty_word.txt\n\n      Returns:\n</div>\n\n<div id=\"sk_nlp.nlp_feature_extract.tokenizer module\">\nsk_nlp.nlp_feature_extract.tokenizer module\n===========================================\n\n\u8bcd\u8bed\u7c92\u5ea6\u7684\u64cd\u4f5c\u6a21\u5757\uff1a\u5206\u8bcd\uff0c\u53bb\u505c\u7528\u8bcd\uff0c\u540c\u4e49\u8bcd\u6797\u8f6c\u6362\n\nclass sk_nlp.nlp_feature_extract.tokenizer.SentenceCut(is_lower=True, stopword_list=[], use_chinese_synonyms=False)\n\n   Bases: \"object\"\n\n   \u53e5\u5b50\u5206\u8bcd\u64cd\u4f5c\u7c7b \u76ee\u524d\u96c6\u6210\u4e86jieba\u5206\u8bcd\n\n   cut_word(sentence_list)\n\n      \u5bf9\u4f20\u8fdb\u6765\u7684\u53e5\u5b50\u8fdb\u884c\u5206\u8bcd\n\n      :param sentence_list:['\u6211\u7231\u4e2d\u56fd', '\u6211\u662f\u4e2d\u56fd\u4eba']\n      :return:seg_lists [['\u6211', '\u7231', '\u4e2d\u56fd'], ['\u6211', '\u662f', '\u4e2d\u56fd', '\n      \u4eba']]  token_count {'\u6211': 2, '\u7231': 1, '\u4e2d\u56fd': 2, '\u662f': 1, '\u4eba':\n      1}\n\n      >>> sen_cut = SentenceCut(use_chinese_synonyms=True)\n      >>> seg_lists, token_count = sen_cut.cut_word(['\u6211\u7231baidu', '\u6211\u662f\u4e2d\u56fd\u4eba'])\n      >>> print(seg_lists, token_count)\n      [['\u6211', '\u7231', '\u767e\u5ea6'], ['\u6211', '\u662f', '\u4e2d\u56fd', '\u4eba']]\n      {'\u6211': 2, '\u7231': 1, '\u767e\u5ea6': 1, '\u662f': 1, '\u4e2d\u56fd': 1, '\u4eba': 1}\n\n   load_chinese_synonyms()\n\n      \u52a0\u8f7d\u540c\u4e49\u8bcd\u6797\n\n      Returns:\n         union_find \uff08\u5e76\u67e5\u96c6\u5b9e\u4f8b\uff09\uff0cword_list\uff08\u540c\u4e49\u8bcd\u6797\u6240\u6709\u7684\u5355\u8bcd\u96c6\u5408\n         \uff09\n\nclass sk_nlp.nlp_feature_extract.tokenizer.StopWord(source='', define_stop_word=[])\n\n   Bases: \"object\"\n\n   \u505c\u7528\u8bcd\u64cd\u4f5c\u7c7b\uff1a \u505c\u7528\u8bcd\u6c47\u8868\u8def\u5f84\u5b58\u653e\u5728 sk-nlp/data/stopword\n\n   load_stop_word()\n\n      \u6839\u636e\u4e0d\u540c\u7684self.source\u52a0\u8f7d\u4e0d\u540c\u7684\u505c\u7528\u8bcd\u8868\n\n      Returns:\n         stop_word_list \u505c\u7528\u8bcd\u5217\u8868\n\n   merge_stop_word(define_stop_word)\n\n      \u5c06\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u505c\u7528\u8bcd\u548c\u7528\u6237\u6307\u5b9a\u7684\u901a\u7528\u8bcd\u5e93\u5408\u5e76\u6210\u4e00\u4e2alist\n\n      Parameters:\n         **define_stop_word** -- \u7528\u6237\u7ed9\u7684\u81ea\u5b9a\u4e49\u505c\u7528\u8bcd\u5217\u8868 list\n\n      Returns:\n         stop_word_list \u505c\u7528\u8bcd\u5217\u8868\n</div>\n</div>\n<div id=\"sk_nlp.nlp_feature_embedding package\">\nsk_nlp.nlp_feature_embedding package\n\n\n\n<div id=\"sk_nlp.nlp_feature_embedding.bert module\">\nsk_nlp.nlp_feature_embedding.bert module\n========================================\n\nbert\u57fa\u672c\u6a21\u578b\u52a0\u8f7d\n\nclass sk_nlp.nlp_feature_embedding.bert.MaskLayer(output_dim=768, **kwargs)\n\n   Bases: \"keras.engine.base_layer.Layer\"\n\n   mask \u5c42\uff0c\u5c4f\u853d\u6389seg_id\u4e3a0\u7684\u8bcd\u8bed\n\n   build(input_shape)\n\n      \u521b\u5efa\u5c42\u7684\u6743\u91cd\n\n      :param input_shape:Keras tensor (future input to layer) or\n      list/tuple of Keras tensors :return:\n\n   call(x)\n\n      This is where the layer's logic lives.\n\n      # Arguments\n         inputs: Input tensor, or list/tuple of input tensors.\n         >>**<<kwargs: Additional keyword arguments.\n\n      # Returns\n         A tensor or list/tuple of tensors.\n\n   compute_output_shape(input_shape)\n\n      Computes the output shape of the layer.\n\n      Assumes that the layer will be built to match that input shape\n      provided.\n\n      # Arguments\n         input_shape: Shape tuple (tuple of integers)\n            or list of shape tuples (one per output tensor of the\n            layer). Shape tuples can include None for free dimensions,\n            instead of an integer.\n\n      # Returns\n         An output shape tuple.\n\nclass sk_nlp.nlp_feature_embedding.bert.ReverseMaskLayer(**kwargs)\n\n   Bases: \"keras.engine.base_layer.Layer\"\n\n   \u53cd\u8f6c mask \u5c42\uff0c\u5c4f\u853d\u6389seg_id\u4e3a1\u7684\u8bcd\u8bed\n\n   call(x)\n\n      This is where the layer's logic lives.\n\n      # Arguments\n         inputs: Input tensor, or list/tuple of input tensors.\n         >>**<<kwargs: Additional keyword arguments.\n\n      # Returns\n         A tensor or list/tuple of tensors.\n\n   compute_output_shape(input_shape)\n\n      Computes the output shape of the layer.\n\n      Assumes that the layer will be built to match that input shape\n      provided.\n\n      # Arguments\n         input_shape: Shape tuple (tuple of integers)\n            or list of shape tuples (one per output tensor of the\n            layer). Shape tuples can include None for free dimensions,\n            instead of an integer.\n\n      # Returns\n         An output shape tuple.\n\nclass sk_nlp.nlp_feature_embedding.bert.SepLayer(**kwargs)\n\n   Bases: \"keras.engine.base_layer.Layer\"\n\n   sep mask \u5c42\uff0c\u5c4f\u853d\u6389sep\u4f4d\u7f6e\u7684\u8f93\u51fa\n\n   call(x)\n\n      This is where the layer's logic lives.\n\n      # Arguments\n         inputs: Input tensor, or list/tuple of input tensors.\n         >>**<<kwargs: Additional keyword arguments.\n\n      # Returns\n         A tensor or list/tuple of tensors.\n\n   compute_output_shape(input_shape)\n\n      Computes the output shape of the layer.\n\n      Assumes that the layer will be built to match that input shape\n      provided.\n\n      # Arguments\n         input_shape: Shape tuple (tuple of integers)\n            or list of shape tuples (one per output tensor of the\n            layer). Shape tuples can include None for free dimensions,\n            instead of an integer.\n\n      # Returns\n         An output shape tuple.\n\nsk_nlp.nlp_feature_embedding.bert.build_model_feature(origin_model, use_cls=False)\n\n   \u642d\u5efa\u65b0\u7684\u53e5\u5b50\u6a21\u578b\n\n   Parameters:\n      * **origin_model** -- \u539f\u59cb\u6a21\u578b\uff0c\u4e00\u822c\u4e3abert\n\n      * **use_cls** -- \u662f\u5426\u4f7f\u7528cls\u4f4d\u7f6e\u7684\u8f93\u51fa\n\n   Returns:\n      model\uff1a\u65b0\u6a21\u578b\n\nsk_nlp.nlp_feature_embedding.bert.encoder(model, data_list, dict_path='/machinelearn/wzh/sk_nlp/sk_nlp/model/bert/chinese_L-12_H-768_A-12/vocab.txt')\n\n   \u4f7f\u7528\u53e5\u5411\u91cf\u6a21\u578b\uff0c\u5c06\u53e5\u5b50\u8f6c\u7801\u6210\u53e5\u5411\u91cf\n\n   Parameters:\n      * **model** -- \u6a21\u578b\n\n      * **data_list** -- \u53e5\u5b50\u5217\u8868\uff08\u6ca1\u6709\u5206\u8bcd\uff09\n\n      * **dict_path** -- bert\u6a21\u578b\u8bcd\u6c47\u8868\n\n   Returns:\n      data_list\u4e2d\u7684\u6bcf\u4e2a\u53e5\u5b50\u5bf9\u5e94\u7684\u53e5\u5411\u91cf\u5217\u8868\n\n   >>> origin_model = load_bert_model()\n   >>> new_model = build_model_feature(origin_model)\n   >>> question_list = [\"\u6211\u7231\u8fd9\u4e2a\u4f1f\u5927\u7684\u4e16\u754c\", \"\u6b23\u8d4f\u4e16\u754c\u7684\u98ce\u666f\"]\n   >>> sen_vector_lists = encoder(new_model, question_list)\n   >>> print(sen_vector_lists.shape)\n\nsk_nlp.nlp_feature_embedding.bert.load_bert_model(with_mlm=True, with_pool=False, return_keras_model=True, config_path='/machinelearn/wzh/sk_nlp/sk_nlp/model/bert/chinese_L-12_H-768_A-12/bert_config.json', checkpoint_path='/machinelearn/wzh/sk_nlp/sk_nlp/model/bert/chinese_L-12_H-768_A-12/bert_model.ckpt')\n\n   \u52a0\u8f7dbert \u6a21\u578b\n\n   Parameters:\n      * **with_mlm** -- \u662f\u5426\u6b63\u5219\u5316\n\n      * **with_pool** -- \u662f\u5426\u6c60\u5316\n\n      * **return_keras_model** -- \u8fd4\u56de\u7684\u662fkeras model \u8fd8\u662f tensorflow\n        \u6a21\u578b\n\n      * **config_path** -- bert \u6a21\u578b\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\n\n      * **checkpoint_path** -- bert \u6a21\u578b\u8def\u5f84\n\n   Returns:\nsk_nlp.nlp_feature_embedding.bert.masked_crossentropy(y_true, y_pred)\n\n   mask\u6389\u975e\u9884\u6d4b\u90e8\u5206\uff0c\u8ba1\u7b97\u4ea4\u53c9\u71b5\n\n   Parameters:\n      * **y_true** -- \u771f\u5b9e\u7684Y\u6807\u7b7e\n\n      * **y_pred** -- \u9884\u6d4b\u7684Y\u6807\u7b7e\n\n   Returns:\n      \u635f\u5931\u503c\n</div>\n\n<div id=\"sk_nlp.nlp_feature_embedding.similarity module\">\nsk_nlp.nlp_feature_embedding.similarity module\n==============================================\n\n\u8ba1\u7b97\u5404\u79cd\u8ddd\u79bb\n\nsk_nlp.nlp_feature_embedding.similarity.get_distance_sim_matrix(matrix1, matrix2, metric='cosine')\n\n   \u8fd4\u56de2\u4e2a\u77e9\u9635\u7684\u5404\u79cd\u8ddd\u79bb\u548c\u76f8\u4f3c\u5ea6\n\n   Parameters:\n      * **matrix1** -- \u53e5\u5b50\u5411\u91cf1\n\n      * **matrix2** -- \u53e5\u5b50\u5411\u91cf2\n\n      * **metric** -- 'braycurtis', 'canberra', 'chebyshev',\n        'cityblock', 'correlation',\n\n   'cosine', 'dice', 'euclidean', 'hamming', 'jaccard',\n   'jensenshannon', 'kulsinski', 'mahalanobis', 'matching',\n   'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n   'sokalmichener', 'sokalsneath', 'sqeuclidean', 'wminkowski', 'yule'\n   :return:\n\nsk_nlp.nlp_feature_embedding.similarity.get_edit_distance(query_sen_list, candidate_sen_list)\n\n   \u8ba1\u7b97\u7f16\u8f91\u8ddd\u79bb\n\n   Parameters:\n      * **query_sen_list** -- \u5982['\u6211\u7231\u4e2d\u56fd', '\u7f8e\u56fd\u603b\u7edf\u7279\u6717\u666e']\n\n      * **candidate_sen_list** -- \u5982['\u6211\u7231\u5730\u7403', '\u7f8e\u56fd\u603b\u7edf\u62dc\u767b']\n\n   Returns:\nsk_nlp.nlp_feature_embedding.similarity.get_edit_similarity(distance_matrix, norm=True)\n\n   \u5148\u53cd\u8f6c\u7f16\u8f91\u8ddd\u79bb\u77e9\u9635\uff0c\u5f97\u5230\u7f16\u8f91\u76f8\u4f3c\u5ea6\u77e9\u9635\uff0c\u7136\u540e\u53ef\u4ee5\u9009\u62e9\u5f52\u4e00\u5316\n\n   Parameters:\n      * **distance_matrix** -- \u8ddd\u79bb\u77e9\u9635\n\n      * **norm** -- True/False\n\n   Returns:\nsk_nlp.nlp_feature_embedding.similarity.get_jaccard_sim(sen_list1, sen_list2, norm=False)\n\n   \u83b7\u5f97\u6770\u5361\u5fb7\u76f8\u4f3c\u5ea6\n\n   Parameters:\n      * **sen_list1** -- [['\u6211', '\u7231','\u4e2d\u56fd'], ['\u7f8e\u56fd', '\u603b\u7edf', '\u7279\u6717\n        \u666e']]\n\n      * **sen_list2** -- [['\u6211', '\u7231','\u5730\u7403'], ['\u7f8e\u56fd', '\u603b\u7edf', '\u62dc\u767b\n        ']]\n\n   :param norm:\u662f\u5426\u5bf9\u7ed3\u679c\u8fdb\u884c\u5f52\u4e00\u5316 :return:\n\nsk_nlp.nlp_feature_embedding.similarity.match_topk(sim_matrix, topk=1, order=0)\n\n   \u8fd4\u56de\u76f8\u4f3c\u5ea6\u77e9\u9635\u524dtopk/\u6216\u8005\u540etopk\n\n   Parameters:\n      * **sim_matrix** --\n\n      * **topk** --\n\n      * **order** --\n\n   Returns:\nsk_nlp.nlp_feature_embedding.similarity.normalization(matrix, reversed=True)\n\n   \u5f52\u4e00\u5316\u77e9\u9635\uff0c\u6309\u7167\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\n\n   Parameters:\n      * **matrix** --\n\n      * **reversed** --\n\n   Returns:\n</div>\n\n<div id=\"sk_nlp.nlp_feature_embedding.w2v module\">\nsk_nlp.nlp_feature_embedding.w2v module\n=======================================\n\n\u4f20\u7edf\u7684w2v\u6a21\u578b:\u5305\u542bskip-gram\u548ccbow \u76ee\u524d\u6709\u4e00\u4e2a\u4ecewiki\u8bed\u6599\u8bad\u7ec3\u51fa\u6765\u7684100\u7ef4\n\u5ea6\u7684skip-gram\u6a21\u578b\n\nclass sk_nlp.nlp_feature_embedding.w2v.WordEmbedding(model_file_path='/machinelearn/wzh/sk_nlp/sk_nlp/model/w2v/skip_gram_wiki2Vec.h5', embedding_dim=100)\n\n   Bases: \"object\"\n\n   fine_tune(new_seg_list, model_file_path)\n\n      \u57fa\u4e8e\u5df2\u6709\u7684w2v\u6a21\u578b\uff0c\u4f7f\u7528\u5176\u4ed6\u8bed\u6599\u8fdb\u884c\u5fae\u8c03\u3002\u7136\u540e\u4fdd\u5b58\u6a21\u578b\u8def\u5f84\u3002\n\n      Parameters:\n         * **new_seg_list** -- \u65b0\u53e5\u5b50\uff08\u5206\u8bcd\u540e\uff09\n\n         * **model_file_path** -- \u6a21\u578b\u7684\u4fdd\u5b58\u8def\u5f84\n\n      Returns:\n      >>> model = WordEmbedding()\n      >>> model.get_embedding()\n      >>> new_seg_list = [['\u6211', '\u7231','\u4e2d\u56fd'], ['\u7f8e\u56fd', '\u603b\u7edf', '\u7279\u6717\u666e']]\n      >>> model.fine_tune(new_seg_list, file_conf.ft_wiki_sg_file_path)\n\n   get_embedding()\n\n      \u83b7\u53d6\u8bcd\u5411\u91cf\u6a21\u578b\u7684\u4fe1\u606f\n\n      Returns:\n         embedding_matrix:\u8bcd\u5411\u91cf\u77e9\u9635\uff1bindex_word\uff1a\u7d22\u5f15\u5230\u5355\u8bcd\u7684\u6620\u5c04\uff1b\n         word_index\uff1a\u5355\u8bcd\u5230\u7d22\u5f15\u7684\u6620\u5c04\n\n   op2model()\n\n      \u7531\u4e8ew2v\u7684\u63a5\u53e3\u592a\u591a\uff0c\u4e0d\u592a\u597d\u5c01\u88c5 \u8fd9\u91cc\u7ed9\u51fa\u4e86\u6a21\u578b\u7684\u4e00\u4e9b\u5e38\u7528\u64cd\u4f5c\u8303\u4f8b\n\n      Returns:\n   train_vec(sentence_list, model_file_path, window=5, min_count=5, sg=0)\n\n      \u4f7f\u7528w2v\u8bad\u7ec3\u8bcd\u5411\u91cf\n\n      Parameters:\n         * **sentence_list** -- \u53e5\u5b50\u5217\u8868\uff0c[['\u6211', '\u7231','\u4e2d\u56fd'], ['\u7f8e\u56fd\n           ', '\u603b\u7edf', '\u7279\u6717\u666e']]\n\n         * **model_file_path** -- \u6a21\u578b\u4fdd\u5b58\u8def\u5f84\n\n         * **window** -- \u6ed1\u52a8\u7a97\u53e3\n\n         * **min_count** -- \u6700\u5c0f\u8bcd\u9891\n\n         * **sg** -- 0\u662f\u4f7f\u7528cbow, 1\u662f\u4f7f\u7528\u8df3\u5b57\u6a21\u578b\n\n      Returns:\n</div>\n</div>\nModule contents\n===============\n\n\nModule contents\n===============\n\n\nMore Resources\n--------------\n\n-   [where is bert pre-train model]  https://github.com/google-research/bert\n-   [where is stopwords corpus]  https://github.com/goto456/stopwords\n-   [Official Python Packaging User Guide](https://packaging.python.org)\n-   [The Hitchhiker's Guide to Packaging]\n\nLicense\n-------\n\nThis is free and unencumbered software released into the public domain.\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any means.\n\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/me/myproject",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "sk-nlp",
            "package_url": "https://pypi.org/project/sk-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/sk-nlp/",
            "project_urls": {
                "Homepage": "https://github.com/me/myproject"
            },
            "release_url": "https://pypi.org/project/sk-nlp/0.1.9/",
            "requires_dist": [
                "numpy",
                "scipy",
                "tensorflow-gpu",
                "bert4keras",
                "sk-common"
            ],
            "requires_python": ">=3.6.0",
            "summary": "nlp kit.",
            "version": "0.1.9",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10896260,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "79ccfc2fcb5025d61a13fd43947d1761",
                    "sha256": "49af0f092876a964ae3b3092a1c9ee7a857e8f42876d6da31f04fe1d35d4b523"
                },
                "downloads": -1,
                "filename": "sk_nlp-0.1.9-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "79ccfc2fcb5025d61a13fd43947d1761",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6.0",
                "size": 317721,
                "upload_time": "2021-07-13T11:41:52",
                "upload_time_iso_8601": "2021-07-13T11:41:52.623508Z",
                "url": "https://files.pythonhosted.org/packages/80/46/ae1192c0599b76ea5aff729b9a6ed2bc717072aa021fe9481ba9261764ea/sk_nlp-0.1.9-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1.0": {
        "info": {
            "author": "Ha Sangchun",
            "author_email": "seomk9896@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/upskyy/Squeezeformer",
            "keywords": "asr,speech_recognition,artificial intelligence,transformer",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "squeezeformer",
            "package_url": "https://pypi.org/project/squeezeformer/",
            "platform": null,
            "project_url": "https://pypi.org/project/squeezeformer/",
            "project_urls": {
                "Homepage": "https://github.com/upskyy/Squeezeformer"
            },
            "release_url": "https://pypi.org/project/squeezeformer/0.1.0/",
            "requires_dist": [
                "torch (>=1.4.0)",
                "numpy"
            ],
            "requires_python": ">=3.6",
            "summary": "An Efficient Transformer for Automatic Speech Recognition",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14095984,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5f08e31bfb9ebb2fd6dbb8ea6925e4f8",
                    "sha256": "a4bd101ee71933edaaad0413a1695a3cb28679f50576b8034585c65b584ea5a1"
                },
                "downloads": -1,
                "filename": "squeezeformer-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "5f08e31bfb9ebb2fd6dbb8ea6925e4f8",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 16951,
                "upload_time": "2022-06-10T16:50:59",
                "upload_time_iso_8601": "2022-06-10T16:50:59.456737Z",
                "url": "https://files.pythonhosted.org/packages/d0/bd/3075790a60dd3693e2765f8c4db847b19a54d2cc71021b46d17101ff7f91/squeezeformer-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "Ha Sangchun",
            "author_email": "seomk9896@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "# Squeezeformer\n\n\n<p  align=\"center\"> \n     <a href=\"https://github.com/sooftware/jasper/blob/main/LICENSE\">\n          <img src=\"http://img.shields.io/badge/license-Apache--2.0-informational\"> \n     </a>\n     <a href=\"https://github.com/pytorch/pytorch\">\n          <img src=\"http://img.shields.io/badge/framework-PyTorch-informational\"> \n     </a>\n     <a href=\"https://www.python.org/dev/peps/pep-0008/\">\n          <img src=\"http://img.shields.io/badge/codestyle-PEP--8-informational\"> \n     </a>\n     <a href=\"https://github.com/sooftware/conformer\">\n          <img src=\"http://img.shields.io/badge/build-passing-success\"> \n     </a>\n\n  \nSqueezeformer incorporates the Temporal U-Net structure, which reduces the cost of the\nmulti-head attention modules on long sequences, and a simpler block structure of feed-forward module,\nfollowed up by multi-head attention or convolution modules,\ninstead of the Macaron structure proposed in Conformer.  \n\n<img width=\"417\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-06-11 \u110b\u1169\u110c\u1165\u11ab 1 19 40\" src=\"https://user-images.githubusercontent.com/54731898/173109027-76a51857-b3cf-4616-938d-d3b990a4cf13.png\">  \n\nThis repository contains only model code, but you can train with squeezeformer at [openspeech](https://github.com/openspeech-team/openspeech).  \n     \n     \n  \n\n## Installation\n```   \npip install squeezeformer  \n```   \n            \n     \n## Usage\n```python\nimport torch\nimport torch.nn as nn\nfrom squeezeformer.model import Squeezeformer\n\n\nBATCH_SIZE = 4\nSEQ_LENGTH = 500\nINPUT_SIZE = 80\nNUM_CLASSES = 10\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ncriterion = nn.CTCLoss().to(device)\nmodel = Squeezeformer(\n     num_classes=NUM_CLASSES,\n).to(device)\n\ninputs = torch.FloatTensor(BATCH_SIZE, SEQ_LENGTH, INPUT_SIZE).to(device)\ninput_lengths = torch.IntTensor([500, 450, 400, 350]).to(device)\ntargets = torch.LongTensor([[1, 3, 3, 3, 3, 3, 4, 5, 6, 2],\n                           [1, 3, 3, 3, 3, 3, 4, 5, 2, 0],\n                           [1, 3, 3, 3, 3, 3, 4, 2, 0, 0],\n                           [1, 3, 3, 3, 3, 3, 6, 2, 0, 0]]).to(device)\ntarget_lengths = torch.LongTensor([9, 8, 7, 7]).to(device)\n\n# Forward propagate\noutputs, output_lengths = model(inputs, input_lengths)\n\n# Calculate CTC Loss\nfor _ in range(3):\n     outputs, output_lengths = model(inputs, input_lengths)\n     loss = criterion(outputs.transpose(0, 1), targets[:, 1:], output_lengths, target_lengths)\n     loss.backward()\n```\n  \n     \n## Reference\n- [kssteven418/Squeezeformer](https://github.com/kssteven418/Squeezeformer)  \n- [sooftware/conformer](https://github.com/sooftware/conformer)\n- [Squeezeformer: An Efficient Transformer for Automatic Speech Recognition](https://arxiv.org/abs/2206.00888)\n  \n     \n## License\n```\nCopyright 2022 Sangchun Ha.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/upskyy/Squeezeformer",
            "keywords": "asr,speech_recognition,artificial intelligence",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "squeezeformer",
            "package_url": "https://pypi.org/project/squeezeformer/",
            "platform": null,
            "project_url": "https://pypi.org/project/squeezeformer/",
            "project_urls": {
                "Homepage": "https://github.com/upskyy/Squeezeformer"
            },
            "release_url": "https://pypi.org/project/squeezeformer/0.1.1/",
            "requires_dist": [
                "torch (>=1.4.0)",
                "numpy"
            ],
            "requires_python": ">=3.6",
            "summary": "An Efficient Transformer for Automatic Speech Recognition",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14095984,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "fd99366f3617d704e493a0e9613cc576",
                    "sha256": "14b65c558e47dfb5760b56b897e7877caaf389955ac704bdfb95febf8977f06f"
                },
                "downloads": -1,
                "filename": "squeezeformer-0.1.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "fd99366f3617d704e493a0e9613cc576",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 18388,
                "upload_time": "2022-06-10T16:59:40",
                "upload_time_iso_8601": "2022-06-10T16:59:40.359202Z",
                "url": "https://files.pythonhosted.org/packages/37/1d/1c4b5c7ecace7fc6b5b3ede942e31216eeb5e4991814ff3de99cbf171b9f/squeezeformer-0.1.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.0.1": {
        "info": {
            "author": "Integrated Intelligence Lab",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/x-rst",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://data.research.vub.be/",
            "keywords": "fairness,bias,inverse design,interpretability,python",
            "license": "MIT",
            "maintainer": "Andres Algaba",
            "maintainer_email": "andres.algaba@vub.be",
            "name": "canonical-sets",
            "package_url": "https://pypi.org/project/canonical-sets/",
            "platform": null,
            "project_url": "https://pypi.org/project/canonical-sets/",
            "project_urls": {
                "Homepage": "https://data.research.vub.be/",
                "Repository": "https://github.com/Integrated-Intelligence-Lab/canonical_sets"
            },
            "release_url": "https://pypi.org/project/canonical-sets/0.0.1/",
            "requires_dist": [
                "matplotlib (>=3.5.2)",
                "numpy (>=1.22.3)",
                "pandas (>=1.4.2)",
                "torch (>=1.11.0)",
                "tensorflow (>=2.9.1)",
                "scikit-learn (>=1.1.1)",
                "tqdm (>=4.64.0)",
                "scipy (>=1.9.0)"
            ],
            "requires_python": ">=3.8,<3.10",
            "summary": "Exposing Algorithmic Bias through Inverse Design.",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16048652,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "96b7fe45320afb881631eef1b8208ac2",
                    "sha256": "8f51ccdc30c350199b0cbe679b1f7ab9c6a0575aca7ab705118c7b66f79d5f72"
                },
                "downloads": -1,
                "filename": "canonical_sets-0.0.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "96b7fe45320afb881631eef1b8208ac2",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8,<3.10",
                "size": 17754,
                "upload_time": "2022-08-26T08:19:41",
                "upload_time_iso_8601": "2022-08-26T08:19:41.813453Z",
                "url": "https://files.pythonhosted.org/packages/61/88/d1d608dd67cde944173f49918f13f50c4acd4f33844844307e9802065f83/canonical_sets-0.0.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "1ad75774c6acea4816ae98ae9729421a",
                    "sha256": "1fac7904abe2757ad493f251218e8f8a733530688f73021b5e698b9c7e0304c3"
                },
                "downloads": -1,
                "filename": "canonical_sets-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "1ad75774c6acea4816ae98ae9729421a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8,<3.10",
                "size": 14752,
                "upload_time": "2022-08-26T08:19:43",
                "upload_time_iso_8601": "2022-08-26T08:19:43.905318Z",
                "url": "https://files.pythonhosted.org/packages/33/9a/46472032edccbc2b97edb1dd6ddf0fb611cb233168bd7a1cdc6327153fed/canonical_sets-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.2": {
        "info": {
            "author": "Integrated Intelligence Lab",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": ".. |nbsp| unicode:: U+00A0 .. NO-BREAK SPACE\n\n.. |pic1| image:: https://img.shields.io/badge/python-3.8%20%7C%203.9-blue\n.. |pic2| image:: https://img.shields.io/github/license/mashape/apistatus.svg\n.. |pic3| image:: https://img.shields.io/badge/code%20style-black-000000.svg\n.. |pic4| image:: https://img.shields.io/badge/%20type_checker-mypy-%231674b1?style=flat\n.. |pic5| image:: https://img.shields.io/badge/platform-windows%20%7C%20linux%20%7C%20macos-lightgrey\n.. |pic6| image:: https://github.com/Integrated-Intelligence-Lab/canonical_sets/actions/workflows/testing.yml/badge.svg\n.. |pic7| image:: https://img.shields.io/readthedocs/canonical_sets\n.. |pic8| image:: https://img.shields.io/pypi/v/canonical_sets\n\n.. _canonical_sets: https://github.com/Integrated-Intelligence-Lab/canonical_sets/tree/main/canonical_sets\n.. _examples: https://github.com/Integrated-Intelligence-Lab/canonical_sets/tree/main/examples\n.. _contribute: https://github.com/Integrated-Intelligence-Lab/canonical_sets/blob/main/CONTRIBUTING.rst\n.. _documentation: https://canonical-sets.readthedocs.io/en/latest/\n.. _LUCID: https://responsibledecisionmaking.github.io/assets/pdf/papers/21.pdf\n.. _LUCIDGAN: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4289597\n\n.. _Twitter: https://twitter.com/DataLabBE\n.. _website: https://data.research.vub.be/\n.. _papers: https://researchportal.vub.be/en/organisations/data-analytics-laboratory/publications/\n\n.. _ctgan: https://github.com/sdv-dev/CTGAN\n.. _ctganbugs: https://github.com/sdv-dev/CTGAN/pulls/AndresAlgaba\n\n\nCanonical sets \n==============\n\n|pic2| |nbsp| |pic5| |nbsp| |pic1| |nbsp| |pic8|\n\n|pic6| |nbsp| |pic7| |nbsp| |pic3| |nbsp| |pic4|\n\nAI systems can create, propagate, support, and automate bias in decision-making processes. To mitigate biased decisions,\nwe both need to understand the origin of the bias and define what it means for an algorithm to make fair decisions.\nBy Locating Unfairness through Canonical Inverse Design (LUCID), we generate a canonical set that shows the desired inputs\nfor a model given a preferred output. The canonical set reveals the model's internal logic and exposes potential unethical\nbiases by repeatedly interrogating the decision-making process.\n\nLUCID-GAN extends on LUCID by generating canonical inputs via a conditional generative model instead of\ngradient-based inverse design. LUCID-GAN generates canonical inputs conditional on the predictions of the model under\nfairness evaluation. LUCID-GAN has several benefits, including that it applies to non-differentiable models, ensures\nthat a canonical set consists of realistic inputs, and allows us to assess indirect discrimination and explicitly\ncheck for intersectional unfairness.\n\nRead our paper on `LUCID`_ and `LUCID-GAN`_ for more details, or check out the `documentation`_.\n\nWe encourage everyone to `contribute`_ to this project by submitting an issue or a pull request!\n\n\nInstallation\n------------\n\nInstall ``canonical_sets`` from PyPi.\n\n.. code-block:: bash\n\n    pip install canonical_sets\n\nFor development install, see `contribute`_. You can also check the `documentation`_.\n\n\nUsage\n-----\n\nLUCID\n~~~~~\n\n``LUCID`` can be used for the gradient-based inverse design to generate canonical sets, and is available for both\n``PyTorch`` and ``Tensorflow`` models. It only requires a model, a preferred output, and an example input\n(which is often a part of the training data). The results are stored in a ``pd.DataFrame``, and can be accessed by\ncalling ``results``. It's fully customizable, but can also be used out-of-the-box for a wide range of\napplications by using its default settings:\n\n.. code-block:: python\n\n    from canonical_sets import LUCID\n\n    lucid = LUCID(model, outputs, example_data)\n    lucid.results.head()\n\nLUCID-GAN\n~~~~~~~~~\n\n``LUCIDGAN`` generates canonical sets by using conditional generative models (GANs). This approach has several benefits,\nincluding that it applies to non--differentiable models, ensures that a canonical set consists of realistic inputs,\nand allows us to assess indirect discrimination and explicitly check for intersectional unfairness. LUCID-GAN only\nrequires the input and predictions of a black-box model. It's fully customizable, but can also be used out-of-the-box\nfor a wide range of applications by using its default settings:\n\n.. code-block:: python\n\n    from canonical_sets import LUCIDGAN\n\n    lucidgan = LUCIDGAN()\n    lucidgan.fit(data, predictions)\n    samples = lucidgan.sample(100)\n    samples.head()\n\nFor detailed examples see `examples`_ and for the source code see `canonical_sets`_. For ``LUCID``, we advice to start with either the\n``tensorflow`` or ``pytorch`` example, and then the advanced example. For ``LUCIDGAN``, you can replicate the experiments from the paper\nwith the ``GAN_adult`` and ``GAN_compas`` examples. Note that the results might slightly differ due to the randomness in generating the\nsamples. You can also check the `documentation`_ for more details. If you have any remaining questions, feel free to submit an issue or PR!\n\n\nOutput-based group metrics\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nMost group fairness notions focus on the equality of outcome by computing statistical parity metrics on a model's output.\nThe two most prominent examples of these statistical output-based metrics are Demographic Parity (DP) and Equality Of Opportunity (EOP).\nIn DP, we compare the Positivity Rate (PR) of the subpopulations under fairness evaluation, and in EOP, we compare the True Positive Rate (TPR).\nThe choice between DP and EOP depends on the underlying assumptions and worldview of the evaluator.\nThe ``Metrics`` class allows you to compute these metrics for binary classification tasks given the predictions and ground truth:\n\n.. code-block:: python\n\n    from canonical_sets.group import Metrics\n\n    metrics = Metrics(preds, targets)\n    metrics.metrics\n\n\nData\n----\n\n``canonical_sets`` contains some functionality to easily access commonly used data sets in the fairness literature:\n\n.. code-block:: python\n\n    from canonical_sets import Adult, Compas\n\n    adult = Adult()\n    adult.train_data.head()\n\n    compas = Compas()\n    compas.train_data.head()\n\nThe default settings can be customized to change the pre-processing, splitting, etc. See `examples`_  for details.\nYou can also check the `documentation`_.\n\n\nCommunity\n---------\n\nIf you are interested in cross-disciplinary research related to machine learning, feel free to:\n\n* Follow DataLab on `Twitter`_.\n* Check the `website`_.\n* Read our `papers`_.\n\n\nDisclaimer\n----------\n\nThe package and the code is provided \"as-is\" and there is NO WARRANTY of any kind. \nUse it only if the content and output files make sense to you.\n\nCurrently some dependencies of the package do not support the Apple M1 and M2 chips.\nWe will offer support asap.\n\n\nAcknowledgements\n----------------\n\nThis project benefited from financial support from Innoviris.\n\n``LUCIDGAN`` is based on the ``CTGAN`` class from the `ctgan`_ package. It has been extended to fix\nseveral bugs (see my PRs on the `ctganbugs`_ GitHub page) and to allow for the extension of the conditional\nvector. Note that a part of the code and comments is identical to the original ``CTGAN`` class.\n\n\nCitation\n--------\n\n.. code-block:: none\n\n    @inproceedings{mazijn_lucid_2023,\n      title={{LUCID: Exposing Algorithmic Bias through Inverse Design}},\n      author={Mazijn, Carmen and Prunkl, Carina and Algaba, Andres and Danckaert, Jan and Ginis, Vincent},\n      booktitle={Thirty-Seventh AAAI Conference on Artificial Intelligence (accepted)},\n      year={2023},\n    }\n\n    @article{algaba_lucidgan_2022,\n      title={{LUCID-GAN: Conditional Generative Models to Locate Unfairness}},\n      author={Algaba, Andres and Mazijn, Carmen and Prunkl, Carina and Danckaert, Jan and Ginis, Vincent},\n      year={2022},\n      journal={Working paper}\n    }\n\n",
            "description_content_type": "text/x-rst",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://data.research.vub.be/",
            "keywords": "fairness,bias,inverse design,generative models,interpretability,python",
            "license": "MIT",
            "maintainer": "Andres Algaba",
            "maintainer_email": "andres.algaba@vub.be",
            "name": "canonical-sets",
            "package_url": "https://pypi.org/project/canonical-sets/",
            "platform": null,
            "project_url": "https://pypi.org/project/canonical-sets/",
            "project_urls": {
                "Homepage": "https://data.research.vub.be/",
                "Repository": "https://github.com/Integrated-Intelligence-Lab/canonical_sets"
            },
            "release_url": "https://pypi.org/project/canonical-sets/0.0.2/",
            "requires_dist": [
                "matplotlib (>=3.5.2)",
                "seaborn (>=0.12.0)",
                "numpy (>=1.22.3)",
                "pandas (>=1.4.2)",
                "torch (>=1.11.0,<1.13.0)",
                "tensorflow (>=2.9.1,<2.11.0)",
                "scikit-learn (>=1.1.1)",
                "tqdm (>=4.64.0)",
                "ctgan (>=0.6.0)"
            ],
            "requires_python": ">=3.8,<3.10",
            "summary": "Exposing Algorithmic Bias with Canonical Sets.",
            "version": "0.0.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16048652,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b06ecda440c96d5f34da18aef5686f5e",
                    "sha256": "15103d88a40f1ed1fc458a2a5d2015494222615de46d92815be6f6be9b7e52bf"
                },
                "downloads": -1,
                "filename": "canonical_sets-0.0.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b06ecda440c96d5f34da18aef5686f5e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8,<3.10",
                "size": 27331,
                "upload_time": "2022-12-09T13:55:33",
                "upload_time_iso_8601": "2022-12-09T13:55:33.576151Z",
                "url": "https://files.pythonhosted.org/packages/11/2f/950022e2b862c212e99f12e6549791f269aaa86564755238deae4a6b81c1/canonical_sets-0.0.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "c89e883c49fd7d861f85126efce70db1",
                    "sha256": "f92eae5969e6e01dc164eadda4173cf7e7b0b85331dcba5b2be61de6ba73e551"
                },
                "downloads": -1,
                "filename": "canonical_sets-0.0.2.tar.gz",
                "has_sig": false,
                "md5_digest": "c89e883c49fd7d861f85126efce70db1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8,<3.10",
                "size": 23268,
                "upload_time": "2022-12-09T13:55:35",
                "upload_time_iso_8601": "2022-12-09T13:55:35.562746Z",
                "url": "https://files.pythonhosted.org/packages/5f/11/844abe37cc3eccad365ee85140e31fc38c1635160944fbce8f4f97073d92/canonical_sets-0.0.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
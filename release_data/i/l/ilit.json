{
    "1.0": {
        "info": {
            "author": "Intel MLP/MLPC Team",
            "author_email": "feng.tian@intel.com, chuanqi.wang@intel.com, pengxin.yuan@intel.com, guoming.zhang@intel.com, haihao.shen@intel.com, jiong.gong@intel.com, xi2.chen@intel.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Science/Research",
                "Programming Language :: Python :: 3",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/intel/lp-opt-tool",
            "keywords": "quantization,auto-tuning,post-training static quantization,post-training dynamic quantization,quantization-aware training,tuning strategy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "ilit",
            "package_url": "https://pypi.org/project/ilit/",
            "platform": "",
            "project_url": "https://pypi.org/project/ilit/",
            "project_urls": {
                "Homepage": "https://github.com/intel/lp-opt-tool"
            },
            "release_url": "https://pypi.org/project/ilit/1.0/",
            "requires_dist": [
                "numpy",
                "pyyaml",
                "scikit-learn",
                "schema",
                "py-cpuinfo",
                "hyperopt",
                "pandas"
            ],
            "requires_python": ">=3.5.0",
            "summary": "Repository of Intel\u00ae Low Precision Optimization Tool",
            "version": "1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 8543637,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "dc2bc04f241d09b0367545529e3ad120",
                    "sha256": "12d728c8fc68e8a4a34679f42f9ff6987aeb79ebf2cd472de4cdedc19c7b0eb2"
                },
                "downloads": -1,
                "filename": "ilit-1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "dc2bc04f241d09b0367545529e3ad120",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.5.0",
                "size": 259214,
                "upload_time": "2020-10-30T16:52:58",
                "upload_time_iso_8601": "2020-10-30T16:52:58.536514Z",
                "url": "https://files.pythonhosted.org/packages/7a/ab/92c2e11eaaf515d4b54abef6f1f107ff8f3c65c4919a6c64275bebc867fd/ilit-1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.0a0": {
        "info": {
            "author": "Intel MLP/MLPC Team",
            "author_email": "feng.tian@intel.com, chuanqi.wang@intel.com, pengxin.yuan@intel.com, guoming.zhang@intel.com, haihao.shen@intel.com, jiong.gong@intel.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Science/Research",
                "Programming Language :: Python :: 3",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.intel.com/intel/lp-inference-kit",
            "keywords": "quantization,auto-tuning,post-training static quantization,post-training dynamic quantization,quantization-aware training,tuning strategy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "ilit",
            "package_url": "https://pypi.org/project/ilit/",
            "platform": "",
            "project_url": "https://pypi.org/project/ilit/",
            "project_urls": {
                "Homepage": "https://github.intel.com/intel/lp-inference-kit"
            },
            "release_url": "https://pypi.org/project/ilit/1.0a0/",
            "requires_dist": [
                "numpy",
                "pyyaml",
                "scikit-learn"
            ],
            "requires_python": ">=3.5.0",
            "summary": "Repository of low precision inference toolkit",
            "version": "1.0a0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 8543637,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d18ed615293eaca8b3c4c845d0042e83",
                    "sha256": "d454c429024bc1a8f17f3fb44cea11d3c8210949c5ad1c9d1f5e880223ef11ac"
                },
                "downloads": -1,
                "filename": "ilit-1.0a0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d18ed615293eaca8b3c4c845d0042e83",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.5.0",
                "size": 104968,
                "upload_time": "2020-07-07T08:22:53",
                "upload_time_iso_8601": "2020-07-07T08:22:53.138778Z",
                "url": "https://files.pythonhosted.org/packages/47/7b/db6cc21d1bf2524df7df719fbf9292f5849a1f270df8f0c16b6bc632713b/ilit-1.0a0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.0b0": {
        "info": {
            "author": "Intel MLP/MLPC Team",
            "author_email": "feng.tian@intel.com, chuanqi.wang@intel.com, pengxin.yuan@intel.com, guoming.zhang@intel.com, haihao.shen@intel.com, jiong.gong@intel.com, xi2.chen@intel.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Science/Research",
                "Programming Language :: Python :: 3",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description": "Intel\u00ae Low Precision Optimization Tool\n=========================================\n\nIntel\u00ae Low Precision Optimization Tool is an open-source python library which is intended to deliver a unified low-precision inference interface cross multiple Intel optimized DL frameworks on both CPU and GPU. It supports automatic accuracy-driven tuning strategies, along with additional objectives like performance, model size, or memory footprint. It also provides the easy extension capability for new backends, tuning strategies, metrics and objectives.\n\n\n> **WARNING**\n>\n> GPU support is under development.\n\nCurrently supported Intel optimized DL frameworks are:\n* [Tensorflow\\*](https://www.tensorflow.org)\n* [PyTorch\\*](https://pytorch.org/)\n* [Apache\\* MXNet](https://mxnet.apache.org)\n\nCurrently supported tuning strategies are:\n* [Basic](docs/introduction.md#basic-strategy)\n* [Bayesian](docs/introduction.md#bayesian-strategy)\n* [MSE](docs/introduction.md#mse-strategy)\n* [Exhaustive](docs/introduction.md#exhaustive-strategy)\n* [Random](docs/introduction.md#random-strategy)\n\n\n# Introduction \n\n  [Introduction](docs/introduction.md) explains Intel\u00ae Low Precision Optimization Tool infrastructure, design philosophy, supported functionality, details of tuning strategy implementations and tuning result on popular models.\n\n# Tutorials\n* [Hello World](examples/helloworld/README.md) demonstrates the simple steps to utilize Intel\u00ae Low Precision Optimization Tool for quanitzation, which can help you quick start with the tool.\n* [Tutorials](docs/README.md) provides\ncomprehensive instructions of how to utilize diffrennt features of Intel\u00ae Low Precision Optimization Tool.\n* [Examples](examples) is a tuning zoo to demonstrate the usage of Intel\u00ae Low Precision Optimization Tool in TensorFlow, PyTorch and MxNet for industry models of diffrent categories.  \n\n# Install from source \n\n  ```Shell\n  git clone https://github.com/intel/lp-opt-tool.git\n  cd lp-opt-tool\n  python setup.py install\n  ```\n\n# Install from binary\n\n  ```Shell\n  # install from pip\n  pip install ilit\n\n  # install from conda\n  conda config --add channels intel\n  conda install ilit\n  ```\n\n# System Requirements\n\n### Hardware\n\nIntel\u00ae Low Precision Optimization Tool supports systems based on Intel 64 architecture or compatible processors.\n\n### Software\n\nIntel\u00ae Low Precision Optimization Tool requires to install Intel optimized framework version for TensorFlow, PyTorch, and MXNet.\n\n# Tuning Zoo\n\nThe followings are the examples integrated with Intel\u00ae Low Precision Optimization Tool for auto tuning.\n\n| TensorFlow Model                                                    | Category  |\n|---------------------------------------------------------------------|------------|\n|[ResNet50 V1](examples/tensorflow/image_recognition/README.md)        | Image Recognition |\n|[ResNet50 V1.5](examples/tensorflow/image_recognition/README.md)      | Image Recognition |\n|[ResNet101](examples/tensorflow/image_recognition/README.md)          | Image Recognition |\n|[Inception V1](examples/tensorflow/image_recognition/README.md)       | Image Recognition |\n|[Inception V2](examples/tensorflow/image_recognition/README.md)       | Image Recognition |\n|[Inception V3](examples/tensorflow/image_recognition/README.md)       | Image Recognition |\n|[Inception V4](examples/tensorflow/image_recognition/README.md)       | Image Recognition |\n|[ResNetV2_50](examples/tensorflow/image_recognition/README.md)        | Image Recognition |\n|[ResNetV2_101](examples/tensorflow/image_recognition/README.md)       | Image Recognition |\n|[ResNetV2_152](examples/tensorflow/image_recognition/README.md)       | Image Recognition |\n|[Inception ResNet V2](examples/tensorflow/image_recognition/README.md)| Image Recognition |\n|[SSD ResNet50 V1](examples/tensorflow/object_detection/README.md)     | Object Detection  |\n|[Wide & Deep](examples/tensorflow/recommendation/wide_deep_large_ds/WND_README.md) | Recommendation |\n|[VGG16](examples/tensorflow/image_recognition/README.md)              | Image Recognition |\n|[VGG19](examples/tensorflow/image_recognition/README.md)              | Image Recognition |\n|[Style_transfer](examples/tensorflow/style_transfer/README.md)        | Style Transfer    |\n\n\n| PyTorch Model                                                               | Category  |\n|---------------------------------------------------------------------|------------|\n|[BERT-Large RTE](examples/pytorch/language_translation/README.md)  | Language Translation   |\n|[BERT-Large QNLI](examples/pytorch/language_translation/README.md) | Language Translation   |\n|[BERT-Large CoLA](examples/pytorch/language_translation/README.md) | Language Translation   |\n|[BERT-Base SST-2](examples/pytorch/language_translation/README.md) | Language Translation   |\n|[BERT-Base RTE](examples/pytorch/language_translation/README.md)   | Language Translation   |\n|[BERT-Base STS-B](examples/pytorch/language_translation/README.md) | Language Translation   |\n|[BERT-Base CoLA](examples/pytorch/language_translation/README.md)  | Language Translation   | \n|[BERT-Base MRPC](examples/pytorch/language_translation/README.md)  | Language Translation   |\n|[DLRM](examples/pytorch/recommendation/README.md)                  | Recommendation   | \n|[BERT-Large MRPC](examples/pytorch/language_translation/README.md) | Language Translation   |\n|[ResNext101_32x8d](examples/pytorch/image_recognition/imagenet/README.md)          | Image Recognition   |\n|[BERT-Large SQUAD](examples/pytorch/language_translation/README.md)                | Language Translation   | \n|[ResNet50 V1.5](examples/pytorch/image_recognition/imagenet/README.md)             | Image Recognition   |\n|[ResNet18](examples/pytorch/image_recognition/imagenet/README.md)             | Image Recognition   |\n|[Inception V3](examples/pytorch/image_recognition/imagenet/README.md)              | Image Recognition   |\n|[YOLO V3](examples/pytorch/object_detection/yolo_v3/README.md)                     | Object Detection   |\n|[Peleenet](examples/pytorch/image_recognition/peleenet/README.md)                  | Image Recognition   |\n|[ResNest50](examples/pytorch/image_recognition/resnest/README.md)                  | Image Recognition   | \n|[SE_ResNext50_32x4d](examples/pytorch/image_recognition/se_resnext/README.md)      | Image Recognition   |\n|[ResNet50 V1.5 QAT](examples/pytorch/image_recognition/imagenet_qat/README.md)     | Image Recognition   | \n|[ResNet18 QAT](examples/pytorch/image_recognition/imagenet_qat/README.md)          | Image Recognition   |\n\n| MxNet Model                                                               | Category  |\n|---------------------------------------------------------------------|------------|\n|[ResNet50 V1](examples/mxnet/image_recognition/README.md)           | Image Recognition      |\n|[MobileNet V1](examples/mxnet/image_recognition/README.md)          | Image Recognition      |\n|[MobileNet V2](examples/mxnet/image_recognition/README.md)          | Image Recognition      |\n|[SSD-ResNet50](examples/mxnet/object_detection/README.md)           | Object Detection       |\n|[SqueezeNet V1](examples/mxnet/image_recognition/README.md)         | Image Recognition      |\n|[ResNet18](examples/mxnet/image_recognition/README.md)              | Image Recognition      |\n|[Inception V3](examples/mxnet/image_recognition/README.md)          | Image Recognition      |\n\n\n# Known Issues\n\n1. KL Divergence Algorithm is very slow at TensorFlow\n\n   Due to TensorFlow not supporting tensor dump naturally, current solution of dumping the tensor content is adding print op and dumpping the value to stdout. So if the model to tune is a TensorFlow model, please restrict calibration.algorithm.activation and calibration.algorithm.weight in user yaml config file to minmax.\n\n2. MSE tuning strategy doesn't work with PyTorch adaptor layer\n\n   MSE tuning strategy requires to compare FP32 tensor and INT8 tensor to decide which op has impact on final quantization accuracy. PyTorch adaptor layer doesn't implement this inspect tensor interface. So if the model to tune is a PyTorch model, please not choose MSE tuning strategy.\n\n# Support\n\nPlease submit your questions, feature requests, and bug reports on the\n[GitHub issues](https://github.com/intel/lp-opt-tool/issues) page. You may also reach out to ilit.maintainers@intel.com.\n\n# Contributing\n\nWe welcome community contributions to Intel\u00ae Low Precision Optimization Tool. If you have an idea on how\nto improve the library:\n\n* For changes impacting the public API, submit\n  an [RFC pull request](CONTRIBUTING.md#RFC_pull_requests).\n* Ensure that the changes are consistent with the\n [code contribution guidelines](CONTRIBUTING.md#code_contribution_guidelines)\n and [coding style](CONTRIBUTING.md#coding_style).\n* Ensure that you can run all the examples with your patch.\n* Submit a [pull request](https://github.com/intel/lp-opt-tool/pulls).\n\nFor additional details, see [contribution guidelines](CONTRIBUTING.md).\n\nThis project is intended to be a safe, welcoming space for collaboration, and\ncontributors are expected to adhere to the\n[Contributor Covenant](CODE_OF_CONDUCT.md) code of conduct.\n\n# License\n\nIntel\u00ae Low Precision Optimization Tool is licensed under\n[Apache License Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).  This\nsoftware includes components with separate copyright notices and license\nterms. Your use of the source code for these components is subject to the terms\nand conditions of the following licenses.\n\nApache License Version 2.0:\n* [Intel TensorFlow Quantization Tool](https://github.com/IntelAI/tools)\n\nMIT License:\n* [bayesian-optimization](https://github.com/fmfn/BayesianOptimization)\n\nSee accompanying [LICENSE](LICENSE) file for full license text and copyright notices.\n\n--------\n\n[Legal Information](legal_information.md)\n\n## Citing\n\nIf you use Intel\u00ae Low Precision Optimization Tool in your research or wish to refer to the tuning results published in the [Tuning Zoo](#tuning-zoo), please use the following BibTeX entry.\n\n```\n@misc{Intel\u00ae Low Precision Optimization Tool,\n  author =       {Feng Tian, Chuanqi Wang, Guoming Zhang, Penghui Cheng, Pengxin Yuan, Haihao Shen, and Jiong Gong},\n  title =        {Intel\u00ae Low Precision Optimization Tool},\n  howpublished = {\\url{https://github.com/intel/lp-opt-tool}},\n  year =         {2020}\n}\n```\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/intel/lp-opt-tool",
            "keywords": "quantization,auto-tuning,post-training static quantization,post-training dynamic quantization,quantization-aware training,tuning strategy",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "ilit",
            "package_url": "https://pypi.org/project/ilit/",
            "platform": "",
            "project_url": "https://pypi.org/project/ilit/",
            "project_urls": {
                "Homepage": "https://github.com/intel/lp-opt-tool"
            },
            "release_url": "https://pypi.org/project/ilit/1.0b0/",
            "requires_dist": [
                "numpy",
                "pyyaml",
                "scikit-learn",
                "schema"
            ],
            "requires_python": ">=3.5.0",
            "summary": "Repository of Intel\u00ae Low Precision Optimization Tool",
            "version": "1.0b0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 8543637,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "52a87302ae2e248b190c3ccd15e88f8d",
                    "sha256": "e63d8ae3498938254e4f327897261f365a9ca89d3a6bac2bac02f7dccac64ea1"
                },
                "downloads": -1,
                "filename": "ilit-1.0b0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "52a87302ae2e248b190c3ccd15e88f8d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.5.0",
                "size": 150436,
                "upload_time": "2020-08-31T10:19:53",
                "upload_time_iso_8601": "2020-08-31T10:19:53.806782Z",
                "url": "https://files.pythonhosted.org/packages/e1/90/4d6d98918e25d7ab37f6c9c1e588bed1a92ad0ac77fd7946df490c20a795/ilit-1.0b0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.4.1": {
        "info": {
            "author": "Jangwon Park",
            "author_email": "adieujw@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/monologg/KoBERT-Transformers",
            "keywords": "distilkobert kobert bert pytorch transformers lightweight",
            "license": "Apache-2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "kobert-transformers",
            "package_url": "https://pypi.org/project/kobert-transformers/",
            "platform": "",
            "project_url": "https://pypi.org/project/kobert-transformers/",
            "project_urls": {
                "Homepage": "https://github.com/monologg/KoBERT-Transformers"
            },
            "release_url": "https://pypi.org/project/kobert-transformers/0.4.1/",
            "requires_dist": [
                "torch (>=1.1.0)",
                "transformers (>=2.9.1)"
            ],
            "requires_python": ">=3",
            "summary": "Transformers library for KoBERT, DistilKoBERT",
            "version": "0.4.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10661145,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "dc05ff5d8d3d4deb6886411c6b7165ba",
                    "sha256": "518d622054ce0965c7853eb9a0710051b8db295f7f6c477f584473ba3f64330e"
                },
                "downloads": -1,
                "filename": "kobert_transformers-0.4.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "dc05ff5d8d3d4deb6886411c6b7165ba",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 12308,
                "upload_time": "2020-05-14T11:33:08",
                "upload_time_iso_8601": "2020-05-14T11:33:08.819817Z",
                "url": "https://files.pythonhosted.org/packages/f3/6d/f4e21513c1f26cacd68c144a428ccaa90dd92d85985e878976ebbaf06624/kobert_transformers-0.4.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.5.1": {
        "info": {
            "author": "Jangwon Park",
            "author_email": "adieujw@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/monologg/KoBERT-Transformers",
            "keywords": "distilkobert kobert bert pytorch transformers lightweight",
            "license": "Apache License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "kobert-transformers",
            "package_url": "https://pypi.org/project/kobert-transformers/",
            "platform": "",
            "project_url": "https://pypi.org/project/kobert-transformers/",
            "project_urls": {
                "Homepage": "https://github.com/monologg/KoBERT-Transformers"
            },
            "release_url": "https://pypi.org/project/kobert-transformers/0.5.1/",
            "requires_dist": [
                "torch (>=1.1.0)",
                "transformers (<5,>=3)",
                "sentencepiece (>=0.1.91)"
            ],
            "requires_python": ">=3.6",
            "summary": "Transformers library for KoBERT, DistilKoBERT",
            "version": "0.5.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10661145,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ba05b79a0e42fb03b3523a77ca4e5e38",
                    "sha256": "aa7760853be5d1ec8ab600b11f1b6626123583c3c3f2f9adc36a5bd7b2e2f0ac"
                },
                "downloads": -1,
                "filename": "kobert_transformers-0.5.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ba05b79a0e42fb03b3523a77ca4e5e38",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 12411,
                "upload_time": "2021-06-16T09:09:15",
                "upload_time_iso_8601": "2021-06-16T09:09:15.099044Z",
                "url": "https://files.pythonhosted.org/packages/ea/69/aa41197a950299eebc1e2991fdb6a7d8d2fa80fa1efe8b580bffddaf43af/kobert_transformers-0.5.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "33625e69e5551325dbe9edbcb7151136",
                    "sha256": "4aba0fa8f4f1eb477c5da91962090fcc958158d6e45bffe6e56e5d90c38bb578"
                },
                "downloads": -1,
                "filename": "kobert-transformers-0.5.1.tar.gz",
                "has_sig": false,
                "md5_digest": "33625e69e5551325dbe9edbcb7151136",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 7792,
                "upload_time": "2021-06-16T09:09:16",
                "upload_time_iso_8601": "2021-06-16T09:09:16.527051Z",
                "url": "https://files.pythonhosted.org/packages/36/04/3b41292198e1c7429c2104dcb05b8912ddb18582c8021b324d233313a807/kobert-transformers-0.5.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.5.1rc1": {
        "info": {
            "author": "Jangwon Park",
            "author_email": "adieujw@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "# KoBERT-Transformers\n\n`KoBERT` & `DistilKoBERT` on \ud83e\udd17 Huggingface Transformers \ud83e\udd17\n\nKoBERT \ubaa8\ub378\uc740 [\uacf5\uc2dd \ub808\ud3ec](https://github.com/SKTBrain/KoBERT)\uc758 \uac83\uacfc \ub3d9\uc77c\ud569\ub2c8\ub2e4. \ubcf8 \ub808\ud3ec\ub294 **Huggingface tokenizer\uc758 \ubaa8\ub4e0 API\ub97c \uc9c0\uc6d0**\ud558\uae30 \uc704\ud574\uc11c \uc81c\uc791\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n\n## \ud83d\udea8 \uc911\uc694! \ud83d\udea8\n\n### \ud83d\ude4f TL;DR\n\n1. `transformers` \ub294 `v3.0` \uc774\uc0c1\uc744 \ubc18\ub4dc\uc2dc \uc124\uce58!\n2. `tokenizer`\ub294 \ubcf8 \ub808\ud3ec\uc758 `kobert_transformers/tokenization_kobert.py`\ub97c \uc0ac\uc6a9!\n\n### 1. Tokenizer \ud638\ud658\n\n`Huggingface Transformers`\uac00 `v2.9.0`\ubd80\ud130 tokenization \uad00\ub828 API\uac00 \uc77c\ubd80 \ubcc0\uacbd\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\uc5d0 \ub9de\ucdb0 \uae30\uc874\uc758 `tokenization_kobert.py`\ub97c \uc0c1\uc704 \ubc84\uc804\uc5d0 \ub9de\uac8c \uc218\uc815\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n### 2. Embedding\uc758 padding_idx \uc774\uc288\n\n\uc774\uc804\ubd80\ud130 `BertModel`\uc758 `BertEmbeddings`\uc5d0\uc11c `padding_idx=0`\uc73c\ub85c **Hard-coding**\ub418\uc5b4 \uc788\uc5c8\uc2b5\ub2c8\ub2e4. (\uc544\ub798 \ucf54\ub4dc \ucc38\uace0)\n\n```python\nclass BertEmbeddings(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n```\n\n\uadf8\ub7ec\ub098 Sentencepiece\uc758 \uacbd\uc6b0 \uae30\ubcf8\uac12\uc73c\ub85c `pad_token_id=1`, `unk_token_id=0`\uc73c\ub85c \uc124\uc815\uc774 \ub418\uc5b4 \uc788\uace0 (\uc774\ub294 KoBERT\ub3c4 \ub3d9\uc77c), \uc774\ub97c \uadf8\ub300\ub85c \uc0ac\uc6a9\ud558\ub294 BertModel\uc758 \uacbd\uc6b0 \uc6d0\uce58 \uc54a\uc740 \uacb0\uacfc\ub97c \uac00\uc838\uc62c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nHuggingface\uc5d0\uc11c\ub3c4 \ucd5c\uadfc\uc5d0 \ud574\ub2f9 \uc774\uc288\ub97c \uc778\uc9c0\ud558\uc5ec \uc774\ub97c \uc218\uc815\ud558\uc5ec `v2.9.0`\uc5d0 \ubc18\uc601\ud558\uc600\uc2b5\ub2c8\ub2e4. ([\uad00\ub828 PR #3793](https://github.com/huggingface/transformers/pull/3793)) config\uc5d0 `pad_token_id=1` \uc744 \ucd94\uac00 \uac00\ub2a5\ud558\uc5ec \uc774\ub97c \ud574\uacb0\ud560 \uc218 \uc788\uac8c \ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n```python\nclass BertEmbeddings(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n```\n\n\uadf8\ub7ec\ub098 `v.2.9.0`\uc5d0\uc11c `DistilBERT`, `ALBERT` \ub4f1\uc5d0\ub294 \uc774 \uc774\uc288\uac00 \ud574\uacb0\ub418\uc9c0 \uc54a\uc544 \uc9c1\uc811 PR\uc744 \uc62c\ub824 \ucc98\ub9ac\ud558\uc600\uace0 ([\uad00\ub828 PR #3965](https://github.com/huggingface/transformers/pull/3965)), **`v2.9.1`\uc5d0 \ucd5c\uc885\uc801\uc73c\ub85c \ubc18\uc601\ub418\uc5b4 \ubc30\ud3ec\ub418\uc5c8\uc2b5\ub2c8\ub2e4.**\n\n\uc544\ub798\ub294 \uc774\uc804\uacfc \ud604\uc7ac \ubc84\uc804\uc758 \ucc28\uc774\uc810\uc744 \ubcf4\uc5ec\uc8fc\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4.\n\n```python\n# Transformers v2.7.0\n>>> from transformers import BertModel, DistilBertModel\n>>> model = BertModel.from_pretrained(\"monologg/kobert\")\n>>> model.embeddings.word_embeddings\nEmbedding(8002, 768, padding_idx=0)\n>>> model = DistilBertModel.from_pretrained(\"monologg/distilkobert\")\n>>> model.embeddings.word_embeddings\nEmbedding(8002, 768, padding_idx=0)\n\n\n### Transformers v2.9.1\n>>> from transformers import BertModel, DistilBertModel\n>>> model = BertModel.from_pretrained(\"monologg/kobert\")\n>>> model.embeddings.word_embeddings\nEmbedding(8002, 768, padding_idx=1)\n>>> model = DistilBertModel.from_pretrained(\"monologg/distilkobert\")\n>>> model.embeddings.word_embeddings\nEmbedding(8002, 768, padding_idx=1)\n```\n\n## KoBERT / DistilKoBERT on \ud83e\udd17 Transformers \ud83e\udd17\n\n### Dependencies\n\n- torch>=1.1.0\n- transformers>=3,<5\n\n### How to Use\n\n```python\n>>> from transformers import BertModel, DistilBertModel\n>>> bert_model = BertModel.from_pretrained('monologg/kobert')\n>>> distilbert_model = DistilBertModel.from_pretrained('monologg/distilkobert')\n```\n\n**Tokenizer\ub97c \uc0ac\uc6a9\ud558\ub824\uba74, [`kobert_transformers/tokenization_kobert.py`](https://github.com/monologg/KoBERT-Transformers/blob/master/kobert_transformers/tokenization_kobert.py) \ud30c\uc77c\uc744 \ubcf5\uc0ac\ud55c \ud6c4, `KoBertTokenizer`\ub97c \uc784\ud3ec\ud2b8\ud558\uba74 \ub429\ub2c8\ub2e4.**\n\n- KoBERT\uc640 DistilKoBERT \ubaa8\ub450 \ub3d9\uc77c\ud55c \ud1a0\ud06c\ub098\uc774\uc800\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n- **\uae30\uc874 KoBERT\uc758 \uacbd\uc6b0 Special Token\uc774 \uc81c\ub300\ub85c \ubd84\ub9ac\ub418\uc9c0 \uc54a\ub294 \uc774\uc288**\uac00 \uc788\uc5b4\uc11c \ud574\ub2f9 \ubd80\ubd84\uc744 \uc218\uc815\ud558\uc5ec \ubc18\uc601\ud558\uc600\uc2b5\ub2c8\ub2e4. ([Issue link](https://github.com/SKTBrain/KoBERT/issues/11))\n\n```python\n>>> from tokenization_kobert import KoBertTokenizer\n>>> tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert') # monologg/distilkobert\ub3c4 \ub3d9\uc77c\n>>> tokenizer.tokenize(\"[CLS] \ud55c\uad6d\uc5b4 \ubaa8\ub378\uc744 \uacf5\uc720\ud569\ub2c8\ub2e4. [SEP]\")\n>>> ['[CLS]', '\u2581\ud55c\uad6d', '\uc5b4', '\u2581\ubaa8\ub378', '\uc744', '\u2581\uacf5\uc720', '\ud569\ub2c8\ub2e4', '.', '[SEP]']\n>>> tokenizer.convert_tokens_to_ids(['[CLS]', '\u2581\ud55c\uad6d', '\uc5b4', '\u2581\ubaa8\ub378', '\uc744', '\u2581\uacf5\uc720', '\ud569\ub2c8\ub2e4', '.', '[SEP]'])\n>>> [2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]\n```\n\n## Kobert-Transformers (Pip library)\n\n[![PyPI](https://img.shields.io/pypi/v/kobert-transformers)](https://pypi.org/project/kobert-transformers/)\n[![license](https://img.shields.io/badge/license-Apache%202.0-red)](https://github.com/monologg/DistilKoBERT/blob/master/LICENSE)\n[![Downloads](https://pepy.tech/badge/kobert-transformers)](https://pepy.tech/project/kobert-transformers)\n\n- `tokenization_kobert.py`\ub97c \ub7a9\ud551\ud55c \ud30c\uc774\uc36c \ub77c\uc774\ube0c\ub7ec\ub9ac\n- KoBERT, DistilKoBERT\ub97c Huggingface Transformers \ub77c\uc774\ube0c\ub7ec\ub9ac \ud615\ud0dc\ub85c \uc81c\uacf5\n- `v0.5.0`\uc5d0\uc11c\ub294 `transformers v3.0` \uc774\uc0c1\uc73c\ub85c \uae30\ubcf8 \uc124\uce58\ud569\ub2c8\ub2e4. (`transformers v4.0` \uae4c\uc9c0\ub294 \uc774\uc288 \uc5c6\uc774 \uc0ac\uc6a9 \uac00\ub2a5)\n\n### Install Kobert-Transformers\n\n```bash\npip3 install kobert-transformers\n```\n\n### How to Use\n\n```python\n>>> import torch\n>>> from kobert_transformers import get_kobert_model, get_distilkobert_model\n>>> model = get_kobert_model()\n>>> model.eval()\n>>> input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n>>> attention_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n>>> token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n>>> sequence_output, pooled_output = model(input_ids, attention_mask, token_type_ids)\n>>> sequence_output[0]\ntensor([[-0.2461,  0.2428,  0.2590,  ..., -0.4861, -0.0731,  0.0756],\n        [-0.2478,  0.2420,  0.2552,  ..., -0.4877, -0.0727,  0.0754],\n        [-0.2472,  0.2420,  0.2561,  ..., -0.4874, -0.0733,  0.0765]],\n       grad_fn=<SelectBackward>)\n```\n\n```python\n>>> from kobert_transformers import get_tokenizer\n>>> tokenizer = get_tokenizer()\n>>> tokenizer.tokenize(\"[CLS] \ud55c\uad6d\uc5b4 \ubaa8\ub378\uc744 \uacf5\uc720\ud569\ub2c8\ub2e4. [SEP]\")\n['[CLS]', '\u2581\ud55c\uad6d', '\uc5b4', '\u2581\ubaa8\ub378', '\uc744', '\u2581\uacf5\uc720', '\ud569\ub2c8\ub2e4', '.', '[SEP]']\n>>> tokenizer.convert_tokens_to_ids(['[CLS]', '\u2581\ud55c\uad6d', '\uc5b4', '\u2581\ubaa8\ub378', '\uc744', '\u2581\uacf5\uc720', '\ud569\ub2c8\ub2e4', '.', '[SEP]'])\n[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]\n```\n\n## Reference\n\n- [KoBERT](https://github.com/SKTBrain/KoBERT)\n- [DistilKoBERT](https://github.com/monologg/DistilKoBERT)\n- [Huggingface Transformers](https://github.com/huggingface/transformers)\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/monologg/KoBERT-Transformers",
            "keywords": "distilkobert kobert bert pytorch transformers lightweight",
            "license": "Apache License 2.0",
            "maintainer": "",
            "maintainer_email": "",
            "name": "kobert-transformers",
            "package_url": "https://pypi.org/project/kobert-transformers/",
            "platform": "",
            "project_url": "https://pypi.org/project/kobert-transformers/",
            "project_urls": {
                "Homepage": "https://github.com/monologg/KoBERT-Transformers"
            },
            "release_url": "https://pypi.org/project/kobert-transformers/0.5.1rc1/",
            "requires_dist": [
                "torch (>=1.1.0)",
                "transformers (<5,>=3)",
                "sentencepiece (>=0.1.91)"
            ],
            "requires_python": ">=3.6",
            "summary": "Transformers library for KoBERT, DistilKoBERT",
            "version": "0.5.1rc1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10661145,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f7aad9919e55fe92cf2043062dfebcba",
                    "sha256": "fc787cd692fec40d27ff69b825681a262b4e1c0dea497f9f59708c366193359e"
                },
                "downloads": -1,
                "filename": "kobert_transformers-0.5.1rc1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "f7aad9919e55fe92cf2043062dfebcba",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 12448,
                "upload_time": "2021-06-16T09:07:01",
                "upload_time_iso_8601": "2021-06-16T09:07:01.925482Z",
                "url": "https://files.pythonhosted.org/packages/3c/2c/b211dd166554838054041c2fae999ed31997b8faa8e2766309a202719a57/kobert_transformers-0.5.1rc1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f0ac21754e019d861e9267a6519560af",
                    "sha256": "ebbdc8bec199262df8ac9559d6b90aa200e6485eaba11af1368307aa7415ec9c"
                },
                "downloads": -1,
                "filename": "kobert-transformers-0.5.1rc1.tar.gz",
                "has_sig": false,
                "md5_digest": "f0ac21754e019d861e9267a6519560af",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 7808,
                "upload_time": "2021-06-16T09:07:03",
                "upload_time_iso_8601": "2021-06-16T09:07:03.489748Z",
                "url": "https://files.pythonhosted.org/packages/03/80/cd9a474ebb3ed7e859b2e56fcc70be1b259e0d84b6506387446526409210/kobert-transformers-0.5.1rc1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
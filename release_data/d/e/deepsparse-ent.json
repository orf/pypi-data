{
    "1.2.0": {
        "info": {
            "author": "Neuralmagic, Inc.",
            "author_email": "support@neuralmagic.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Information Technology",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "License :: Other/Proprietary License",
                "Operating System :: POSIX :: Linux",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3 :: Only",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Mathematics",
                "Topic :: Software Development",
                "Topic :: Software Development :: Libraries :: Python Modules"
            ],
            "description": "<!--\nCopyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing,\nsoftware distributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n\n\n<div style=\"display: flex; flex-direction: column; align-items: center;\">\n  <h1>\n    <img alt=\"tool icon\" src=\"https://raw.githubusercontent.com/neuralmagic/deepsparse/main/docs/source/icon-deepsparse.png\" />\n    &nbsp;&nbsp;DeepSparse Engine\n  </h1>\n  <h3> Sparsity-aware neural network inference engine for GPU-class performance on CPUs </h3>\n  <div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap\">\n    <a href=\"https://docs.neuralmagic.com/deepsparse/\">\n      <img alt=\"Documentation\" src=\"https://img.shields.io/badge/documentation-darkred?&style=for-the-badge&logo=read-the-docs\" height=\"25\" />\n    </a>\n    <a href=\"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ/\">\n      <img alt=\"Slack\" src=\"https://img.shields.io/badge/slack-purple?style=for-the-badge&logo=slack\" height=\"25\" />\n    </a>\n    <a href=\"https://github.com/neuralmagic/deepsparse/issues/\">\n      <img alt=\"Support\" src=\"https://img.shields.io/badge/support%20forums-navy?style=for-the-badge&logo=github\" height=\"25\" />\n    </a>\n    <a href=\"https://github.com/neuralmagic/deepsparse/actions/workflows/quality-check.yaml\">\n      <img alt=\"Main\" src=\"https://img.shields.io/github/workflow/status/neuralmagic/deepsparse/Quality%20Checks/main?label=build&style=for-the-badge\" height=\"25\" />\n    </a>\n    <a href=\"https://github.com/neuralmagic/deepsparse/releases\">\n      <img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/neuralmagic/deepsparse.svg?style=for-the-badge\" height=\"25\" />\n    </a>\n    <a href=\"https://github.com/neuralmagic/deepsparse/blob/main/CODE_OF_CONDUCT.md\">\n      <img alt=\"Contributor Covenant\" src=\"https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?color=yellow&style=for-the-badge\" height=\"25\" />\n    </a>\n    <a href=\"https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA\">\n      <img alt=\"YouTube\" src=\"https://img.shields.io/badge/-YouTube-red?&style=for-the-badge&logo=youtube&logoColor=white\" height=\"25\" />\n    </a>\n    <a href=\"https://medium.com/limitlessai\">\n      <img alt=\"Medium\" src=\"https://img.shields.io/badge/medium-%2312100E.svg?&style=for-the-badge&logo=medium&logoColor=white\" height=\"25\" />\n    </a>\n    <a href=\"https://twitter.com/neuralmagic\">\n      <img alt=\"Twitter\" src=\"https://img.shields.io/twitter/follow/neuralmagic?color=darkgreen&label=Follow&style=social\" height=\"25\" />\n    </a>\n  </div>\n</div>\n\nA CPU runtime that takes advantage of sparsity within neural networks to reduce compute. Read more about sparsification [here](https://docs.neuralmagic.com/main/source/getstarted.html#sparsification).\n\nNeural Magic's DeepSparse Engine is able to integrate into popular deep learning libraries (e.g., Hugging Face, Ultralytics) allowing you to leverage DeepSparse for loading and deploying sparse models with ONNX. \nONNX gives the flexibility to serve your model in a framework-agnostic environment. \nSupport includes [PyTorch,](https://pytorch.org/docs/stable/onnx.html) [TensorFlow,](https://github.com/onnx/tensorflow-onnx) [Keras,](https://github.com/onnx/keras-onnx) and [many other frameworks](https://github.com/onnx/onnxmltools).\n\nThe DeepSparse Engine is available in two editions: \n1. [**The Community Edition**](#installation) is open-source and free for evaluation, research, and non-production use with our [Engine Community License](https://neuralmagic.com/legal/engine-license-agreement/).\n2. [**The Enterprise Edition**](https://docs.neuralmagic.com/products/deepsparse-ent) requires a Trial License or [can be fully licensed](https://neuralmagic.com/legal/master-software-license-and-service-agreement/) for production, commercial applications.\n\n## Features\n\n- \ud83d\udd0c [DeepSparse Server](https://github.com/neuralmagic/deepsparse/tree/main/src/deepsparse/server)\n- \ud83d\udcdc [DeepSparse Benchmark](https://github.com/neuralmagic/deepsparse/tree/main/src/deepsparse/benchmark)\n- \ud83d\udc69\u200d\ud83d\udcbb [NLP and Computer Vision Tasks Supported](https://github.com/neuralmagic/deepsparse/tree/main/examples)\n\n## \ud83e\uddf0 Hardware Support and System Requirements\n\nReview [CPU Hardware Support for Various Architectures](https://docs.neuralmagic.com/deepsparse/source/hardware.html) to understand system requirements. \nThe DeepSparse Engine works natively on Linux; Mac and Windows require running Linux in a Docker or virtual machine; it will not run natively on those operating systems.\n\nThe DeepSparse Engine is tested on Python 3.7-3.10, ONNX 1.5.0-1.12.0, ONNX opset version 11+, and manylinux compliant. \nUsing a [virtual environment](https://docs.python.org/3/library/venv.html) is highly recommended. \n\n## Installation\n\nInstall the DeepSparse Community Edition as follows: \n\n```bash\npip install deepsparse\n```\n\nTo trial or inquire about licensing for DeepSparse Enterprise Edition, see the [DeepSparse Enterprise documentation](https://docs.neuralmagic.com/products/deepsparse-ent).\n\n## Features\n\n### \ud83d\udd0c DeepSparse Server\n\nThe DeepSparse Server allows you to serve models and pipelines from the terminal. The server runs on top of the popular FastAPI web framework and Uvicorn web server. Install the server using the following command:\n\n```bash\npip install deepsparse[server]\n```\n\n#### Single Model\n\nOnce installed, the following example CLI command is available for running inference with a single BERT model:\n\n```bash\ndeepsparse.server \\\n    task question_answering \\\n    --model_path \"zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/12layer_pruned80_quant-none-vnni\"\n```\n\nTo look up arguments run: `deepsparse.server --help`.\n\n#### Multiple Models\nTo serve multiple models in your deployment you can easily build a `config.yaml`. In the example below, we define two BERT models in our configuration for the question answering task:\n\n```yaml\nnum_cores: 1\nnum_workers: 1\nendpoints:\n    - task: question_answering\n      route: /predict/question_answering/base\n      model: zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/base-none\n      batch_size: 1\n    - task: question_answering\n      route: /predict/question_answering/pruned_quant\n      model: zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/12layer_pruned80_quant-none-vnni\n      batch_size: 1\n```\n\nFinally, after your `config.yaml` file is built, run the server with the config file path as an argument:\n```bash\ndeepsparse.server config config.yaml\n```\n\n[Getting Started with the DeepSparse Server](https://github.com/neuralmagic/deepsparse/tree/main/src/deepsparse/server) for more info.\n\n### \ud83d\udcdc DeepSparse Benchmark\n\nThe benchmark tool is available on your CLI to run expressive model benchmarks on the DeepSparse Engine with minimal parameters.\n\nRun `deepsparse.benchmark -h` to look up arguments:\n\n```shell\ndeepsparse.benchmark [-h] [-b BATCH_SIZE] [-shapes INPUT_SHAPES]\n                          [-ncores NUM_CORES] [-s {async,sync}] [-t TIME]\n                          [-nstreams NUM_STREAMS] [-pin {none,core,numa}]\n                          [-q] [-x EXPORT_PATH]\n                          model_path\n\n```\n\n[Getting Started with CLI Benchmarking](https://github.com/neuralmagic/deepsparse/tree/main/src/deepsparse/benchmark) includes examples of select inference scenarios: \n- Synchronous (Single-stream) Scenario\n- Asynchronous (Multi-stream) Scenario\n\n\n### \ud83d\udc69\u200d\ud83d\udcbb NLP Inference Example\n\n```python\nfrom deepsparse import Pipeline\n\n# SparseZoo model stub or path to ONNX file\nmodel_path = \"zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/12layer_pruned80_quant-none-vnni\"\n\nqa_pipeline = Pipeline.create(\n    task=\"question-answering\",\n    model_path=model_path,\n)\n\nmy_name = qa_pipeline(question=\"What's my name?\", context=\"My name is Snorlax\")\n```\n\nNLP Tutorials:\n- [Getting Started with Hugging Face Transformers \ud83e\udd17](https://github.com/neuralmagic/deepsparse/tree/main/examples/huggingface-transformers)\n\nTasks Supported: \n- [Token Classification: Named Entity Recognition](https://neuralmagic.com/use-cases/sparse-named-entity-recognition/)\n- [Text Classification: Multi-Class](https://neuralmagic.com/use-cases/sparse-multi-class-text-classification/)\n- [Text Classification: Binary](https://neuralmagic.com/use-cases/sparse-binary-text-classification/)\n- [Text Classification: Sentiment Analysis](https://neuralmagic.com/use-cases/sparse-sentiment-analysis/)\n- [Question Answering](https://neuralmagic.com/use-cases/sparse-question-answering/)\n\n### \ud83e\udd89 SparseZoo ONNX vs. Custom ONNX Models\n\nDeepSparse can accept ONNX models from two sources: \n\n- **SparseZoo ONNX**: our open-source collection of sparse models available for download. [SparseZoo](https://github.com/neuralmagic/sparsezoo) hosts inference-optimized models, trained on repeatable sparsification recipes using state-of-the-art techniques from [SparseML](https://github.com/neuralmagic/sparseml).\n\n- **Custom ONNX**: your own ONNX model, can be dense or sparse. Plug in your model to compare performance with other solutions.\n\n```bash\n> wget https://github.com/onnx/models/raw/main/vision/classification/mobilenet/model/mobilenetv2-7.onnx\nSaving to: \u2018mobilenetv2-7.onnx\u2019\n```\n\nCustom ONNX Benchmark example:\n```python\nfrom deepsparse import compile_model\nfrom deepsparse.utils import generate_random_inputs\nonnx_filepath = \"mobilenetv2-7.onnx\"\nbatch_size = 16\n\n# Generate random sample input\ninputs = generate_random_inputs(onnx_filepath, batch_size)\n\n# Compile and run\nengine = compile_model(onnx_filepath, batch_size)\noutputs = engine.run(inputs)\n```\n\nThe [GitHub repository](https://github.com/neuralmagic/deepsparse) includes package APIs along with examples to quickly get started benchmarking and inferencing sparse models.\n\n### Scheduling Single-Stream, Multi-Stream, and Elastic Inference\n\nThe DeepSparse Engine offers up to three types of inferences based on your use case. Read more details here: [Inference Types](https://github.com/neuralmagic/deepsparse/blob/main/docs/source/scheduler.md).\n\n1 \u26a1 Single-stream scheduling: the latency/synchronous scenario, requests execute serially. [`default`]\n\n<img src=\"https://raw.githubusercontent.com/neuralmagic/deepsparse/main/docs/source/single-stream.png\" alt=\"single stream diagram\" />\n\nUse Case: It's highly optimized for minimum per-request latency, using all of the system's resources provided to it on every request it gets.\n\n2 \u26a1 Multi-stream scheduling: the throughput/asynchronous scenario, requests execute in parallel.\n\n<img src=\"https://raw.githubusercontent.com/neuralmagic/deepsparse/main/docs/source/multi-stream.png\" alt=\"multi stream diagram\" />\n\nPRO TIP: The most common use cases for the multi-stream scheduler are where parallelism is low with respect to core count, and where requests need to be made asynchronously without time to batch them.\n\n3 \u26a1 Elastic scheduling: requests execute in parallel, but not multiplexed on individual NUMA nodes.\n\nUse Case: A workload that might benefit from the elastic scheduler is one in which multiple requests need to be handled simultaneously, but where performance is hindered when those requests have to share an L3 cache.\n\n## Resources\n#### Libraries\n- [DeepSparse](https://docs.neuralmagic.com/deepsparse/)\n\n- [SparseML](https://docs.neuralmagic.com/sparseml/)\n\n- [SparseZoo](https://docs.neuralmagic.com/sparsezoo/)\n\n- [Sparsify](https://docs.neuralmagic.com/sparsify/)\n\n\n#### Versions\n- [DeepSparse](https://pypi.org/project/deepsparse) | stable\n\n- [DeepSparse-Nightly](https://pypi.org/project/deepsparse-nightly/) | nightly (dev)\n\n- [GitHub](https://github.com/neuralmagic/deepsparse/releases) | releases\n\n#### Info\n\n- [Blog](https://www.neuralmagic.com/blog/) \n\n- [Resources](https://www.neuralmagic.com/resources/)\n\n\n## Community\n\n### Be Part of the Future... And the Future is Sparse!\n\n\nContribute with code, examples, integrations, and documentation as well as bug reports and feature requests! [Learn how here.](https://github.com/neuralmagic/deepsparse/blob/main/CONTRIBUTING.md)\n\nFor user help or questions about DeepSparse, sign up or log in to our **[Deep Sparse Community Slack](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ)**. We are growing the community member by member and happy to see you there. Bugs, feature requests, or additional questions can also be posted to our [GitHub Issue Queue.](https://github.com/neuralmagic/deepsparse/issues) You can get the latest news, webinar and event invites, research papers, and other ML Performance tidbits by [subscribing](https://neuralmagic.com/subscribe/) to the Neural Magic community.\n\nFor more general questions about Neural Magic, complete this [form.](http://neuralmagic.com/contact/)\n\n### License\n\nThe Community Edition of the project's binary containing the DeepSparse Engine is licensed under the [Neural Magic Engine License.](https://github.com/neuralmagic/deepsparse/blob/main/LICENSE-NEURALMAGIC) \nExample files and scripts included in this repository are licensed under the [Apache License Version 2.0](https://github.com/neuralmagic/deepsparse/blob/main/LICENSE) as noted.\n\n[The Enterprise Edition](https://docs.neuralmagic.com/products/deepsparse-ent) requires a Trial License or [can be fully licensed](https://neuralmagic.com/legal/master-software-license-and-service-agreement/) for production, commercial applications.\n\n### Cite\n\nFind this project useful in your research or other communications? Please consider citing:\n\n```bibtex\n@InProceedings{\n    pmlr-v119-kurtz20a, \n    title = {Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks}, \n    author = {Kurtz, Mark and Kopinsky, Justin and Gelashvili, Rati and Matveev, Alexander and Carr, John and Goin, Michael and Leiserson, William and Moore, Sage and Nell, Bill and Shavit, Nir and Alistarh, Dan}, \n    booktitle = {Proceedings of the 37th International Conference on Machine Learning}, \n    pages = {5533--5543}, \n    year = {2020}, \n    editor = {Hal Daum\u00e9 III and Aarti Singh}, \n    volume = {119}, \n    series = {Proceedings of Machine Learning Research}, \n    address = {Virtual}, \n    month = {13--18 Jul}, \n    publisher = {PMLR}, \n    pdf = {http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf},\n    url = {http://proceedings.mlr.press/v119/kurtz20a.html}\n}\n\n@article{DBLP:journals/corr/abs-2111-13445,\n  author    = {Eugenia Iofinova and\n               Alexandra Peste and\n               Mark Kurtz and\n               Dan Alistarh},\n  title     = {How Well Do Sparse Imagenet Models Transfer?},\n  journal   = {CoRR},\n  volume    = {abs/2111.13445},\n  year      = {2021},\n  url       = {https://arxiv.org/abs/2111.13445},\n  eprinttype = {arXiv},\n  eprint    = {2111.13445},\n  timestamp = {Wed, 01 Dec 2021 15:16:43 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-13445.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/neuralmagic/deepsparse",
            "keywords": "inference,machine learning,x86,x86_64,avx2,avx512,neural network,sparse,inference engine,cpu,runtime,deepsparse,computer vision,object detection,sparsity",
            "license": "Neural Magic Engine License, Apache",
            "maintainer": "",
            "maintainer_email": "",
            "name": "deepsparse-ent",
            "package_url": "https://pypi.org/project/deepsparse-ent/",
            "platform": null,
            "project_url": "https://pypi.org/project/deepsparse-ent/",
            "project_urls": {
                "Homepage": "https://github.com/neuralmagic/deepsparse"
            },
            "release_url": "https://pypi.org/project/deepsparse-ent/1.2.0/",
            "requires_dist": null,
            "requires_python": ">=3.7, <3.11",
            "summary": "Neural network inference engine that delivers GPU-class performance for sparsified models on CPUs",
            "version": "1.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15559897,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "65bbc1ca26a773c980deed18104383b7",
                    "sha256": "9e3de64a8b75d42159d8be2e6ce5db3aa07d3acd478dc8ae154f68709c75cb16"
                },
                "downloads": -1,
                "filename": "deepsparse_ent-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "has_sig": false,
                "md5_digest": "65bbc1ca26a773c980deed18104383b7",
                "packagetype": "bdist_wheel",
                "python_version": "cp310",
                "requires_python": ">=3.7, <3.11",
                "size": 40644782,
                "upload_time": "2022-10-27T23:49:13",
                "upload_time_iso_8601": "2022-10-27T23:49:13.378817Z",
                "url": "https://files.pythonhosted.org/packages/83/ff/363efe37def4e461fe7b15d77e5ec233cbaa1f44ac0d9e853c1dee3c2038/deepsparse_ent-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "40eb36a67d1ffdf0e65e8848e6fbc8bb",
                    "sha256": "1cc8d33c6d87c6f168eb2c99311239c642054c91e76233875608148382bc29ad"
                },
                "downloads": -1,
                "filename": "deepsparse_ent-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "has_sig": false,
                "md5_digest": "40eb36a67d1ffdf0e65e8848e6fbc8bb",
                "packagetype": "bdist_wheel",
                "python_version": "cp37",
                "requires_python": ">=3.7, <3.11",
                "size": 40661732,
                "upload_time": "2022-10-27T23:48:23",
                "upload_time_iso_8601": "2022-10-27T23:48:23.042716Z",
                "url": "https://files.pythonhosted.org/packages/eb/fb/23c67acef504a2907508e0de63e28813945ba378d9963f9e1b96bb07194c/deepsparse_ent-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "3a27a66a74a3379d006e26f8f9d91179",
                    "sha256": "d8e39be071e8664d400ea36b1cce1b1bc0fc5c13055e849a56e4ba777e5d47a0"
                },
                "downloads": -1,
                "filename": "deepsparse_ent-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "has_sig": false,
                "md5_digest": "3a27a66a74a3379d006e26f8f9d91179",
                "packagetype": "bdist_wheel",
                "python_version": "cp38",
                "requires_python": ">=3.7, <3.11",
                "size": 40644883,
                "upload_time": "2022-10-27T23:48:41",
                "upload_time_iso_8601": "2022-10-27T23:48:41.244487Z",
                "url": "https://files.pythonhosted.org/packages/43/f1/8845785414b28be15d90310806b0ac43b4243686d84b53b90a2ebfe2c310/deepsparse_ent-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "8b389353022c303251282da0aaa6338c",
                    "sha256": "2a178f0ff7fc60ecf716a8a2f9c3b443e1e0fd7c18d5b2eca9494c04392ca547"
                },
                "downloads": -1,
                "filename": "deepsparse_ent-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "has_sig": false,
                "md5_digest": "8b389353022c303251282da0aaa6338c",
                "packagetype": "bdist_wheel",
                "python_version": "cp39",
                "requires_python": ">=3.7, <3.11",
                "size": 40645143,
                "upload_time": "2022-10-27T23:48:57",
                "upload_time_iso_8601": "2022-10-27T23:48:57.234789Z",
                "url": "https://files.pythonhosted.org/packages/15/f9/9457688825707de17bbdb62d76d42bbd09f4c690a3e31791fbb7c17eb3e4/deepsparse_ent-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "b0ec8b25a7c76e4d11ff15f8ad44398a",
                    "sha256": "fa4c6f2cf8e9dddb4fee3cfdb8e77857af8845f762b036537e4a25f0c59e90c0"
                },
                "downloads": -1,
                "filename": "deepsparse-ent-1.2.0.tar.gz",
                "has_sig": false,
                "md5_digest": "b0ec8b25a7c76e4d11ff15f8ad44398a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7, <3.11",
                "size": 40329917,
                "upload_time": "2022-10-27T23:48:01",
                "upload_time_iso_8601": "2022-10-27T23:48:01.677670Z",
                "url": "https://files.pythonhosted.org/packages/7a/97/ef3975d5f6aaf529a00cd7762a3ea1da7957db1e5d2daae00e7a8f03d77e/deepsparse-ent-1.2.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
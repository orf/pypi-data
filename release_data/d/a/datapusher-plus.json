{
    "0.0.21": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/dathere/datapusher-plus",
            "keywords": "ckan csv xls excel qsv",
            "license": "AGPL",
            "maintainer": "",
            "maintainer_email": "",
            "name": "datapusher-plus",
            "package_url": "https://pypi.org/project/datapusher-plus/",
            "platform": null,
            "project_url": "https://pypi.org/project/datapusher-plus/",
            "project_urls": {
                "Homepage": "https://github.com/dathere/datapusher-plus"
            },
            "release_url": "https://pypi.org/project/datapusher-plus/0.0.21/",
            "requires_dist": [
                "ckanserviceprovider (>=1.0)",
                "datasize",
                "psycopg2-binary",
                "requests"
            ],
            "requires_python": "",
            "summary": "A standalone web service that parses the contents of a CKAN site's data files and pushes them into its DataStore. Accelerated by qsv.",
            "version": "0.0.21",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15630166,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e618817f162b4242a99ff1775a152fe1",
                    "sha256": "ec0b713484fd3403c57153a3151d0e6197da14bafa2b7ef8a4a3ff79fcd8f3e9"
                },
                "downloads": -1,
                "filename": "datapusher_plus-0.0.21-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "e618817f162b4242a99ff1775a152fe1",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 30139,
                "upload_time": "2022-05-05T01:03:45",
                "upload_time_iso_8601": "2022-05-05T01:03:45.395315Z",
                "url": "https://files.pythonhosted.org/packages/0f/83/ae2d59df757388c872d61121fac40bf9daeb3a0bd6b281e66be92ae0454f/datapusher_plus-0.0.21-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "6b4241c256bbccf1d649c3b3002a6878",
                    "sha256": "96f42dce90e2e7a84cb7620050d89e65e68bb8a9bcf798605f7ade21b45c5dd3"
                },
                "downloads": -1,
                "filename": "datapusher-plus-0.0.21.tar.gz",
                "has_sig": false,
                "md5_digest": "6b4241c256bbccf1d649c3b3002a6878",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 24980,
                "upload_time": "2022-05-05T01:03:47",
                "upload_time_iso_8601": "2022-05-05T01:03:47.662479Z",
                "url": "https://files.pythonhosted.org/packages/55/61/745281701d202330692252f66f88f4752bcaaea5533ec3ac8215cc369d04/datapusher-plus-0.0.21.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.22": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/dathere/datapusher-plus",
            "keywords": "ckan csv tsv xls ods excel qsv",
            "license": "AGPL",
            "maintainer": "",
            "maintainer_email": "",
            "name": "datapusher-plus",
            "package_url": "https://pypi.org/project/datapusher-plus/",
            "platform": null,
            "project_url": "https://pypi.org/project/datapusher-plus/",
            "project_urls": {
                "Homepage": "https://github.com/dathere/datapusher-plus"
            },
            "release_url": "https://pypi.org/project/datapusher-plus/0.0.22/",
            "requires_dist": [
                "ckanserviceprovider (>=1.0)",
                "requests",
                "psycopg2-binary",
                "datasize"
            ],
            "requires_python": "",
            "summary": "A standalone web service that parses the contents of a CKAN site's data files and pushes them into its DataStore. Accelerated by qsv.",
            "version": "0.0.22",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15630166,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "77af899c07520a462e7fc4ae1df4e9c6",
                    "sha256": "d8082f0f7b5e851164f6f9e1e93dc1a7dd3d63696d9d06634c87eb0e2a56041c"
                },
                "downloads": -1,
                "filename": "datapusher_plus-0.0.22-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "77af899c07520a462e7fc4ae1df4e9c6",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 31058,
                "upload_time": "2022-05-09T12:37:27",
                "upload_time_iso_8601": "2022-05-09T12:37:27.029542Z",
                "url": "https://files.pythonhosted.org/packages/99/80/9b0c51b87d59d9fc111a9cd09b6769057d6db8a698b8f1a18337b22f89ae/datapusher_plus-0.0.22-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "7ad783b16b9aaa4236ff4986e8b1604c",
                    "sha256": "5a410f9ceaf888b8d6db10160cc3a0eda4934a68aee31f5d16a117c360f30437"
                },
                "downloads": -1,
                "filename": "datapusher-plus-0.0.22.tar.gz",
                "has_sig": false,
                "md5_digest": "7ad783b16b9aaa4236ff4986e8b1604c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 37121,
                "upload_time": "2022-05-09T12:37:29",
                "upload_time_iso_8601": "2022-05-09T12:37:29.941505Z",
                "url": "https://files.pythonhosted.org/packages/e0/2c/0d98e36afa8f80e4809e229d93d3b60d9b0b57514da91c1403b6cb473da8/datapusher-plus-0.0.22.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.23": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/dathere/datapusher-plus",
            "keywords": "ckan csv tsv xls ods excel qsv",
            "license": "AGPL",
            "maintainer": "",
            "maintainer_email": "",
            "name": "datapusher-plus",
            "package_url": "https://pypi.org/project/datapusher-plus/",
            "platform": null,
            "project_url": "https://pypi.org/project/datapusher-plus/",
            "project_urls": {
                "Homepage": "https://github.com/dathere/datapusher-plus"
            },
            "release_url": "https://pypi.org/project/datapusher-plus/0.0.23/",
            "requires_dist": [
                "wheel",
                "ckanserviceprovider (>=1.0)",
                "requests",
                "psycopg2-binary",
                "datasize"
            ],
            "requires_python": "",
            "summary": "A standalone web service that parses the contents of a CKAN site's data files and pushes them into its DataStore. Accelerated by qsv.",
            "version": "0.0.23",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15630166,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6dd0cdc05e2602d2d628e612c64c6aa8",
                    "sha256": "a3ca97745ef7e852c4514292ce286a5a430415685bff7e90c2c7e6209884d322"
                },
                "downloads": -1,
                "filename": "datapusher_plus-0.0.23-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "6dd0cdc05e2602d2d628e612c64c6aa8",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 31065,
                "upload_time": "2022-05-09T12:58:03",
                "upload_time_iso_8601": "2022-05-09T12:58:03.100687Z",
                "url": "https://files.pythonhosted.org/packages/d3/cd/22dc48c4e6e4d6246610ae8e6c35b18fbe271293d8ed7ad842b3a7cf2d85/datapusher_plus-0.0.23-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "34f8f36cb2cf7c5bd7a50a3bb1abcea9",
                    "sha256": "6f85448d026be4ac6cb9a15de810d91c6dd2b4703d5eabe4aceb2bff61cc619e"
                },
                "downloads": -1,
                "filename": "datapusher-plus-0.0.23.tar.gz",
                "has_sig": false,
                "md5_digest": "34f8f36cb2cf7c5bd7a50a3bb1abcea9",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 37117,
                "upload_time": "2022-05-09T12:58:04",
                "upload_time_iso_8601": "2022-05-09T12:58:04.760461Z",
                "url": "https://files.pythonhosted.org/packages/9d/6c/07bae67cf1eab7135abb9b09bcbff1b2718d6fbe6c2bfb50ab269c84e6c6/datapusher-plus-0.0.23.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.0": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": "[CKAN Service Provider]: https://github.com/ckan/ckan-service-provider\n[Messytables]: https://github.com/okfn/messytables\n[qsv]: https://github.com/jqnatividad/qsv#qsv-ultra-fast-csv-data-wrangling-toolkit\n\n# DataPusher+\n\nDataPusher+ is a fork of [Datapusher](https://github.com/ckan/datapusher) that combines the speed and robustness of\n[ckanext-xloader](https://github.com/ckan/ckanext-xloader) with the data type guessing of Datapusher.\n\nDatapusher+ is built using [CKAN Service Provider][], with [Messytables] replaced by [qsv].\n\n[TNRIS](https://tnris.org)/[TWDB](https://www.twdb.texas.gov/) provided the use cases that informed and supported the development\nof Datapusher+, specifically, to support a [Resource-first upload workflow](#Resource-first-Upload-Workflow).\n\nIt features:\n\n* **\"Bullet-proof\", ultra-fast data type inferencing with qsv**\n\n  Unlike [Messytables][] which scans only the the first few rows to guess the type of\n  a column, [qsv][] scans the entire table so its data type inferences are guaranteed[^1].\n\n  Despite this, qsv is still exponentially faster even if it scans the whole file, not\n  only inferring data types, it also calculates some descriptive statistics as well. For example,\n  [scanning a 2.7 million row, 124MB CSV file for types and stats took 0.16 seconds](https://github.com/jqnatividad/qsv/blob/master/docs/whirlwind_tour.md#a-whirlwind-tour)[^2].\n\n  It is very fast as qsv is written in [Rust](https://www.rust-lang.org/), is multithreaded,\n  and uses all kinds of [performance techniques](https://github.com/jqnatividad/qsv/blob/master/docs/PERFORMANCE.md#performance-tuning)\n  especially designed for data-wrangling.\n\n* **Exponentially faster loading speed**\n\n  Similar to xloader, we use PostgreSQL COPY to directly pipe the data into the datastore,\n  short-circuiting the additional processing/transformation/API calls used by Datapusher.\n\n  But unlike xloader, we load everything using the proper data types and not as text, so there's\n  no need to reload the data again after adjusting the Data Dictionary, as you would with xloader.\n\n* **Production-ready Robustness**\n\n  In production, the number one source of support issues is Datapusher - primarily, because of\n  data quality issues and Datapusher's inability to correctly infer data types, gracefully handle\n  errors[^3], and provide the Data Publisher actionable information to correct the data.\n\n  Datapusher+'s design directly addresses all these issues.\n\n* **More informative datastore loading messages**\n\n  Datapusher+ messages are designed to be more verbose and actionable, so the data publisher's\n  user experience is far better and makes it possible to have a resource-first upload workflow.\n\n* **Extended data-wrangling with qsv**\n\n  Apart from bullet-proof data type inferences, qsv is leveraged by Datapusher+ to convert XLS/ODS files;\n  count the number of rows; transcode to UTF-8 if required; validate if a CSV conforms to the [RFC 4180 standard](https://datatracker.ietf.org/doc/html/rfc4180);\n  optionally create a preview subset and optionally deduplicate rows in this initial version.\n\n  Future versions of Datapusher+ will further leverage qsv's 70+ commands to do additional\n  data wrangling, preprocessing and validation. The Roadmap is available [here](https://github.com/dathere/datapusher-plus/issues/5).\n  Ideas, suggestions and your feedback are most welcome!\n\n[^1]: [Why use qsv instead of a \"proper\" python data analysis library like pandas?](https://github.com/dathere/datapusher-plus/discussions/15)\n[^2]: It takes 0.16 seconds with an index to run `qsv stats` against the [qsv whirlwind tour sample file](https://raw.githubusercontent.com/wiki/jqnatividad/qsv/files/wcp.zip) on a Ryzen 4800H (8 physical/16 logical cores) with 32 gb memory and a 1 TB SSD.\nWithout an index, it takes 1.3 seconds.\n[^3]: Imagine you have a 1M row CSV, and the last row has an invalid value for a numeric column (e.g. \"N/A\" instead of a number). \n      After spending hours pushing the data very slowly, legacy datapusher will abort on the last row and the ENTIRE job is invalid. \n      Ok, that's bad, but what makes it worse is that the old table has been deleted already, and Datapusher doesn't tell you what \n      caused the job to fail! YIKES!!!!\n\n## Resource-first Upload Workflow\n\nIn traditional CKAN, the dataset package upload workflow is as follows:\n\n1. Enter package metadata\n2. Upload resource/s\n3. Check if the datapusher uploaded the dataset correctly.\n   - With the Datapusher,this make take a while, and when it fails, it doesn't really give you\n     actionable information on why it failed.\n   - With xloader, its 10x faster. But then, that speed comes at the cost of all columns defined as text,\n     and the Data Publisher will need to manually change the data types in the Data Dictionary and\n     reload the data again.\n\nIn [TNRIS/TWDB's extensive user research](https://internetofwater.org/blog/building-the-texas-water-data-hub-from-the-ground-up/),\none of the key usability gaps they found with CKAN is this workflow. Why can't the data publisher\nupload the primary resource first, before entering the metadata? And more importantly, why can't some of the metadata\nbe automatically inferred and populated based on the attributes of the dataset?\n\nThis is why qsv's speed is critical for a Resource-first upload workflow. By the time the data publisher\nuploads the resource and starts populating the rest of the form a few seconds later, a lot of inferred metadata\n(Data Dictionary for this initial version) should be available for pre-populating the rest of the form.\n\nSee this [discussion](https://github.com/ckan/ckan/discussions/6689) and this [issue](https://github.com/ckan/ideas/issues/150)\nabout the \"Multi-pass Datapusher\" from May 2015 for additional context.\n\n## Development installation\n\nDatapusher+ is a drop-in replacement for Datapusher, so it's installed the same way.\n\nCreate a virtual environment for Datapusher+ using at least python 3.7:\n\n    python -m venv dpplus_venv\n    . dpplus_venv/bin/activate\n    cd dpplus_venv\n\n> \u2139\ufe0f **NOTE:** DP+ requires at least python 3.7. However, Ubuntu 18.04 LTS only comes with python 3.6. \n> To install python 3.7 on Ubuntu 18.04 (or even a higher version, as DP+ works with python 3.7 and above),\n> follow the procedure below:\n> \n> ```\n> sudo add-apt-repository ppa:deadsnakes/ppa\n> # we use 3.7 here, but you can get a higher version by changing the version suffix of the packages below\n> sudo apt install python3.7 python3.7-venv python3.7-dev\n> ```\n>\n> Note that DP+ still works with CKAN<=2.8, which uses older versions of python.\n\nInstall the required packages:\n\n    sudo apt-get install python-dev python-virtualenv build-essential libxslt1-dev libxml2-dev zlib1g-dev git libffi-dev\n\nGet the code:\n\n    git clone https://github.com/datHere/datapusher-plus\n    cd datapusher-plus\n\nInstall the dependencies:\n\n    pip install -r requirements-dev.txt\n    pip install -e .\n\nInstall qsv:\n\n[Download the appropriate precompiled binaries](https://github.com/jqnatividad/qsv/releases/latest) for your platform and copy\nit to the appropriate directory, e.g. for Linux:\n\n    wget https://github.com/jqnatividad/qsv/releases/download/0.67.0/qsv-0.67.0-x86_64-unknown-linux-gnu.zip\n    unzip qsv-0.67.0-x86_64-unknown-linux-gnu.zip\n    sudo mv qsv* /usr/local/bin\n\nAlternatively, if you want to install qsv from source, follow\nthe instructions [here](https://github.com/jqnatividad/qsv#installation). Note that when compiling from source,\nyou may want to look into the [Performance Tuning](https://github.com/jqnatividad/qsv#performance-tuning)\nsection to squeeze even more performance from qsv.\n\n\n> \u2139\ufe0f **NOTE:** qsv is a general purpose CSV data-wrangling toolkit that gets regular updates. To update to the latest version, just run\n`sudo qsv`/`sudo qsvlite` and it will check the repo for the latest version and update as required.\n\n\nCopy `datapusher/settings.py` to a new file like `settings_local.py` and modify your configuration as required.\nMake sure to create the `datapusher` PostgreSQL user (see [DataPusher+ Database Setup](#DataPusher+_Database_Setup)).\n\n    cp datapusher/settings.py settings_local.py\n    nano settings_local.py\n\nRun DataPusher+:\n\n    export JOB_CONFIG=$(realpath settings_local.py)\n    python datapusher/main.py\n\nBy default, DataPusher+ should be running at the following port:\n\n    http://localhost:8800/\n\n## Production deployment\n\n\nThese instructions assume you already have CKAN installed on this server in the\ndefault location described in the CKAN install documentation\n(`/usr/lib/ckan/default`).  If this is correct you should be able to run the\nfollowing commands directly, if not you will need to adapt the previous path to\nyour needs.\n\nThese instructions set up the DataPusher web service on\n[uWSGI](https://uwsgi-docs.readthedocs.io/en/latest/) running on port 8800, but\ncan be easily adapted to other WSGI servers like Gunicorn. You'll probably need\nto set up Nginx as a reverse proxy in front of it and something like Supervisor\nto keep the process up.\n\n\n    # Install requirements for DataPusher+\n    sudo apt install python3-venv python3-dev build-essential libxslt1-dev libxml2-dev libffi-dev\n\n    # Create a virtualenv for DataPusher+. DP+ requires python 3.7+.\n    # If you are on Ubuntu 18.04 LTS and installed python3.7 manually as noted below\n    sudo python3.7 -m venv /usr/lib/ckan/datapusher-plus\n    # If you already have Python 3.7+\n    sudo python3 -m venv /usr/lib/ckan/datapusher-plus\n\n    # Install qsvdp binary, if required\n    wget https://github.com/jqnatividad/qsv/releases/download/0.67.0/qsv-0.67.0-x86_64-unknown-linux-gnu.zip\n    unzip qsv-0.67.0-x86_64-unknown-linux-gnu.zip\n    sudo mv qsvdp /usr/local/bin\n\n    # Install DataPusher-plus and uwsgi for production\n    sudo /usr/lib/ckan/datapusher-plus/bin/pip install datapusher-plus uwsgi\n\n    # generate a settings file and tune it, as well as a uwsgi ini file\n    sudo mkdir -p /etc/ckan/datapusher\n    sudo curl https://raw.githubusercontent.com/dathere/datapusher-plus/master/datapusher/settings.py -o /etc/ckan/datapusher/settings.py\n    sudo curl https://raw.githubusercontent.com/dathere/datapusher-plus/master/deployment/datapusher-uwsgi.ini -o /etc/ckan/datapusher/uwsgi.ini\n\n    # Initialize the database. Be sure to edit settings.py first!\n    /usr/lib/ckan/datapusher-plus/bin/datapusher_initdb /etc/ckan/datapusher/settings.py\n\n    # Create a user to run the web service (if necessary)\n    sudo addgroup www-data\n    sudo adduser -G www-data www-data\n\nAt this point you can run DataPusher+ with the following command:\n\n    export JOB_CONFIG=/etc/ckan/datapusher/settings.py \n    /usr/lib/ckan/datapusher-plus/bin/uwsgi --enable-threads -i /etc/ckan/datapusher/uwsgi.ini\n\nYou might need to change the `uid` and `guid` settings when using a different user.\n\nTo deploy it using supervisor:\n\n    sudo curl https://raw.githubusercontent.com/dathere/datapusher-plus/master/deployment/datapusher-uwsgi.conf -o /etc/supervisor/conf.d/datapusher-uwsgi.conf\n    sudo service supervisor restart\n\n\n## Configuring\n\n\n### CKAN Configuration\n\nAdd `datapusher` to the plugins in your CKAN configuration file\n(generally located at `/etc/ckan/default/production.ini` or `/etc/ckan/default/ckan.ini`):\n\n    ckan.plugins = <other plugins> datapusher\n\nIn order to tell CKAN where this webservice is located, the following must be\nadded to the `[app:main]` section of your CKAN configuration file :\n\n    ckan.datapusher.url = http://127.0.0.1:8800/\n\nThere are other CKAN configuration options that allow to customize the CKAN - DataPusher\nintegration. Please refer to the [DataPusher Settings](https://docs.ckan.org/en/latest/maintaining/configuration.html#datapusher-settings) section in the CKAN documentation for more details.\n\n> \u2139\ufe0f **NOTE:** DP+ recognizes some additional TSV and spreadsheet subformats - `xlsm` and `xlsb` for Excel Spreadsheets,\n> and `tab` for TSV files. To process these subformats, set `ckan.datapusher.formats` as follows in your CKAN.INI file:\n>\n>```\n> ckan.datapusher.formats = csv xls xlsx xlsm xlsb tsv tab application/csv application/vnd.ms-excel application/vnd.openxmlformats-officedocument.spreadsheetml.sheet ods application/vnd.oasis.opendocument.spreadsheet\n>```\n>\n>and add this entry to your CKAN's `resource_formats.json` file.\n>\n>```\n> [\"TAB\", \"Tab Separated Values File\", \"text/tab-separated-values\", []],\n>```\n\n\n### DataPusher+ Configuration\n\nThe DataPusher+ instance is configured in the `deployment/datapusher_settings.py`\nfile. The location of this file can be adjusted using the `JOB_CONFIG`\nenvironment variable which should provide an absolute path to a python-formatted\nconfig file.\n\nHere's a summary of the options available.\n\n| Name | Default | Description |\n| -- | -- | -- |\n| HOST | '0.0.0.0' | Web server host |\n| PORT | 8800 | Web server port |\n| SQLALCHEMY_DATABASE_URI | 'postgresql://datapusher_jobs:<br/>YOURPASSWORD<br/>@localhost/datapusher_jobs' | SQLAlchemy Database URL. See note below about setting up the `datapusher_jobs` db beforehand. |\n| MAX_CONTENT_LENGTH | '1024000' | Max size of files to process in bytes |\n| CHUNK_SIZE | '16384' | Chunk size when processing the data file |\n| DOWNLOAD_TIMEOUT | '30' | Download timeout for requesting the file |\n| SSL_VERIFY | False | Do not validate SSL certificates when requesting the data file (*Warning*: Do not use this setting in production) |\n| TYPES | 'String', 'Float', 'Integer', 'DateTime', 'Date', 'NULL' | These are the types that qsv can infer. |\n| TYPE_MAPPING | {'String': 'text', 'Integer': 'numeric', 'Float': 'numeric', 'DateTime': 'timestamp', 'Date': 'timestamp', 'NULL': 'text'} | Internal qsv type mapping to PostgreSQL types |\n| LOG_FILE | `/tmp/ckan_service.log` | Where to write the logs. Use an empty string to disable |\n| STDERR | `True` | Log to stderr? |\n| QSV_BIN | /usr/local/bin/qsvdp | The location of the qsv binary to use. qsvdp is the DP+ optimized version of qsv. It only has the commands used by DP+, has the self-update engine removed, and is 6x smaller than qsv and 3x smaller than qsvlite. You may also want to look into using `qsvdp_nightly`, for even more performance. |\n| PREVIEW_ROWS | 1000 | The number of rows to insert to the data store. Set to 0 to insert all rows |\n| QSV_DEDUP | `True` | Automatically deduplicate rows? |\n| DEFAULT_EXCEL_SHEET | 0 | The zero-based index of the Excel sheet to export to CSV and insert into the Datastore. Negative values are accepted, i.e. -1 is the last sheet, -2 is 2nd to the last, etc. |\n| AUTO_ALIAS | `True` | Automatically create a resource alias - RESOURCE_NAME-PACKAGE_NAME-OWNER_ORG, that's easier to use in API calls and with the scheming datastore_choices helper |\n| WRITE_ENGINE_URL | | The Postgres connection string to use to write to the Datastore using Postgres COPY. This should be **similar** to your `ckan.datastore.write_url`, except you'll need to use the `datapusher` user |\n\nAll of the configuration options above can be also provided as environment\nvariables prepending the name with `DATAPUSHER_`, eg\n`DATAPUSHER_SQLALCHEMY_DATABASE_URI`, `DATAPUSHER_PORT`, etc. For variables with\nboolean values you must use `1` or `0`.\n\n### DataPusher+ Database Setup\n\nDP+ requires a dedicated PostgreSQL account named `datapusher` to connect to the CKAN Datastore.\n\nTo create the `datapusher` user and give it the required privileges to the `datastore_default` database:\n\n```\nsu - postgres\npsql -d datastore_default\nCREATE ROLE datapusher LOGIN PASSWORD 'thepassword';\nGRANT CREATE, CONNECT, TEMPORARY ON DATABASE datastore_default TO datapusher;\nGRANT SELECT, INSERT, UPDATE, DELETE, TRUNCATE ON ALL TABLES IN SCHEMA public TO datapusher;\n\\q\n```\n\nDP+ also requires its own job_store database to keep track of all the DP+ jobs. In the original Datapusher,\nthis was a sqlite database by default. Though DP+ can still use a sqlite database, we are discouraging its use.\n\nTo setup the `datapusher_jobs` database and its user:\n\n    sudo -u postgres createuser -S -D -R -P datapusher_jobs\n    sudo -u postgres createdb -O datapusher_jobs datapusher_jobs -E utf-8\n\n## Usage\n\nAny file that has one of the supported formats (defined in [`ckan.datapusher.formats`](https://docs.ckan.org/en/latest/maintaining/configuration.html#ckan-datapusher-formats)) will be attempted to be loaded\ninto the DataStore.\n\nYou can also manually trigger resources to be resubmitted. When editing a resource in CKAN (clicking the \"Manage\" button on a resource page), a new tab named \"DataStore\" will appear. This will contain a log of the last attempted upload and a button to retry the upload.\n\n![DataPusher+ UI](images/datapusher-plus-scn1.png)\n![DataPusher+ UI 2](images/datapusher-plus-scn2.png)\n\n### Command line\n\nRun the following command to submit all resources to datapusher, although it will skip files whose hash of the data file has not changed:\n\n    ckan -c /etc/ckan/default/ckan.ini datapusher resubmit\n\nOn CKAN<=2.8:\n\n    paster --plugin=ckan datapusher resubmit -c /etc/ckan/default/ckan.ini\n\nTo Resubmit a specific resource, whether or not the hash of the data file has changed::\n\n    ckan -c /etc/ckan/default/ckan.ini datapusher submit {dataset_id}\n\nOn CKAN<=2.8:\n\n    paster --plugin=ckan datapusher submit <pkgname> -c /etc/ckan/default/ckan.ini\n\n\n## License\n\nThis material is copyright (c) 2020 Open Knowledge Foundation and other contributors\n\nIt is open and licensed under the GNU Affero General Public License (AGPL) v3.0\nwhose full text may be found at:\n\nhttp://www.fsf.org/licensing/licenses/agpl-3.0.html\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/dathere/datapusher-plus",
            "keywords": "ckan csv tsv xls ods excel qsv",
            "license": "AGPL",
            "maintainer": "",
            "maintainer_email": "",
            "name": "datapusher-plus",
            "package_url": "https://pypi.org/project/datapusher-plus/",
            "platform": null,
            "project_url": "https://pypi.org/project/datapusher-plus/",
            "project_urls": {
                "Homepage": "https://github.com/dathere/datapusher-plus"
            },
            "release_url": "https://pypi.org/project/datapusher-plus/0.1.0/",
            "requires_dist": [
                "wheel",
                "ckanserviceprovider (>=1.0)",
                "requests",
                "psycopg2-binary",
                "datasize"
            ],
            "requires_python": "",
            "summary": "A standalone web service that parses the contents of a CKAN site's data files and pushes them into its DataStore. Accelerated by qsv.",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15630166,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f3417031e2c0ab37f17ea253a2d5bf4e",
                    "sha256": "968a1f5f8d20ddc63073d4858bed123fe70e4412b8a95f6bb0e420ac1a5c1eae"
                },
                "downloads": -1,
                "filename": "datapusher_plus-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "f3417031e2c0ab37f17ea253a2d5bf4e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 31572,
                "upload_time": "2022-09-09T19:13:55",
                "upload_time_iso_8601": "2022-09-09T19:13:55.216164Z",
                "url": "https://files.pythonhosted.org/packages/28/d3/dc8f79241ae9d876079352b8494626fdd6fec1240c100e9a5c12a52193e3/datapusher_plus-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "04f6ef3f0a4313d061a7c07457fa58b1",
                    "sha256": "4c7d950dede8fb33ecb6f3fdccd48448f867b11fc13e0927a43951e4126b3dce"
                },
                "downloads": -1,
                "filename": "datapusher-plus-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "04f6ef3f0a4313d061a7c07457fa58b1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 37838,
                "upload_time": "2022-09-09T19:13:56",
                "upload_time_iso_8601": "2022-09-09T19:13:56.759023Z",
                "url": "https://files.pythonhosted.org/packages/c3/0c/da4166c037e70a89cf1efd030afba09e2f3e3e07196964a9f9cbacf6d310/datapusher-plus-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1.15": {
        "info": {
            "author": "Cleanlab Inc",
            "author_email": "team@cleanlab.ai",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: Information Technology",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: English",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Mathematics"
            ],
            "description": "# cleanlab-studio [![Build Status](https://github.com/cleanlab/cleanlab-studio/workflows/CI/badge.svg)](https://github.com/cleanlab/cleanlab-studio/actions?query=workflow%3ACI) [![PyPI](https://img.shields.io/pypi/v/cleanlab-studio.svg)][PyPI]\n\nCommand line interface for all things Cleanlab Studio.\n\nThis currently supports generating <a href=\"#schema\">dataset schema</a>, uploading <a href=\"#dataset-format\">\ndatasets</a> into Cleanlab Studio, and downloading cleansets from Cleanlab Studio.\n\n## Installation\n\nYou can install the Cleanlab Studio CLI [from PyPI][PyPI] with:\n\n```bash\npip install cleanlab-studio\n```\n\nIf you already have the CLI installed and wish to upgrade to the latest version, run:\n\n```bash\npip install --upgrade cleanlab-studio\n```\n\n## Workflow\n\nUploading datasets to Cleanlab Studio is a two-step process.\n\n1. We generate a schema describing the dataset and its <a href=\"#data-types-and-feature-types\">data and feature\n   types</a>, which is verified by the user.\n2. Based on this schema, the dataset is parsed and uploaded to Cleanlab Studio.\n\n### Upload a dataset\n\nTo upload a dataset without\nfirst [generating a schema](https://github.com/cleanlab/cleanlab-studio/#generate-dataset-schema) (i.e. Cleanlab will\nsuggest one for you):\n\n`cleanlab dataset upload -f [dataset filepath]`\n\nYou will be asked to `\"Specify your dataset modality (text, tabular):\"`.\n\n* Enter `text` to only find label errors based on a single column of text in your dataset.\n* Enter `tabular` to find data and label issues based on any subset of the column features.\n\nTo upload a dataset with a schema:\n\n`cleanlab dataset upload -f [dataset filepath] -s [schema filepath]`\n\nTo **resume uploading** a dataset whose upload was interrupted:\n\n`cleanlab dataset upload -f [dataset filepath] --id [dataset ID]`\n\nA dataset ID is generated and printed to the terminal the first time the dataset is uploaded. It can also be accessed by\nvisiting https://app.cleanlab.ai/datasets and selecting 'Resume' for the relevant dataset.\n\n#### Generate dataset schema\n\nTo generate a dataset schema (prior to uploading your dataset):\n\n`cleanlab dataset schema generate -f [dataset filepath]`\n\n* For `Id column: `, please enter the string name of of the column in your dataset that contains the id of each row.\n* For `Modality (text, tabular): `, please enter `text` to only find label errors based on a single column of text,\n  otherwise enter `tabular` to find data and label issues based on any subset of the column features.\n\nTo validate an existing schema, i.e. check that it is complete, well-formatted, and\nhas <a href=\"#data-types-and-feature-types\">data types with sensible feature types</a>:\n\n`cleanlab dataset schema validate -s [schema filepath]`\n\nYou may then wish to inspect the generated schema to check that the fields and metadata are correct.\n\n### Download clean labels\n\nTo download clean labels (i.e. labels that have been fixed through the Cleanlab Studio interface):\n\n`cleanlab cleanset download --id [cleanset ID]`\n\nTo download clean labels and combine them with your local dataset:\n\n`cleanlab cleanset download --id [cleanset ID] -f [dataset filepath]`\n\n## Commands\n\n**`cleanlab login` authenticates you**\n\nAuthenticates you when uploading datasets to Cleanlab Studio. Pass in your API key using `--key [API key]`. Your API key\ncan be accessed at [https://app.cleanlab.ai/upload](https://app.cleanlab.ai/upload).\n\n**`cleanlab dataset schema generate` generates dataset schemas**\n\nGenerates a schema based on your dataset. Specify your target dataset with `--filepath [dataset filepath]`. You will be\nprompted to save the generated schema JSON and to specify a save location. This can be specified\nusing `--output [output filepath]`.\n\n**`cleanlab dataset schema validate` validates a schema JSON file**\n\nValidates a schema JSON file, checking that a schema is complete, well-formatted, and\nhas <a href=\"#data_types_and_feature_types\">data types with sensible feature types</a>. Specify your target schema\nwith `--schema [schema filepath]`.\n\nYou may also validate an existing schema with respect to a dataset (`-d [dataset filepath]`), i.e. all previously\nmentioned checks and the additional check that all fields in the schema are present in the dataset.\n\n**`cleanlab dataset upload` uploads your dataset**\n\nUploads your dataset to Cleanlab Studio. Specify your target dataset with `--filepath [dataset filepath]`. You will be\nprompted for further details about the dataset's modality and ID column. These may be supplied to the command\nwith `--modality [modality]`, `--id-column [name of ID column]`, and you may also specify a custom dataset name\nwith`--name [custom dataset name]`.\n\nAfter uploading your dataset, you will be prompted to save the list of dataset issues (if any) encountered during the\nupload process. These issues include missing IDs, duplicate IDs, missing values, and values whose types do not match the\nschema. You may specify the save location with `--output [output filepath]`.\n\n**`cleanlab cleanset download` downloads Cleanlab columns from your cleanset**\n\nCleansets are initialized through the Cleanlab Studio interface. In a cleanset, users can inspect their dataset and\nverify their labels. Clean labels are the labels after this set of manual fixes have been applied.\n\nThis command downloads the clean labels and saves them locally as a .csv, .xls/.xlsx, or .json, with columns `id`\nand `clean_label`. Include the `--filepath [dataset filepath]` to combine the clean labels with the original dataset as\na new column `clean_label`, which will be outputted to `--output [output filepath]`. Include the `--all` flag to\ninclude **all** Cleanlab columns, i.e. issue, label quality, suggested label, clean label, instead of only the clean\nlabel column.\n\n## Dataset format\n\nCleanlab currently only supports text and tabular dataset modalities.\n(If your dataset contains both text and tabular data, treat it as tabular.)\nThe accepted dataset file types are: `.csv`, `.json`, and `.xls/.xlsx`.\n\nBelow are some examples of how to format your dataset depending on modality and file type.\n\nEvery dataset must have an **ID column** (i.e. a column containing identifiers that uniquely identify each row) and a\n**label column** (for the prediction task).\n\nApart from the reserved column name: `clean_label`, You are free to name the columns in your dataset in any way you\nwant.\n\n<details>\n<summary>Tabular</summary>\n<br />\n<details>\n<summary>.csv, .xls/.xlsx</summary>\n\n| flower_id | width | length | color | species |\n|:----------|:------|--------|-------|---------|\n| flower_01 | 4     | 3      | red   | rose    |\n| flower_02 | 7     | 2      | white | lily    |\n\n</details>\n<details>\n<summary>.json</summary>\n\n```json\n{\n  \"rows\": [\n    {\n      \"flower_id\": \"flower_01\",\n      \"width\": 4,\n      \"length\": 3,\n      \"color\": \"red\",\n      \"species\": \"rose\"\n    },\n    {\n      \"flower_id\": \"flower_02\",\n      \"width\": 7,\n      \"length\": 2,\n      \"color\": \"white\",\n      \"species\": \"lily\"\n    }\n  ]\n}\n```\n\n</details>\n</details>\n\n<details>\n<summary>Text</summary>\n<br />\n<details>\n<summary>.csv, .xls/.xlsx</summary>\n\n| review_id | review | sentiment |\n|:----------|:-------|-----------|\n| review_1  | The sales rep was fantastic!     | positive  |\n| review_2  | He was a bit wishy-washy.     | negative  |\n\n</details>\n\n<details>\n<summary>.json</summary>\n\n```json\n{\n  \"rows\": [\n    {\n      \"review_id\": \"review_1\",\n      \"review\": \"The sales rep was fantastic!\",\n      \"label\": \"positive\"\n    },\n    {\n      \"review_id\": \"review_2\",\n      \"review\": \"He was a bit wishy-washy.\",\n      \"label\": \"negative\"\n    }\n  ]\n}\n```\n\n</details>\n</details>\n\n## Schema\n\nTo specify the column types in your dataset, create a JSON file named `schema.json`. We recommend\nusing `cleanlab dataset schema generate` to generate an initial schema and editing from there.\n\nYour schema file should be formatted as follows:\n\n```\n{\n  \"metadata\": {\n    \"id_column\": \"tweet_id\",\n    \"modality\": \"text\",\n    \"name\": \"Tweets.csv\"\n  },\n  \"fields\": {\n    \"tweet_id\": {\n      \"data_type\": \"string\",\n      \"feature_type\": \"identifier\"\n    },\n    \"sentiment\": {\n      \"data_type\": \"string\",\n      \"feature_type\": \"categorical\"\n    },\n    \"sentiment_confidence\": {\n      \"data_type\": \"float\",\n      \"feature_type\": \"numeric\"\n    },\n    \"retweet_count\": {\n      \"data_type\": \"integer\",\n      \"feature_type\": \"numeric\"\n    },\n    \"text\": {\n      \"data_type\": \"string\",\n      \"feature_type\": \"text\"\n    },\n    \"tweet_created\": {\n      \"data_type\": \"boolean\",\n      \"feature_type\": \"boolean\"\n    },\n    \"tweet_created\": {\n      \"data_type\": \"string\",\n      \"feature_type\": \"datetime\"\n    },\n  },\n  \"version\": \"0.1.12\"\n}\n```\n\nThis is the schema of a hypothetical dataset `Tweets.csv` that contains tweets, where the column `tweet_id` contains a\nunique identifier for each record. Each column in the dataset is specified under `fields` with its data type and feature\ntype.\n\n### Data types and Feature types\n\n**Data type** refers to the type of the field's values: string, integer, float, or boolean.\n\nNote that the integer type is partially *strict*, meaning floats that are equal to integers (e.g. `1.0`, `2.0`, etc)\nwill be accepted, but floats like `0.8` and `1.5` will not. In contrast, the float type is *lenient*, meaning integers\nare accepted. Users should select the float type if the field may include float values. Note too that integers can have\ncategorical and identifier feature types, whereas floats cannot.\n\nFor booleans, the list of accepted values are: true/false, t/f, yes/no, 1/0, 1.0/0.0.\n\n**Feature type** refers to the secondary type of the field, relating to how it is used in a machine learning model, such\nas whether it is:\n\n- a categorical value\n- a numeric value\n- a datetime value\n- a boolean value\n- text\n- an identifier \u2014 a string / integer that identifies some entity\n\nSome feature types can only correspond to specific data types. The list of possible feature types for each data type is\nshown below\n\n| Data type  | Feature type                               |\n|:-----------|:-------------------------------------------|\n| string     | text, categorical, datetime, identifier    |\n| integer    | categorical, datetime, identifier, numeric |\n| float      | datetime, numeric                          |\n| boolean    | boolean                                    |\n\nThe `datetime` type should be used for datetime strings, e.g. \"2015-02-24 11:35:52 -0800\", and Unix timestamps (which\nwill be integers or floats). Datetime values must be parsable\nby [pandas.to_datetime()](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html).\n\n`version` indicates the version of the Cleanlab CLI package version used to generate the schema. The current Cleanlab\nschema version is `0.1.15`.\n\n[PyPI]: https://pypi.org/project/cleanlab-studio/\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/cleanlab/cleanlab-studio",
            "keywords": "cleanlab",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "cleanlab-studio",
            "package_url": "https://pypi.org/project/cleanlab-studio/",
            "platform": null,
            "project_url": "https://pypi.org/project/cleanlab-studio/",
            "project_urls": {
                "Bug Tracker": "https://github.com/cleanlab/cleanlab-studio/issues",
                "Homepage": "https://github.com/cleanlab/cleanlab-studio"
            },
            "release_url": "https://pypi.org/project/cleanlab-studio/0.1.15/",
            "requires_dist": [
                "aiohttp (>=3.8.1)",
                "Click (>=8.1.0)",
                "colorama (>=0.4.4)",
                "pandas (>=1.0.0)",
                "pyexcel (>=0.7.0)",
                "pyexcel-xls (>=0.7.0)",
                "pyexcel-xlsx (>=0.6.0)",
                "requests (>=2.27.1)",
                "tqdm (>=4.64.0)",
                "ijson (>=3.1.4)",
                "jsonstreams (>=0.6.0)",
                "semver (>=2.13.0)",
                "Pillow (>=9.2.0)"
            ],
            "requires_python": ">=3.8",
            "summary": "Client interface for all things Cleanlab Studio",
            "version": "0.1.15",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15526292,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "300912787150202b030de93f00f47ca7",
                    "sha256": "df85b8f7ef58b7c5946e223ed10e1fb5d52d66a74db844b2cede07dfb1652f1f"
                },
                "downloads": -1,
                "filename": "cleanlab_studio-0.1.15-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "300912787150202b030de93f00f47ca7",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8",
                "size": 42147,
                "upload_time": "2022-10-25T00:22:26",
                "upload_time_iso_8601": "2022-10-25T00:22:26.058914Z",
                "url": "https://files.pythonhosted.org/packages/25/66/78a5a3fca1a50f8de33cf8a262884d9598855742809b835ea351547f7370/cleanlab_studio-0.1.15-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "206abe56de5b18e5c3023778167a3f21",
                    "sha256": "81f4c8b1114995a751c068642140806faf487648d298c7940d758edb264f1405"
                },
                "downloads": -1,
                "filename": "cleanlab-studio-0.1.15.tar.gz",
                "has_sig": false,
                "md5_digest": "206abe56de5b18e5c3023778167a3f21",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8",
                "size": 35013,
                "upload_time": "2022-10-25T00:22:27",
                "upload_time_iso_8601": "2022-10-25T00:22:27.933961Z",
                "url": "https://files.pythonhosted.org/packages/14/dc/bc2b9fe7942532d620a13170a81bf6f0e7cf2d5e338ef229c6cf01de52b0/cleanlab-studio-0.1.15.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
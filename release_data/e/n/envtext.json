{
    "0.0.10": {
        "info": {
            "author": "Bi Huaibin",
            "author_email": "bi.huaibin@foxmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Text Processing",
                "Topic :: Text Processing :: Indexing",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/celtics1863/envtext",
            "keywords": "NLP,bert,Chinese,LSTM,RNN,domain text analysis",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "envtext",
            "package_url": "https://pypi.org/project/envtext/",
            "platform": "",
            "project_url": "https://pypi.org/project/envtext/",
            "project_urls": {
                "Bug Tracker": "https://github.com/celtics1863/envtext/issues",
                "Homepage": "https://github.com/celtics1863/envtext"
            },
            "release_url": "https://pypi.org/project/envtext/0.0.10/",
            "requires_dist": [
                "jieba",
                "datasets",
                "gensim",
                "tqdm",
                "numpy",
                "pytorch-crf",
                "pandas",
                "torch",
                "transformers"
            ],
            "requires_python": ">=3.6",
            "summary": "envtext for Chinese texts analysis in Environment domain",
            "version": "0.0.10",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 12960951,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e49d799039060cbd9e79e18dd54fcf74",
                    "sha256": "80e38a6f4e06f6f8a3a5f148265785c9195710131a2e7abe0e0f0f3d3172b1c9"
                },
                "downloads": -1,
                "filename": "envtext-0.0.10-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "e49d799039060cbd9e79e18dd54fcf74",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 35535999,
                "upload_time": "2022-02-20T14:21:28",
                "upload_time_iso_8601": "2022-02-20T14:21:28.300580Z",
                "url": "https://files.pythonhosted.org/packages/d8/19/f8e1e98fe53082ea593a23640703c4999d3d11ba658c1ea25ced55257b7f/envtext-0.0.10-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "b65935a2a9e31821b6995d4a9601bed1",
                    "sha256": "f88b1bf4ef9ffce5499d29fcaf32a09bbb7a2ba1f139df6351221ac4e3b92199"
                },
                "downloads": -1,
                "filename": "envtext-0.0.10.tar.gz",
                "has_sig": false,
                "md5_digest": "b65935a2a9e31821b6995d4a9601bed1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 35490691,
                "upload_time": "2022-02-20T14:22:39",
                "upload_time_iso_8601": "2022-02-20T14:22:39.791943Z",
                "url": "https://files.pythonhosted.org/packages/a1/df/4fa91f80a0194d338a4d001551e5c3c2bbce3ba3a45b1b8c69e08a9a3feb/envtext-0.0.10.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.12": {
        "info": {
            "author": "Bi Huaibin",
            "author_email": "bi.huaibin@foxmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Text Processing",
                "Topic :: Text Processing :: Indexing",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/celtics1863/envtext",
            "keywords": "NLP,bert,Chinese,LSTM,RNN,domain text analysis",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "envtext",
            "package_url": "https://pypi.org/project/envtext/",
            "platform": "",
            "project_url": "https://pypi.org/project/envtext/",
            "project_urls": {
                "Bug Tracker": "https://github.com/celtics1863/envtext/issues",
                "Homepage": "https://github.com/celtics1863/envtext"
            },
            "release_url": "https://pypi.org/project/envtext/0.0.12/",
            "requires_dist": [
                "jieba",
                "datasets",
                "gensim",
                "tqdm",
                "numpy",
                "pytorch-crf",
                "pandas",
                "torch",
                "transformers"
            ],
            "requires_python": ">=3.6",
            "summary": "envtext for Chinese texts analysis in Environment domain",
            "version": "0.0.12",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 12960951,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7ab652a6f41e8804a49edcf4b0bd506d",
                    "sha256": "2cdcdf7a227d5209aa6d2185ec4e17599e7e41077254c9b8ad9e86b16577bb28"
                },
                "downloads": -1,
                "filename": "envtext-0.0.12-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7ab652a6f41e8804a49edcf4b0bd506d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 35536699,
                "upload_time": "2022-02-21T14:55:13",
                "upload_time_iso_8601": "2022-02-21T14:55:13.814382Z",
                "url": "https://files.pythonhosted.org/packages/e6/1e/05e75eacb73403b6cf1789f937f78a82c2bfd6b5f4a4e9e6129ce8cc2207/envtext-0.0.12-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "792e0b5a2a3c3221bef68417356cc6df",
                    "sha256": "6838f945241ccf3c7469ff2f8409d70bdc4caf4a54c8a53f2cf72e3cea4c7b35"
                },
                "downloads": -1,
                "filename": "envtext-0.0.12.tar.gz",
                "has_sig": false,
                "md5_digest": "792e0b5a2a3c3221bef68417356cc6df",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 35491497,
                "upload_time": "2022-02-21T14:56:34",
                "upload_time_iso_8601": "2022-02-21T14:56:34.521653Z",
                "url": "https://files.pythonhosted.org/packages/c2/bf/040ee15b26142a9275679c3d27d9f4e4ca1971c13233aada24bc51603b55/envtext-0.0.12.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.8": {
        "info": {
            "author": "Bi Huaibin",
            "author_email": "bi.huaibin@foxmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: Apache Software License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Text Processing",
                "Topic :: Text Processing :: Indexing",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description": "# envText\n\n**\u9996\u6b3e**\u4e2d\u6587\u73af\u5883\u9886\u57df\u6587\u672c\u5206\u6790\u5de5\u5177\u3002\u4ecd\u7136\u5728\u5185\u6d4b\u4e2d\uff0c\u656c\u8bf7\u671f\u5f85\u3002\n\n\u7279\u6027\uff1a  \n1. :one:\u652f\u6301\u4e2d\u6587\u73af\u5883\u9886\u57df\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b**envBert**\uff01\n\n2. :two:\u652f\u6301\u4e2d\u6587\u73af\u5883\u9886\u57df\u5927\u89c4\u6a21\u9884\u8bad\u7ec3**\u8bcd\u5411\u91cf**!\n\n3. :three:\u652f\u6301\u4e2d\u6587\u73af\u5883\u9886\u57df\u4e13\u5bb6\u8fc7\u6ee4\u7684**\u8bcd\u8868**!\n\n4. :four: **\u4e00\u4e14\u8bbe\u8ba1\u5747\u4e3a\u9886\u57df\u4e13\u5bb6\u7814\u7a76\u670d\u52a1**\uff1a\n    - \u4e3a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7cbe\u7b80\u4e86\u63a5\u53e3\uff0c\u53ea\u4fdd\u7559\u4e86\u5fc5\u8981\u7684batch_size, learning_rate\u7b49\u53c2\u6570\n    - \u8fdb\u4e00\u6b65\u4f18\u5316huggingface transformers\u8f93\u5165\u8f93\u51fa\u63a5\u53e3\uff0c\u652f\u630120\u4f59\u79cd\u6570\u636e\u96c6\u683c\u5f0f\n    - \u4e00\u952e\u4f7f\u7528\u6a21\u578b\uff0c\u8ba9\u9886\u57df\u4e13\u5bb6\u7cbe\u529b\u96c6\u4e2d\u5728\u5206\u6790\u95ee\u9898\u4e0a\n\n5. :five: \u4f7f\u7528transformers\u63a5\u53e3\uff0c\u652f\u6301\u8f7b\u677e\u81ea\u5b9a\u4e49\u6a21\u578b\n\n\u4e0b\u4e00\u6b65\u8ba1\u5212\uff1a  \n- [ ] \u6570\u636e\u96c6\u652f\u6301\uff1a\u652f\u6301\u5e38\u7528**\u6807\u6ce8\u5de5\u5177**\u6570\u636e\u96c6  \n    - [ ] \u7cbe\u7075\u6807\u6ce8\u52a9\u624b  \n    - [ ] Doccano  \n    - [ ] universal data annotator\n- [ ] **\u4e13\u9898\u652f\u6301**  \n    - [ ] \u65e0\u76d1\u7763\u5b9e\u4f53/\u77ed\u8bed/\u56fa\u5b9a\u642d\u914d\u6316\u6398  \n    - [ ] \u6c14\u5019\u53d8\u5316\u6587\u672c\u5206\u6790\u5de5\u5177\u7bb1  \n    - [ ] \u73af\u5883\u9886\u57df\u5b9e\u4f53  \n- [ ] \u66f4\u65b0\u6587\u6863\u548c\u6848\u4f8b  \n        \n\n\u5982\u679c\u60a8\u89c9\u5f97\u672c\u9879\u76ee\u6709\u7528\u6216\u662f\u6709\u5e2e\u52a9\u5230\u60a8\uff0c\u9ebb\u70e6\u60a8\u70b9\u51fb\u4e00\u4e0b\u53f3\u4e0a\u89d2\u7684star :star:\u3002\u60a8\u7684\u652f\u6301\u662f\u6211\u4eec\u7ef4\u62a4\u9879\u76ee\u7684\u6700\u5927\u52a8\u529b:metal:\uff01\n\n\n# \u4f7f\u7528\u65b9\u6cd5\n\n### 1. \u5b89\u88c5\n\npython\u73af\u5883\u914d\u7f6e\n\n```bash\npip install envtext\n\n#\u56fd\u5185\u7528\u6237\u4f7f\u7528\u6e05\u534e\u955c\u50cf\u52a0\u901f\npip install envtext -i https://pypi.tuna.tsinghua.edu.cn/simple \n```\n\u7531\u4e8eenvtext\u5e93\u4f9d\u8d56\u4e8etransformers\u548cpytorch\uff0c\u6545\u5b89\u88c5\u65f6\u95f4\u6bd4\u8f83\u957f\uff0c\u5efa\u8bae\u7b49\u5f85\u65f6\u559d\u4e00\u676f\u5496\u5561:coffee:\u3002\n\n\n### 2. \u63a8\u7406\n\n\u76ee\u524d\u652f\u6301\u7684\u6a21\u578b\u6709\uff1a\n\n| \u4efb\u52a1\u540d\u79f0 | Bert\u6a21\u578b | RNNs\u6a21\u578b | \u5176\u4ed6\u6a21\u578b |\n| ------ | ------ | ------ | ------ |\n| \u5b8c\u578b\u586b\u7a7a | BertMLM  |  ------  |  ------  |\n|  \u5206\u7c7b   | BertCLS  |  RNNCLS  |  ------  |\n| \u60c5\u611f\u5206\u6790\uff08\u56de\u5f52\uff09 | BertSA  |  RNNSA  |  ------  |\n|  \u591a\u9009   |BertMultiChoice | RNNMultiChoice | ----- |\n| \u5b9e\u4f53\u8bc6\u522b | BertNER  | RNNNER  | -----    |\n| \u8bcd\u5411\u91cf  |  -----  |  -----   | Word2Vec |\n\n\u9664\u6587\u672c\u751f\u6210\u4efb\u52a1\u5916\uff0c\u57fa\u672c\u652f\u6301\u7edd\u5927\u90e8\u5206NLP\u4efb\u52a1\u3002\n\nBert \u652f\u6301\u73af\u5883\u9886\u57df\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b`envBert`\uff0c\u4e5f\u652f\u6301\u5176\u4ed6huggingface transformer\u7684Bert\u6a21\u578b\u3002\n\nRNNs\u6a21\u578b\u5305\u62ec`LSTM`,`GRU`,`RNN`\u4e09\u79cd\uff0c\u53ef\u4ee5\u9009\u62e9\u4f7f\u7528\u73af\u5883\u9886\u57df\u9884\u8bad\u7ec3\u7684\u8bcd\u5411\u91cf\u521d\u59cb\u5316\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528Onehot\u7f16\u7801\u521d\u59cb\u5316\u3002\n\n\n#### 2.1 \u4f7f\u7528Bert\n\n\u7531\u4e8ebert\u6a21\u578b\u8f83\u5927\uff0c\u5efa\u8bae\u4ecehuggingface transformer\u4e0a\u9884\u5148\u4e0b\u8f7d\u6a21\u578b\u6743\u91cd\uff0c\n\u6216\u8005\u4ece\u6211\u4eec\u63d0\u4f9b\u7684\u767e\u5ea6\u7f51\u76d8\u94fe\u63a5\u4e0a\u4e0b\u8f7d\u6743\u91cd\uff0c\u4fdd\u5b58\u5230\u672c\u5730\uff0c\u65b9\u4fbf\u4f7f\u7528\u3002\n\n\u767e\u5ea6\u7f51\u76d8\u94fe\u63a5\uff1a  \n\u94fe\u63a5\uff1a[\u767e\u5ea6\u7f51\u76d8 envBert \u6a21\u578b](https://pan.baidu.com/s/1KNE5JnUoulLgVK9yW5WtAw)\n\u63d0\u53d6\u7801\uff1alfwm \n\n```python\n#\u5bfc\u5165\u5b8c\u5f62\u586b\u7a7a\u6a21\u578b(masked language model)\nfrom envtext.models import BertMLM\nmodel = BertMLM('celtics1863/env-bert-chinese')\n\n#\u8fdb\u884c\u9884\u6d4b\nmodel('[MASK][MASK][MASK][MASK]\u662f\u5404\u56fd\u653f\u5e9c\u90fd\u5173\u5fc3\u7684\u8bdd\u9898')\n\n\n#\u5bfc\u51fa\u7ed3\u679c\nmodel.save_result('result.csv')\n```\n#### 2.2 \u4f7f\u7528RNN\n\n```python\nfrom envtext.models import RNNCLS\n\nmodel = RNNCLS('\u672c\u5730pytorch_model.bin\u6240\u5728\u6587\u4ef6\u5939')\n\n#\u8fdb\u884c\u9884\u6d4b\nmodel('\u6c14\u5019\u53d8\u5316\u662f\u5404\u56fd\u653f\u5e9c\u90fd\u5173\u5fc3\u7684\u8bdd\u9898')\n\n#\u5bfc\u51fa\u7ed3\u679c\nmodel.save_result('result.csv')\n```\n\n#### 2.3 \u4f7f\u7528word2vec\n\nenvtext\u81ea\u5e26\u957f\u5ea6\u4e3a64\u7684\u9884\u8bad\u7ec3\u8bcd\u5411\u91cf\u3002\n```python\nfrom envtext.models import load_word2vec\n\nmodel = load_word2vec()\n\nmodel.most_similar('\u73af\u5883\u4fdd\u62a4')\n```\n\n### 3. \u8bad\u7ec3\n\n\n```python\n#\u5bfc\u5165\u5206\u7c7b\u6a21\u578b(classification)\nfrom envtext.models import BertCLS\nmodel = BertCLS('celtics1863/env-bert-chinese')\n\nmodel.load_dataset('\u6570\u636e\u96c6\u4f4d\u7f6e',task = 'cls',format = '\u6570\u636e\u96c6\u683c\u5f0f')\n\n#\u6a21\u578b\u8bad\u7ec3\nmodel.train()\n\n\n#\u6a21\u578b\u4fdd\u5b58\nmodel.save_model('classification') #\u8f93\u5165\u5f85\u4fdd\u5b58\u7684\u6587\u4ef6\u5939\n```\n\n\u6216\u8005\uff1a\n\n```python\n#\u5bfc\u5165\u5206\u7c7b\u6a21\u578b(classification)\nfrom envtext.models import BertCLS\nfrom envtext.data.utils import load_dataset\n\ndatasets,config = load_dataset('\u6570\u636e\u96c6\u4f4d\u7f6e',task = 'cls',format = '\u6570\u636e\u96c6\u683c\u5f0f')\nmodel = BertCLS('celtics1863/env-bert-chinese',config)\n\n#\u6a21\u578b\u8bad\u7ec3\nmodel.train(datasets)\n\n#\u6a21\u578b\u4fdd\u5b58\nmodel.save_model('classification') #\u8f93\u5165\u5f85\u4fdd\u5b58\u7684\u6587\u4ef6\u5939\n```\n\n### 4. \u81ea\u5b9a\u4e49\u6a21\u578b\n\n##### 4.1 \u81ea\u5b9a\u4e49Bert\u6a21\u578b\n\u9996\u5148\u81ea\u5b9a\u4e49\u4e00\u4e2a\u56de\u5f52\u4efb\u52a1\u7684Bert\u6a21\u578b\n```python\nfrom envtext.models.bert_base import BertBase\nimport torch\nfrom transformers import BertPreTrainedModel,BertModel\n\nclass MyBert(BertPreTrainedModel):\n    def __init__(self, config):\n        super(MyBert, self).__init__(config)\n        self.bert = BertModel(config) #bert\u6a21\u578b\n        self.regressor = torch.nn.Linear(config.hidden_size, 1) #\u56de\u5f52\u5668\n        self.loss = torch.nn.MSELoss() #\u635f\u5931\u51fd\u6570\n        \n    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,\n              position_ids=None, inputs_embeds=None, head_mask=None):\n        outputs = self.bert(input_ids,\n                            attention_mask=attention_mask,\n                            token_type_ids=token_type_ids,\n                            position_ids=position_ids,\n                            head_mask=head_mask,\n                            inputs_embeds=inputs_embeds)\n        #\u4f7f\u7528[CLS] token\n        cls_output = outputs[0][:,0,:] \n\n        # \u5f97\u5230\u5224\u522b\u503c\n        logits = self.regressor(cls_output)\n\n        outputs = (logits,)\n        \n        #\u8fd9\u91cc\u9700\u8981\u4e0ebert\u7684\u63a5\u53e3\u4fdd\u6301\u4e00\u81f4\uff0c\u5728\u6709labels\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd4\u56de(loss,logits)\uff0c\u5426\u5219\u8fd4\u56de(logits,)\n        if labels is not None: \n            loss = self.loss(logits.squeeze(),labels)\n            outputs = (loss,) + outputs\n        return outputs\n\n```\n\u5c06\u6a21\u578b\u4e0eenvtext\u7684\u63a5\u53e3\u5bf9\u63a5\n\n```python\nclass MyBertModel(BertBase):\n    #\u91cd\u5199\u521d\u59cb\u5316\u51fd\u6570\n    def initialize_bert(self,path = None,config = None,**kwargs):\n        super().initialize_bert(path,config,**kwargs)\n        self.model = MyBert.from_pretrained(self.model_path)\n\n    #\u91cd\u5199\u9884\u6d4b\u51fd\u6570\n    def predict_per_sentence(self,text, print_result = True ,save_result = True):\n        tokens=self.tokenizer.encode(text, return_tensors='pt',add_special_tokens=True).to(self.model.device) #\u83b7\u5f97token\n        logits = self.model(tokens)[0] #\u83b7\u5f97logits\n        \n        if print_result:\n            #\u6253\u5370\u7ed3\u679c\n            print(logits[0].clone().detach().cpu())\n        \n        if save_result:\n            #\u4fdd\u5b58\u7ed3\u679c\n            self.result[text] = logits[0].clone().detach().cpu()\n            \n     #[Optional] \u53ef\u9009 \u91cd\u65b0\u8ba1\u7b97\u5224\u522b\u503c\u51fd\u6570\uff0c\u7528\u4e8e\u8bad\u7ec3\u65f6\u63d0\u4f9b\u9664loss\u5916\u7684metrics\u4fe1\u606f\n     def compute_metrics(eval_pred)\n         from envtext.utils.metrics import metrics_for_reg\n         return metrics_for_reg(eval_pred)\n     \n     #[Optional] \u53ef\u9009 \u7528\u4e8e\u5bf9\u9f50config\u4e2d\u7684\u53c2\u6570\uff0c\n     #\u56e0\u4e3a\u6709\u7684\u65f6\u5019\u9700\u8981\u63a5\u53d7\u591a\u79cd\u53c2\u6570\u7684\u8f93\u5165\uff0c\u4f8b\u5982\u5206\u7c7b\u4efb\u52a1\u65f6\u53ef\u4ee5\u63a5\u53d7\u7c7b\u522b\u6570\u91cf\uff0c\u4e5f\u53ef\u4ee5\u63a5\u53d7\u7c7b\u522b\u7684\u5217\u8868\uff0c\u8fd9\u65f6\u5019\u53ef\u4ee5\u901a\u8fc7\u8fd9\u4e2a\u63a5\u53e3\u5bf9\u9f50\u3002\n     def align_config(self):\n         super().align_config()\n         ##\u53ef\u4ee5\u4f7f\u7528self.update_config() \u6216 self.set_attribute() \u63a5\u53e3\u91cd\u65b0\u8bbe\u7f6econfig\n         pass\n```\n\n##### 4.1 \u81ea\u5b9a\u4e49RNN\u6a21\u578b\n\n\u5b9a\u4e49RNN\u6a21\u578b\u4e5f\u662f\u7c7b\u4f3c\u7684\u3002  \n\u5148\u5b9e\u73b0\u4e00\u4e2aLSTM\u5206\u7c7b\u6a21\u578b\u5982\u4e0b\uff1a\n\n```python\nfrom torch import nn\nimport torch\nclass MyRNN(nn.Module):\n    def __init__(self,config):\n        self.rnn = nn.LSTM(config.embed_size, config.hidden_size ,config.num_layers,batch_first = True)\n        self.classifier = nn.Linear(config.hidden_size,config.num_labels)\n    \n    def forward(self,X,labels = None):\n        X,_ = self.rnn(X)\n        logits = self.classifier(X)\n        \n        #\u5bf9\u9f50\u63a5\u53e3\uff0c\u4ecd\u7136\u9700\u8981\u5728labels\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u8f93\u51fa(loss,logits)\uff0c\u4e0d\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u8f93\u51fa(logits,)\n        if labels is not None:\n            loss = self.loss_fn(logits,labels)\n            return (loss,logits) \n        return (logits,)\n```\n\n\u518d\u5c06\u6a21\u578b\u4e0eenvtext\u63a5\u53e3\u5bf9\u63a5\uff0c\n```python\nclass MyRNNModel(BertBase):\n    #\u91cd\u5199\u521d\u59cb\u5316\u51fd\u6570\n    def initialize_bert(self,path = None,config = None,**kwargs):\n        super().initialize_bert(path,config,**kwargs) #\u4fdd\u6301\u4e0d\u53d8\n        self.model = MyRNN.from_pretrained(self.model_path) \n\n    #\u91cd\u5199\u9884\u6d4b\u51fd\u6570\n    def predict_per_sentence(self,text, print_result = True ,save_result = True):\n        tokens=self.tokenizer.encode(text, return_tensors='pt').to(self.model.device) #\u83b7\u5f97token\n        logits = self.model(tokens)[0] #\u83b7\u5f97logits\n        preds,probs = torch.argmax(logits,dim = -1) #\u83b7\u5f97\u9884\u6d4b\u7ed3\u679c\n        \n        if print_result:\n            #\u6253\u5370\u7ed3\u679c\n            print(preds.clone().detach().cpu().numpy())\n        \n        if save_result:\n            #\u4fdd\u5b58\u7ed3\u679c\n            self.result[text] = preds.clone().detach().cpu().numpy().tolist()\n            \n    #[Optional] \u53ef\u9009 \u91cd\u5199metrics\uff0c\u589e\u52a0loss\u4ee5\u5916\u7684metric\n    def compute_metrics(eval_pred):\n        return {} #\u8fd4\u56de\u4e00\u4e2adict\n        \n    #[Optional] \u53ef\u9009 \u91cd\u5199align_config\uff0c\u5bf9\u9f50config\u53c2\u6570\n    def align_config(self):\n        super().align_config()\n        pass\n```\n\n\u66f4\u8be6\u7ec6\u7684\u6559\u7a0b\uff0c\u8bf7\u53c2\u89c1\u6211\u4eec\u7684\u6848\u4f8b [jupyter notebooks]('jupyter_notebooks')\n\n\n# LISENCE\nApache Lisence\n\n\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/celtics1863/envtext",
            "keywords": "NLP,bert,Chinese,LSTM,RNN,domain text analysis",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "envtext",
            "package_url": "https://pypi.org/project/envtext/",
            "platform": "",
            "project_url": "https://pypi.org/project/envtext/",
            "project_urls": {
                "Bug Tracker": "https://github.com/celtics1863/envtext/issues",
                "Homepage": "https://github.com/celtics1863/envtext"
            },
            "release_url": "https://pypi.org/project/envtext/0.0.8/",
            "requires_dist": [
                "jieba",
                "datasets",
                "gensim",
                "tqdm",
                "numpy",
                "pytorch-crf",
                "pandas",
                "torch",
                "transformers"
            ],
            "requires_python": ">=3.6",
            "summary": "envtext for Chinese texts analysis in Environment domain",
            "version": "0.0.8",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 12960951,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7ab2041c9a1069089a15789c5a2f62ed",
                    "sha256": "638f211927979bca1662d159c69dda8c636a618149083c1d27d25415eba5e127"
                },
                "downloads": -1,
                "filename": "envtext-0.0.8-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7ab2041c9a1069089a15789c5a2f62ed",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 35532635,
                "upload_time": "2022-02-19T01:00:23",
                "upload_time_iso_8601": "2022-02-19T01:00:23.785899Z",
                "url": "https://files.pythonhosted.org/packages/56/18/10d4bf20ec3bef0ed15f5af8de326aa4197220ce9277da3c9289f5eee60d/envtext-0.0.8-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "20fd7843d4702c3d5bfe7279d884e3e1",
                    "sha256": "6461548195df238f6c45ec17bd35e660001b8f9a79f2d51746fee08ced0f2859"
                },
                "downloads": -1,
                "filename": "envtext-0.0.8.tar.gz",
                "has_sig": false,
                "md5_digest": "20fd7843d4702c3d5bfe7279d884e3e1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 35487919,
                "upload_time": "2022-02-19T01:01:53",
                "upload_time_iso_8601": "2022-02-19T01:01:53.424943Z",
                "url": "https://files.pythonhosted.org/packages/7c/4e/7a6ac6a2d13b4444d3265dd5e75c1e5776e6c0ff9c477705522334d7d919/envtext-0.0.8.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
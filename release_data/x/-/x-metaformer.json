{
    "0.1.6": {
        "info": {
            "author": "Robert M\u00fcller",
            "author_email": "robert.mueller1990@googlemail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 4 - Beta",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description": "# x - Metaformer\n### \ud83d\udea7 Repo is under active development ...\nA PyTorch implementation of [\"MetaFormer Baselines\"](https://arxiv.org/abs/2210.13452) with optional extensions.\n\n## Setup\nSimply run:\n```pip install x-metaformer```\n\n## Example\n```py\nimport torch\nfrom x_metaformer import CAFormer, ConvFormer\n\n\nmy_metaformer = CAFormer(\n    in_channels=3,\n    depths=(3, 3, 9, 3),\n    dims=(64, 128, 320, 512),\n    init_kernel_size=3,\n    init_stride=2,\n    drop_path_rate=0.5,\n    norm='ln',  # ln, bn or rms (layernorm, batchnorm or rmsnorm)\n    use_pos_emb=True,  # use 2d sinusodial positional embeddings\n    head_dim=32,\n    num_heads=4,\n    attn_dropout=0.1,\n    proj_dropout=0.1,\n    scale_value=1.0, # scale attention logits by this value\n    trainable_scale=False, # if scale can be trained\n    num_mem_vecs=0, # additional memory vectors (in the attention layers)\n    sparse_topk=0,  # sparsify - keep only top k values (in the attention layers)\n    l2=False,   # l2 norm on tokens (in the attention layers) \n    improve_locality=False,  # remove attention on own token\n    use_starreglu=False  # use gated StarReLU\n)\n\nx   = torch.randn(64, 3, 64, 64)  # B C H W\nout = my_metaformer(x, return_embeddings=False)  # returns average pooled tokens\n```\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/romue404/x-metaformer",
            "keywords": "artificial intelligence,pytorch,metaformer,transformer,attention,convolutions",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "x-Metaformer",
            "package_url": "https://pypi.org/project/x-Metaformer/",
            "platform": null,
            "project_url": "https://pypi.org/project/x-Metaformer/",
            "project_urls": {
                "Homepage": "https://github.com/romue404/x-metaformer"
            },
            "release_url": "https://pypi.org/project/x-Metaformer/0.1.6/",
            "requires_dist": [
                "torch (>=1.6)",
                "numpy"
            ],
            "requires_python": "",
            "summary": "A PyTorch implementation of \"MetaFormer Baselines\" with optional extensions.",
            "version": "0.1.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16034767,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d003b03e25f79fc83660273e432e14a1",
                    "sha256": "ea07a05bbfcb7a435d93027088060ed95b6bebf966cdd1a35748a2b34e751c13"
                },
                "downloads": -1,
                "filename": "x_Metaformer-0.1.6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d003b03e25f79fc83660273e432e14a1",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 10408,
                "upload_time": "2022-12-08T12:57:13",
                "upload_time_iso_8601": "2022-12-08T12:57:13.785444Z",
                "url": "https://files.pythonhosted.org/packages/92/24/8ed89fe2bf56f601d5eb51ec6718f6a7081cef6f191e4cac0e87f5733d8a/x_Metaformer-0.1.6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "6ed021f596a18066a7afd7375a5cb0b4",
                    "sha256": "dd9548ff23da83f189d7edf8f84b649f899beba48a1cc2d54c5e1dac6634ad00"
                },
                "downloads": -1,
                "filename": "x-Metaformer-0.1.6.tar.gz",
                "has_sig": false,
                "md5_digest": "6ed021f596a18066a7afd7375a5cb0b4",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 7943,
                "upload_time": "2022-12-08T12:57:15",
                "upload_time_iso_8601": "2022-12-08T12:57:15.387644Z",
                "url": "https://files.pythonhosted.org/packages/1f/1b/2f6858842b8a7534a42eed54a074bab8971128d133a4183ec3978d51a1f6/x-Metaformer-0.1.6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
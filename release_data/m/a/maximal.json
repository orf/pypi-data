{
    "0.3": {
        "info": {
            "author": "Ivan Bongiorni",
            "author_email": "ivanbongiorni@protonmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 4 - Beta",
                "Intended Audience :: Developers",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Topic :: Scientific/Engineering"
            ],
            "description": "# maximal\n\nCurrent version: **0.3.0 (Beta)**\n\nA TensorFlow-compatible Python library that provides models and layers to implement custom Transformer neural networks.\n\nBuilt on TensorFlow 2.\n\n<br>\n\n# Installation\nIts installation is straightforward:\n\n```\npip install maximal\n```\n\n<br>\n\n# How to use it?\n`maximal` is commonly called as:\n\n```\nimport maximal as max\n```\n\n<br>\n\n# Documentation\nAn official [documentation website] with explanations and tutorials is on the way.\n\n<br>\n\n# Elements\n\nIn `layers.py`:\n- `SelfAttention`: `keras.Layer`, computes *Scaled Dot-Product Attention*.\n\n- `MultiHeadSelfAttention`: `keras.Layer`, it is a concatenation of `SelfAttention` layers, resized back to original input shape through linear transformation.\n\n- `PositionalEmbedding`: `keras.Layer`, implements double Embedding layers used in Transformers literature, for tokens and positions. Positional encoding is learned through a `tf.keras.layers.Embedding()` layer, instead of deterministic positional encoding in the original paper.\n\n- `TransformerLayer`: `keras.Layer` single Transformer Encoder piece. It can be used inside any `Sequential()` model in Keras.\n\nIn `schedules.py`:\n- `OriginalTransformerSchedule`: `keras.Layer` implements the learning rate schedule of the original Transformer paper. It is taken from this [official TensorFlow tutorial](https://www.tensorflow.org/text/tutorials/transformer).\n\n<br>\n\n# Requirements\n```\nnumpy\ntensorflow >= 2.0\n```\n\n<br>\n\n# Author\nIvan Bongiorni. [LinkedIn](https://www.linkedin.com/in/ivan-bongiorni-b8a583164/)\n\n<br>\n\n# License\n2020 Ivan Bongiorni\n\nThis repository is licensed under the MIT license. See [LICENCE.txt]() for further details.",
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/IvanBongiorni/maximal",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "maximal",
            "package_url": "https://pypi.org/project/maximal/",
            "platform": null,
            "project_url": "https://pypi.org/project/maximal/",
            "project_urls": {
                "Homepage": "https://github.com/IvanBongiorni/maximal"
            },
            "release_url": "https://pypi.org/project/maximal/0.3/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "TensorFlow-compatible Transformer layers and models.",
            "version": "0.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15183318,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1414b333e37b7817b1dba25fcaea853f",
                    "sha256": "2a52ce95ad98eb0197d7988b3c503ba0cf35dd9569e09773a04b043c112636a3"
                },
                "downloads": -1,
                "filename": "maximal-0.3.tar.gz",
                "has_sig": false,
                "md5_digest": "1414b333e37b7817b1dba25fcaea853f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 4572,
                "upload_time": "2022-09-22T20:31:53",
                "upload_time_iso_8601": "2022-09-22T20:31:53.677482Z",
                "url": "https://files.pythonhosted.org/packages/31/8b/3a55ba1ab8000b7d446999a4267f6e66af85d1efc7edb4560d4eab281120/maximal-0.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
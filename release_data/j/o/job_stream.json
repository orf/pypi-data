{
    "0.1": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "fc481b4e146a17ec507d32f0c4589fb9",
                    "sha256": "f188dcfd843df94823ef1a96db9f4aef92729830b55a9502cd1f5493f66d2279"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "fc481b4e146a17ec507d32f0c4589fb9",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 41092,
                "upload_time": "2014-12-22T21:29:29",
                "upload_time_iso_8601": "2014-12-22T21:29:29.162924Z",
                "url": "https://files.pythonhosted.org/packages/ee/38/c4c0b32be4408e5ff87556b416514f06844b0519ad845516282b8b5ca9b9/job_stream-0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.1/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7a74b028dcfe23a59526f982b8ecf0d0",
                    "sha256": "510171a93f94d93505aaa6452b05697feb0d211e2e467f4f0302138498722967"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "7a74b028dcfe23a59526f982b8ecf0d0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 98603,
                "upload_time": "2014-12-22T22:33:13",
                "upload_time_iso_8601": "2014-12-22T22:33:13.358340Z",
                "url": "https://files.pythonhosted.org/packages/8f/ac/605e5cf063f51b7a204260093b9d70a542da0ffd67c5ae3cf8d6ae0f53db/job_stream-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.10": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.10/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.10",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "0d5a7db3651373dd08120c568f5ffba1",
                    "sha256": "9a0a0e0744c3cd33c834c4c8618d275afb79da2b46f6cd946a91eb7bb83708b2"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.10.tar.gz",
                "has_sig": false,
                "md5_digest": "0d5a7db3651373dd08120c568f5ffba1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 434094,
                "upload_time": "2016-06-15T21:04:11",
                "upload_time_iso_8601": "2016-06-15T21:04:11.818494Z",
                "url": "https://files.pythonhosted.org/packages/11/6b/243ca67eb149496c969ab47f92f143c127d018c4a5cc2f2b960a216b30ed/job_stream-0.1.10.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.11": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.11/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.11",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "8c4e35219d26366e516e913c07a15f8d",
                    "sha256": "39daf8aabea77f36e36bce3013d62f1ca9d8197814c8fd787b6ba837857de370"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.11.tar.gz",
                "has_sig": false,
                "md5_digest": "8c4e35219d26366e516e913c07a15f8d",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 433781,
                "upload_time": "2016-06-22T16:17:42",
                "upload_time_iso_8601": "2016-06-22T16:17:42.165519Z",
                "url": "https://files.pythonhosted.org/packages/75/fd/005df2705a064dec560305443ec872ef7b9006a6867cadd1d49a32f94ba7/job_stream-0.1.11.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.12": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.12/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.12",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7c5ce443be4d9b2708ede492b4481e67",
                    "sha256": "943812f94163b154324c1e45a609235f22cebf59cf78700781aa7612a58b590b"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.12.tar.gz",
                "has_sig": false,
                "md5_digest": "7c5ce443be4d9b2708ede492b4481e67",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 434450,
                "upload_time": "2016-06-23T22:25:25",
                "upload_time_iso_8601": "2016-06-23T22:25:25.493555Z",
                "url": "https://files.pythonhosted.org/packages/4e/d1/b6e533ce8c7a219ae9afc65e1ec40ee837380ba85948cbbffab47fc9181f/job_stream-0.1.12.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.13": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.13/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.13",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3c6222e269d97ee2fb4de4e2ee24f5bd",
                    "sha256": "322152e988b08fd37c0803d125536201f86f13cd84928ac5bb373d1c2dd99a83"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.13.tar.gz",
                "has_sig": false,
                "md5_digest": "3c6222e269d97ee2fb4de4e2ee24f5bd",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 436045,
                "upload_time": "2016-06-24T22:13:33",
                "upload_time_iso_8601": "2016-06-24T22:13:33.408115Z",
                "url": "https://files.pythonhosted.org/packages/86/6b/45b8430a05d18a04f8714499f9ffef9ec527678f4ab1492e4033e78bd790/job_stream-0.1.13.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.14": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.14/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.14",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e98209fbac21f2a3d3ad830054458e8c",
                    "sha256": "58cae9fc3f6235b0c71992acaee812dd5e9c7ca2e4898199da308678462fec72"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.14.tar.gz",
                "has_sig": false,
                "md5_digest": "e98209fbac21f2a3d3ad830054458e8c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 436428,
                "upload_time": "2016-06-27T16:16:26",
                "upload_time_iso_8601": "2016-06-27T16:16:26.672026Z",
                "url": "https://files.pythonhosted.org/packages/e9/44/5fae629c1a11fbe6ddae32a02d3cd1938ac5f0d553e557ed8f621c749c6a/job_stream-0.1.14.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.15": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.15/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.15",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6a88d3f7a97e56b63d6251957c58459d",
                    "sha256": "5dd6c9bf617628519d56535a7b60d5de8eb2d09be00d18305b42f9cd01e5e94c"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.15.tar.gz",
                "has_sig": false,
                "md5_digest": "6a88d3f7a97e56b63d6251957c58459d",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 442857,
                "upload_time": "2016-06-28T23:42:29",
                "upload_time_iso_8601": "2016-06-28T23:42:29.509644Z",
                "url": "https://files.pythonhosted.org/packages/c8/74/a398300f7e5d178d3de069187f3a5be5a8f7d5c640b44367c6a892e22912/job_stream-0.1.15.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.16": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.16/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.16",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b1ab13671a56885e3f33c4fcfef06558",
                    "sha256": "a957dae54ed50f32db452688c32fb575ada0977a2691448a00a8aee4a722baca"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.16.tar.gz",
                "has_sig": false,
                "md5_digest": "b1ab13671a56885e3f33c4fcfef06558",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 439976,
                "upload_time": "2016-06-29T00:06:51",
                "upload_time_iso_8601": "2016-06-29T00:06:51.880741Z",
                "url": "https://files.pythonhosted.org/packages/e0/db/07bc2cbfa0b830012021d97a48aaa68de5146c21976e4e6e6f9e69f72667/job_stream-0.1.16.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.17": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.17/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.17",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e30c613e5fbe0cc0e15927d248719065",
                    "sha256": "abd7a804a2c2b3e109407cd68f24e189620229b596aa5f9079a147c132b9b719"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.17.tar.gz",
                "has_sig": false,
                "md5_digest": "e30c613e5fbe0cc0e15927d248719065",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 440780,
                "upload_time": "2016-06-29T00:16:43",
                "upload_time_iso_8601": "2016-06-29T00:16:43.271829Z",
                "url": "https://files.pythonhosted.org/packages/c3/eb/b4f7502bbaecb8ccf01e3c91bad88d7c525396578e271b8572236e3b3177/job_stream-0.1.17.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.18": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.18/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.18",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "25f3bf060a35e37a7d8dd198a125214f",
                    "sha256": "688610cdec5fd8824aeb01dc1912872a1706bf07d130e4fd542b6630691b744b"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.18.tar.gz",
                "has_sig": false,
                "md5_digest": "25f3bf060a35e37a7d8dd198a125214f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 443337,
                "upload_time": "2016-07-05T18:40:18",
                "upload_time_iso_8601": "2016-07-05T18:40:18.829423Z",
                "url": "https://files.pythonhosted.org/packages/c4/d7/e2c28e271c61ce87ab06f3f376639ea3ff3ebccee51f550248fee7bd26d2/job_stream-0.1.18.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.19": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.19/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.19",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b167f0de4c33062589a031d71dbd8119",
                    "sha256": "0448d8780168beb4fa85e1d71081e4ff0fe204957cc8131d3ca62ae2d05b1d7f"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.19.tar.gz",
                "has_sig": false,
                "md5_digest": "b167f0de4c33062589a031d71dbd8119",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 445780,
                "upload_time": "2016-07-07T16:48:19",
                "upload_time_iso_8601": "2016-07-07T16:48:19.698107Z",
                "url": "https://files.pythonhosted.org/packages/cb/47/be5932b2b35bca066d5fef7e09b3252e823a84d6b3cb1873f6ceb5c78d32/job_stream-0.1.19.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.2/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9745b1a170ae3f67b92b8f0a02fc6dfa",
                    "sha256": "ac1ea04fb4b37212390775d3461fab6e4fa5c3d376dee3e273cc589e85f385d3"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.2.tar.gz",
                "has_sig": false,
                "md5_digest": "9745b1a170ae3f67b92b8f0a02fc6dfa",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 100725,
                "upload_time": "2014-12-22T23:34:17",
                "upload_time_iso_8601": "2014-12-22T23:34:17.642629Z",
                "url": "https://files.pythonhosted.org/packages/ec/b4/8dc151f1a9473f9f25426fa01338d346ae9b177624a1cc7e737ee0ef647f/job_stream-0.1.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.20": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.20/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.20",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "883928a857b2dc3068febf7b3ede19aa",
                    "sha256": "dee6fede6db8ab10bee251fe87acff7587d3943f5cd4e40a5a4f371295c0a7b1"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.20.tar.gz",
                "has_sig": false,
                "md5_digest": "883928a857b2dc3068febf7b3ede19aa",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 451150,
                "upload_time": "2016-07-27T03:13:07",
                "upload_time_iso_8601": "2016-07-27T03:13:07.538597Z",
                "url": "https://files.pythonhosted.org/packages/26/a7/ff3fc71dccf3957b22c992c0c24d9811239e61adb1cda1eff6f20c2b7f3a/job_stream-0.1.20.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.21": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.21/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.21",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "136cdf0743f9c62a4e6a57cd78637afe",
                    "sha256": "2ad6c5dcf0dfe4dc1776502996c38f283668e472868084b56246c5972d9fec5f"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.21.tar.gz",
                "has_sig": false,
                "md5_digest": "136cdf0743f9c62a4e6a57cd78637afe",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 451257,
                "upload_time": "2016-07-27T08:41:06",
                "upload_time_iso_8601": "2016-07-27T08:41:06.821492Z",
                "url": "https://files.pythonhosted.org/packages/28/a8/2444ebf17a204425b754e99d7fdbf30d565f74dadbf83f397f631a47a4e9/job_stream-0.1.21.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.22": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.22/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.22",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "bfd3256cfe0bfca7a17cbfc94142ff4f",
                    "sha256": "4c93569bc7d01b884a2f20388f980095cc26b7c9d857eb7ee1d15fe07c1c9caa"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.22.tar.gz",
                "has_sig": false,
                "md5_digest": "bfd3256cfe0bfca7a17cbfc94142ff4f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 451671,
                "upload_time": "2016-07-27T20:00:08",
                "upload_time_iso_8601": "2016-07-27T20:00:08.300204Z",
                "url": "https://files.pythonhosted.org/packages/6d/bf/404012cbb1044879b3ee29b55938c500aacc010cba72d0ef414b21861820/job_stream-0.1.22.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.23": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.23/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.23",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "75f19004f5cbbcd666633777db9c1b58",
                    "sha256": "fddcc26552cb553fc72f5ce743892a2b06fe99ad25ac24f914393097f7375b53"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.23.tar.gz",
                "has_sig": false,
                "md5_digest": "75f19004f5cbbcd666633777db9c1b58",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 452498,
                "upload_time": "2016-07-28T17:36:18",
                "upload_time_iso_8601": "2016-07-28T17:36:18.948789Z",
                "url": "https://files.pythonhosted.org/packages/c8/ec/04c7ecdf1b0f1ab16fae954a89444c05786e67f3b851980d7f1d59c899a1/job_stream-0.1.23.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.24": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.24/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.24",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7f47e32cd5f46902440dfe9609772f1e",
                    "sha256": "59380ba60f7615bf383ecbcad15a4304621a9d16992fb38123bc0952ee5ce486"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.24.tar.gz",
                "has_sig": false,
                "md5_digest": "7f47e32cd5f46902440dfe9609772f1e",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 490130,
                "upload_time": "2016-08-08T21:58:11",
                "upload_time_iso_8601": "2016-08-08T21:58:11.866319Z",
                "url": "https://files.pythonhosted.org/packages/4a/9e/2eafb2c07fa60f5d60f9d675d666c59476a3cec85407ce919a25054f6d0c/job_stream-0.1.24.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.25": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.25/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.25",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9cefdfe3760607005598fee5509edd2f",
                    "sha256": "9c6a9795eb1fdda96f11431524586aa70eceb5a592b4300f5e8211446cdc1f76"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.25.tar.gz",
                "has_sig": false,
                "md5_digest": "9cefdfe3760607005598fee5509edd2f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 452821,
                "upload_time": "2016-10-11T17:51:22",
                "upload_time_iso_8601": "2016-10-11T17:51:22.171414Z",
                "url": "https://files.pythonhosted.org/packages/c3/a1/2fc1e1f52540f702264bceb56da27f370197471f806d3c6fb1c75ef3fea7/job_stream-0.1.25.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.26": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.26/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.26",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1ca4ddee2794ac1844e4181ccc49636a",
                    "sha256": "6df46681aac2012b5751f947a95a9fa5b0a658989ea2d816462e33535b486f1c"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.26.tar.gz",
                "has_sig": false,
                "md5_digest": "1ca4ddee2794ac1844e4181ccc49636a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 453607,
                "upload_time": "2016-10-12T21:39:24",
                "upload_time_iso_8601": "2016-10-12T21:39:24.861038Z",
                "url": "https://files.pythonhosted.org/packages/9d/16/7f9acac7a01c4dfc74853fc8e1515d308166686eb3e4de0f964f1fe69773/job_stream-0.1.26.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.27": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.27/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.27",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a4465ad746b26f52319f42dd7faaeb1f",
                    "sha256": "2a525bd1efdf3487c4428ca0771b08708375e8421eecc756878c9056613ed466"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.27.tar.gz",
                "has_sig": false,
                "md5_digest": "a4465ad746b26f52319f42dd7faaeb1f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 454442,
                "upload_time": "2016-10-18T23:04:17",
                "upload_time_iso_8601": "2016-10-18T23:04:17.171414Z",
                "url": "https://files.pythonhosted.org/packages/bc/9c/7617ea2b1a7a946d1304b1366a094299bd670163375edc8a92333bb82448/job_stream-0.1.27.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.28": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.28/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.28",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "26b9a59f3415501355941290e4e0ea7d",
                    "sha256": "3b64c0e395c55612fb16580bece8d9c14e4ea31363899eed658cd5a58b0bfdc0"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.28.tar.gz",
                "has_sig": false,
                "md5_digest": "26b9a59f3415501355941290e4e0ea7d",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 481317,
                "upload_time": "2016-10-20T21:18:15",
                "upload_time_iso_8601": "2016-10-20T21:18:15.390434Z",
                "url": "https://files.pythonhosted.org/packages/92/c2/58df60be36f40fbf4bc98d7dcd44fff1cab28552cfdf7e75161246988391/job_stream-0.1.28.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.29": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.29/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.29",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9f95ec3575b93cafc9223322bcc4d3ed",
                    "sha256": "37bc6d8a7c0e204245c37aec953be961f77c39c107ff0e8baed6824dcb8333ef"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.29.tar.gz",
                "has_sig": false,
                "md5_digest": "9f95ec3575b93cafc9223322bcc4d3ed",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 458337,
                "upload_time": "2016-10-27T17:53:27",
                "upload_time_iso_8601": "2016-10-27T17:53:27.558596Z",
                "url": "https://files.pythonhosted.org/packages/64/07/c74688bb709ebb64f976530fedd9e8c3b7372c75d656756aba808dfe1f2a/job_stream-0.1.29.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.3": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.3/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3863e794e14b74054979723f25fa5f8f",
                    "sha256": "03539308546808d25e7e4eef59f409d2b1cace5ecdcb46783d3cf3dc1731c1c5"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.3.tar.gz",
                "has_sig": false,
                "md5_digest": "3863e794e14b74054979723f25fa5f8f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 184407,
                "upload_time": "2014-12-23T20:54:04",
                "upload_time_iso_8601": "2014-12-23T20:54:04.449822Z",
                "url": "https://files.pythonhosted.org/packages/a4/31/95df02bc1f21da8164737fbe59141d98c0dd8c8470545858e5aeff91083f/job_stream-0.1.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.30": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.30/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.30",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "66ec02c318a2d57ffab6bad03960c2ec",
                    "sha256": "cdea7fa197ff070636f75859622828913032239c9eac7bcac927eb9adff6bb38"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.30.tar.gz",
                "has_sig": false,
                "md5_digest": "66ec02c318a2d57ffab6bad03960c2ec",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 414758,
                "upload_time": "2017-02-09T16:15:02",
                "upload_time_iso_8601": "2017-02-09T16:15:02.280745Z",
                "url": "https://files.pythonhosted.org/packages/4b/97/cea7797e08eaf18a388a88d018cd8b8298d6f56e2443480620828a687d85/job_stream-0.1.30.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.31": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.31/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.31",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a9f15b3241492e2c913ae95c08dc6b4c",
                    "sha256": "fb9f9b1bebc37d07d026621019523d12692ad7fab62626c2a219c15d7e0828ba"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.31.tar.gz",
                "has_sig": false,
                "md5_digest": "a9f15b3241492e2c913ae95c08dc6b4c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 414646,
                "upload_time": "2017-03-04T21:43:26",
                "upload_time_iso_8601": "2017-03-04T21:43:26.334841Z",
                "url": "https://files.pythonhosted.org/packages/9c/44/5b4ef7dc1e68c73e8bfd43a58b0e68598509ca463360dcf8e8dfba77deb0/job_stream-0.1.31.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.32": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.32/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.32",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b380c5108119e704f878afcb02ff473b",
                    "sha256": "a232a845e3fe624cc8bd5553cd3f647668d161ad68fef1e2ecbcfda9cffc847e"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.32.tar.gz",
                "has_sig": false,
                "md5_digest": "b380c5108119e704f878afcb02ff473b",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 385976,
                "upload_time": "2018-07-30T22:30:17",
                "upload_time_iso_8601": "2018-07-30T22:30:17.783368Z",
                "url": "https://files.pythonhosted.org/packages/13/fa/3b08ce53e7f6e054a160851cb38736f01377bb61c9d1707d1639ba7dee75/job_stream-0.1.32.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.4": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.4/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "dae011b4c8f61bc3853eed9c752a8b65",
                    "sha256": "ae32da4d5f0458905c904b402279e6a638b7c364edb85eaaf67fbd3238d35646"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.4.tar.gz",
                "has_sig": false,
                "md5_digest": "dae011b4c8f61bc3853eed9c752a8b65",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 192344,
                "upload_time": "2014-12-28T04:12:57",
                "upload_time_iso_8601": "2014-12-28T04:12:57.447450Z",
                "url": "https://files.pythonhosted.org/packages/e0/5f/f6f648e5f8ebbb7ab37cee244be516a55fc880ab62209e0b27b418a57fde/job_stream-0.1.4.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.5": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.5/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a76baa557232a979dbe6807b49c0f0d3",
                    "sha256": "fed2d684fd43ef10d6fd210c63bfc65af80fa933c2912f4897ec19956ec2491d"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.5.tar.gz",
                "has_sig": false,
                "md5_digest": "a76baa557232a979dbe6807b49c0f0d3",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 202826,
                "upload_time": "2015-01-29T20:17:12",
                "upload_time_iso_8601": "2015-01-29T20:17:12.667904Z",
                "url": "https://files.pythonhosted.org/packages/5f/2a/b88c8a7a1ff39cef458839edfa8ccceb78b2c23ceaf883c018eb54102a59/job_stream-0.1.5.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.6": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.6/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ca6da7634d057a96b5d371eb9d9e24b1",
                    "sha256": "0f37219230885f7ecc4b6bfa72c16d5fdf9099f75d3ede82cc1d79baa3138d81"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.6.tar.gz",
                "has_sig": false,
                "md5_digest": "ca6da7634d057a96b5d371eb9d9e24b1",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 208467,
                "upload_time": "2015-03-26T22:45:31",
                "upload_time_iso_8601": "2015-03-26T22:45:31.506356Z",
                "url": "https://files.pythonhosted.org/packages/10/4e/950ce39cd6d40465c59761c984900dc0a3d7184ade3dbc26da75e3eb7ff2/job_stream-0.1.6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.7": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.7/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.7",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "636c1a45312a49bc437a211bb4f5944a",
                    "sha256": "ee987a4d0852f436b818e7b8bcac11e4c16ede16498ece41ad222490137c2862"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.7.tar.gz",
                "has_sig": false,
                "md5_digest": "636c1a45312a49bc437a211bb4f5944a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 208499,
                "upload_time": "2016-05-27T17:56:47",
                "upload_time_iso_8601": "2016-05-27T17:56:47.525755Z",
                "url": "https://files.pythonhosted.org/packages/d1/c4/dc47991d03c7768f964328eed69262c3ee42f329e7106c99620b124e5b90/job_stream-0.1.7.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.8": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.8/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.8",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "8d48daff6cdf5dd7fd97793a01ef775b",
                    "sha256": "91a9eed87d797d32cee1212160e486f4a54a05562e33655237d204474e5d5d9d"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.8.tar.gz",
                "has_sig": false,
                "md5_digest": "8d48daff6cdf5dd7fd97793a01ef775b",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 237666,
                "upload_time": "2016-06-15T00:08:31",
                "upload_time_iso_8601": "2016-06-15T00:08:31.090144Z",
                "url": "https://files.pythonhosted.org/packages/3c/c0/6e77dcbe2ec208c82bd0803cbe32caa05b11368a6e62fda922df343badfd/job_stream-0.1.8.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.9": {
        "info": {
            "author": "Walt Woods",
            "author_email": "woodswalben@gmail.com",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "Job Stream\n==========\n\nContents:\n\n* [Introduction](#introduction)\n* [Requirements](#requirements)\n* [Building job_stream](#building-job_stream)\n    * [Building and Installing the Python Module](#building-and-installing-the-python-module)\n    * [Building the C++ Shared Library](#building-shared-library)\n    * [Build Paths](#build-paths)\n        * [Linux](#linux)\n* [Python](#python)\n    * [The Inline Module](#the-inline-module)\n        * [inline.Work](#inline-work)\n            * [inline.Work.init](#inline-work-init)\n            * [inline.Work.job](#inline-work-job)\n            * [inline.Work.finish](#inline-work-finish)\n            * [inline.Work.frame](#inline-work-frame)\n            * [inline.Work.reduce](#inline-work-reduce)\n            * [inline.Work.result](#inline-work-result)\n            * [inline.Work.run](#inline-work-run)\n        * [inline.Object](#inline-object)\n        * [inline.Multiple](#inline-multiple)\n    * [Running External Programs (job_stream.invoke)](#python-running-external-programs)\n    * [Executing Code on the main host only (job_stream.getRank)](#python-get-rank)\n    * [Recipes](#python-recipes)\n        * [map](#python-map)\n        * [for x in ...](#for-x-in)\n        * [Nested for i in x](#nested-for-i-in-x)\n        * [Aggregating outside of a for loop](#aggregating-outside-of-a-for-loop)\n        * [Aggregating multiple items outside of a for loop](#aggregating-multiple-items-outside-of-a-for-loop)\n* [C++ Basics](#c-basics)\n    * [Reducers and Frames](#reducers-and-frames)\n* [Words of Warning](#words-of-warning)\n* [Unfriendly Examples](#unfriendly-examples)\n* [Recent Changelog](#recent-changelog)\n* [Roadmap](#roadmap)\n* [Appendix](#appendix)\n    * [Running the Tests](#running-the-tests)\n    * [Running a job_stream C++ Application](#running-a-job_stream-application)\n    * [Running in Python](#running-in-python)\n\n##<a name=\"introduction\"></a>Introduction\n\njob_stream is a straightforward and effective way to implement distributed computations.  How straightforward?  Well, if we wanted to find all primes between 0 and 999:\n\n```python\n# Import the main Work object that makes using job_stream dead simple\nfrom job_stream.inline import Work\nimport math\n\n# Start by declaring work based on the list of numbers between 0 and 999 as a\n# piece of `Work`.  When the w object goes out of context, the job_stream will\n# get exectued\nwith Work(range(1000)) as w:\n    # For each of those numbers, execute this method to see if that number is prime\n    @w.job\n    def isPrime(x):\n        for i in range(2, int(math.sqrt(x)) + 1):\n            if x % i == 0:\n                return\n        print(x)\n```\n\n\nOr for more of a real-world example, if we wanted line counts for all of the files in a directory:\n\n```python\n# Import the inline library of job_stream (works for 99% of cases and produces code\n# that is easier to follow).  Object is a blank object, and Work is the workhorse of\n# the job_stream.inline library.\nfrom job_stream.inline import Object, Work\nimport os\nimport sys\npath = sys.argv[1] if len(sys.argv) > 1 else '.'\n\n# Start by defining our Work as the files in the given directory\nw = Work([ p for p in os.listdir(path)\n        if os.path.isfile(p) ])\n\n# For each file given, count the number of lines in the file and print\n@w.job\ndef countLines(filename):\n    count = len(list(open(filename)))\n    print(\"{}: {} lines\".format(filename, count))\n    return count\n\n# Join all of the prior line counts by summing them into an object's \"total\" attribute\n@w.reduce(store = lambda: Object(total = 0))\ndef sumDirectory(store, inputs, others):\n    for count in inputs:\n        store.total += count\n    for o in others:\n        store.total += o.total\n\n# Now that we have the total, print it\n@w.job\ndef printTotal(store):\n    print(\"======\")\n    print(\"Total: {} lines\".format(store.total))\n\n# Execute the job stream\nw.run()\n```\n\n\nPretty simple, right?  job_stream lets developers write their code in an imperative style, and does all the heavy lifting behind the scenes.  While there are a lot of task processing libraries out there, job_stream bends over backwards to make writing distributed processing tasks easy.  What all is in the box?\n\n* **Easy python interface** to keep coding in a way that you are comfortable\n* **Jobs and reducers** to implement common map/reduce idioms.  However, job_stream reducers also allow *recurrence*!\n* **Frames** as a more powerful, recurrent addition to map/reduce.  If the flow of your data depends on that data, for instance when running a calculation until the result fits a specified tolerance, frames are a powerful tool to get the job done.\n* **Automatic checkpointing** so that you don't lose all of your progress if a multi-day computations crashes on the second day\n* **Intelligent job distribution** including job stealing, so that overloaded machines receive less work than idle ones\n* **Execution Statistics** so that you know exactly how effectively your code parallelizes\n\n\n##<a name=\"requirements\"></a>Requirements\n\n* [boost](http://www.boost.org/) (filesystem, mpi, python, regex, serialization, system, thread)\n* mpi (perhaps [OpenMPI](http://www.open-mpi.org/))\n\nNote that job_stream also uses [yaml-cpp](https://code.google.com/p/yaml-cpp/),\nbut for convenience it is packaged with job_stream.\n\n\n##<a name=\"building-job-stream\"></a>Building job_stream\n\n###<a name=\"building-and-installing-the-python-module\"></a>Building and Installing the Python Module\n\nThe python module job\\_stream can be built and installed via:\n\n    pip install job_stream\n\nor locally:\n\n    python setup.py install\n\nIf using [Conda](https://www.continuum.io/downloads), then install boost first:\n\n    conda install boost\n    pip install job_stream\n\n*Note: If not using `conda`, you may need to specify custom include or library paths:*\n\n    CPLUS_INCLUDE_PATH=~/my/path/to/boost/ \\\n        LD_LIBRARY_PATH=~/my/path/to/boost/stage/lib/ \\\n        pip install job_stream\n\n*Different mpicxx: If you want to use an mpicxx other than your system's\ndefault, you may also specify MPICXX=... as an environment variable.*\n\n\n###<a name=\"building-shared-library\"></a>Building the C++ Shared Library\n\nCreate a build/ folder, cd into it, and run:\n\n    cmake .. && make -j8 test\n\n*Note: You may need to tell the compiler where boost's libraries or include\nfiles are located.  If they are not in the system's default paths, extra paths\nmay be specified with e.g. environment variables like this:*\n\n    CPLUS_INCLUDE_PATH=~/my/path/to/boost/ \\\n        LD_LIBRARY_PATH=~/my/path/to/boost/stage/lib/ \\\n        bash -c \"cmake .. && make -j8 test\"\n\n\n###<a name=\"build-paths\"></a>Build Paths\n\nSince job\\_stream uses some of the compiled boost libraries,\nknow your platform's mechanisms of amending default build and run paths:\n\n####<a name=\"linux\"></a>Linux\n\n* CPLUS_INCLUDE_PATH=... - Colon-delimited paths to include directories\n* LIBRARY_PATH=... - Colon-delimited paths to static libraries for linking only\n* LD_LIBRARY_PATH=... - Colon-delimited paths to shared libraries for linking\n  and running binaries\n\n\n##<a name=\"python\"></a>Python\n\n###<a name=\"the-inline-module\"></a>The Inline Module\n\nThe primary (user-friendly) way to use job_stream in python is via the inline\nmodule, which provides the objects `Work`, `Object`, and `Multiple`.  Usually,\nonly the `Work` object is required:\n\n```python\nfrom job_stream.inline import Work\n```\n\n####<a name=\"inline-work\"></a>inline.Work\n\nThe main element used by `job_stream.inline` is the `Work` object.  `Work`\nis initialized with a list (or generator).  Each element of this initial\nlist enters the system as a piece of work within the job stream.  \n\nSimilar to traditional imperative coding practices, `job_stream.inline` passes\nwork in the same direction as the source file.  In other words, if the system\nstarts with:\n\n```python\nw = Work([ 1, 2, 3 ])\n```\n\nThen the numbers 1, 2, and 3 will be distributed into the system.  Once work\nis in the system, we typically deal with them using decorated methods.  *The\nordering of the decorated methods matters!*  `job_stream.inline` is designed\nso that your work flows in the same direction as your code.  For instance,\nrunning:\n\n```python\nw = Work([ 1, 2 ])\n@w.job\ndef first(w):\n    print(\"a: {}\".format(w))\n    return w\n\n@w.job\ndef second(w):\n    print(\"b: {}\".format(w))\n    return w\n\nw.run()\n```\n\nwill always print \"a: ...\" before \"b: ...\" for any given piece of work that\nenters the system.  More can be learned about [`inline.Work.job`](#inline-work-job)\nin the corresponding section.\n\n> **Multiprocessing** - Python has the <a href=\"https://wiki.python.org/moin/GlobalInterpreterLock\">GIL</a>\n  in the default implementation, which typically limits pure-python code to a single thread.  To get around\n  this, the `job_stream` module by default uses multiprocessing for all jobs - that is,\n  your python code will run in parallel on all cores, in different processes.\n\n> If this behavior is not desired, particularly if your application loads a lot of data\n  in memory that you would rather not duplicate, passing useMultiprocessing = False to the\n  `Work()` object's initializer will force all job_stream activity to happen\n  within the original process:\n\n>     w = Work([ 1, 2 ], useMultiprocessing = False)\n\n#####<a name=\"inline-work-init\"></a>inline.Work.init\n\nIn practical systems, the initial work often might be generated by some\ninitial code.  If you distribute your code to multiple machines, then all\ncode outside of `Work`'s methods will be executed N times, where N\nis the number of machines that you run your script on.  For example, running:\n\n```python\nprint(\"Init!\")\nw = Work([ 1 ])\nw.run()\n```\n\non four machines, like this:\n\n    $ mpirun -host a,b,c,d python script.py\n    Init!\n    Init!\n    Init!\n    Init!\n\nwill print, \"Init!\", four times.  The work element, `1`, will be be constructed\nand put  into four different lists (one on each machine).  However, as a piece\nof work, `1` will only go into the system once.\n\nIf it is important that setup code only be run once, for instance if a results\nfile needs to be initialized, or some debug information is printed, then\nthe init function is useful.  For instance, the above code might be refactored\nas this:\n\n```python\nw = Work()\n@w.init\ndef generateWork():\n    print(\"Init!\")\n    return 1\nw.run()\n```\n\nNow, no matter how many machines the code is parallelized on, \"Init!\" will\nonly be printed once, and the initial work `1` is only generated on one\nmachine.  Since it is just an integer in this case, that's not so bad, but\nfor more complicated initial work it might make a difference.\n\nThe final work passed into the system will be the union of anything passed\nto `Work`'s initializer, and anything returned from an `@Work.init` decorated\nfunction.  Returning `None` from a function will result in no work being added.\nTo emit multiple pieces of work, look at the [`inline.Multiple`](#inline-multiple)\nobject.\n\n**Note:** `Work.init` is special in that it does not matter where in your\nsource code it appears.  Any functions declared with `Work.init` are *always*\nexecuted exactly one time, before any work is processed.\n\n\n#####<a name=\"inline-work-job\"></a>inline.Work.job\n\nA job is the main workhorse of `job_stream`.  It takes as input a single piece\nof work, processes it, and in turn emits zero or more pieces of work that flow\nto the next element of the pipeline.  For instance, to add one to a list of\nintegers:\n\n```python\nfrom job_stream.inline import Work\nw = Work([ 1, 2, 3 ])\n\n# Now that we have 1, 2, and 3 as pieces of work in the system, this next\n# function will be called once with each value (possibly in parallel).\n\n@w.job\ndef addOne(w):\n    return w + 1\n\n# addOne will have been called 3 times, and have emitted 3 more pieces of work\n# to the next element in the job stream.\n\nw.run()\n```\n\n**I/O Safety:** It is not safe to write external i/o (such as a file) within\na job.  This is because jobs have no parallelism guards - that is, two jobs\nexecuting concurrently might open and append to a file at the same time.  On\nsome filesystems, this results in e.g. two lines of a csv being combined into\na single, invalid line.  To work around this, see [`inline.Work.result`](#inline-work-result).\n\n\n#####<a name=\"inline-work-finish\"></a>inline.Work.finish\n\nDecorates a method that only runs on the main host, and only after all work has\nfinished.  Since MPI common code (outside of job_stream, that is) runs on all\nmachines, it is occasionally useful to run code only once to finish a\ncalculation.  For instance, maybe the final results should be pretty-printed\nthrough `pandas`:\n\n```python\nimport pandas\nfrom job_stream.inline import Work\nw = Work([ 1, 2, 3 ])\n@w.job\ndef addOne(w):\n    return w + 1\n\n@w.finish\ndef pandasPrintResults(results):\n    print(pandas.DataFrame(results))\n```\n\nNote that this function is similar to [inline.Work.result](#inline-work-result),\nbut less efficient as it requires keeping all results leaving the job stream in\nmemory.  On the other hand, `finish` has access to all results at once, unlike\n`result`.\n\n\n#####<a name=\"inline-work-frame\"></a>inline.Work.frame\n\nFrames (and their cousins Reducers) are the most complicated feature in\n`job_stream`.  A frame is appropriate if:\n\n* A while loop would be used in non-parallelizable code\n* Individual pieces of work need fan-out and fan-in\n\nFrames have three parts - an \"all outstanding work is finished\" handler, an\naggregator, and everything in between, which is used to process recurred work.\n\nFor example, suppose we want to sum all digits between 1 and our work, and\nreport the result.  The best way to design this type of system is with a Frame,\nimplemented in `inline` through `Work.frame` and `Work.frameEnd`.  The easiest\nway to think of these is as the two ends of a `while` loop - `frame` is\nevaluated as a termination condition, and is also evaluated before anything\nhappens.  `frameEnd` exists to aggregate logic from within the `while` loop\ninto something that `frame` can look at.\n\n```python\nfrom job_stream.inline import Work, Multiple\nw = Work([ 4, 5, 8 ])\n\n@w.frame\ndef sumThrough(store, first):\n    # Remember, this is called like the header of a while statement: once at\n    # the beginning, and each time our recurred work finishes.  Anything\n    # returned from this function will keep the loop running.\n    if not hasattr(store, 'value'):\n        # Store hasn't been initialized yet, meaning that this is the first\n        # evaluation\n        store.first = first\n        store.value = 0\n        return first\n\n    # If we reach here, we're done.  By not returning anything, job_stream knows\n    # to exit the loop (finish the reduction).  The default behavior of frame is\n    # to emit the store object itself, which is fine.\n\n# Anything between an @frame decorated function and @frameEnd will be executed\n# for anything returned by the @frame or @frameEnd functions.  We could have\n# returned multiple from @frame as well, but this is a little more fun\n\n@w.job\ndef countTo(w):\n    # Generate and emit as work all integers ranging from 1 to w, inclusive\n    return Multiple(range(1, w + 1))\n\n@w.frameEnd\ndef handleNext(store, next):\n    # next is any work that made it through the stream between @frame and\n    # @frameEnd.  In our case, it is one of the integers between 1 and our\n    # initial work.\n    store.value += next\n\n@w.result\ndef printMatchup(w):\n    print(\"{}: {}\".format(w.first, w.value))\n\nw.run()\n```\n\nRunning the above code will print:\n\n    $ python script.py\n    4: 10\n    8: 36\n    5: 15\n\nNote that the original work is out of order, but the sums line up.  This is\nbecause a frame starts a new reduction for each individual piece of work\nentering the `@frame` decorated function.\n\n#####<a name=\"inline-work-reduce\"></a>inline.Work.reduce\n\nTODO.  Almost always, programs won't need a reducer.  Frames and the\n`Work.result` decorator replace them.  However, if the aggregation of a\ncalculation is resource intensive, `Work.reduce` can help since it can be\ndistributed.\n\n\n#####<a name=\"inline-work-result\"></a>inline.Work.result\n\nSince jobs are not I/O safe, `job_stream.inline.Work` provides the `result`\ndecorator.  The `result` decorator must be the last element in your job stream,\nand decorates a function that takes as input a single piece of work.  The\ndecorated function will be called exactly once for each piece of work exiting\nthe stream, and is always handled on the main host.  \n\nFor example, here is some code that takes a few objects, increments their `b`\nmember, and dumps them to a csv:\n\n```python\nfrom job_stream.inline import Work\nw = Work([ { 'name': 'yodel', 'b': 1 }, { 'name': 'casper', 'b': 99 } ])\n\n@w.job\ndef addOne(w):\n    w['b'] += 1\n    return w\n\n# Note that @w.init is special, and can be declared immediately before the\n# output job, regardless of jobs before it.  It will always be executed first.\n@w.init\ndef makeCsv():\n    with open('out.csv', 'w') as f:\n        f.write(\"name,b\\n\")\n\n# @w.result is also special, as it is not allowed to be anywhere except for\n# the end of your job stream.  \n@w.result\ndef handleResult(w):\n    with open('out.csv', 'a') as f:\n        f.write(\"{},{}\\n\".format(w['name'], w['b']))\n\nw.run()\n```\n\nReturn values from `Work.result` are ignored.\n\n#####<a name=\"inline-work-run\"></a>inline.Work.run\n\nAfter all elements in the job stream are specified, calling `Work.run()` will\nexecute the stream.  If your stream takes a long time to execute, it might\nbe worth turning on checkpointing.  `run()` takes the following kwargs:\n\n* **checkpointFile** (string) The file path to save checkpoints at.  If\n  specified, checkpoints are enabled.  By default, a checkpoint\n  will be taken every 10 minutes (even with 20 machines, checkpoints typically\n  take around 10 seconds).\n* **checkpointInterval** (float) The number of seconds between the completion of\n  one checkpoint and the starting of the next.  Defaults to 600.\n* **checkpointSyncInterval** (float) Used for debugging only.  This\n  is the mandatory quiet period between the detection of all communication\n  ceasing and the actual checkpointing.\n\nTypically, `Work.run()` will return `None`.  However, if your stream has no\n`Work.result` decorated function, then on the primary host, `Work.run()` will\nreturn a list of work that left the system.  On other hosts, it will still\nreturn `None`.\n\n####<a name=\"inline-object\"></a>inline.Object\n\n`inline.Object` is just a basic object that can be used to store arbitrary\nattributes.  As a bonus, its constructor can take kwargs to set.  `Object` is\ntypically used with frames and reducers:\n\n```python\nfrom job_stream.inline import Work, Object\nw = Work([ 1 ])\n\n@w.frame(store = lambda: Object(init = False))\ndef handleFirst(store, obj):\n    if not store.init:\n        store.init = True\n        # ...\n\n# ...\n```\n\n####<a name=\"inline-multiple\"></a>inline.Multiple\n\nThe Zen of Python states that explicit is better than implicit.  Since lists or\nlist-like objects may be desired to float around a job stream, all of\n`job_stream.inline` assumes that return values are single pieces of work.  If\nthat is not the case, and a single job should emit multiple pieces of work,\nsimply wrap a collection with the `Multiple` object:\n\n```python\nfrom job_stream.inline import Work, Multiple\nw = Work([ 1 ])\n\n@w.job\ndef duplicate(w):\n    return Multiple([ w, w ])\n```\n\nNow, whatever work flows into `duplicate` will flow out of it with an extra\ncopy.\n\n\n###<a name=\"python-running-external-programs\"></a>Running External Programs (job_stream.invoke)\n\nIt is tricky to launch another binary from an MPI process.\nUse `job_stream.invoke()` instead of e.g. `subprocess.Popen` to work around\na lot of the issues caused by doing this.  Example usage:\n\n```python\nfrom job_stream import invoke\nout, err = invoke([ '/bin/echo', 'hi', 'there' ])\n# out == 'hi there\\n'\n# err == '' (contents of stderr)\n```\n\n`job_stream.invoke()` will raise a RuntimeError exception for any non-zero\nreturn value from the launched program.  If some errors are transient, and those\nerrors have a unique footprint in stderr, the strings specifying those errors\nmay be passed as kwarg `transientErrors`.  Example:\n\n```python\nfrom job_stream import invoke\nout, err = invoke([ '/bin/mkdir', 'test' ],\n        transientErrors = [ 'Device not ready' ])\n```\n\nmkdir will be run up to kwarg `maxRetries` times (default 20), retrying until\na non-zero result is given.\n\n###<a name=\"python-get-rank\"></a>Executing Code on the main host only (job_stream.getRank)\n\nWhen running `job_stream` code in a multi-machine environment, code will normally get executed multiple times.  For instance, running the following script via `mpirun -host a,b,c script.py`:\n\n```python\nprint(\"Hello, world!\")\n```\n\nwill print \"Hello, world!\" three different times, one on each host.  In part of a workflow, this may be circumvented via `inline.Work.init`.  However, this only properly handles initialization code.  If manual control over the execution of code across multiple machines is desired, `job_stream.getRank()` should be used as follows:\n\n```python\nimport job_stream\nif job_stream.getRank() == 0:\n    print(\"Hello, world!\")\n```\n\nThis configuration will only result in \"Hello, world!\" begin printed a single time.\n\n###<a name=\"python-recipes\"></a>Recipes\n\n####<a name=\"python-map\"></a>map\n\nIf you want to replace a python `map(func, sequence[, sequence, ...])` with\na parallelized version, `job_stream` provides `job_stream.map()` which has\nthe same syntax:\n\n```python\nfrom job_stream import map\naddOne = lambda w: w+1\nprint(map(addOne, [ 1, 2, 3 ]))\n# prints [2, 3, 4]\n```\n\n####<a name=\"for-x-in\"></a>for x in ...\n\nTo parallelize this:\n\n```python\nfor x in range(10):\n    print x\n```\n\nDo this:\n\n```python\nfrom job_stream.inline import Work\nw = Work(range(10))\n\n@w.job\ndef printer(x):\n    print x\n    # Any value returned (except for a list type) will be emitted from the job.\n    # A list type will be unwrapped (emit multiple)\n    return x\n\nw.run()\n```\n\n\n####<a name=\"nested-for-i-in-x\"></a>Nested for i in x\n\nTo parallelize this:\n\n```python\nfor x in range(10):\n    sum = 0\n    for i in range(x):\n        sum += i\n    print(\"{}: {}\".format(x, sum))\n```\n\nWrite this:\n\n```python\nfrom job_stream.inline import Work\nw = Work(range(10))\n\n# For each of our initial bits of work, we open a frame to further parallelize within\n# each bit of work\n@w.frame\ndef innerFor(store, first):\n    \"\"\"This function is called whenever everything in the frame is finished.  Usually,\n    that means it is called once when a frame should request more work, and once when\n    all of that work is done.\n\n    Any work returned by this function will be processed by the jobs within the frame,\n    and finally aggregated into the 'store' variable at the frameEnd function.\"\"\"\n\n    if not hasattr(store, 'init'):\n        # First run, uninitialized\n        store.init = True\n        store.value = 0\n        # Anything returned from a frame or frameEnd function will recur to all of the\n        # jobs between the frame and its corresponding frameEnd\n        return list(range(first))\n\n    # If we get here, we've already processed all of our earlier recurs.  To mimic the\n    # nested for loop above, that just means that we need to print our results\n    print(\"{}: {}\".format(first, store.value))\n\n@w.frameEnd\ndef innerForEnd(store, next):\n    store.value += next\n\nw.run()\n```\n\n\n####<a name=\"aggregating-outside-of-a-for-loop\"></a>Aggregating outside of a for loop\n\nTo parallelize this:\n\n```python\nresults = []\nfor i in range(10):\n    results.append(i * 2)\nresult = sum(results)\n```\n\nWrite this:\n\n```python\nfrom job_stream.inline import Object, Work\nw = Work(range(10))\n\n@w.job\ndef timesTwo(i):\n    return i * 2\n\n# reduce is\n@w.reduce(store = lambda: Object(value = 0), emit = lambda store: store.value)\ndef gatherResults(store, inputs, others):\n    for i in inputs:\n        store.value += i\n    for o in others:\n        store.value += o.value\n\n# Run the job stream and collect the first (and only) result into our sum\nresult, = w.run()\n```\n\n\n####<a name=\"aggregating-multiple-items-outside-of-a-for-loop\"></a>Aggregating multiple items outside of a for loop\n\nTo parallelize this:\n\n```python\nresults = []\nfor i in range(10):\n    results.append(i)\n    results.append(i * 2)\nresult = sum(results)\n```\n\nWrite this:\n\n```python\nfrom job_stream.inline import Multiple, Object, Work\nw = Work(range(10))\n\n@w.job\ndef timesTwo(i):\n    return Multiple([ i, i * 2 ])\n\n# reduce is\n@w.reduce(store = lambda: Object(value = 0), emit = lambda store: store.value)\ndef gatherResults(store, inputs, others):\n    for i in inputs:\n        store.value += i\n    for o in others:\n        store.value += o.value\n\n# Run the job stream and collect the first (and only) result into our sum\nresult, = w.run()\n```\n\n\n##<a name=\"c-basics\"></a>C++ Basics\n\njob_stream works by allowing you to specify various \"streams\" through your\napplication's logic.  The most basic unit of work in job_stream is the job,\nwhich takes some input work and transforms it into zero or more outputs:\n\n![A job_stream job takes some input, transforms it, and emits zero or more outputs](doc/readme/01_basic.png)\n\nThat is, some input work is required for a job to do anything.  However, the\njob may choose to not pass anything forward (perhaps save something to a file\ninstead), or it might apply some transformation(s) to the input and then output\nthe changed data.  For our first job, supppose we wanted to make a basic job\nthat takes an integer and increments it, forwarding on the result:\n\n![A job that adds one to the input and emits it](doc/readme/02_addOne.png)\n\nThe corresponding code for this job follows:\n\n    #include <job_stream/job_stream.h>\n    //All work comes into job_stream jobs as a unique_ptr; this can be used\n    //to optimize memory bandwidth locally.\n    using std::unique_ptr;\n\n    /** Add one to the integer input and forward it. */\n    class AddOneJob : public job_stream::Job<AddOneJob, int> {\n    public:\n        /** The name used to describe this job in a YAML file */\n        static const char* NAME() { return \"addOne\"; }\n        void handleWork(unique_ptr<int> work) {\n            this->emit(*work + 1);\n        }\n    } addOneJob;\n\nThe parts of note are:\n\n* Template arguments to job_stream::Job - the class being defined, and the\n  expected type of input,\n* NAME() method, which returns a string that we'll use to refer to this\n  type of job,\n* handleWork() method, which is called for each input work generated,\n* this->emit() call, which is used to pass some serializable object forward as\n  output, and\n* this->emit() can take any type of argument - the output's type and content do\n  not need to have any relation to the input.\n* There MUST be a global instance allocated after the class definition.  This\n  instance is not ever used in code, but C++ requires a instance for certain\n  templated code to be generated.\n\n*NOTE - all methods in a job_stream job must be thread-safe!*\n\nIn order to use this job, we would need to define a simple `adder.yaml` file:\n\n    jobs:\n      - type: addOne\n\nRunning this with some input produces the expected result:\n\n    local$ pwd\n    /.../dev/job_stream\n    local$ cd build\n    local$ cmake .. && make -j8 example\n    ...\n    # Any arguments after the YAML file and any flags mean to run the job stream\n    # with precisely one input, interpreted from the arguments\n    local$ example/job_stream_example ../example/adder.yaml 1\n    2\n    (some stats will be printed on termination)\n    # If no arguments exist, then stdin will be used.\n    local$ example/job_stream_example ../example/adder.yaml <<!\n    3\n    8\n    !\n    # Results - note that when you run this, the 9 might print before the 4!\n    # This depends on how the thread scheduling works out.\n    4\n    9\n    (some stats will be printed on termination)\n    local$\n\n##<a name=\"reducers-and-frames\"></a>Reducers and Frames\n\nOf course, if we could only transform and potentially duplicate input then\njob_stream wouldn't be very powerful.  job_stream has two mechanisms that make\nit much more useful - reducers, which allow several independently processed\nwork streams to be merged, and recursion, which allows a reducer to pass work\nback into itself.  Frames are a job_stream idiom to make the combination of\nreducers and recursion more natural.\n\nTo see how this fits, we'll calculate pi experimentally to a desired precision.\nWe'll be using the area calculation - since A = R*pi^2, pi = sqrt(A / R).  \nRandomly distributing points in a 1x1 grid and testing if they lie within the\nunit circle, we can estimate the area:\n\n![Estimating pi](doc/readme/03_calculatePi.png)\n\nThe job_stream part of this will take as its input a floating point number which\nis the percentage of error that we want to reach, and will emit the number of\nexperimental points evaluated in order to reach that accuracy.  The network\nlooks like this:\n\n![Estimating pi](doc/readme/04_piPipeline.png)\n\nAs an aside, the \"literally anything\" that the piCalculator needs to feed to\npiEstimate is because we'll have piEstimate decide which point to evaluate.  \nThis is an important part of designing a job_stream pipeline - generality.  If,\nfor instance, we were to pass the point that needs evaluating to piEstimate,\nthen we have locked our piCalculator into working with only one method of\nevaluating pi.  With the architecture shown, we can substitute any number of\npi estimators and compare their relative efficiencies.\n\nBefore coding our jobs, let's set up the YAML file `pi.yaml`:\n\n    jobs:\n      - frame:\n            type: piCalculator\n        jobs:\n            - type: piEstimate\n\nThis means that our pipe will consist of one top-level job, which itself has no\ntype and a stream of \"jobs\" it will use to transform data.  Wrapped around its\nstream is a \"frame\" of type piCalculator.  This corresponds to our above\ndiagram.\n\npiCalculator being a frame means that it will take an initial work,\nrecur into itself, and then aggregate results (which may be of a different type\nthan the initial work) until it stops recurring.  The code for it looks like\nthis:\n\n    struct PiCalculatorState {\n        float precision;\n        float piSum;\n        int trials;\n\n    private:\n        //All structures used for storage or emit()'d must be serializable\n        friend class boost::serialization::access;\n        template<class Archive>\n        void serialize(Archive& ar, const unsigned int version) {\n            ar & precision & piSum & trials;\n        }\n    };\n\n    /** Calculates pi to the precision passed as the first work.  The template\n        arguments for a Frame are: the Frame's class, the storage type, the\n        first work's type, and subsequent (recurred) work's type. */\n    class PiCalculator : public job_stream::Frame<PiCalculator,\n            PiCalculatorState, float, float> {\n    public:\n        static const char* NAME() { return \"piCalculator\"; }\n\n        void handleFirst(PiCalculatorState& current, unique_ptr<float> work) {\n            current.precision = *work * 0.01;\n            current.piSum = 0.0f;\n            current.trials = 0;\n            //Put work back into this Frame.  This will trigger whatever method\n            //of pi approximation is defined in our YAML.  We'll pass the\n            //current trial index as debug information.\n            this->recur(current.trials++);\n        }\n\n        void handleWork(PiCalculatorState& current, unique_ptr<float> work) {\n            current.piSum += *work;\n        }\n\n        void handleDone(PiCalculatorState& current) {\n            //Are we done?\n            float piCurrent = current.piSum / current.trials;\n            if (fabsf((piCurrent - M_PI) / M_PI) < current.precision) {\n                //We're within desired precision, emit trials count\n                fprintf(stderr, \"Pi found to be %f, +- %.1f%%\\n\", piCurrent,\n                        current.precision * 100.f);\n                this->emit(current.trials);\n            }\n            else {\n                //We need more iterations.  Double our trial count\n                for (int i = 0, m = current.trials; i < m; i++) {\n                    this->recur(current.trials++);\n                }\n            }\n        }\n    } piCalculator;\n\nSimilar to our first addOne job, but we've added a few extra methods -\nhandleFirst and handleDone.  handleFirst is called for the work that starts\na reduction and should initialize the state of the current reduction.  \nhandleWork is called whenever a recur'd work finishes its loop and ends up back\nat the Frame.  Its result should be integrated into the current state somehow.\nhandleDone is called when there is no more pending work in the frame, at which\npoint the frame may either emit its current result or recur more work.  If\nnothing is recur'd, the reduction is terminated.\n\nOur piEstimate job is much simpler:\n\n    class PiEstimate : public job_stream::Job<PiEstimate, int> {\n    public:\n        static const char* NAME() { return \"piEstimate\"; }\n        void handleWork(unique_ptr<int> work) {\n            float x = rand() / (float)RAND_MAX;\n            float y = rand() / (float)RAND_MAX;\n            if (x * x + y * y <= 1.0) {\n                //Estimate area as full circle\n                this->emit(4.0f);\n            }\n            else {\n                //Estimate area as nothing\n                this->emit(0.0f);\n            }\n        }\n    } piEstimate;\n\nSo, let's try it!\n\n    local$ cd build\n    local$ cmake .. && make -j8 example\n    local$ example/job_stream_example ../example/pi.yaml 10\n    Pi found to be 3.000000, +- 10.0%\n    4\n    (debug info as well)\n\nSo, it took 4 samples to arrive at a pi estimation of 3.00, which is within 10%\nof 3.14.  Hooray!  We can also run several tests concurrently:\n\n    local$ example/job_stream_example ../example/pi.yaml <<!\n    10\n    1\n    0.1\n    !\n    Pi found to be 3.000000, +- 10.0%\n    4\n    Pi found to be 3.167969, +- 1.0%\n    Pi found to be 3.140625, +- 0.1%\n    1024\n    1024\n    0 4% user time (3% mpi), 1% user cpu, 977 messages (0% user)\n    C 4% user time, 0% user cpu, quality 0.00 cpus, ran 1.238s\n\nThe example works!  Bear in mind that the efficiency ratings for a task like\nthis are pretty poor.  Since each job only does a few floating point operations,\nhe communication overhead well outweighs the potential benefits of parallelism.\nHowever, once your jobs start to do even a little more work, job_stream quickly\nbecomes beneficial.  On our modest research cluster, I have jobs that routinely\nreport a user-code quality of 200+ cpus.\n\n\n##<a name=\"words-of-warning\"></a>Words of Warning\n\nfork()ing a child process can be difficult in a threaded MPI application.  To\nwork around these difficulties, it is suggested that your application use\njob_stream::invoke (which forwards commands to a properly controlled\nlibexecstream).\n\nJob and reduction routines MUST be thread safe.  Job_stream handles most of this\nfor you.  However, do NOT create a shared buffer in which to do your work as\npart of a job class.  If you do, make sure you declare it thread\\_local (which\nrequires static).\n\nIt is wrong to build a Reducer or Frame that simply appends new work into a\nlist.  Doing so will cause excessively large objects to be written to checkpoint\nfiles and cause the backups required to support checkpoints to bloat\nunnecessarily (backups meaning the copy of each store object that represents its\nnon-mutated state before the work began.  Without this, checkpointing would have\nto wait for all Work to finish before completing).\nThis leads to very long-running de/serialization routines, which can cause very\npoor performance in some situations.\n\nIf you use checkpoints and your process crashes, it is possible that any\nactivity _outside_ of job_stream will be repeated.  In other words, if one of\nyour jobs appends content to a file, then that content might appear in the\nfile multiple times.  The recommended way to get around this is to have your\nwork output to different files, with a unique, deterministic file name for each\npiece of work that outputs.  Another approach is to use a reducer which gathers\nall completed work, and then dumps it all to a file at once in handleDone().\n\nSometimes, passing -bind-to-core to mpirun can have a profoundly positive impact\non performance.\n\n\n##<a name=\"unfriendly-examples\"></a>Unfriendly Examples\n\n*These are old and aren't laid out quite as nicely.  However, there is reasonably\ngood information here that isn't covered above.  So, it's left here for now.*\n\nThe following example is fully configured in the \"example\" subdirectory.\n\nEssentially, you code some jobs, and optionally a reducer for combining results:\n\n    #include <job_stream/job_stream.h>\n\n    using std::unique_ptr;\n\n    /** Add one to any integer we receive */\n    class AddOneJob : public job_stream::Job<int> {\n    public:\n        static AddOneJob* make() { return new AddOneJob(); }\n\n        void handleWork(unique_ptr<int> work) {\n            this->emit(*work + 1);\n        }\n    };\n\n\n    class DuplicateJob : public job_stream::Job<int> {\n    public:\n        static DuplicateJob* make() { return new DuplicateJob(); }\n\n        void handleWork(unique_ptr<int> work) {\n            this->emit(*work);\n            this->emit(*work);\n        }\n    };\n\n\n    class GetToTenJob : public job_stream::Job<int> {\n    public:\n        static GetToTenJob* make() { return new GetToTenJob(); }\n\n        void handleWork(unique_ptr<int> work) {\n            if (*work < 10) {\n                this->emit(*work, \"keep_going\");\n            }\n            else {\n                this->emit(*work, \"done\");\n            }\n        }\n    };\n\n\n    class SumReducer : public job_stream::Reducer<int> {\n    public:\n        static SumReducer* make() { return new SumReducer(); }\n\n        /** Called to initialize the accumulator for this reduce.  May be called\n            several times on different hosts, whose results will later be merged\n            in handleJoin(). */\n        void handleInit(int& current) {\n            current = 0;\n        }\n\n        /** Used to add a new output to this Reducer */\n        void handleAdd(int& current, unique_ptr<int> work) {\n            current += *work;\n        }\n\n        /** Called to join this Reducer with the accumulator from another */\n        void handleJoin(int& current, unique_ptr<int> other) {\n            current += *other;\n        }\n\n        /** Called when the reduction is complete, or nearly - recur() may be used\n            to keep the reduction alive (inject new work into this reduction). */\n        void handleDone(int& current) {\n            this->emit(current);\n        }\n    };\n\n\n    class GetToValueReducer : public job_stream::Reducer<int> {\n    public:\n        static GetToValueReducer* make() { return new GetToValueReducer(); }\n\n        void handleInit(int& current) {\n            current = 0;\n        }\n\n        void handleAdd(int& current, unique_ptr<int> work) {\n            //Everytime we get an output less than 2, we'll need to run it through\n            //the system again.\n            printf(\"Adding %i\\n\", *work);\n            if (*work < 3) {\n                this->recur(3);\n            }\n            current += *work;\n        }\n\n        void handleJoin(int& current, unique_ptr<int> other) {\n            current += *other;\n        }\n\n        void handleDone(int& current) {\n            printf(\"Maybe done at %i\\n\", current);\n            if (current >= this->config[\"value\"].as<int>()) {\n                this->emit(current);\n            }\n            else {\n                //Not really done, put work back in as our accumulated value.\n                this->recur(current);\n            }\n        }\n    };\n\nRegister them in your main, and call up a processor:\n\n    int main(int argc, char* argv []) {\n        job_stream::addJob(\"addOne\", AddOneJob::make);\n        job_stream::addJob(\"duplicate\", DuplicateJob::make);\n        job_stream::addJob(\"getToTen\", GetToTenJob::make);\n        job_stream::addReducer(\"sum\", SumReducer::make);\n        job_stream::addReducer(\"getToValue\", GetToValueReducer::make);\n        job_stream::runProcessor(argc, argv);\n        return 0;\n    }\n\nDefine a pipeline / configuration:\n\n    # example1.yaml\n    reducer: sum\n    jobs:\n        - type: addOne\n        - type: addOne\n\nAnd run it!\n\n    # This will compute 45 + 2 and 7 + 2 separately, then sum them, returning\n    # one number (because of the reducer).\n    $ mpirun -np 4 ./job_stream_example example1.yaml <<!\n        45\n        7\n        !\n    56\n    $\n\nWant to get a little more complicated?  You can embed modules:\n\n    # example2.yaml\n    jobs:\n        - type: addOne\n        # Not defining type (or setting it to \"module\") starts a new module\n        # that can have its own reducer and job chain\n        -   reducer: sum\n            jobs:\n                - type: duplicate\n\nThat pipeline will, individually for each input row, add one and double it:\n\n    $ mpirun -np 4 ./job_stream_example example2.yaml <<!\n        1\n        2\n        3\n        !\n    4\n    6\n    8\n    $\n\nDoes your program have more complex flow?  The emit() function can take a second\nargument, which is the name of the target to route to.  For instance, if we add\nto main.cpp:\n\n    class GetToTenJob : public job_stream::Job<int> {\n    public:\n        static GetToTenJob* make() { return new GetToTenJob(); }\n\n        void handleWork(unique_ptr<int> work) {\n            if (*work < 10) {\n                this->emit(*work, \"keep_going\");\n            }\n            else {\n                this->emit(*work, \"done\");\n            }\n        }\n    };\n\n    //Remember to register it in main...\n\nAnd then you set up example3.yaml:\n\n    # example3.yaml\n    # Note that our module now has an \"input\" field - this determines the first\n    # job to receive work.  Our \"jobs\" field is now a map instead of a list,\n    # with the key being the id of each job.  \"to\" determines where emitted\n    # work goes - if \"to\" is a mapping, the job uses \"emit\" with a second\n    # argument to guide each emitted work.\n    input: checkValue\n    jobs:\n        addOne:\n            type: addOne\n            to: checkValue\n        checkValue:\n            type: getToTen\n            to:\n                keep_going: addOne\n                done: output\n\nRun it:\n\n    $ mpirun -np 4  ./job_stream_example example3.yaml <<!\n        1\n        8\n        12\n        !\n    12\n    10\n    10\n    $\n\nNote that the \"12\" is output first, since it got routed to output almost\nimmediately rather than having to pass through many AddOneJobs.\n\nYou can also have recurrence in your reducers - that is, if a reduction finishes\nbut the results do not match a criteria yet, you can put more tuples through\nin the same reduction:\n\n    # example4.yaml\n    # Reducer recurrence\n    reducer:\n        type: getToValue\n        value: 100\n    jobs:\n        - type: duplicate\n        - type: addOne\n\nRunning this with 1 will yield 188 - essentially, since handleAdd() calls recur\nfor each value less than 3, two additional \"3\" works get added into the system\nearly on.  So handleDone() gets called with 20, 62, and finally 188.\n\n\n\n##<a name=\"recent-changelog\"></a>Recent Changelog\n\n* 2016-6-14 - Python 3 support and embedded two of the boost libraries that\n  are not typically associated with boost-python.  In other words, a\n  `conda install boost` preceding a `pip install job_stream` now works with\n  both Python 2 and 3.  System boost libraries should still work as before\n  (although job_stream might use an outdated version of boost-mpi).\n\n  Version bump to 0.1.8 and 0.1.9 (build fix).\n* 2016-4-14 - Added a `map()` function that is compatible with the builtin\n  `map()` function.\n* 2015-5-26 - README warning about Frames and Reducers that store a list of\n  objects.  Python inline frames can specify useMultiprocessing=False separate\n  from the work.  Minor efficiency improvement to copy fewer Python object\n  strings.\n* 2015-5-21 - Build on Mac OS X is now fixed.\n* 2015-3-26 - `job_stream.inline.Work` can now be used in `with` blocks and has\n  a `finish()` method.  Args for `Work.run()` were moved to `Work`'s\n  initializer.\n* 2015-2-6 - job_stream.inline python module can disable multiprocessing by\n  passing useMultiprocessing = False in the `Work` object's initializer.\n* 2015-1-30 - Updated README to include job_stream.invoke, and exposed\n  checkpointInfo function for debugging.\n* 2015-1-29 - Added inline.result() function, which lets users write code that\n  is executed exactly once per result, and always on the main host.\n* 2015-1-28 - Added inline.init() function, which ensures code is only executed\n  once regardless of checkpoint or host status.\n* 2015-1-7 - Added job_stream.invoke to the python module.  Useful for launching\n  an external process, e.g. Xyce.\n* 2014-12-26 - Finished up job_stream.inline, the more intuitive way to\n  parallelize using job_stream.  Minor bug fixes, working on README.  Need\n  to curate everything and fix the final test_pipes.py test that is failing\n  before redeploying to PyPI\n* 2014-12-23 - Embedded yaml-cpp into job_stream's source to ease compilation.\n  Bumped PyPI to 0.1.3.\n* 2014-12-22 - Finished python support (initial version, anyway).  Supports\n  config, multiprocessing, proper error reporting.  Pushed version 0.1.2 to\n  PyPI :)\n* 2014-12-18 - Python support.  Frame methods renamed for clarity\n  (handleWork -> handleNext).  Frames may now be specified as a string for\n  type, just like reducers.\n* 2014-12-04 - Checkpoints no longer are allowed for interactive mode.  All\n    input must be spooled into the system before a checkpoint will be allowed.\n* 2014-11-14 - Fixed job_stream checkpoints to be continuous.  That is, a\n    checkpoint no longer needs current work to finish in order to complete.  This\n    cuts the runtime for checkpoints from several hours in some situations down\n    to a couple of seconds.  Also, added test-long to cmake, so that tests can\n    be run repeatedly for any period of time in order to track down transient\n    failures.\n\n    Fixed a bug with job_stream::invoke which would lock up if a program wrote\n    too much information to stderr or stdout.\n\n    Re-did steal ring so that it takes available processing power into account.\n* 2014-11-06 - Fixed invoke::run up so that it supported retry on user-defined\n    transient errors (For me, Xyce was having issues creating a sub directory\n    and would crash).\n* 2014-11-03 - Added --checkpoint-info for identifying what makes checkpoint\n    files so large sometimes.  Miscellaneous cleanup to --help functionality.\n    Serialization will refuse to serialize a non-pointer version of a polymorphic\n    class, since it takes a long time to track down what's wrong in that\n    situation.\n* 2014-10-17 - Apparently yaml-cpp is not thread safe.  Wtf.  Anyway, as a\n    \"temporary\" solution, job_stream now uses some custom globally locked classes\n    as a gateway to yaml-cpp.  All functionality should still work exactly like\n    vanilla yaml-cpp.\n\n    Also, no work happens during a checkpoint now.  That was causing corrupted\n    checkpoint files with duplicated ring tests.\n* 2014-9-10 - Fixed up duplicated and end-of-job-sequence (output) submodules.\n    Host name is now used in addition to MPI rank when reporting results.\n* 2014-6-13 - Finalized checkpoint code for initial release.  A slew of new\n    tests.\n* 2014-4-24 - Fixed up shared_ptr serialization.  Fixed synchronization issue\n    in reduction rings.\n* 2014-2-19 - Added Frame specialization of Reducer.  Expects a different\n    first work than subsequent.  Usage pattern is to do some initialization work\n    and then recur() additional work as needed.\n* 2014-2-12 - Serialization is now via pointer, and supports polymorphic classes\n    completely unambiguously via dynamic_cast and\n    job_stream::serialization::registerType.  User cpu % updated to be in terms of\n    user time (quality measure) for each processor, and cumulative CPUs for\n    cumulative time.\n* 2014-2-5 - In terms of user ticks / wall clock ms, less_serialization is on\n    par with master (3416 vs 3393 ticks / ms, 5% error), in addition\n    to all of the other fixes that branch has.  Merged in.\n* 2014-2-4 - Got rid of needed istream specialization; use an if and a\n    runtime\\_exception.\n* 2014-2-4 - handleWork, handleAdd, and handleJoin all changed to take a\n    unique\\_ptr rather than references.  This allows preventing more memory\n    allocations and copies.  Default implementation with += removed.\n\n\n##<a name=\"roadmap\"></a>Roadmap\n\n* Memory management helper - psutil.get_memory_info().rss,\n    psutil.phymem_usage().available, inline multiprocessing disable, etc.  Use\n    statistical probabilities to determine the memory consumption per job,\n    INCLUDING job_stream.invoke memory.  Assume one (or two) std deviations (or\n    high watermark) of memory are required above average for job allocation.\n    How to do this?\n    Low watermark before jobs are handled.  Periodically sample memory usage,\n    and ...?  Assume used memory is evenly distributed amongst jobs?  Python\n    does multiprocessing... this affects these stats.  Hmm..\n\n    Maybe what would be best is add a \"memoryRequired\" to SharedBase override.  This\n    much RAM is required FOR THE WHOLE DURATION of the job.  E.g., it will double\n    count memory.  Eventually, tracking avg time to completion + std dev, can fade\n    out memory bias on running jobs.  But initially, naive is OK.\n\n    Also, needs to be nice to other people's experiments.  That is, collaborate\n    across job_stream instances (since I've got most of the lab using job_stream).\n    Goals:\n    - Maximize resources available to all job_streams (use all cores amongst\n        job_streams, and all memory).\n    - Distribute those resources evenly, but also greedily.  That is, not all\n        job_streams will use 100% of what is available.  Ones that need more should\n        expand into the gap.\n\n    So...\n    Distributed arbitration?  Requests and\n    yields?  E.g., each job_stream status file has two fields: allocated\n    cores & ram, and desired.  Allocated is moved towards desired based on\n    capacity (cores, mb) minus sum of allocated.  Allocated is moved down when\n    desired is lower.  Balanced across user, then jobs.\n\n    Traverse parent pid chain to count all memory usage.  Allocated memory should\n    probably be a virtual figure - that is, the allocated memory is IN ADDITION\n    to actual allocations.  Although, that has a 50% error margin.  Other way\n    to do it would be to have allocated memory be a minimum of sorts...\n    memory = max(baseline + allocation, actual)\n\n    We now have hard limits and soft limits.  Make sure we have a concept of\n    running vs desired running, too.\n\n* to: Should be a name or YAML reference, emit() or recur() should accept an\n    argument of const YAML::Node& so that we can use e.g. stepTo: *priorRef as\n    a normal config.  DO NOT overwrite to!  Allow it to be specified in pipes, e.g.\n\n        - to: *other\n          needsMoreTo: *next\n        - &next\n          type: ...\n          to: output\n        - &other\n          type: ...\n\n    In general, allow standard YAML rather than a specially split \"to\" member.\n* Smarter serialization....... maybe hash serialized entities, and store a dict\n    of hashes, so as to only write the same data once even if it is NOT a\n    duplicated pointer.\n* depth-first iteration as flag\n* Ability to let job_stream optimize work size.  That is, your program says\n    something like this->getChunk(__FILE__, __LINE__, 500) and then job_stream\n    tracks time spent on communicating vs processing and optimizes the size of\n    the work a bit...\n* Fix timing statistics in continue'd runs from checkpoints\n* Errors during a task should push the work back on the stack and trigger a\n    checkpoint before exiting.  That would be awesome.  Should probably be an\n    option though, since it would require \"checkpointing\" reduce accumulations\n    and holding onto emitted data throughout each work's processing\n* Prevent running code on very slow systems... maybe make a CPU / RAM sat\n    metric by running a 1-2 second test and see how many cycles of computation\n    we get, then compare across systems.  If we also share how many contexts each\n    machine has, then stealing code can balance such that machines 1/2 as capable\n    only keep half their cores busy maximum according to stealing.\n* Progress indicator, if possible...\n* Merge job\\_stream\\_inherit into job\\_stream\\_example (and test it)\n* TIME\\_COMM should not include initial isend request, since we're not using\n    primitive objects and that groups in the serialization time\n* Frame probably shouldn't need handleJoin (behavior would be wrong, since\n    the first tuple would be different in each incarnation)\n* Replace to: output with to: parent; input: output to input: reducer\n* Consider replacing \"reducer\" keyword with \"frame\" to automatically rewrite\n    recurTo as input and input as reducer\n* Consider attachToNext() paired w/ emit and recur; attachments have their own\n    getAttached<type>(\"label\") retriever that returns a modifiable version of the\n    attachment.  removeAttached(\"label\").  Anyway, attachments go to all child\n    reducers but are not transmitted via emitted() work from reducers.  Would\n    greatly simplify trainer / maximize code... though, if something is required,\n    passing it in a struct is probably a better idea as it's a compile-time error.\n    Then again, it wouldn't work for return values, but it would work for\n    attaching return values to a recur'd tuple and waiting for it to come back\n    around.\n* Update README with serialization changes, clean up code.  Note that unique\\_ptr\n    serialize() is specified in serialization.h.  Also Frame needs doc.\n* Idle time tracking - show how much time is spent e.g. waiting on a reducer\n* Solve config problem - if e.g. all jobs need to fill in some globally shared\n    information (tests to run, something not in YAML)\n* Python embedded bindings / application\n* Reductions should always happen locally; a dead ring should merge them.\n    * Issue - would need a merge() function on the templated reducer base class.  Also, recurrence would have to re-initialize those rings.  Might be better to hold off on this one until it's a proven performance issue.\n    * Unless, of course, T_accum == T_input always and I remove the second param.  Downsides include awkwardness if you want other components to feed into the reducer in a non-reduced format... but, you'd have to write a converter anyway (current handleMore).  So...\n    * Though, if T_accum == T_input, it's much more awkward to make generic, modular components.  For instance, suppose you have a vector calculation.  Sometimes you just want to print the vectors, or route them to a splicer or whatever.  If you have to form them as reductions, that's pretty forced...\n    * Note - decided to go with handleJoin(), which isn't used currently, but will be soon (I think this will become a small issue)\n* Tests\n* Subproject - executable integrated with python, for compile-less / easier work\n\n##<a name=\"appendix\"></a>Appendix\n\n##<a name=\"running-the-tests\"></a>Running the Tests\n\nMaking the \"test\" target (with optional ARGS passed to test executable) will\nmake and run any tests packaged with job\\_stream:\n\n    cmake .. && make -j8 test [ARGS=\"[serialization]\"]\n\nOr to test the python library:\n\n    cmake .. && make -j8 test-python [ARGS=\"../python/job_stream/test/\"]\n\n\n##<a name=\"running-a-job_stream-application\"></a>Running a job_stream C++ Application\n\nA typical job\\_stream application would be run like this:\n\n    mpirun -host a,b,c my_application path/to/config.yaml [-c checkpointFile] [-t hoursBetweenCheckpoints] Initial work string (or int or float or whatever)\n\nNote that -np to specify parallelism is not needed, as job\\_stream implicitly\nmulti-threads your application.  If a checkpointFile is provided, then the file\nwill be used if it exists.  If it does not exist, it will be created and updated\nperiodically to allow resuming with a minimal loss of computation time.  It is\nfairly simple to write a script that will execute the application until success:\n\n    RESULT=1\n    for i in `seq 1 100`; do\n        mpirun my_application config.yaml -c checkpoint.chkpt blahblah\n        RESULT=$?\n        if [ $RESULT -eq 0 ]; then\n            break\n        fi\n    done\n\n    exit $RESULT\n\nIf -t is not specified, checkpoints will be taken every 10 minutes.\n\n\n##<a name=\"running-in-python\"></a>Running in Python\n\nPython is much more straightforward:\n\n    LD_LIBRARY_PATH=... ipython\n    >>> import job_stream\n    >>> class T(job_stream.Job):\n            def handleWork(self, w):\n                self.emit(w * 2)\n    # Omit this next line to use stdin for initial work\n    >>> job_stream.work = [ 1, 2, 3 ]\n    >>> job_stream.run({ 'jobs': [ T ] })",
            "description_content_type": null,
            "docs_url": null,
            "download_url": "UNKNOWN",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/wwoods/job_stream",
            "keywords": null,
            "license": "MIT",
            "maintainer": null,
            "maintainer_email": null,
            "name": "job_stream",
            "package_url": "https://pypi.org/project/job_stream/",
            "platform": "UNKNOWN",
            "project_url": "https://pypi.org/project/job_stream/",
            "project_urls": {
                "Download": "UNKNOWN",
                "Homepage": "https://github.com/wwoods/job_stream"
            },
            "release_url": "https://pypi.org/project/job_stream/0.1.9/",
            "requires_dist": null,
            "requires_python": null,
            "summary": "job_stream: easy and sophisticated parallelization",
            "version": "0.1.9",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 4118112,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "10ececb7db30ebb3c500ea2db84b762b",
                    "sha256": "1dd4bf5beeebcb16902146a533b3324827beb70a54936ab2abe623d3b8afca05"
                },
                "downloads": -1,
                "filename": "job_stream-0.1.9.tar.gz",
                "has_sig": false,
                "md5_digest": "10ececb7db30ebb3c500ea2db84b762b",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 236038,
                "upload_time": "2016-06-15T05:31:59",
                "upload_time_iso_8601": "2016-06-15T05:31:59.810351Z",
                "url": "https://files.pythonhosted.org/packages/3b/07/e89cd3adcd32f4e9574b9f1b403934d21bb57347ea72c670fc3bd00746cd/job_stream-0.1.9.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
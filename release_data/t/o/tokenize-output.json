{
    "0.4.1": {
        "info": {
            "author": "anki",
            "author_email": "author@example.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/tokenizer/tkoenize-output",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tokenize-output",
            "package_url": "https://pypi.org/project/tokenize-output/",
            "platform": "any",
            "project_url": "https://pypi.org/project/tokenize-output/",
            "project_urls": {
                "Code": "https://github.com/tokenizer/tkoenize-output",
                "Documentation": "https://github.com/tokenizer/tkoenize-output/blob/master/README.md",
                "Homepage": "https://github.com/tokenizer/tkoenize-output",
                "Issue tracker": "https://github.com/tokenizer/tkoenize-output/issues"
            },
            "release_url": "https://pypi.org/project/tokenize-output/0.4.1/",
            "requires_dist": [
                "demjson"
            ],
            "requires_python": ">=3.6",
            "summary": "Get identifiers, names, paths, URLs and words from the command output.",
            "version": "0.4.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14338385,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f150108378e435f3aee41b48542fb37d",
                    "sha256": "46aa8dda28de77ff8fa5cc26a6b6b890c76faf7256d943a83824d56420e210c3"
                },
                "downloads": -1,
                "filename": "tokenize_output-0.4.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "f150108378e435f3aee41b48542fb37d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 4688,
                "upload_time": "2020-05-24T11:16:23",
                "upload_time_iso_8601": "2020-05-24T11:16:23.872074Z",
                "url": "https://files.pythonhosted.org/packages/36/14/e26571dcf37a2f24ae62cce8c61bea55a2d32830e4d99ad8d1da4de5ef0b/tokenize_output-0.4.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "9af34e8d4d640645706f8c17b27d9d7d",
                    "sha256": "f2687fc725048bebd44950b872f8463656ce55c816b2737eb66bbc15c421fd9c"
                },
                "downloads": -1,
                "filename": "tokenize-output-0.4.1.tar.gz",
                "has_sig": false,
                "md5_digest": "9af34e8d4d640645706f8c17b27d9d7d",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 4488,
                "upload_time": "2020-05-24T11:16:25",
                "upload_time_iso_8601": "2020-05-24T11:16:25.797728Z",
                "url": "https://files.pythonhosted.org/packages/6e/53/0878e43bcbf563f8deceda7548f01f0497659c344d706699df060226c1a4/tokenize-output-0.4.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.2": {
        "info": {
            "author": "anki",
            "author_email": "author@example.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/tokenizer/tkoenize-output",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tokenize-output",
            "package_url": "https://pypi.org/project/tokenize-output/",
            "platform": "any",
            "project_url": "https://pypi.org/project/tokenize-output/",
            "project_urls": {
                "Code": "https://github.com/tokenizer/tkoenize-output",
                "Documentation": "https://github.com/tokenizer/tkoenize-output/blob/master/README.md",
                "Homepage": "https://github.com/tokenizer/tkoenize-output",
                "Issue tracker": "https://github.com/tokenizer/tkoenize-output/issues"
            },
            "release_url": "https://pypi.org/project/tokenize-output/0.4.2/",
            "requires_dist": [
                "demjson"
            ],
            "requires_python": ">=3.6",
            "summary": "Get identifiers, names, paths, URLs and words from the command output.",
            "version": "0.4.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14338385,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "2d6b23afc2d4550438818ad483afcc41",
                    "sha256": "200f4c55e007b216bd0209da4996d7d273ee08424b197d6006a4f07fd3948fc6"
                },
                "downloads": -1,
                "filename": "tokenize_output-0.4.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "2d6b23afc2d4550438818ad483afcc41",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 4685,
                "upload_time": "2020-09-10T22:37:08",
                "upload_time_iso_8601": "2020-09-10T22:37:08.954213Z",
                "url": "https://files.pythonhosted.org/packages/37/64/6b3c3a930b4d65a30024654282e7d32faff655f05484299e02f0e039a002/tokenize_output-0.4.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "50112aeb8e3e8e1c49c077d8e94a55fe",
                    "sha256": "7a99c660edf9a4766c67b342e247f8fca93c2d68dbc422da0f9986516da052f8"
                },
                "downloads": -1,
                "filename": "tokenize-output-0.4.2.tar.gz",
                "has_sig": false,
                "md5_digest": "50112aeb8e3e8e1c49c077d8e94a55fe",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 4517,
                "upload_time": "2020-09-10T22:37:09",
                "upload_time_iso_8601": "2020-09-10T22:37:09.812818Z",
                "url": "https://files.pythonhosted.org/packages/22/b8/3e17b4d28823639210df1c3556ab6b822354e3729677bdf5d6be84817469/tokenize-output-0.4.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.3": {
        "info": {
            "author": "anki",
            "author_email": "author@example.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/tokenizer/tkoenize-output",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tokenize-output",
            "package_url": "https://pypi.org/project/tokenize-output/",
            "platform": "any",
            "project_url": "https://pypi.org/project/tokenize-output/",
            "project_urls": {
                "Code": "https://github.com/tokenizer/tkoenize-output",
                "Documentation": "https://github.com/tokenizer/tkoenize-output/blob/master/README.md",
                "Homepage": "https://github.com/tokenizer/tkoenize-output",
                "Issue tracker": "https://github.com/tokenizer/tkoenize-output/issues"
            },
            "release_url": "https://pypi.org/project/tokenize-output/0.4.3/",
            "requires_dist": [
                "demjson"
            ],
            "requires_python": ">=3.6",
            "summary": "Get identifiers, names, paths, URLs and words from the command output.",
            "version": "0.4.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14338385,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6ad0effa004fca881202764cec538d61",
                    "sha256": "944c9edda752e867d98aeb52b885b85327c785c729c80a28cba11924a80cae9a"
                },
                "downloads": -1,
                "filename": "tokenize_output-0.4.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "6ad0effa004fca881202764cec538d61",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 5573,
                "upload_time": "2020-09-10T22:47:31",
                "upload_time_iso_8601": "2020-09-10T22:47:31.927035Z",
                "url": "https://files.pythonhosted.org/packages/3e/99/3e5643193b88f4a818170f4c74d9f56ce9814973a9cce03bc1773239809d/tokenize_output-0.4.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "34783e4c0ea958a68cea90d5b7120d14",
                    "sha256": "420564be4a58a48f8a266cfd396a186d1ced480f02d65cd69c85e800b1a51701"
                },
                "downloads": -1,
                "filename": "tokenize-output-0.4.3.tar.gz",
                "has_sig": false,
                "md5_digest": "34783e4c0ea958a68cea90d5b7120d14",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 5271,
                "upload_time": "2020-09-10T22:47:33",
                "upload_time_iso_8601": "2020-09-10T22:47:33.040612Z",
                "url": "https://files.pythonhosted.org/packages/76/72/948560a180d68d619afcb8e8f18301e4c779d39d9313adef46e744fc1312/tokenize-output-0.4.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.4": {
        "info": {
            "author": "anki",
            "author_email": "author@example.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/tokenizer/tokenize-output",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tokenize-output",
            "package_url": "https://pypi.org/project/tokenize-output/",
            "platform": "any",
            "project_url": "https://pypi.org/project/tokenize-output/",
            "project_urls": {
                "Code": "https://github.com/tokenizer/tokenize-output",
                "Documentation": "https://github.com/tokenizer/tokenize-output/blob/master/README.md",
                "Homepage": "https://github.com/tokenizer/tokenize-output",
                "Issue tracker": "https://github.com/tokenizer/tokenize-output/issues"
            },
            "release_url": "https://pypi.org/project/tokenize-output/0.4.4/",
            "requires_dist": [
                "demjson"
            ],
            "requires_python": ">=3.6",
            "summary": "Get identifiers, names, paths, URLs and words from the command output.",
            "version": "0.4.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14338385,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3af0927e1e29e2acd8663baf88116efa",
                    "sha256": "0a70940180c26f554a2e8771d98d95b15ac7138008662009371f3bacdae911c2"
                },
                "downloads": -1,
                "filename": "tokenize_output-0.4.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3af0927e1e29e2acd8663baf88116efa",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 5568,
                "upload_time": "2020-09-10T23:07:56",
                "upload_time_iso_8601": "2020-09-10T23:07:56.931517Z",
                "url": "https://files.pythonhosted.org/packages/b0/79/824eecc4dd58934fc04391da4a163478cf649a0b7d9d5edc28292c5d789b/tokenize_output-0.4.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "d2e99973d5c78530e05b3c6cc8f0eee2",
                    "sha256": "f074406fe781dfd1fed36ac757ffeda71b3473a8b08abb71b7870a50c4d27d26"
                },
                "downloads": -1,
                "filename": "tokenize-output-0.4.4.tar.gz",
                "has_sig": false,
                "md5_digest": "d2e99973d5c78530e05b3c6cc8f0eee2",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 5254,
                "upload_time": "2020-09-10T23:07:57",
                "upload_time_iso_8601": "2020-09-10T23:07:57.765286Z",
                "url": "https://files.pythonhosted.org/packages/3d/d8/0730c88c6102431233f62f045fdb50e2733a5b1c0207ebc98837fbd55c4b/tokenize-output-0.4.4.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.6": {
        "info": {
            "author": "anki",
            "author_email": "author@example.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/tokenizer/tokenize-output",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tokenize-output",
            "package_url": "https://pypi.org/project/tokenize-output/",
            "platform": "any",
            "project_url": "https://pypi.org/project/tokenize-output/",
            "project_urls": {
                "Code": "https://github.com/tokenizer/tokenize-output",
                "Documentation": "https://github.com/tokenizer/tokenize-output/blob/master/README.md",
                "Homepage": "https://github.com/tokenizer/tokenize-output",
                "Issue tracker": "https://github.com/tokenizer/tokenize-output/issues"
            },
            "release_url": "https://pypi.org/project/tokenize-output/0.4.6/",
            "requires_dist": [
                "demjson3"
            ],
            "requires_python": ">=3.6",
            "summary": "Get identifiers, names, paths, URLs and words from the command output.",
            "version": "0.4.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14338385,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d1beb02494d13fe546f2c2e088b669cc",
                    "sha256": "f76689de4bbbc6320d66d8aca9cd36ab368df532bbb02ab3266cab2c82ffe05b"
                },
                "downloads": -1,
                "filename": "tokenize_output-0.4.6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d1beb02494d13fe546f2c2e088b669cc",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 5581,
                "upload_time": "2022-02-28T11:46:56",
                "upload_time_iso_8601": "2022-02-28T11:46:56.132990Z",
                "url": "https://files.pythonhosted.org/packages/ca/54/6162ae62aacf8f61ce30d34bf4349097278834af901e6bb29d7f350ee98b/tokenize_output-0.4.6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "cf0869e9fca6d0038b16d5789e15a77f",
                    "sha256": "8e11a3b602c8e08fbdd0139057e44f2069e814785ad197a7fdfae0eda9f54d89"
                },
                "downloads": -1,
                "filename": "tokenize-output-0.4.6.tar.gz",
                "has_sig": false,
                "md5_digest": "cf0869e9fca6d0038b16d5789e15a77f",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 5043,
                "upload_time": "2022-02-28T11:46:57",
                "upload_time_iso_8601": "2022-02-28T11:46:57.481396Z",
                "url": "https://files.pythonhosted.org/packages/5c/e0/3b785c782d401ced2d586f7b869105b5a916db1bf6c4bfb7f3cf623808f5/tokenize-output-0.4.6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4.7": {
        "info": {
            "author": "anki-code",
            "author_email": "author@example.com",
            "bugtrack_url": null,
            "classifiers": [
                "Programming Language :: Python"
            ],
            "description": "<p align=\"center\">\nGet identifiers, names, paths, URLs and words from the command output.<br> \nThe <a href=\"https://github.com/anki-code/xontrib-output-search\">xontrib-output-search</a> for <a href=\"https://xon.sh/\">xonsh shell</a> is using this library.\n</p>\n\n<p align=\"center\">  \nIf you like the idea click \u2b50 on the repo and stay tuned by watching releases.\n</p>\n\n## Install\n```shell script\npip install -U tokenize-output\n```\n\n## Usage\n\n#### Words tokenizing\n```shell script\n$ echo \"Try https://github.com/xxh/xxh\" | tokenize-output -p\nTry\nhttps://github.com/xxh/xxh\n```\n\n#### JSON, Python dict and JavaScript object tokenizing\n```shell script\n$ echo '{\"Try\": \"xonsh shell\"}' | tokenize-output -p\nTry\nshell\nxonsh\nxonsh shell\n```    \n\n#### env tokenizing\n```shell script\n$  echo 'PATH=/one/two:/three/four' | tokenize-output -p\n/one/two\n/one/two:/three/four\n/three/four\nPATH\n```    \n\n## Development\n\n### Tokenizers\nTokenizer is a functions which extract tokens from the text.\n\n| Priority | Tokenizer  | Text  | Tokens |\n| ---------| ---------- | ----- | ------ |\n| 1        | **dict**   | `{\"key\": \"val as str\"}` | `['key', 'val as str']` |\n| 2        | **env**    | `PATH=/bin:/etc` | `['PATH', '/bin:/etc', '/bin', '/etc']` |   \n| 3        | **split**  | `Split  me \\n now!` | `['Split', 'me', 'now!']` |   \n| 4        | **strip**  | `{Hello}` | `['Hello']` |   \n\nYou can create your tokenizer and add it to `tokenizers_all` in `tokenize_output.py`.\n\nTokenizing is a recursive process where every tokenizer returns `final` and `new` tokens. \nThe `final` tokens directly go to the result list of tokens. The `new` tokens go to all \ntokenizers again to find new tokens. As result if there is a mix of json and env data \nin the output it will be found and tokenized in appropriate way.  \n\n### Test and debug\nRun tests:\n```shell script\ncd ~\ngit clone https://github.com/anki-code/tokenize-output\ncd tokenize-output\npython -m pytest tests/\n```\nTo debug the tokenizer:\n```shell script\necho \"Hello world\" | ./tokenize-output -p\n```\n\n## Related projects\n* [xontrib-output-search][XONTRIB_OUTPUT_SEARCH] for [xonsh shell][XONSH]\n\n[XONTRIB_OUTPUT_SEARCH]: https://github.com/anki-code/xontrib-output-search\n[XONSH]: https://xon.sh/\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/anki-code/tokenize-output",
            "keywords": "",
            "license": "BSD",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tokenize-output",
            "package_url": "https://pypi.org/project/tokenize-output/",
            "platform": "any",
            "project_url": "https://pypi.org/project/tokenize-output/",
            "project_urls": {
                "Code": "https://github.com/anki-code/tokenize-output",
                "Documentation": "https://github.com/anki-code/tokenize-output/blob/master/README.md",
                "Homepage": "https://github.com/anki-code/tokenize-output",
                "Issue tracker": "https://github.com/anki-code/tokenize-output/issues"
            },
            "release_url": "https://pypi.org/project/tokenize-output/0.4.7/",
            "requires_dist": [
                "demjson3"
            ],
            "requires_python": ">=3.6",
            "summary": "Get identifiers, names, paths, URLs and words from the command output.",
            "version": "0.4.7",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 14338385,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "2fa718f29ac7e91c3500e42545db8369",
                    "sha256": "50865d9d3dcc2ea4b85419f4ce09ff801950bcf3fab45309b6b4816d39017631"
                },
                "downloads": -1,
                "filename": "tokenize_output-0.4.7-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "2fa718f29ac7e91c3500e42545db8369",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 5582,
                "upload_time": "2022-07-05T09:40:47",
                "upload_time_iso_8601": "2022-07-05T09:40:47.570629Z",
                "url": "https://files.pythonhosted.org/packages/ca/58/99c16c0bab30afc8c99241f340c4a47ef80aba2cca73a4306e0e37dac241/tokenize_output-0.4.7-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "5241249bbd96b4d6042675cec924acfb",
                    "sha256": "6ff7df87997a60ef40db4bed7a40465cb31975f5dfaf353d9f35f2c5aef1651d"
                },
                "downloads": -1,
                "filename": "tokenize-output-0.4.7.tar.gz",
                "has_sig": false,
                "md5_digest": "5241249bbd96b4d6042675cec924acfb",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 5061,
                "upload_time": "2022-07-05T09:40:48",
                "upload_time_iso_8601": "2022-07-05T09:40:48.842378Z",
                "url": "https://files.pythonhosted.org/packages/4d/fe/41a98f3e305d3d78e7ad7799ae460a0e7d45145d7b8b9196154493f4384f/tokenize-output-0.4.7.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.0.0": {
        "info": {
            "author": "Juan Sensio",
            "author_email": "juansensio03@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.7",
                "Topic :: Software Development :: Build Tools"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/juansensio/mypytorch",
            "keywords": "python,pytorch",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mypytorch",
            "package_url": "https://pypi.org/project/mypytorch/",
            "platform": "",
            "project_url": "https://pypi.org/project/mypytorch/",
            "project_urls": {
                "Homepage": "https://github.com/juansensio/mypytorch"
            },
            "release_url": "https://pypi.org/project/mypytorch/0.0.0/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "My Pytorch bindings",
            "version": "0.0.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7255657,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5df0411d11fb2db2d957c3b0fcd527fd",
                    "sha256": "64ecbca477b14bccec8456d4cf0fbbc6c83ded73eda0696043c123ab3920cc13"
                },
                "downloads": -1,
                "filename": "mypytorch-0.0.0.tar.gz",
                "has_sig": false,
                "md5_digest": "5df0411d11fb2db2d957c3b0fcd527fd",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 2389,
                "upload_time": "2020-05-13T10:11:36",
                "upload_time_iso_8601": "2020-05-13T10:11:36.779255Z",
                "url": "https://files.pythonhosted.org/packages/d6/13/c428906f7b0cbb1161d90c0a6a9447bc8eb920599b0ba6e5f794d4587842/mypytorch-0.0.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1": {
        "info": {
            "author": "Juan Sensio",
            "author_email": "juansensio03@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.7",
                "Topic :: Software Development :: Build Tools"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/juansensio/mypytorch",
            "keywords": "python,pytorch",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mypytorch",
            "package_url": "https://pypi.org/project/mypytorch/",
            "platform": "",
            "project_url": "https://pypi.org/project/mypytorch/",
            "project_urls": {
                "Homepage": "https://github.com/juansensio/mypytorch"
            },
            "release_url": "https://pypi.org/project/mypytorch/0.0.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "My Pytorch bindings",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7255657,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b24cbfc817574fd788ec6bc5fa2419e8",
                    "sha256": "bc9b418628c2205670e4a4fb4bfcc32c3db2a02eb8c2a4d2cceb8585a843a4d4"
                },
                "downloads": -1,
                "filename": "mypytorch-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "b24cbfc817574fd788ec6bc5fa2419e8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 15039,
                "upload_time": "2020-05-13T15:40:57",
                "upload_time_iso_8601": "2020-05-13T15:40:57.817061Z",
                "url": "https://files.pythonhosted.org/packages/43/64/5f34f176cc7b8737e44bd3f2f91e70a2134b6d8fc6d92937007323db99cd/mypytorch-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.2": {
        "info": {
            "author": "Juan Sensio",
            "author_email": "juansensio03@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.7",
                "Topic :: Software Development :: Build Tools"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/juansensio/mypytorch",
            "keywords": "python,pytorch",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mypytorch",
            "package_url": "https://pypi.org/project/mypytorch/",
            "platform": "",
            "project_url": "https://pypi.org/project/mypytorch/",
            "project_urls": {
                "Homepage": "https://github.com/juansensio/mypytorch"
            },
            "release_url": "https://pypi.org/project/mypytorch/0.0.2/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "My Pytorch bindings",
            "version": "0.0.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7255657,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "761e925e47ed01ed810624193ce39648",
                    "sha256": "c5c4cbddca56a9d5b3ede0980aaea3ebb2424b298a295104543964ebc7870d0c"
                },
                "downloads": -1,
                "filename": "mypytorch-0.0.2.tar.gz",
                "has_sig": false,
                "md5_digest": "761e925e47ed01ed810624193ce39648",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 15246,
                "upload_time": "2020-05-13T16:17:24",
                "upload_time_iso_8601": "2020-05-13T16:17:24.990002Z",
                "url": "https://files.pythonhosted.org/packages/5d/74/0dc370cd2361c06d1b66af4bc0609ff23d596e3a84aca80e0a5c40eafc3a/mypytorch-0.0.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.3": {
        "info": {
            "author": "Juan Sensio",
            "author_email": "juansensio03@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.7",
                "Topic :: Software Development :: Build Tools"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/juansensio/mypytorch",
            "keywords": "python,pytorch",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mypytorch",
            "package_url": "https://pypi.org/project/mypytorch/",
            "platform": "",
            "project_url": "https://pypi.org/project/mypytorch/",
            "project_urls": {
                "Homepage": "https://github.com/juansensio/mypytorch"
            },
            "release_url": "https://pypi.org/project/mypytorch/0.0.3/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "My Pytorch bindings",
            "version": "0.0.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7255657,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "980dc7979cc96606ad2945cb93bba060",
                    "sha256": "995eeb8ff930c5f675d025893c6aab9a4486186e6f09d5a934c876a912eeb15f"
                },
                "downloads": -1,
                "filename": "mypytorch-0.0.3.tar.gz",
                "has_sig": false,
                "md5_digest": "980dc7979cc96606ad2945cb93bba060",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 15274,
                "upload_time": "2020-05-13T16:58:04",
                "upload_time_iso_8601": "2020-05-13T16:58:04.815372Z",
                "url": "https://files.pythonhosted.org/packages/0b/2d/cf3f2db737da9a51afc2f0404f3fed9d819c8c634202b42344011b7d080d/mypytorch-0.0.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.4": {
        "info": {
            "author": "Juan Sensio",
            "author_email": "juansensio03@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.7",
                "Topic :: Software Development :: Build Tools"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/juansensio/mypytorch",
            "keywords": "python,pytorch",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mypytorch",
            "package_url": "https://pypi.org/project/mypytorch/",
            "platform": "",
            "project_url": "https://pypi.org/project/mypytorch/",
            "project_urls": {
                "Homepage": "https://github.com/juansensio/mypytorch"
            },
            "release_url": "https://pypi.org/project/mypytorch/0.0.4/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "My Pytorch bindings",
            "version": "0.0.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7255657,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5f5ed68231221eed891e9a834c08f3b8",
                    "sha256": "a75885fcac4e87309b3a38751b910768f88a3344d63455963961a8466b34158e"
                },
                "downloads": -1,
                "filename": "mypytorch-0.0.4.tar.gz",
                "has_sig": false,
                "md5_digest": "5f5ed68231221eed891e9a834c08f3b8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 15498,
                "upload_time": "2020-05-13T17:28:11",
                "upload_time_iso_8601": "2020-05-13T17:28:11.034658Z",
                "url": "https://files.pythonhosted.org/packages/90/7a/4d35db4a3435f745e1e8bc82695e6a9ea8931ffd6a33d57c96be18d3423b/mypytorch-0.0.4.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.5": {
        "info": {
            "author": "Juan Sensio",
            "author_email": "juansensio03@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.7",
                "Topic :: Software Development :: Build Tools"
            ],
            "description": "# MyPytorch\n\n`MyPytorch` provides convenient functionality to abstract some of `Pytorch` tedious and repetitive work but without compromising on flexibility.\n\n\n```python\nfrom mypytorch import *\n```\n\nLet's see how to work with `MyPytorch` with the following example. First, we download some data (in this case we work with MNIST).\n\n\n```python\n# get some data\n\nfrom sklearn.datasets import fetch_openml\nimport numpy as np\n\nX, y = fetch_openml(\n    'mnist_784', \n    version=1, \n    return_X_y=True)\n\ny = y.astype(np.int)\n```\n\n\n```python\n# visualize images\n\nimport matplotlib.pyplot as plt\nimport random\n\nfig, axs = plt.subplots(3,5, figsize=(10,7))\nfor _ax in axs:\n    for ax in _ax:\n        ix = random.randint(0, len(X)-1)\n        img = X[ix].reshape((28,28))\n        ax.imshow(img)\n        ax.set_title(y[ix])\n        ax.axis('off')\n\nplt.show()\n```\n\n\n![png](pics/output_6_0.png)\n\n\n\n```python\n# train-validation-test split\n\nX_train, y_train, X_test, y_test = X[:1100] / 255., y[:1100], X[1100:1200] / 255., y[1100:1200]\nX_train, y_train, X_eval, y_eval = X_train[:1000], y_train[:1000], X_train[1000:], y_train[1000:]\n\nX_train.shape, y_train.shape, X_eval.shape, y_eval.shape, X_test.shape, y_test.shape\n```\n\n\n\n\n    ((1000, 784), (1000,), (100, 784), (100,), (100, 784), (100,))\n\n\n\nThe basic module of `MyPytorch` is the `Model`, and in order to define a model we first need a `Network`. You define a neural network like in `Pytorch`.\n\n\n```python\n# define a network\n\nimport torch\n\nclass Net(torch.nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.fc1 = torch.nn.Linear(28*28, 100)\n        self.relu = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(100, 10)\n    \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\n    \nnet = Net()\nnet(torch.randn(32, 28*28)).shape\n```\n\n\n\n\n    torch.Size([32, 10])\n\n\n\nThe `Model` is instantiated with the `Network` but in order to train it we need to `compile` it with an `optimizer` and a `loss` function. We can define them just like in `Pytorch`.\n\n\n```python\n# define a model\n\nnet = Net()\nmodel = MyModel(net)\n\n# define optimizer and loss function\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\n\n# compile the model\n\nmodel.compile(optimizer, loss)\n```\n\nTo train the `Network` we call the `fit` function of our `Model`. We only need to pass a `Dataloader`. You can define your own dataloader and it will work as long as you can iterate on it.\n\n\n```python\n# train the network\n\nbatch_size = 32\nbatches = len(X_train) // batch_size\ndataloader = [\n    (torch.tensor(X_train[i*batch_size:(i+1)*batch_size]).float(), \n     torch.tensor(y_train[i*batch_size:(i+1)*batch_size]).long()) \n    for i in range(batches)\n]\n\nhist = model.fit(dataloader)\n```\n\n\nEpoch 1/10  loss 1.99136<p>Epoch 2/10  loss 1.15712<p>Epoch 3/10  loss 0.71965<p>Epoch 4/10  loss 0.54304<p>Epoch 5/10  loss 0.44808<p>Epoch 6/10  loss 0.38635<p>Epoch 7/10  loss 0.34145<p>Epoch 8/10  loss 0.30618<p>Epoch 9/10  loss 0.27706<p>Epoch 10/10  loss 0.25207\n\n\nYou can (and should) use `Pytorch` own `DataLoaders`.\n\n\n```python\nfrom torch.utils.data import Dataset, DataLoader\n\nclass MyDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, ix):\n        return torch.tensor(self.X[ix]).float(), torch.tensor(self.y[ix]).long()\n    \ndataset = MyDataset(X_train, y_train)\ndatalaoder = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n```\n\n\n```python\nnet = Net()\nmodel = MyModel(net)\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmodel.compile(optimizer, loss)\nhist = model.fit(dataloader)\n```\n\n\nEpoch 1/10  loss 1.95815<p>Epoch 2/10  loss 1.10758<p>Epoch 3/10  loss 0.69818<p>Epoch 4/10  loss 0.53266<p>Epoch 5/10  loss 0.44248<p>Epoch 6/10  loss 0.38358<p>Epoch 7/10  loss 0.3405<p>Epoch 8/10  loss 0.30634<p>Epoch 9/10  loss 0.27786<p>Epoch 10/10  loss 0.25341\n\n\nYou can pass a list of `Metrics` to the `compile` function in order to evaluate the `Network` during training. \n\n\n```python\n# adding metrics\n\nnet = Net()\nmodel = MyModel(net)\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy()]\n\nmodel.compile(optimizer, loss, metrics)\n\nhist = model.fit(dataloader)\n```\n\n\nEpoch 1/10  loss 1.99799 acc 0.4869<p>Epoch 2/10  loss 1.15223 acc 0.76915<p>Epoch 3/10  loss 0.6995 acc 0.8377<p>Epoch 4/10  loss 0.5272 acc 0.86694<p>Epoch 5/10  loss 0.43763 acc 0.88407<p>Epoch 6/10  loss 0.38001 acc 0.89214<p>Epoch 7/10  loss 0.33786 acc 0.90625<p>Epoch 8/10  loss 0.30444 acc 0.91734<p>Epoch 9/10  loss 0.27655 acc 0.92843<p>Epoch 10/10  loss 0.25238 acc 0.93246\n\n\nA `Metric` is just a regular class with a `name` and the corresponding function to compute the metric. You can use multiple `Metrics` and also write your own.\n\n\n```python\nfrom sklearn.metrics import f1_score\n\nclass F1():\n    def __init__(self):\n        self.name = \"F1\"\n    def __call__(self, y_hat, y):\n        return f1_score(y.cpu(), torch.argmax(y_hat, axis=1).cpu().detach(), average='macro').item()\n\nnet = Net()\nmodel = MyModel(net)\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy(), F1()]\n\nmodel.compile(optimizer, loss, metrics)\n\nhist = model.fit(dataloader)\n```\n\n\nEpoch 1/10  loss 1.97591 acc 0.51008 F1 0.4544<p>Epoch 2/10  loss 1.11875 acc 0.75605 F1 0.71131<p>Epoch 3/10  loss 0.70105 acc 0.83367 F1 0.80737<p>Epoch 4/10  loss 0.53526 acc 0.86694 F1 0.84931<p>Epoch 5/10  loss 0.44538 acc 0.87601 F1 0.86108<p>Epoch 6/10  loss 0.38682 acc 0.89415 F1 0.87824<p>Epoch 7/10  loss 0.34412 acc 0.90524 F1 0.8888<p>Epoch 8/10  loss 0.31014 acc 0.91532 F1 0.90095<p>Epoch 9/10  loss 0.28198 acc 0.92339 F1 0.91297<p>Epoch 10/10  loss 0.25767 acc 0.92944 F1 0.92055\n\n\nYou can pass data for evaluation during training as a second parameter of the `compile` function. Evaluation data must be also a `Dataloader`.\n\n\n```python\n# adding evaluation data\n\neval_dataset = MyDataset(X_eval, y_eval)\neval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=True)\n        \nnet = Net()\nmodel = MyModel(net)\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy(), F1()]\n\nmodel.compile(optimizer, loss, metrics)\n\nhist = model.fit(dataloader, eval_dataloader)\n```\n\n\nEpoch 1/10  loss 1.97824 acc 0.54435 F1 0.476  eval_loss 1.62018 eval_acc 0.70312 eval_F1 0.52057<p>Epoch 2/10  loss 1.12812 acc 0.7621 F1 0.71212  eval_loss 1.03902 eval_acc 0.75 eval_F1 0.62577<p>Epoch 3/10  loss 0.70452 acc 0.83972 F1 0.81291  eval_loss 0.79963 eval_acc 0.78906 eval_F1 0.6761<p>Epoch 4/10  loss 0.53748 acc 0.8629 F1 0.84499  eval_loss 0.89987 eval_acc 0.74219 eval_F1 0.66277<p>Epoch 5/10  loss 0.44723 acc 0.87802 F1 0.86192  eval_loss 0.65931 eval_acc 0.79688 eval_F1 0.74391<p>Epoch 6/10  loss 0.38843 acc 0.89113 F1 0.87569  eval_loss 0.67273 eval_acc 0.79688 eval_F1 0.68275<p>Epoch 7/10  loss 0.3454 acc 0.90625 F1 0.89326  eval_loss 0.57253 eval_acc 0.84375 eval_F1 0.8178<p>Epoch 8/10  loss 0.31145 acc 0.91935 F1 0.9052  eval_loss 0.71521 eval_acc 0.78906 eval_F1 0.71851<p>Epoch 9/10  loss 0.28318 acc 0.92843 F1 0.91801  eval_loss 0.60076 eval_acc 0.85156 eval_F1 0.81746<p>Epoch 10/10  loss 0.25873 acc 0.93145 F1 0.92216  eval_loss 0.55954 eval_acc 0.85156 eval_F1 0.76582\n\n\nBy default computations are executed on a `GPU` if available (if not the model will run in the `CPU`). You can specify your device in different ways.\n\n\n```python\nnet = Net()\nmodel = MyModel(net, device=\"cpu\") # now the default device is CPU for everything\n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy(), F1()]\n\nmodel.compile(optimizer, loss, metrics)\n\nhist = model.fit(dataloader, eval_dataloader, epochs=2)\n```\n\n\nEpoch 1/2  loss 1.96979 acc 0.53024 F1 0.46063  eval_loss 1.47816 eval_acc 0.71094 eval_F1 0.62278<p>Epoch 2/2  loss 1.1105 acc 0.76613 F1 0.72816  eval_loss 1.18418 eval_acc 0.70312 eval_F1 0.60498\n\n\n\n```python\nnet = Net()\nmodel = MyModel(net) \n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy(), F1()]\n\nmodel.compile(optimizer, loss, metrics)\n\n# fit on CPU, but the default device still is GPU (if available)\n\nhist = model.fit(dataloader, eval_dataloader, epochs=10, device=\"cpu\") \n```\n\n\nEpoch 1/10  loss 1.9707 acc 0.50403 F1 0.43994  eval_loss 1.51756 eval_acc 0.67969 eval_F1 0.5174<p>Epoch 2/10  loss 1.12484 acc 0.7631 F1 0.72922  eval_loss 1.01289 eval_acc 0.79688 eval_F1 0.75185<p>Epoch 3/10  loss 0.69954 acc 0.8377 F1 0.81406  eval_loss 1.00583 eval_acc 0.71094 eval_F1 0.6564<p>Epoch 4/10  loss 0.53259 acc 0.86895 F1 0.85148  eval_loss 0.72211 eval_acc 0.78906 eval_F1 0.71051<p>Epoch 5/10  loss 0.44368 acc 0.88306 F1 0.86737  eval_loss 0.84888 eval_acc 0.74219 eval_F1 0.66741<p>Epoch 6/10  loss 0.38588 acc 0.89113 F1 0.87572  eval_loss 0.60628 eval_acc 0.85938 eval_F1 0.80177<p>Epoch 7/10  loss 0.34355 acc 0.90121 F1 0.88637  eval_loss 0.67603 eval_acc 0.78906 eval_F1 0.69369<p>Epoch 8/10  loss 0.30982 acc 0.91734 F1 0.90263  eval_loss 0.57527 eval_acc 0.85156 eval_F1 0.80583<p>Epoch 9/10  loss 0.28156 acc 0.9244 F1 0.91464  eval_loss 0.61433 eval_acc 0.8125 eval_F1 0.755<p>Epoch 10/10  loss 0.25711 acc 0.93347 F1 0.92495  eval_loss 0.87156 eval_acc 0.82031 eval_F1 0.75841\n\n\nThe `fit` function will return the `history` of the training so you can plot training curves.\n\n\n```python\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(15,5))\nplt.subplot(121)\nplt.plot(hist[\"epochs\"], hist[\"metrics\"][\"loss\"], label=\"loss\")\nplt.plot(hist[\"epochs\"], hist[\"metrics\"][\"eval_loss\"], label=\"eval loss\")\nplt.grid(True)\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.subplot(122)\nplt.plot(hist[\"epochs\"], hist[\"metrics\"][\"acc\"], label=\"acc\")\nplt.plot(hist[\"epochs\"], hist[\"metrics\"][\"eval_acc\"], label=\"eval acc\")\nplt.plot(hist[\"epochs\"], hist[\"metrics\"][\"F1\"], label=\"F1\")\nplt.plot(hist[\"epochs\"], hist[\"metrics\"][\"eval_F1\"], label=\"eval F1\")\nplt.xlabel(\"Epoch\")\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n\n![png](pics/output_27_0.png)\n\n\nYou can `evaluate` your model to get some metrics like this \n\n\n```python\nmodel.evaluate(eval_dataloader)\n```\n\n\neval_loss 0.52886 eval_acc 0.875 eval_F1 0.84095\n\n\nAnd get some predictions with the `predict` method\n\n\n```python\ntest_dataloader = [torch.tensor(X_test[:10]).float()]\n\ny_hat = model.predict(test_dataloader)\nprobas = torch.softmax(y_hat, axis = 1)\npreds = torch.argmax(probas, axis = 1)\n\npreds, y_test[:10]\n```\n\n\n\n<div>\n    <style>\n        /* Turns off some styling */\n        progress {\n            /* gets rid of default border in Firefox and Opera. */\n            border: none;\n            /* Needs to be in here for Safari polyfill so background images work as expected. */\n            background-size: auto;\n        }\n        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n            background: #F44336;\n        }\n    </style>\n  <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n  100.00% [1/1 00:00<00:00]\n</div>\n\n\n\n\n\n\n    (tensor([6, 8, 5, 9, 5, 8, 7, 0, 3, 5], device='cuda:0',\n            grad_fn=<NotImplemented>),\n     array([6, 8, 0, 9, 5, 8, 7, 0, 3, 5]))\n\n\n\n## Flexibility\n\nYou can use our building blocks to do more complicated stuff like `early stopping` or `learning rate scheduling` (although we support that).\n\n\n```python\nnet = Net()\nmodel = MyModel(net) \n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.01)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy(), F1()]\n\nmodel.compile(optimizer, loss, metrics)\n\nepochs = 100\nbest_loss, step, early_stop = 1e10, 0, 3\nfor e in range(1, epochs+1):\n    \n    train_metrics = model.train(dataloader)    \n    eval_metrics = model.eval(eval_dataloader, device=\"cpu\")\n    print(f\"Epoch {e}/{epochs} {train_metrics} {eval_metrics}\")\n    \n    # early stop\n    eval_loss = eval_metrics['eval_loss']\n    step = step + 1\n    if eval_loss < best_loss:\n        best_loss = eval_loss\n        step = 0\n    if step >= early_stop:\n        print(f\"Early stopping at epoch {e}\")\n        break\n```\n\n    Epoch 1/100  loss 2.28437 acc 0.14214 F1 0.09496  eval_loss 2.24477 eval_acc 0.15625 eval_F1 0.10752\n    Epoch 2/100  loss 2.22458 acc 0.30948 F1 0.26141  eval_loss 2.1856 eval_acc 0.5 eval_F1 0.40614\n    Epoch 3/100  loss 2.15845 acc 0.50101 F1 0.44378  eval_loss 2.13385 eval_acc 0.57031 eval_F1 0.43026\n    Epoch 4/100  loss 2.08266 acc 0.60484 F1 0.54757  eval_loss 2.05999 eval_acc 0.5625 eval_F1 0.46542\n    Epoch 5/100  loss 1.99796 acc 0.6623 F1 0.60319  eval_loss 1.9568 eval_acc 0.71094 eval_F1 0.56703\n    Epoch 6/100  loss 1.90427 acc 0.69153 F1 0.63079  eval_loss 1.8793 eval_acc 0.76562 eval_F1 0.70411\n    Epoch 7/100  loss 1.80246 acc 0.70968 F1 0.65215  eval_loss 1.79829 eval_acc 0.75781 eval_F1 0.67091\n    Epoch 8/100  loss 1.69496 acc 0.72581 F1 0.67075  eval_loss 1.75112 eval_acc 0.77344 eval_F1 0.68644\n    Epoch 9/100  loss 1.58603 acc 0.73589 F1 0.67894  eval_loss 1.57126 eval_acc 0.73438 eval_F1 0.65294\n    Epoch 10/100  loss 1.47924 acc 0.74294 F1 0.69032  eval_loss 1.58471 eval_acc 0.6875 eval_F1 0.57087\n    Epoch 11/100  loss 1.37742 acc 0.75504 F1 0.70785  eval_loss 1.50139 eval_acc 0.75 eval_F1 0.63293\n    Epoch 12/100  loss 1.28234 acc 0.77016 F1 0.7249  eval_loss 1.34448 eval_acc 0.82812 eval_F1 0.78028\n    Epoch 13/100  loss 1.19535 acc 0.77823 F1 0.73671  eval_loss 1.32964 eval_acc 0.71875 eval_F1 0.63572\n    Epoch 14/100  loss 1.11691 acc 0.78327 F1 0.7467  eval_loss 1.1703 eval_acc 0.83594 eval_F1 0.79638\n    Epoch 15/100  loss 1.04675 acc 0.79839 F1 0.76401  eval_loss 1.28964 eval_acc 0.73438 eval_F1 0.66533\n    Epoch 16/100  loss 0.98435 acc 0.81149 F1 0.78336  eval_loss 1.19126 eval_acc 0.78125 eval_F1 0.6906\n    Epoch 17/100  loss 0.9289 acc 0.82157 F1 0.7928  eval_loss 1.07859 eval_acc 0.83594 eval_F1 0.77242\n    Epoch 18/100  loss 0.87959 acc 0.82863 F1 0.80025  eval_loss 1.04709 eval_acc 0.78125 eval_F1 0.62931\n    Epoch 19/100  loss 0.83565 acc 0.83569 F1 0.81038  eval_loss 0.95057 eval_acc 0.83594 eval_F1 0.73592\n    Epoch 20/100  loss 0.79636 acc 0.84173 F1 0.8185  eval_loss 0.93946 eval_acc 0.83594 eval_F1 0.76038\n    Epoch 21/100  loss 0.76113 acc 0.84677 F1 0.82489  eval_loss 1.02549 eval_acc 0.78125 eval_F1 0.70139\n    Epoch 22/100  loss 0.72943 acc 0.8498 F1 0.82764  eval_loss 0.91239 eval_acc 0.83594 eval_F1 0.80488\n    Epoch 23/100  loss 0.70078 acc 0.85181 F1 0.83018  eval_loss 0.94465 eval_acc 0.77344 eval_F1 0.63058\n    Epoch 24/100  loss 0.67479 acc 0.85887 F1 0.83703  eval_loss 0.9098 eval_acc 0.77344 eval_F1 0.6976\n    Epoch 25/100  loss 0.6511 acc 0.86089 F1 0.84087  eval_loss 0.79746 eval_acc 0.82812 eval_F1 0.77353\n    Epoch 26/100  loss 0.62944 acc 0.86492 F1 0.84596  eval_loss 0.93608 eval_acc 0.78125 eval_F1 0.70442\n    Epoch 27/100  loss 0.60954 acc 0.86794 F1 0.84983  eval_loss 0.79635 eval_acc 0.84375 eval_F1 0.75108\n    Epoch 28/100  loss 0.5912 acc 0.875 F1 0.85971  eval_loss 0.85732 eval_acc 0.79688 eval_F1 0.71984\n    Epoch 29/100  loss 0.57424 acc 0.875 F1 0.85881  eval_loss 0.7743 eval_acc 0.79688 eval_F1 0.70714\n    Epoch 30/100  loss 0.55849 acc 0.87601 F1 0.8598  eval_loss 0.80398 eval_acc 0.85156 eval_F1 0.78112\n    Epoch 31/100  loss 0.54383 acc 0.88004 F1 0.86276  eval_loss 0.9629 eval_acc 0.74219 eval_F1 0.65322\n    Epoch 32/100  loss 0.53014 acc 0.88306 F1 0.86988  eval_loss 0.77224 eval_acc 0.85156 eval_F1 0.80185\n    Epoch 33/100  loss 0.51732 acc 0.88407 F1 0.87062  eval_loss 0.8065 eval_acc 0.80469 eval_F1 0.72396\n    Epoch 34/100  loss 0.5053 acc 0.88508 F1 0.87196  eval_loss 0.67485 eval_acc 0.85938 eval_F1 0.8332\n    Epoch 35/100  loss 0.49399 acc 0.8881 F1 0.87297  eval_loss 1.03528 eval_acc 0.80469 eval_F1 0.71252\n    Epoch 36/100  loss 0.48333 acc 0.88911 F1 0.87394  eval_loss 0.79309 eval_acc 0.80469 eval_F1 0.74181\n    Epoch 37/100  loss 0.47325 acc 0.89113 F1 0.87593  eval_loss 0.70955 eval_acc 0.86719 eval_F1 0.81513\n    Early stopping at epoch 37\n    \n\nOr even build your custom `Model` (you will have access to the `optimizer`, `loss` function, `metrics`, batches, etc).\n\n\n```python\nclass MyCustomModel(MyModel):\n    \n    # build your own prediction function\n    \n    def predict(self, dataset, device=\"cpu\"):\n        self.net.to(device)\n        self.net.eval()\n        preds = []\n        for X in dataset:\n            X = torch.tensor(X).float()\n            X = X.to(device)\n            y_hat = self.net(X.unsqueeze(0))\n            probas = torch.softmax(y_hat, axis=1)\n            pred = torch.argmax(probas, axis=1)\n            preds.append(pred.item())\n        return preds\n```\n\n\n```python\nnet = Net()\nmodel = MyCustomModel(net) \n\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)\nloss = torch.nn.CrossEntropyLoss()\nmetrics = [Accuracy(), F1()]\n\nmodel.compile(optimizer, loss, metrics)\n\nhist = model.fit(dataloader, eval_dataloader)\n```\n\n\nEpoch 1/10  loss 1.95079 acc 0.5121 F1 0.444  eval_loss 1.45498 eval_acc 0.72656 eval_F1 0.66349<p>Epoch 2/10  loss 1.10137 acc 0.76815 F1 0.72531  eval_loss 1.08671 eval_acc 0.75781 eval_F1 0.65991<p>Epoch 3/10  loss 0.69632 acc 0.83972 F1 0.81439  eval_loss 1.02583 eval_acc 0.78906 eval_F1 0.74668<p>Epoch 4/10  loss 0.53076 acc 0.86492 F1 0.84749  eval_loss 0.70602 eval_acc 0.85938 eval_F1 0.80634<p>Epoch 5/10  loss 0.44148 acc 0.88004 F1 0.86564  eval_loss 0.6754 eval_acc 0.86719 eval_F1 0.81322<p>Epoch 6/10  loss 0.38359 acc 0.89617 F1 0.88165  eval_loss 0.6672 eval_acc 0.86719 eval_F1 0.8592<p>Epoch 7/10  loss 0.34096 acc 0.90323 F1 0.88823  eval_loss 0.55951 eval_acc 0.86719 eval_F1 0.80959<p>Epoch 8/10  loss 0.307 acc 0.91633 F1 0.90295  eval_loss 0.63003 eval_acc 0.82031 eval_F1 0.67254<p>Epoch 9/10  loss 0.27858 acc 0.92742 F1 0.91722  eval_loss 0.52667 eval_acc 0.86719 eval_F1 0.83345<p>Epoch 10/10  loss 0.25406 acc 0.93145 F1 0.92172  eval_loss 0.52484 eval_acc 0.86719 eval_F1 0.81528\n\n\n\n```python\npreds = model.predict(X_test)\n\npreds[:10], y_test[:10]\n```\n\n\n\n\n    ([6, 8, 5, 9, 5, 8, 7, 0, 3, 5], array([6, 8, 0, 9, 5, 8, 7, 0, 3, 5]))\n\n\n\n\n```python\n\n```",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/juansensio/mypytorch",
            "keywords": "python,pytorch",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mypytorch",
            "package_url": "https://pypi.org/project/mypytorch/",
            "platform": "",
            "project_url": "https://pypi.org/project/mypytorch/",
            "project_urls": {
                "Homepage": "https://github.com/juansensio/mypytorch"
            },
            "release_url": "https://pypi.org/project/mypytorch/0.0.5/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "My Pytorch bindings",
            "version": "0.0.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7255657,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e1b7768bd0760dd901e774de636aabda",
                    "sha256": "8fff91e5140bac649c169442788667ebf18ca36c111077dae009be3465892912"
                },
                "downloads": -1,
                "filename": "mypytorch-0.0.5.tar.gz",
                "has_sig": false,
                "md5_digest": "e1b7768bd0760dd901e774de636aabda",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 16318,
                "upload_time": "2020-05-16T13:54:48",
                "upload_time_iso_8601": "2020-05-16T13:54:48.141997Z",
                "url": "https://files.pythonhosted.org/packages/5f/2d/056c5e5a0e237b70fb8fb02ab7ac6eefb40c26780c6ca0fc138c8887d831/mypytorch-0.0.5.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
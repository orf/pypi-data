{
    "1.1.0": {
        "info": {
            "author": "Timofey Arkhangelskiy",
            "author_email": "timarkh@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Topic :: Text Processing :: Linguistic"
            ],
            "description": "# Turoyo morphological analyzer\n\nThis is a rule-based morphological analyzer for \u1e6curoyo (``tru``, Afro-Asiatic > Central Neo-Aramaic). It is based on a formalized description of Turoyo morphology and uses [uniparser-morph](https://github.com/timarkh/uniparser-morph) for parsing. It performs full morphological analysis of Turoyo words (lemmatization, POS tagging, grammatical tagging). The text to be analyzed should be written in a version of Latin Turoyo alphabet which is somewhat closer to IPA: it uses *\u0294* instead of *'*, *\u0295* instead of *c*, *\u0259* insteadt of *\u00eb* etc.\n\n## How to use\n### Python package\nThe analyzer is available as a Python package. If you want to analyze Turoyo texts in Python, install the module:\n\n```\npip3 install uniparser-turoyo\n```\n\nImport the module and create an instance of ``TuroyoAnalyzer`` class. Set ``mode='strict'`` if you are going to process text in standard Latin Turoyo alphabet, or ``mode='nodiacritics'`` if you expect some words to lack the diacritics (e.g. *t* instead of *\u1e6d*). After that, you can either parse tokens or lists of tokens with ``analyze_words()``, or parse a frequency list with ``analyze_wordlist()``. Here is a simple example:\n\n```python\nfrom uniparser_turoyo import TuroyoAnalyzer\na = TuroyoAnalyzer(mode='strict')\n\nanalyses = a.analyze_words('koro\u1e25amnux')\n# The parser is initialized before first use, so expect\n# some delay here (usually several seconds)\n\n# You will get a list of Wordform objects\n# The analysis attributes are stored in its properties\n# as string values, e.g.:\nfor ana in analyses:\n        print(ana.wf, ana.lemma, ana.gramm)\n\n# You can also pass lists (even nested lists) and specify\n# output format ('xml', 'json' or 'conll')\n# If you pass a list, you will get a list of analyses\n# with the same structure\nanalyses = a.analyze_words([['koro\u1e25amnux'], ['\u0295\u0259barwo', 'lab', 'bote', '.']],\n\t                       format='xml')\nanalyses = a.analyze_words([['koro\u1e25amnux'], ['\u0295\u0259barwo', 'lab', 'bote', '.']],\n\t                       format='conll')\nanalyses = a.analyze_words(['koro\u1e25amnux', [['la\u1e25mawo'], ['\u0295\u0259barwo', 'lab', 'bote', '.']]],\n\t                       format='json')\n```\n\nRefer to the [uniparser-morph documentation](https://uniparser-morph.readthedocs.io/en/latest/) for the full list of options.\n\n<!---\n### Disambiguation\nApart from the analyzer, this repository contains a set of [Constraint Grammar](https://visl.sdu.dk/constraint_grammar.html) rules that can be used for partial disambiguation of analyzed Turoyo texts. If you want to use them, set ``disambiguation=True`` when calling ``analyze_words``:\n\n```python\nanalyses = a.analyze_words(['\u0295\u0259barwo', 'lab', 'bote', '.'], disambiguate=True)\n```\n\nIn order for this to work, you have to install the ``cg3`` executable separately. On Ubuntu/Debian, you can use ``apt-get``:\n\n```\nsudo apt-get install cg3\n```\n\nOn Windows, download the binary and add the path to the ``PATH`` environment variable. See [the documentation](https://visl.sdu.dk/cg3/single/#installation) for other options.\n\nNote that each time you call ``analyze_words()`` with ``disambiguate=True``, the CG grammar is loaded and compiled from scratch, which makes the analysis even slower. If you are analyzing a large text, it would make sense to pass the entire text contents in a single function call rather than do it sentence-by-sentence, for optimal performance.\n-->\n\n### Word lists\nAlternatively, you can use a preprocessed word list. The ``wordlists`` directory contains a list of words from a 600-thousand-word [\u1e6curoyo corpus](https://neo-aramaic.web-corpora.net/index_en.html) (``wordlist.csv``) with 53,000 unique tokens, list of analyzed tokens (``wordlist_analyzed.txt``; each line contains all possible analyses for one word in an XML format), and list of tokens the parser could not analyze (``wordlist_unanalyzed.txt``). The recall of the analyzer on the corpus texts is about 90%. (This number is somewhat low due to orthographic variability in the texts.)\n\n## Description format\nThe description is carried out in the ``uniparser-morph`` format and involves a description of the inflection (paradigms/paradigms_XXX.txt) and a grammatical dictionary (lexemes-XXX.txt files). The dictionary contains descriptions of individual lexemes, each of which is accompanied by information about its stem, its part-of-speech tag and some other grammatical information, its consonant root, its inflectional type (paradigm), and English and/or German translations. See more about the format [in the uniparser-morph documentation](https://uniparser-morph.readthedocs.io/en/latest/format.html).\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/margisk/uniparser-grammar-turoyo",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "uniparser-turoyo",
            "package_url": "https://pypi.org/project/uniparser-turoyo/",
            "platform": "",
            "project_url": "https://pypi.org/project/uniparser-turoyo/",
            "project_urls": {
                "Bug Tracker": "https://github.com/margisk/uniparser-grammar-turoyo/issues",
                "Homepage": "https://github.com/margisk/uniparser-grammar-turoyo"
            },
            "release_url": "https://pypi.org/project/uniparser-turoyo/1.1.0/",
            "requires_dist": [
                "uniparser-morph (>=2.4.1)",
                "importlib-resources"
            ],
            "requires_python": ">=3.7",
            "summary": "Rule-based morphological analysis for Turoyo",
            "version": "1.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 11458965,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "fcdd0a6027381ed7cabb84127a46d2bd",
                    "sha256": "3cbc21162e49781641bc0d8160b53c1b387b4ba818790280d90ae6dfbf44fb13"
                },
                "downloads": -1,
                "filename": "uniparser_turoyo-1.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "fcdd0a6027381ed7cabb84127a46d2bd",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 1178539,
                "upload_time": "2021-09-15T13:42:24",
                "upload_time_iso_8601": "2021-09-15T13:42:24.266961Z",
                "url": "https://files.pythonhosted.org/packages/4a/06/e93216a9a4d0cb0becea57da4e0ce22a1448ab384f81d31a62766bd747df/uniparser_turoyo-1.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "8c85161c5f36ecf68577ef81a18b15ff",
                    "sha256": "c8947083b50c66766297fae6db79896e821320c4a723b0794ee045a0524520e3"
                },
                "downloads": -1,
                "filename": "uniparser-turoyo-1.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "8c85161c5f36ecf68577ef81a18b15ff",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 1158771,
                "upload_time": "2021-09-15T13:42:26",
                "upload_time_iso_8601": "2021-09-15T13:42:26.242779Z",
                "url": "https://files.pythonhosted.org/packages/4b/d8/46990c130580516198deb614bcfa750dd271e71be7b0cc37f419a3ff3234/uniparser-turoyo-1.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
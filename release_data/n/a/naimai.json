{
    "1.0.0": {
        "info": {
            "author": "Yassine Kaddi",
            "author_email": "yassine@naimai.fr",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8"
            ],
            "description": "<p align =\"center\">\n  <img src=\"https://github.com/yassinekdi/naimai/blob/master/logo.png?raw=true\" \n  alt=\"Naimai logo\" height=\"25%\" width=\"25%\"/>\n</p>\n\nNaimAI is a Python package that (1) <b>searches effeciently in papers</b> and (2) <b>generates an automatic review</b>. It does do by structures each scientific paper using their abstract into 3 categories : objectives methods and results. \nHence, when searching, the results will be showed by category. The results can then be reviewed and a review text will be \nautomatically generated along with the references.\n<br>\nAll the features are deployed on the <a href=\"https://www.naimai.fr\" target=\"_blank\">NaimAI's website</a>, where millions of paper are processed. \n<br>\nA <a href=\"\" target=\"_blank\">Medium article</a> goes more in depth with naimai's features of the <a href=\"https://www.naimai.fr\" target=\"_blank\">web app</a>. \n<h1>Search in your own papers</h1>\n\nYou can either give a directory of the folder with articles in PDF format or a csv file with abstracts and other meta data as showed \n<a href=\"tests/papers/input_data\" target=\"_blank\">here</a>.\n<br>\nThe processing, the results and searching for relevent papers are explained in \n<a href=\"https://colab.research.google.com/drive/1xUDOkalxR7MFO6Zug48Cx1ysmgipaJCT?usp=sharing\" target=\"_blank\">this colab</a>.\n\n<h1> Search in millions of papers </h1>\nTo search in the millions of papers already processed, you can use the <a href=\"https://www.naimai.fr\" target=\"_blank\">naimai website</a>.\nI might open source this part too if needed.\n\n<h1>Structure your abstract</h1>\nIf you already have an abstract and want to test the segmentor (naimai's algorithm that structures abstract into Background, \nObjectives, Methods and Results), <a href=\"https://colab.research.google.com/drive/16PMGC7yxkTcFpUnlZtioBMa22tpaTid5?usp=sharing\">this colab</a>\nwalks you through the necessary steps.\n\n<h1> Features to improve </h2>\n<h3>Review Generation\u00a0</h3>\n<p>\nThe review generation needs more enhancement. The actual method consists of only rephrasing the objective phrase of each paper. \nI've some idea to go further and improve the review generation part. Let me know if you're interested and we'll do it\ntogether!</p>\n<p>\u00a0Besides the generated text, the references generation still can be brushed up to meet with many references style,\n and also to export it to other formats (BibTeX..).\n</p>\n<h3>Semantic search\u00a0</h3>\nThe search is mainly based on a v0 semantic algorithm (using TfIdf model mainly). In a previous version, \nI've finetuned bert model for each field and the results were pretty interesting. The problem is that, with 10 fields \non the web app, I ended up having 10 fine-tuned model. So the usage was pretty slow and the models were heavy.\nIf you have any idea and/or want to contribute in this part, I'll be happy to talk to you!\u00a0\n\n<h3>Data papers\u00a0</h3>\nI've used about 10 millions open access abstracts I found here and there on the internet. If you've any source that could be useful, or even better, if we can process much more papers together to get more informations for the users, that'd be cool!\n<h1>References</h1>\n<ul>\n    <li>\n    For abbreviations purposes, I used <a href=\"https://gist.github.com/ijmarshall/b3d1de6ccf4fb8b5ee53\" target=\"_blank\">this code</a>.\n    </li>\n    <li>\n    For PDF processing, I used <a href=\"https://github.com/kermitt2/grobid\" target=\"_blank\">Grobid</a>.\n    </li>\n</ul>\n\n\n[![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]\n\nThis work is licensed under a\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa].\n\n[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]\n\n[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/\n[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\n[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/yassinekdi/naimai",
            "keywords": "science,review,bibliography,python,nlp,machine-learning,information-extraction",
            "license": "CC BY-NC-SA",
            "maintainer": "Yassine Kaddi",
            "maintainer_email": "yassine@naimai.fr",
            "name": "naimai",
            "package_url": "https://pypi.org/project/naimai/",
            "platform": null,
            "project_url": "https://pypi.org/project/naimai/",
            "project_urls": {
                "Homepage": "https://github.com/yassinekdi/naimai"
            },
            "release_url": "https://pypi.org/project/naimai/1.0.0/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Python library to help with scientific literature research",
            "version": "1.0.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15999515,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b3d7cb9dd1dea963d64d86b89e2f5345",
                    "sha256": "8d638619db16a7e39cd630893e0540b7770230825f6e3de816ff7b1a6c9648a7"
                },
                "downloads": -1,
                "filename": "naimai-1.0.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b3d7cb9dd1dea963d64d86b89e2f5345",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 30576,
                "upload_time": "2022-12-05T20:08:20",
                "upload_time_iso_8601": "2022-12-05T20:08:20.752123Z",
                "url": "https://files.pythonhosted.org/packages/22/88/534020d8b7b904ac739d9730512f12ad8b7d17d4ae3a4005f9e47d204131/naimai-1.0.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "ad31892af62d715807787b06e2d3b16e",
                    "sha256": "f4811adb234581a2d4505c9c39b2357e255dab487a96f8f5f6e4c6f011785302"
                },
                "downloads": -1,
                "filename": "naimai-1.0.0.tar.gz",
                "has_sig": false,
                "md5_digest": "ad31892af62d715807787b06e2d3b16e",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 21043,
                "upload_time": "2022-12-05T20:08:22",
                "upload_time_iso_8601": "2022-12-05T20:08:22.857560Z",
                "url": "https://files.pythonhosted.org/packages/34/66/7737b6d73e8a55238099addfc6e519369c18af540508643d54ba3e7f7b35/naimai-1.0.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
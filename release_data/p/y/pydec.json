{
    "0.1.0": {
        "info": {
            "author": "Sen Yang",
            "author_email": "yangsen@smail.nju.edu.cn",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.9",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description": "\n[![Test](https://github.com/DoubleVII/pydec/actions/workflows/python-package-conda.yml/badge.svg?branch=master)](https://github.com/DoubleVII/pydec/actions/workflows/python-package-conda.yml)\n![Coverage badge](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/DoubleVII/pydec/python-coverage-comment-action-data/endpoint.json)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n\n\n<h1 align=\"center\" style=\"font-size:60px\">\n  PyDec\n</h1>\n\nPyDec is a linear decomposition toolkit for neural network based on [PyTorch](https://pytorch.org/), which can decompose the tensor in the forward process into given components with a small amount of code. The result of decomposition can be applied to tasks such as attribution analysis.\n\n# Examples\n## Attribution\nContribution Heat maps of the Roberta model (fine-tuned on SST-2). Warm colors indicate high\ncontribution while cool colors indicate low contribution. The outputs of the model were positive, negative and positive, but the latter two samples did not match the labels.\n\n<div align=\"center\">\n<img src=\"./docs/source/_static/img/pydec_demo1.png\" width=\"70%\">\n</div>\n\n## Data flow visualization\n\n![demo2](./docs/source/_static/img/pydec_demo2_1.gif)\n\n![demo2](./docs/source/_static/img/pydec_demo2_2.gif)\n\n# Requirements and Installation\n* [PyTorch](https://pytorch.org/) version >= 1.11.0\n* Python version >= 3.7\n* To install PyDec and develop locally:\n\n``` bash\ngit clone https://github.com/DoubleVII/pydec\ncd pydec\npip install --editable ./\n```\n\n# Getting Started\n\n## Example: deompose a tiny network\n\nSuppose a simple feedforward neural network containing two input tensors and outputting one tensor.\n```python\nclass NN(nn.Module):\n    def __init__(self) -> None:...\n\n    def forward(self, x1:Tensor, x2:Tensor) -> Tensor:\n        x1 = self.linear1(x1)\n        x1 = self.relu(x1)\n\n        x2 = self.linear2(x2)\n        x2 = self.relu(x2)\n\n        out = self.linear3(x1+x2)\n        return out\n```\nIn order to keep track of the components of inputs x1 and x2 in each hidden tensor, simply initialize the corresponding compositions and apply the same operation for them.\n```python\nclass NN(nn.Module):\n    def __init__(self) -> None:...\n\n    def forward(self, x1: Tensor, x2: Tensor) -> Tensor:\n        x1 = self.linear1(x1)\n        x1 = self.relu(x1)\n\n        x2 = self.linear2(x2)\n        x2 = self.relu(x2)\n\n        out = self.linear3(x1 + x2)\n\n        import pydec\n        from pydec import Composition\n        # Initialize composition\n        c1 = Composition(x1.size(), component_num=2).to(x1)\n        c1[0] = x1 # Assign x1 to the first component of c1.\n\n        c2 = Composition(x2.size(), component_num=2).to(x2)\n        c2[1] = x2 # Assign x2 to the second component of c2.\n\n        # Apply the same operation for composition\n        c1 = pydec.nn.functional.linear(\n            c1, weight=self.linear1.weight, bias=self.linear1.bias\n        )\n        c1 = pydec.nn.functional.relu(c1)\n\n        c2 = pydec.nn.functional.linear(\n            c2, weight=self.linear2.weight, bias=self.linear2.bias\n        )\n        c2 = pydec.nn.functional.relu(c2)\n        \n        c_out = pydec.nn.functional.linear3(\n            c1 + c2, weight=self.linear3.weight, bias=self.linear3.bias\n        )\n        return out, c_out\n```\n\nIn the above example, each composition consists of two components whose sum is always equal to the corresponding tensor being decomposed, e.g., $x_1=c_1[0]+c_1[1]$ and $out=c_{out}[0]+c_{out}[1]$. Usually, you can think of $c_{out}[i]$ as the contribution of $x_i$ to the tensor $out$.\n\n# Tutorials: understand composition\n\n## Decomposition\n\nGiven an arbitrary tensor $h$ in the network, there exists a way to decompose it into the sum of several components. As shown in the following equation,\n\n$$\nh = \\frac{\\mathscr{D}h}{\\mathscr{D}x_1} + \\cdots + \\frac{\\mathscr{D}h}{\\mathscr{D}x_m},\n$$\n\nwhere $x_1,\\cdots,x_m$ are the inputs to the network. Each component corresponds to one or some of the inputs (marked in the denominator), e.g., the components of $h$ corresponding to $\\{x_1, x_2\\}$ are denoted as $\\frac{\\mathscr{D}h}{\\mathscr{D}x_1\\mathscr{D}x_2}$\n\n## Composition\nIn PyDec, we use the data structure (i.e., Composition) to store the components, i.e., the right part of the above equation, while the left part can be obtained simply by summing the components.\n\n### Create a Composition\n```python\n>>> import pydec\n```\n\n**From size and component number**\n```python\n>>> size = (3, 2)\n>>> component_num = 4\n>>> c = pydec.Composition(size, component_num)\n```\nThis creates a composition containing 4 tensors of size (3, 2), initialized with 0.\n\n**From another Composition**\n```python\n>>> c_copy = pydec.Composition(c)\n```\nThis will clone an identical c, but without preserving any computational graph.\n\n**From component tensors**\n```python\n>>> component_num = 4\n>>> c_size = (component_num, 3, 2)\n>>> t = torch.randn(c_size) # 4 x 3 x 2\n\n>>> c_tensor = pydec.Composition(t)\n```\nThis also creates a composition containing 4 tensors of size (3, 2), initialized with tensor t.\n\n### Initialize a Composition\nAfter creating a Composition, we usually initialize the value of the Composition based on orthogonality, i.e.,\n\n$$\n\\frac{\\mathscr{D}x_i}{\\mathscr{D}x_j}=\\begin{cases}x_i, &\\text{if}\\ i=j\\\\ 0, &\\text{otherwise}\\end{cases}.\n$$\n\n**By assign**\n\n```python\n# The input consists of x0 and x1, each containing a tensor with a feature number of 2.\n>>> size = (2,)\n>>> x0 = torch.randn(size)\n>>> x1 = torch.randn(size)\n>>> c0 = pydec.Composition(size, component_num=2)\n>>> c1 = pydec.Composition(size, component_num=2)\n# Initialize by assign\n>>> c0[0] = x0\n>>> c1[1] = x1\n```\n*You can access the components by indices, e.g. `c[0]` and `c[3:5]`.*\n\n**By diagonal scatter**\n\nIn practice, usually all inputs are batched into a tensor. Therefore a more useful initialization method is based on the `torch.diagonal_scatter` function.\n```python\n>>> component_num = 3\n>>> size = (3, 2)\n>>> x = torch.randn(size)\n>>> c = pydec.Composition(size, component_num)\n>>> c = pydec.diagonal_init(c, src=x, dim=0)\n```\nOut:\n```python\n>>> x\n    tensor([[-0.4682,  1.2375],\n           [ 0.7185,  0.2311],\n           [-0.4043, -1.5946]])\n>>> c\n    composition 0:\n    tensor([[-0.4682,  1.2375],\n            [ 0.0000,  0.0000],\n            [ 0.0000,  0.0000]])\n    composition 1:\n    tensor([[0.0000, 0.0000],\n            [0.7185, 0.2311],\n            [0.0000, 0.0000]])\n    composition 2:\n    tensor([[ 0.0000,  0.0000],\n            [ 0.0000,  0.0000],\n            [-0.4043, -1.5946]])\n    residual:\n    tensor([[0., 0.],\n            [0., 0.],\n            [0., 0.]])\n```\n\n## Attributes of a Composition\n**Size**\n\n`Composition.size()` returns the shape of each composition tensor, `Composition.c_size()` returns the shape whose first dimension is the number of components.\n```python\n>>> c = pydec.Composition((3, 2), component_num=4)\n>>> c.size()\n    torch.Size([3, 2])\n>>> c.size()\n    torch.Size([4, 3, 2])\n```\n\n`len()` and `Composition.numc()` return the number of components.\n```python\n>>> len(c)\n    4\n>>> c.numc()\n    4\n```\n\n## Residual of a Composition\n\nThe decomposition of the tensor in the network with respect to the inputs is usually not complete, resulting in a residual component which represents the contribution of the bias parameters of the model (usually used in the linear layer), i.e.,\n\n$$\nh = \\frac{\\mathscr{D}h}{\\mathscr{D}x_1} + \\cdots + \\frac{\\mathscr{D}h}{\\mathscr{D}x_m} + \\frac{\\mathscr{D}h}{\\mathscr{D}b^1\\cdots\\mathscr{D}b^L},\n$$\n\nwhere $b$ is the bias parameters of the model. \n\nBy default, the term $\\frac{\\mathscr{D}h}{\\mathscr{D}b^1\\cdots\\mathscr{D}b^L}$ is saved to `Composition._residual`. PyDec configures some strategies to reallocate the bias term to the components corresponding to the input (see [Bias decomposition](#bias-decomposition)), so the residual may be 0 or some other value (depending on the reallocation strategy).\n\n\n## Operations on Compositions\n\nWe have implemented some common operations on Compositions, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing).\n\nMost of the operations are the same as tensor operations, and a convenient expression to understand is that performing one operation on a composition is equivalent to performing the same operation for all components of the composition, including the residual component. More details about the operations can be found here (TODO).\n\nExample:\n```python\n>>> c\n    composition 0:\n    tensor([[1., 1., 1., 1.],\n            [0., 0., 0., 0.]])\n    composition 1:\n    tensor([[0., 0., 0., 0.],\n            [1., 1., 1., 1.]])\n    residual:\n    tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n>>> 3 * c # multiply\n    composition 0:\n    tensor([[3., 3., 3., 3.],\n            [0., 0., 0., 0.]])\n    composition 1:\n    tensor([[0., 0., 0., 0.],\n            [3., 3., 3., 3.]])\n    residual:\n    tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n>>> c + c # add\ncomposition 0:\n    tensor([[2., 2., 2., 2.],\n            [0., 0., 0., 0.]])\n    composition 1:\n    tensor([[0., 0., 0., 0.],\n            [2., 2., 2., 2.]])\n    residual:\n    tensor([[0., 0., 0., 0.],\n            [0., 0., 0., 0.]])\n>>> W = torch.randn((4,3))\n>>> W\n    tensor([[-0.4682,  1.2375,  0.7185],\n            [ 0.2311, -0.4043, -1.5946],\n            [-0.4981,  0.2654,  0.0849],\n            [ 1.0203, -0.4293, -0.2616]])\n>>> c @ W # matmul\ncomposition 0:\n    tensor([[ 0.2851,  0.6694, -1.0529],\n            [ 0.0000,  0.0000,  0.0000]])\n    composition 1:\n    tensor([[ 0.0000,  0.0000,  0.0000],\n            [ 0.2851,  0.6694, -1.0529]])\n    residual:\n    tensor([[0., 0., 0.],\n            [0., 0., 0.]])\n```\n\n## Bias decomposition\n\nIn order to reallocate bias term, PyDec will assign them to components other than residual whenever it encounters bias addition operation.\n\nAssume that $h^\\prime=h+b$ and $h$ is denoted as the sum of $m$ components, i.e., $h=c_1+\\cdots+c_m$. Then $b$ is decomposed into $m$ parts and added to each of the $m$ components:\n$$\nb=p_1+\\cdots+p_m \\\\\nc^\\prime_i=c_i+p_i.\n$$\nThe decomposition of $h^\\prime$ was thus obtained as $h^\\prime=c^\\prime_1+\\cdots+c^\\prime_m$\n\nPyDec has some built-in strategies to decompose bias, and they mostly calculate $p_i$ based on the value of $c_i$. By default, PyDec just adds bias to residual component without performing any bias decomposition. More details about the bias decomposition can be found here (TODO).\n\n## Tracking forward propagation\n\nTo obtain the decomposition of the output or intermediate variables, the input to the network is first wrapped with Composition, and then the linear transformations and operations defined by the network are applied to Composition. Composition automatically maintains the decomposition of the corresponding variables of the original network.\n\n### Initializing Compositions\nCreate a corresponding Composition for each tensor that is fed into the network instead of for each input variable, e.g. if all inputs are organized in a certain dimension in a tensor, then only a Composition needs to be created for this tensor.\n\nThe number of components in Composition is determined by the user's needs, such as creating a Composition with 2 components corresponding to the first 10 tokens and the remaining tokens of the sentence, or setting the number of components to the number of features to observe the impact of different features. For attribution analysis, a more common setup is to set the number of components to the number of tokens of text or the number of pixels of an image.\n\nSuppose the input is an embedding representation of a piece of text, with a batch size of 16, a text length of 20, and 512 embedding features:\n\n```python\n>>> input = torch.randn((16, 20, 512))\n```\n\nInitializing to decompose in the sentence length dimension\uff1a\n```python\n>>> c = pydec.Composition((16, 20, 512), component_num=20)\n>>> c = pydec.diagonal_init(c, src=input, dim=1)\n```\n\nInitializing to decompose in the feature dimension:\n```python\n>>> c = pydec.Composition((16, 20, 512), component_num=512)\n>>> c = pydec.diagonal_init(c, src=input, dim=2)\n```\n\nInitializing to decompose in the joint feature dimension and sentence length dimension:\n```python\n>>> c = pydec.Composition((16, 20, 512), component_num=20*512)\n>>> c = c.view(16, 20*512)\n>>> c = pydec.diagonal_init(c, src=input.view(16,20*512), dim=1)\n>>> c = c.view_as(input)\n```\n\nIf you want to compute the decomposition in training and keep the computational graph of the components. Do not use the `requires_grad` parameter in the constructor of Composition, otherwise the initialization of Composition as a leaf node cannot be completed by assignment. It is recommended to assign the input with gradient to the Composition without gradient.\n\n### Forward Compositions\n\nUse the operations provided by PyDec to complete the forward computation. `pydec.nn` also provides some wrapped high-level components. Since the decomposition is usually done in the Inference phase, it is recommended to use the functions provided by `pydec.nn.functional`.\n\nTo get a decomposition of the output or intermediate variables, mimic the operation you performed on the input in the forward function on the initialized Composition.\n\nFor example, you get the tensor `h3` by the following operation:\n\n```python\nh3 = -h1 @ W + 3 * h2.permute(-1,0,1)\n```\n\nThen you need to perform the following operation on the Composition corresponding to `h1` and `h2` to get the Composition of `h3`.\n\n```python\nc3 = -c1 @ W + 3 * c2.permute(-1,0,1)\n```\n\nWe have implemented a number of common functions for `pydec.Composition`. In most cases you just need to use the same functions and parameters to complete the trace. In most cases you just need to use the same functions and arguments to complete the trace. Other functions related to component operations start with `c_`. If you use a function not yet provided by PyDec, you may need to use other functions to do the equivalent operation or implement the function yourself (PR is welcome).\n\n## Error control\n\nAlthough in theory the recovery from Composition is exactly equivalent to the ground truth. However, in practice, there will be errors brought by the computer. Especially in deep networks, the error may be magnified to an unacceptable degree. We give some suggestions for reducing errors and provide tools for error checking.\n\n### Error reduction\n\nOur most recommended method for reducing errors is to use double precision computations, usually by simply adding `model=model.double()` after the model is loaded. If you enable double precision calculations, the error from the decomposition is almost negligible.\n\nWhen double precision computation cannot be enabled for speed and memory reasons, you may consider adding the error term to Composition as bias. Depending on the bias reallocation policy, the error is added to the residual or assigned to each component.\n\nYou can even consider making the ground truth equal to Composition's recovery, but this may change the classification result of the network.\n\n### Error checking\nYou can use `PyDec.check_error` to check the error of the given Composition and reference. In order to provide ground truth as a reference, you usually need to keep the forward process of the original network. We recommend that you use it often during development, not only for error control, but also to help you find bugs in your code.\n\n# Documentation\n\nWe will release latter.\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "pydec",
            "package_url": "https://pypi.org/project/pydec/",
            "platform": null,
            "project_url": "https://pypi.org/project/pydec/",
            "project_urls": {
                "Homepage": "https://github.com/"
            },
            "release_url": "https://pypi.org/project/pydec/0.1.0/",
            "requires_dist": [
                "torch (>=1.11.0)",
                "numpy"
            ],
            "requires_python": ">=3.7.0",
            "summary": "Linear decomposition toolkit for neural network based on pytorch.",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15555174,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f08ebee63e08cb4986ffb7ee94572791",
                    "sha256": "0be6c40356ce98d9e48e79a96ca4de4084068aca9e1e68ce6826f27e657ce44d"
                },
                "downloads": -1,
                "filename": "pydec-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "f08ebee63e08cb4986ffb7ee94572791",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7.0",
                "size": 25932,
                "upload_time": "2022-10-27T16:16:28",
                "upload_time_iso_8601": "2022-10-27T16:16:28.686415Z",
                "url": "https://files.pythonhosted.org/packages/02/23/10a436156838c5341d500534f3ef6f267fb5e29666ad0709341772e3ea24/pydec-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "9a0779d91ec2215fc350316a7d739988",
                    "sha256": "1a11b015ad9ae1657f85ec97459ed1f55011bc12fe2dafc387d9ab3b4edc80de"
                },
                "downloads": -1,
                "filename": "pydec-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "9a0779d91ec2215fc350316a7d739988",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7.0",
                "size": 29704,
                "upload_time": "2022-10-27T16:16:30",
                "upload_time_iso_8601": "2022-10-27T16:16:30.563456Z",
                "url": "https://files.pythonhosted.org/packages/76/f6/436b4683a7df0f7755488fcc0e917133d271c1179b90655d9a0ee15195b8/pydec-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
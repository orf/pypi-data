{
    "0.0.1": {
        "info": {
            "author": "",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 2 - Pre-Alpha",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: English",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3 :: Only",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: Implementation :: CPython",
                "Programming Language :: Python :: Implementation :: PyPy"
            ],
            "description": "# lich_scrapy_random_useragent\n\nScrapy project auto generated by [os-scrapy-cookiecutter](https://github.com/cfhamlet/os-scrapy-cookiecutter). \n\n\n## Project\n\nThis scrapy project is a python package generated by os-scrapy-cookiecutter.\n\nYou can run it as normal scrapy project with scrapy commands.\n\nIt is also a python package, the scaffolds can be used for formatting, testing, installing.\n\n* lint\n  \n    ```\n    sh scripts/lint.sh\n    ```\n\n* test\n\n    ```\n    sh scripts/test.sh\n    ```\n\n* install\n\n    ```\n    python setup.py install\n    ```\n\n* example\n\n    You can run example spider:\n\n    ```\n    scrapy crawl example\n    ```\n\n* files\n\n    ```\n    .\n    \u251c\u2500\u2500 lich_scrapy_random_useragent # scrapy project          \n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 items.py\n    \u2502   \u251c\u2500\u2500 middlewares.py\n    \u2502   \u251c\u2500\u2500 pipelines.py\n    \u2502   \u251c\u2500\u2500 settings.py\n    \u2502   \u2514\u2500\u2500 spiders\n    \u2502       \u2514\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 LICENSE # license file\n    \u251c\u2500\u2500 MANIFEST.in # setup install package file\n    \u251c\u2500\u2500 pytest.ini # pytest config file\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 requirements\n    \u2502   \u251c\u2500\u2500 requirements-lint.txt # requirements of format tools used by scripts/lint.sh and tox\n    \u2502   \u251c\u2500\u2500 requirements-test.txt # requirements of test used by tox\n    \u2502   \u2514\u2500\u2500 requirements.txt # requirements of this project\n    \u251c\u2500\u2500 scrapy.cfg # scrapy project entrypoint file\n    \u251c\u2500\u2500 scripts\n    \u2502   \u251c\u2500\u2500 test.sh # run test \n    \u2502   \u2514\u2500\u2500 lint.sh # format the source file\n    \u251c\u2500\u2500 setup.cfg # setup tool config file\n    \u251c\u2500\u2500 setup.py # setup tool \n    \u251c\u2500\u2500 tests\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u2514\u2500\u2500 test_scrapy_check.py # unit test with scrapy check\n    \u2514\u2500\u2500 tox.ini # tox config file\n    ```\n\n## Install\n\n```\npython setup.py install\n```\n\n## Usage\n\n```\nscrapy -h\n```\n\n## Unit Tests\n\n```\nsh scripts/test.sh\n```\n\n## License\n\nMIT licensed.\n",
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "MIT License",
            "maintainer": "",
            "maintainer_email": "",
            "name": "lich_scrapy_random_useragent",
            "package_url": "https://pypi.org/project/lich_scrapy_random_useragent/",
            "platform": "",
            "project_url": "https://pypi.org/project/lich_scrapy_random_useragent/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/lich_scrapy_random_useragent/0.0.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Auto Generated by os-scrapy-cookiecutter",
            "version": "0.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 7950268,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "439859772c99066e9de793e69b2164a2",
                    "sha256": "c62bdec34f889763187692b2edf888098fdc04118033a4e254e29f4de2d8d290"
                },
                "downloads": -1,
                "filename": "lich_scrapy_random_useragent-0.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "439859772c99066e9de793e69b2164a2",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 7792,
                "upload_time": "2020-08-13T06:42:59",
                "upload_time_iso_8601": "2020-08-13T06:42:59.433997Z",
                "url": "https://files.pythonhosted.org/packages/89/d1/8879c046701703def51c31050b045789b419dc6a588d5cca13efc1fffec9/lich_scrapy_random_useragent-0.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
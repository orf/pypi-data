{
    "0.3.1": {
        "info": {
            "author": "The Inseq Team",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Environment :: Console",
                "Environment :: GPU",
                "Environment :: GPU :: NVIDIA CUDA",
                "Environment :: GPU :: NVIDIA CUDA :: 11.3",
                "Framework :: Jupyter",
                "Framework :: Sphinx",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: Apache Software License",
                "License :: Other/Proprietary License",
                "Operating System :: OS Independent",
                "Programming Language :: Python",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description": "<div align=\"center\">\n  <img src=\"/docs/source/images/inseq_logo.png\" width=\"300\"/>\n  <h4>Intepretability for Sequence Generation Models \ud83d\udd0d</h4>\n</div>\n<br/>\n<div align=\"center\">\n\n[![Build status](https://github.com/inseq-team/inseq/workflows/build/badge.svg?branch=master&event=push)](https://github.com/inseq-team/inseq/actions?query=workflow%3Abuild)\n[![Python Version](https://img.shields.io/pypi/pyversions/inseq.svg)](https://pypi.org/project/inseq/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![License](https://img.shields.io/github/license/inseq-team/inseq)](https://github.com/inseq-team/inseq/blob/main/LICENSE)\n\n</div>\n\nInseq is a Pytorch-based hackable toolkit to democratize the access to common post-hoc **in**terpretability analyses of **seq**uence generation models.\n\n## Installation\n\nInseq is available on PyPI and can be installed with `pip`:\n\n```bash\npip install inseq\n```\n\n<details>\n  <summary>Dev Installation</summary>\nTo install the package, clone the repository and run the following commands:\n\n```bash\ncd inseq\nmake poetry-download # Download and install the Poetry package manager\nmake install # Installs the package and all dependencies\n```\n\nIf you have a GPU available, use `make install-gpu` to install the latest `torch` version with GPU support.\n\nFor library developers, you can use the `make install-dev` command to install and its GPU-friendly counterpart `make install-dev-gpu` to install all development dependencies (quality, docs, extras).\n\nAfter installation, you should be able to run `make fast-test` and `make lint` without errors.\n</details>\n\n<details>\n  <summary>FAQ Installation</summary>\n\n  - Installing the `tokenizers` package requires a Rust compiler installation. You can install Rust from [https://rustup.rs](https://rustup.rs) and add `$HOME/.cargo/env` to your PATH.\n\n  - Installing `sentencepiece` requires various packages, install with `sudo apt-get install cmake build-essential pkg-config` or `brew install cmake gperftools pkg-config`.\n</details>\n\n## Example usage in Python\n\nThis example uses the Integrated Gradients attribution method to attribute the English-French translation of a sentence taken from the WinoMT corpus:\n\n```python\nimport inseq\n\nmodel = inseq.load_model(\"Helsinki-NLP/opus-mt-en-fr\", \"integrated_gradients\")\nout = model.attribute(\n  \"The developer argued with the designer because her idea cannot be implemented.\",\n  n_steps=100\n)\nout.show()\n```\n\nThis produces a visualization of the attribution scores for each token in the input sentence (token-level aggregation is handled automatically). Here is what the visualization looks like inside a Jupyter Notebook:\n\n![WinoMT Attribution Map](docs/source/images/heatmap_winomt.png)\n\nInseq also supports decoder-only models such as [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html), enabling usage of a variety of attribution methods and customizable settings directly from the console:\n\n```python\nimport inseq\n\nmodel = inseq.load_model(\"gpt2\", \"integrated_gradients\")\nmodel.attribute(\n    \"Hello ladies and\",\n    generation_args={\"max_new_tokens\": 9},\n    n_steps=500,\n    internal_batch_size=50\n).show()\n```\n\n![GPT-2 Attribution in the console](docs/source/images/inseq_python_console.gif)\n\n## What does Inseq support?\n\n- Feature attribution of sequence generation for most `ForConditionalGeneration` (encoder-decoder) and `ForCausalLM` (decoder-only) models from \ud83e\udd17 Transformers\n\n- Support for single and batched attribution using multiple gradient-based feature attribution methods from Captum\n\n- Post-hoc aggregation of feature attribution maps via `Aggregator` classes.\n\n- Attribution visualization in notebooks, browser and command line.\n\n- Command line interface for attributing single examples or entire \ud83e\udd17 datasets.\n\n- Custom attribution of target functions, supporting advanced usage for cases such as contrastive and uncertainty-weighted feature attributions.\n\n- Extract and visualize custom scores for every generation step alongsides attribution maps.\n\n## What we plan to support in the future?\n\n- Attention-based and occlusion-based feature attribution methods\n\n- Interoperability with other interpretability libraries\n\n- Rich and interactive visualizations in a tabbed interface\n\n## Using the Inseq client\n\nThe Inseq library also provides useful client commands to enable repeated attribution of individual examples and even entire \ud83e\udd17 datasets directly from the console. See the available options by typing `inseq -h` in the terminal after installing the package.\n\nFor now, two commands are supported:\n\n- `\u00ecnseq attribute`: Wraps the `attribute` method shown above, requires explicit inputs to be attributed.\n\n- `inseq attribute-dataset`: Enables attribution for a full dataset using Hugging Face `datasets.load_dataset`.\n\nBoth commands support the full range of parameters available for `attribute`, attribution visualization in the console and saving outputs to disk.\n\n**Example:** The following command can be used to perform attribution (both source and target-side) of Italian translations for a dummy sample of 20 English sentences taken from the FLORES-101 parallel corpus, using a MarianNMT translation model from Hugging Face `transformers`. We save the visualizations in HTML format in the file `attributions.html`. See the `--help` flag for more options.\n\n```bash\ninseq attribute-dataset \\\n  --model_name_or_path Helsinki-NLP/opus-mt-en-it \\\n  --attribution_method saliency \\\n  --do_prefix_attribution \\\n  --dataset_name inseq/dummy_enit \\\n  --input_text_field en \\\n  --dataset_split \"train[:20]\" \\\n  --viz_path attributions.html \\\n  --batch_size 8 \\\n  --hide\n```\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/inseq-team/inseq",
            "keywords": "seq2seq,transformers,natural language processing,XAI,explainable ai,interpretability",
            "license": "Apache Software License 2.0",
            "maintainer": "gsarti",
            "maintainer_email": "gabriele.sarti996@gmail.com",
            "name": "inseq",
            "package_url": "https://pypi.org/project/inseq/",
            "platform": null,
            "project_url": "https://pypi.org/project/inseq/",
            "project_urls": {
                "Homepage": "https://github.com/inseq-team/inseq",
                "Repository": "https://github.com/inseq-team/inseq"
            },
            "release_url": "https://pypi.org/project/inseq/0.3.1/",
            "requires_dist": [
                "captum (>=0.5.0,<0.6.0)",
                "datasets[torch] (>=2.3.2,<3.0.0) ; extra == \"datasets\"",
                "ipykernel (>=6.15.0,<7.0.0) ; extra == \"notebook\"",
                "ipywidgets (>=8.0.0rc2,<9.0.0) ; extra == \"notebook\"",
                "joblib (>=1.2.0,<2.0.0) ; extra == \"sklearn\"",
                "json-tricks (>=3.15.5,<4.0.0)",
                "matplotlib (>=3.5.2,<4.0.0)",
                "numpy (>=1.22.4,<2.0.0)",
                "poethepoet (>=0.13.1,<0.14.0)",
                "protobuf (>=3.20.2,<4.0.0)",
                "rich (>=10.13.0,<11.0.0)",
                "scikit-learn (>=1.1.1,<2.0.0) ; extra == \"sklearn\"",
                "scipy (>=1.8.1,<2.0.0)",
                "torch (>=1.13.0,<2.0.0)",
                "torchtyping (>=0.1.4,<0.2.0)",
                "tqdm (>=4.64.0,<5.0.0)",
                "transformers[sentencepiece,tokenizers,torch] (>=4.22.0,<5.0.0)"
            ],
            "requires_python": ">=3.8.1,<3.12",
            "summary": "Interpretability for Sequence Generation Models \ud83d\udd0d",
            "version": "0.3.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 16058318,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f1c4bd6ec237b262da5b0ae7cc410053",
                    "sha256": "369c8e78cd5ad0bc23e14c15102fca2e245c880c911f9549edf3513064bcd387"
                },
                "downloads": -1,
                "filename": "inseq-0.3.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "f1c4bd6ec237b262da5b0ae7cc410053",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8.1,<3.12",
                "size": 84455,
                "upload_time": "2022-12-10T14:38:42",
                "upload_time_iso_8601": "2022-12-10T14:38:42.131053Z",
                "url": "https://files.pythonhosted.org/packages/f8/44/9dd8b6d054fbd53410bc8ac13334b8a5408b16ca94041e2fe30d4eb8182d/inseq-0.3.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "0ffd50c88afd2ff00f081c5dc4e5c209",
                    "sha256": "ebc5c958430100ca942bf4891f90be001f5cbe2e80287f7044d1f72e4495ae88"
                },
                "downloads": -1,
                "filename": "inseq-0.3.1.tar.gz",
                "has_sig": false,
                "md5_digest": "0ffd50c88afd2ff00f081c5dc4e5c209",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8.1,<3.12",
                "size": 71066,
                "upload_time": "2022-12-10T14:38:44",
                "upload_time_iso_8601": "2022-12-10T14:38:44.885603Z",
                "url": "https://files.pythonhosted.org/packages/82/c7/75073351a755a3ccbbf5e166bf9059b204ebd92d243cf0426798c456f756/inseq-0.3.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
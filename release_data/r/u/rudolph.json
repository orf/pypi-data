{
    "0.0.1rc0": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc0/",
            "requires_dist": [
                "rudalle (==0.4.0)",
                "taming-transformers (==0.0.1)",
                "more-itertools (~=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (~=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "PyWavelets (==1.1.1)",
                "segmentation-models-pytorch (==0.1.3)",
                "opencv-python (==4.5.4.60)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "458e60e8c53c7cfaa17443dc750ea55f",
                    "sha256": "2495ed0b5ad6e1ebac6de0c8c7c6983fac7c3bb59262c3a6e40a129dbdda687c"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "458e60e8c53c7cfaa17443dc750ea55f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 229097,
                "upload_time": "2022-01-07T17:11:22",
                "upload_time_iso_8601": "2022-01-07T17:11:22.777419Z",
                "url": "https://files.pythonhosted.org/packages/1d/6a/acf42e17b7803a66cef53907b92566a6a727e579e4698f27c2fcce8162d0/rudolph-0.0.1rc0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "955f66ac6cfe857ef7df7e79285750fd",
                    "sha256": "16937aed0061e6fbd26d22f2b76a5c32d2993108003ccb5179d06134a24fe7fb"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc0.tar.gz",
                "has_sig": false,
                "md5_digest": "955f66ac6cfe857ef7df7e79285750fd",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 647448,
                "upload_time": "2022-01-07T17:11:28",
                "upload_time_iso_8601": "2022-01-07T17:11:28.752906Z",
                "url": "https://files.pythonhosted.org/packages/e9/08/e6e6242d789d58dbddb57f40adaef3b13839aa0399d6e943bf45be5a2765/rudolph-0.0.1rc0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc1": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc1/",
            "requires_dist": [
                "taming-transformers (==0.0.1)",
                "rudalle (==0.5.0rc1)",
                "more-itertools (~=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (~=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "PyWavelets (==1.1.1)",
                "segmentation-models-pytorch (==0.1.3)",
                "opencv-python (==4.5.4.60)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "15f82baa4c18b7d39386c426fd9434e8",
                    "sha256": "efdccf2917b6c48c1707e7f77ad6a12a59f1336af7e66710f7946f02a3a41eed"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "15f82baa4c18b7d39386c426fd9434e8",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 230151,
                "upload_time": "2022-01-08T12:38:38",
                "upload_time_iso_8601": "2022-01-08T12:38:38.222664Z",
                "url": "https://files.pythonhosted.org/packages/71/47/4ca151bc79daffa3ca669662f5e58ccafdc4ef3fdb5bb1db67980e40ff30/rudolph-0.0.1rc1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "6858dfaf0f4c87f871b6c9c37eab9fc6",
                    "sha256": "31ff83881f93d18c330a850506e3e94c4ce7b6684ddf587d92b401f901c169ac"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc1.tar.gz",
                "has_sig": false,
                "md5_digest": "6858dfaf0f4c87f871b6c9c37eab9fc6",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 650132,
                "upload_time": "2022-01-08T12:38:46",
                "upload_time_iso_8601": "2022-01-08T12:38:46.436387Z",
                "url": "https://files.pythonhosted.org/packages/69/57/714e5e97a33d70c9791d99415b9e3307de43af1404d4506fc0a2afb67812/rudolph-0.0.1rc1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc10": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": null,
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc10/",
            "requires_dist": [
                "rudalle (==1.1.3)",
                "taming-transformers (==0.0.1)",
                "more-itertools (>=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (>=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc10",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "873192501c9ee450fe4a468c5cf3fc50",
                    "sha256": "e861d9a4a9fe080a62b8d054e9fc4bde19a091a3f0844d91d200a513779aa658"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc10-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "873192501c9ee450fe4a468c5cf3fc50",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 22845,
                "upload_time": "2022-10-06T21:00:37",
                "upload_time_iso_8601": "2022-10-06T21:00:37.104890Z",
                "url": "https://files.pythonhosted.org/packages/d5/2e/14860b23c36426cc18ca827fbe505b54ea171f3420dd8f82c6e8e6721ad4/rudolph-0.0.1rc10-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "1608bb20152b0071f87900ff50ebb9ae",
                    "sha256": "d5bc6c20c9bd38c61a536077243ef9f760025b8b730fd37d7678f2524e2f47ab"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc10.tar.gz",
                "has_sig": false,
                "md5_digest": "1608bb20152b0071f87900ff50ebb9ae",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 22078,
                "upload_time": "2022-10-06T21:00:38",
                "upload_time_iso_8601": "2022-10-06T21:00:38.813852Z",
                "url": "https://files.pythonhosted.org/packages/05/12/258e75c7bef66c69ef7ffb9707dfdcc9786ba081c1478721143a458e8a2a/rudolph-0.0.1rc10.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc2": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc2/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (~=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (~=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "PyWavelets (==1.1.1)",
                "segmentation-models-pytorch (==0.1.3)",
                "opencv-python (==4.5.4.60)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "58043b79b99d797f66258891169e087a",
                    "sha256": "8c7c32078b163a47bd2dc32baafa54cda22a6d0d0aa2a1032360aac88da01b41"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "58043b79b99d797f66258891169e087a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23465,
                "upload_time": "2022-01-14T12:13:22",
                "upload_time_iso_8601": "2022-01-14T12:13:22.407856Z",
                "url": "https://files.pythonhosted.org/packages/53/2c/9d29c321a2330d84c7907f0d1b04e38410cacdb33979440117bd8f4172ee/rudolph-0.0.1rc2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "40829c6e5bf2edec5f47e9be45dcf988",
                    "sha256": "3a86767adab8df1554cd8a0750fb1a338beff2c165c5eb191feb537f7c9bcbcd"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc2.tar.gz",
                "has_sig": false,
                "md5_digest": "40829c6e5bf2edec5f47e9be45dcf988",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 24535,
                "upload_time": "2022-01-14T12:13:24",
                "upload_time_iso_8601": "2022-01-14T12:13:24.759441Z",
                "url": "https://files.pythonhosted.org/packages/97/8d/05cd749ec921c11f1510dab55082ece58309658695dcb9251373726e5c0c/rudolph-0.0.1rc2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc3": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc3/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (~=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (~=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "PyWavelets (==1.1.1)",
                "segmentation-models-pytorch (==0.1.3)",
                "opencv-python (==4.5.4.60)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5989f5fd4fe7a083ac507e9cd34494cc",
                    "sha256": "110b6964844b3a44b04d806348ce97703678eff690a51bca93daec1ac8ec81de"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "5989f5fd4fe7a083ac507e9cd34494cc",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23395,
                "upload_time": "2022-01-18T21:27:49",
                "upload_time_iso_8601": "2022-01-18T21:27:49.573824Z",
                "url": "https://files.pythonhosted.org/packages/0f/54/2165759de6e0c9e1d7a5a03b88b3125fe6197a60eb52323d48d6b7031ae4/rudolph-0.0.1rc3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "5cd5558be18e33ec0b8d302144a059fc",
                    "sha256": "d254656de8a75674218bb0cfdf3dd29fabc9469e85f4882f636289c37bd786ca"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc3.tar.gz",
                "has_sig": false,
                "md5_digest": "5cd5558be18e33ec0b8d302144a059fc",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 24403,
                "upload_time": "2022-01-18T21:27:51",
                "upload_time_iso_8601": "2022-01-18T21:27:51.373316Z",
                "url": "https://files.pythonhosted.org/packages/3d/92/4fbfab5943469b79c374b4332bca03a491fe3f023534086926f081e08d10/rudolph-0.0.1rc3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc4": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc4/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (~=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (~=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "PyWavelets (==1.1.1)",
                "segmentation-models-pytorch (==0.1.3)",
                "opencv-python (==4.5.4.60)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "45f7484ee779fc45124dbc4fd6dda352",
                    "sha256": "4e9fca1e65ba06fbda4eab1fd837f2714f94e96044861a96d82ffc49087b2033"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "45f7484ee779fc45124dbc4fd6dda352",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23434,
                "upload_time": "2022-01-18T21:45:41",
                "upload_time_iso_8601": "2022-01-18T21:45:41.414536Z",
                "url": "https://files.pythonhosted.org/packages/5e/d0/a38bdedc82aed566de7f0b557ff8eabd08990ed44188564a6259ed5e5df7/rudolph-0.0.1rc4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f3fa6a2d13b6d7b801c6e37c7bca794c",
                    "sha256": "6b6aabb7e20f973c600debe147b3468d43815280d63683b1a6998f533cd6c313"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc4.tar.gz",
                "has_sig": false,
                "md5_digest": "f3fa6a2d13b6d7b801c6e37c7bca794c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 24443,
                "upload_time": "2022-01-18T21:45:44",
                "upload_time_iso_8601": "2022-01-18T21:45:44.484553Z",
                "url": "https://files.pythonhosted.org/packages/b6/19/073e7181cf4510dcd5b1cbec90914883a8c0a2e8b417292b3c8ea87d9d5a/rudolph-0.0.1rc4.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc5": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc5/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (~=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (~=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "PyWavelets (==1.1.1)",
                "segmentation-models-pytorch (==0.1.3)",
                "opencv-python (==4.5.4.60)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1181b84e78b1115a21e25862c7d8a55f",
                    "sha256": "04b5c6c601582e8ffc4cd1f10a0405264462ebe6961b09689f7f0322edc7ce45"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1181b84e78b1115a21e25862c7d8a55f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23831,
                "upload_time": "2022-01-31T12:35:42",
                "upload_time_iso_8601": "2022-01-31T12:35:42.693910Z",
                "url": "https://files.pythonhosted.org/packages/26/07/2e697e224117d5b7496bda724a80a71ee358ab3a6ce1b10d38fe007f26d3/rudolph-0.0.1rc5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "4d38543a3486a859de05a0ee5ac603b2",
                    "sha256": "62c5a34a24d4db5c4e83e3e5a363b4a52afaee68b1029a44be673129f5384926"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc5.tar.gz",
                "has_sig": false,
                "md5_digest": "4d38543a3486a859de05a0ee5ac603b2",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 25304,
                "upload_time": "2022-01-31T12:35:47",
                "upload_time_iso_8601": "2022-01-31T12:35:47.408971Z",
                "url": "https://files.pythonhosted.org/packages/8c/b2/c688bd7a3e72047aaa26534ca76b25b116c0bcb3d1a4793532b9f8c39163/rudolph-0.0.1rc5.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc6": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc6/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (>=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (>=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "06e1bc3b406bb9d204f943ff378a3bc2",
                    "sha256": "c60c9fcf19ca16792126ec1ba867c02b44cb24f1e72e20ba7ee8f7c16b3093dd"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "06e1bc3b406bb9d204f943ff378a3bc2",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23777,
                "upload_time": "2022-01-31T13:45:24",
                "upload_time_iso_8601": "2022-01-31T13:45:24.570200Z",
                "url": "https://files.pythonhosted.org/packages/94/31/359fbe9bda49082e227c07ec6b72640b314ed87876469583cd123fec97fa/rudolph-0.0.1rc6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "539b91b72de4cdf04901ae0d8ccda889",
                    "sha256": "c73a4019e111119ba9d4f6851c2ecd41d14ce0faa8b2e9b9b1f24240450a7ff9"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc6.tar.gz",
                "has_sig": false,
                "md5_digest": "539b91b72de4cdf04901ae0d8ccda889",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 25253,
                "upload_time": "2022-01-31T13:45:30",
                "upload_time_iso_8601": "2022-01-31T13:45:30.190497Z",
                "url": "https://files.pythonhosted.org/packages/e2/fd/60280c0fec9594f5265528e7e6ba8d9024f33266b50053fbe38627807cf1/rudolph-0.0.1rc6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc7": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc7/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (>=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (>=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc7",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9a88a9a7d67668202874564ae7da8382",
                    "sha256": "8d4e383b6e6093a64ea84d1209d6a3627ce5b6e1e8dd54544db95729a4ec8c35"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc7-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "9a88a9a7d67668202874564ae7da8382",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23906,
                "upload_time": "2022-01-31T16:18:17",
                "upload_time_iso_8601": "2022-01-31T16:18:17.292077Z",
                "url": "https://files.pythonhosted.org/packages/5f/c3/16fe1891c9c7b78cb5f019a9481593ca2991276fcf41ca10378860c95664/rudolph-0.0.1rc7-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f6c3cafd50e4d3f70fb2c79eca100081",
                    "sha256": "27cc72faba408a61a759c88ed82fc76def23c68e20aa937e189aa65dcf900f90"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc7.tar.gz",
                "has_sig": false,
                "md5_digest": "f6c3cafd50e4d3f70fb2c79eca100081",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 25348,
                "upload_time": "2022-01-31T16:18:19",
                "upload_time_iso_8601": "2022-01-31T16:18:19.770561Z",
                "url": "https://files.pythonhosted.org/packages/f1/57/1634a299a100b6df8841a21b8c95395db3180699a7946b4e6924f30d8048/rudolph-0.0.1rc7.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.0.1rc8": {
        "info": {
            "author": "SberAI, SberDevices",
            "author_email": "shonenkov@phystech.edu",
            "bugtrack_url": null,
            "classifiers": [],
            "description": "[[Paper]]() [[\u0425\u0430\u0431\u0440]]() [[Model Card]](https://huggingface.co/sberbank-ai/RuDOLPH-350M) [[Colab]](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing) [[Kaggle]]()\n\n\n## <img src=\"https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/rudolph.png?token=GHSAT0AAAAAABQH6MST7ZEGAF274DV33K7KYOYRSBQ\" height=\"60\"/> RuDOLPH \ud83e\udd8c\ud83c\udf84\u2603\ufe0f\n\n*One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP*\n\n---\n\n**Ru**ssian **D**iffusion **O**n **L**anguage **P**icture **H**yper-modality (RuDOLPH) is a fast \nand light text-image-text transformer (350M GPT-3) designed for a quick and easy fine-tuning setup \nfor the solution of various tasks: from generating images by text description and image classification \nto visual question answering and more. This model demonstrates the power of Hyper-modality Transformers.\n\n*(!!!) Hyper-modality means generalized multi-modal, e.g., model that consists of two multi-modal parts: text-2-image and image-2-text becomes text and image hyper-modality model*\n\n\n![](./pics/scheme.png)\n\n# Sparse Attention Mask\n`row - col - row - [last] conv`\n\n![](./pics/attention_masks.png)\n\n# Models\n+ [350M (RuDOLPH)](https://huggingface.co/sberbank-ai/RuDOLPH-350M)\n+ 1.3B (In Progress)\n+ 4B (In Progress)\n\n\n![](./pics/high_res.png)\n\n# Installing\n```\npip install rudolph==0.0.1rc8\n```\n\n# Usage\n\nFine-Tuning example by [@Alex Wortega](https://github.com/AlexWortega) \n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12YRRzhl5cHER_U2F-buQxif8GlhMPWq3?usp=sharing)\n\n### Init models\n```python\nfrom rudalle import get_tokenizer, get_vae\nfrom rudalle.utils import seed_everything\nfrom rudalle.image_prompts import ImagePrompts\n\nfrom rudolph.model import get_rudolph_model\nfrom rudolph.pipelines import zs_clf, generate_codebooks, self_reranking_by_image, self_reranking_by_text, show, generate_captions, generate_texts\nfrom rudolph import utils\n\ndevice = 'cuda'\nmodel = get_rudolph_model('350M', fp16=True, device=device)\nmodel.to(device);\ntokenizer = get_tokenizer()\nvae = get_vae(dwt=False).to(device)\n```\n\n### Setup for Fast Image Generation\n\n```python\ntext = '\u0441\u0442\u0430\u0440\u0438\u043d\u043d\u044b\u0439 \u0431\u0443\u0434\u0438\u043b\u044c\u043d\u0438\u043a \u043c\u043d\u043e\u0433\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u043e\u0439 \u0444\u043e\u0440\u043c\u044b'\nbs, images_num = 48, 48\ntop_k, top_p = 512, 0.9\nwith torch.no_grad():\n    codebooks = generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs)\n    ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=bs)\n    images = vae.decode(codebooks[ppl_text.argsort()[:4]])\nimages = torchvision.utils.make_grid(images, nrow=2)\nimg = torchvision.transforms.functional.to_pil_image(images)\nimg\n```\n![](./pics/pipelines/example.png)\n\n\n### Text Generation\n```python\ngenerate_texts(\n    tokenizer,\n    model,\n    template='\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 ',\n    top_k=32, top_p=0.8, texts_num=32, bs=32, seed=42\n)[:8]\n\n[{'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0438 \u0434\u0435\u0440\u0435\u0432\u044c\u044f \u0432 \u0433\u043e\u0440\u0430\u0445 \u0441 \u0441\u0438\u043d\u0438\u043c \u043d\u0435\u0431\u043e\u043c \u0438 \u043e\u0431\u043b\u0430\u043a\u0430\u043c\u0438 \u0432 \u0441\u043e\u043b\u043d\u0435\u0447\u043d\u044b\u0439 \u0434\u0435\u043d\u044c. \u043a\u0430\u0440\u043f\u0430\u0442\u044b \u0443\u043a\u0440\u0430\u0438\u043d\u0430', 'ppl': 155.72},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u0433\u043e\u0440\u043d\u044b\u043c \u043e\u0437\u0435\u0440\u043e\u043c \u0438 \u043a\u0440\u0430\u0441\u0438\u0432\u044b\u043c \u043f\u0435\u0439\u0437\u0430\u0436\u0435\u043c \u043d\u0430 \u0432\u043e\u0441\u0445\u043e\u0434\u0435 \u0441\u043e\u043b\u043d\u0446\u0430', 'ppl': 195.81},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u0433\u043e\u0440\u043d\u044b\u043c\u0438 \u0432\u0435\u0440\u0448\u0438\u043d\u0430\u043c\u0438 \u0438 \u0447\u0438\u0441\u0442\u044b\u043c \u043d\u0435\u0431\u043e\u043c', 'ppl': 219.57},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u0433\u043e\u0440\u0430\u043c\u0438 \u0432 \u0442\u0443\u043c\u0430\u043d\u0435, \u043f\u043e\u043a\u0440\u044b\u0432\u0430\u044e\u0449\u0438\u043c\u0438 \u0433\u043e\u0440\u044b', 'ppl': 221.36},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0438 \u0432\u043e\u0434\u043e\u043f\u0430\u0434 \u0432 \u043d\u0430\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u043c \u043f\u0430\u0440\u043a\u0435 \u043f\u0445\u0443\u0442\u0442\u0430 \u0432 \u0442\u0430\u0438\u043b\u0430\u043d\u0434\u0435', 'ppl': 248.82},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u0433\u043e\u043b\u0443\u0431\u044b\u043c \u043d\u0435\u0431\u043e\u043c \u0438 \u0431\u0435\u043b\u044b\u043c \u043e\u0431\u043b\u0430\u043a\u043e\u043c', 'ppl': 260.76},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u0440\u0435\u043a\u043e\u0439, \u0433\u043e\u0440\u044b \u0438 \u0433\u043e\u043b\u0443\u0431\u043e\u0435 \u043d\u0435\u0431\u043e', 'ppl': 273.1},\n {'text': '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u0437\u0435\u043b\u0435\u043d\u044b\u043c\u0438 \u0434\u0435\u0440\u0435\u0432\u044c\u044f\u043c\u0438 \u0438 \u0433\u043e\u043b\u0443\u0431\u044b\u043c \u043d\u0435\u0431\u043e\u043c', 'ppl': 286.22}]\n```\n\n### Image Generation + Self Reranking\n```python\ntext = '\u043a\u0440\u0430\u0441\u0438\u0432\u044b\u0439 \u043f\u0435\u0439\u0437\u0430\u0436 \u0441 \u043e\u0437\u0435\u0440\u043e\u043c \u0438 \u043b\u0435\u0441\u043e\u043c \u043d\u0430 \u0437\u0430\u0434\u043d\u0435\u043c \u043f\u043b\u0430\u043d\u0435'\nimages_num, bs = 256, 32\nseed_everything(42)\ncodebooks = []\nfor top_k, top_p, images_num in [\n    (2048, 0.975, images_num),\n    (1536, 0.975, images_num),\n    (1024, 0.975, images_num),\n]:\n    codebooks.append(generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs))\n\ncodebooks = torch.cat(codebooks)\n\nppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=bs)\nwith torch.no_grad():\n    images = vae.decode(codebooks[ppl_text.argsort()[:16]])\n\npil_images = utils.torch_tensors_to_pil_list(images)\nshow(pil_images, 8)\n```\n![](./pics/pipelines/lake.png)\n\n\n```python\ntext = '\u0437\u0438\u043c\u043d\u0435\u0435 \u0432\u0440\u0435\u043c\u044f \u0433\u043e\u0434\u0430'\n\nppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)\nwith torch.no_grad():\n    images = vae.decode(codebooks[ppl_text.argsort()[:16]])\n\npil_images = utils.torch_tensors_to_pil_list(images)\nshow(pil_images, 8)\n```\n![](./pics/pipelines/lake_winter.png)\n\n\n```python\ntext = '\u043d\u043e\u0447\u043d\u043e\u0435 \u0432\u0440\u0435\u043c\u044f \u0441\u0443\u0442\u043e\u043a'\n\nppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)\nwith torch.no_grad():\n    images = vae.decode(codebooks[ppl_text.argsort()[:16]])\n\npil_images = utils.torch_tensors_to_pil_list(images)\nshow(pil_images, 8)\n```\n![](./pics/pipelines/lake_night.png)\n\n\n### Image Prompt (like Inpainting)\n![](pics/pipelines/lake_image_prompt.png)\n```python\ntext = '\u043b\u043e\u0434\u043a\u0430 \u0441 \u0430\u043b\u044b\u043c\u0438 \u043f\u0430\u0440\u0443\u0441\u0430\u043c\u0438'\n\nimages_num = 1024\nbs = 32\n\nborders = {'up': 6, 'left': 4, 'right': 6, 'down': 2}\nimage_prompts = ImagePrompts(pil_img, borders, vae, device, crop_first=True)\n\nseed_everything(42)\ncodebooks = []\nfor top_k, top_p, images_num in [\n    (1024, 0.99, images_num),\n]:\n    codebooks.append(\n        generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs, image_prompts=image_prompts)\n    )\n\ncodebooks = torch.cat(codebooks)\n\nppl_text, ppl_image = self_reranking_by_text(\n    text,\n    codebooks,\n    tokenizer,\n    model,\n    bs=bs,\n)\nwith torch.no_grad():\n    images = vae.decode(codebooks[ppl_text.argsort()[:16]])\n\npil_images = utils.torch_tensors_to_pil_list(images)\nshow(pil_images, 8)\n```\n![](./pics/pipelines/lake_ship.png)\n\n### Diffusion (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))\n\n### Image Captioning + Self Reranking\n\n```python\ntexts = generate_captions(pil_img, tokenizer, model, vae, template='\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 ', top_k=16, captions_num=128, bs=32, top_p=0.6, temperature=0.8, seed=43, limit_eos=False)\nppl_text, ppl_image = self_reranking_by_image(texts, pil_img, tokenizer, model, vae, bs=32, seed=42)\nfor idx in ppl_image.argsort()[:8]:\n    print(f'-{texts[idx]}')\n```\n\n![](./pics/pipelines/final_lake_ship.png)\n```python\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u043e - \u043a\u0430\u044f\u043a \u0441 \u043f\u043b\u0430\u0432\u0430\u044e\u0449\u0435\u0439 \u043d\u0430 \u043d\u0435\u043c \u0436\u0435\u043d\u0449\u0438\u043d\u043e\u0439\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 - \u043b\u043e\u0434\u043a\u0430 \u0441 \u043f\u0440\u0438\u0437\u0440\u0430\u043a\u0430\u043c\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043a\u043e\u0440\u0430\u0431\u043b\u044c \u00ab \u00bb, \u0432\u0438\u0434 \u0441 \u0432\u043e\u0437\u0434\u0443\u0445\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043b\u043e\u0434\u043a\u0430 \u0441 \u043f\u0430\u0440\u0443\u0441\u043e\u043c \u0438 3d \u044d\u0444\u0444\u0435\u043a\u0442\u043e\u043c, \u0432\u0438\u0434 \u0441 \u0432\u043e\u0437\u0434\u0443\u0445\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043b\u043e\u0434\u043a\u0430 \u0441 \u043f\u0440\u0438\u0432\u0438\u0434\u0435\u043d\u0438\u044f\u043c\u0438, \u0432\u0438\u0434 \u0441\u0432\u0435\u0440\u0445\u0443\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043f\u043e\u0434\u0432\u043e\u0434\u043d\u0430\u044f \u043b\u043e\u0434\u043a\u0430 \u00ab\u0430\u043a\u0443\u043b\u0430\u00bb, \u0432\u0438\u0434 \u0441 \u0432\u043e\u0437\u0434\u0443\u0445\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u043e - \u043d\u0430\u0434\u0443\u0432\u043d\u0430\u044f \u043b\u043e\u0434\u043a\u0430 \u0441 \u0436\u0435\u0441\u0442\u043a\u0438\u043c \u0434\u043d\u043e\u043c\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441 \u0441\u0430\u0439\u0442\u0430 esquire, \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u0439 \u043a\u0440\u0430\u0441\u043d\u044b\u0439 \u043a\u043e\u0440\u0430\u0431\u043b\u044c\n```\n\n![](./pics/pipelines/captioning_dog.png)\n```python\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0434\u043b\u0438\u043d\u043d\u044b\u043c\u0438 \u0443\u0448\u0430\u043c\u0438, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u0443\u0448\u0430\u043c\u0438 \u0438 \u0441 \u0434\u043b\u0438\u043d\u043d\u044b\u043c\u0438 \u043b\u0430\u043f\u0430\u043c\u0438, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u0443\u0448\u0430\u043c\u0438 \u0438 \u043c\u043e\u0440\u0434\u043e\u0439 \u0441\u043e\u0431\u0430\u043a\u0438, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u0435\u043b\u043e\u0439 \u0433\u0440\u0438\u0432\u043e\u0439, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u043a\u043e\u0440\u0438\u0447\u043d\u0435\u0432\u044b\u043c \u0446\u0432\u0435\u0442\u043e\u043c\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u0443\u0448\u0430\u043c\u0438 \u0438 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u0443\u0448\u0430\u043c\u0438, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u0443\u0448\u0430\u043c\u0438 \u0438 \u043a\u043e\u0440\u0438\u0447\u043d\u0435\u0432\u044b\u043c \u043c\u0435\u0445\u043e\u043c, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u0435\u043b\u043e\u0439 \u0433\u0440\u0438\u0432\u043e\u0439, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u0435\u043b\u043e\u0439 \u0433\u0440\u0438\u0432\u043e\u0439\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0441\u043e\u0431\u0430\u043a\u0430 \u0441 \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u0443\u0448\u0430\u043c\u0438 \u0438 \u0434\u043b\u0438\u043d\u043d\u044b\u043c\u0438 \u0443\u0448\u0430\u043c\u0438, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n```\n\n![](./pics/pipelines/captioning_street.png)\n```python\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d \u0436\u0438\u043b\u043e\u0439 \u043a\u043e\u043c\u043f\u043b\u0435\u043a\u0441 \u00ab\u0430\u0440\u0431\u0430\u0442\u00bb\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0438\u0434\u043d\u043e \u0437\u0434\u0430\u043d\u0438\u0435 \u0441 \u043e\u043a\u043d\u0430\u043c\u0438 \u0432 \u0446\u0435\u043d\u0442\u0440\u0435 \u0433\u043e\u0440\u043e\u0434\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d \u0436\u0438\u043b\u043e\u0439 \u0434\u043e\u043c \u0441 \u0432\u0438\u0434\u043e\u043c \u043d\u0430 \u0443\u043b\u0438\u0446\u0443\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0438\u0434\u043d\u0435\u0435\u0442\u0441\u044f \u0437\u0434\u0430\u043d\u0438\u0435 \u0432 \u0446\u0435\u043d\u0442\u0440\u0435 \u0433\u043e\u0440\u043e\u0434\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d \u0432\u0438\u0434 \u043d\u0430 \u0436\u0438\u043b\u043e\u0439 \u043a\u043e\u043c\u043f\u043b\u0435\u043a\u0441, \u0432\u0438\u0434 \u0441 \u0443\u043b\u0438\u0446\u044b\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0438\u0434\u043d\u0430 \u0431\u0430\u0448\u043d\u044f \u0431\u0430\u043d\u043a\u0430 \u0441\u0431\u0435\u0440\u0431\u0430\u043d\u043a\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d \u0444\u0430\u0441\u0430\u0434 \u0437\u0434\u0430\u043d\u0438\u044f \u0441 \u043e\u043a\u043d\u0430\u043c\u0438 \u0432 \u0446\u0435\u043d\u0442\u0440\u0435 \u0433\u043e\u0440\u043e\u0434\u0430\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0438\u0434\u043d\u0435\u0435\u0442\u0441\u044f \u0437\u0434\u0430\u043d\u0438\u0435 \u0441 \u0431\u0430\u043b\u043a\u043e\u043d\u043e\u043c\n```\n\n![](./pics/pipelines/captioning_moto.png)\n```python\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b \u0438\u0436 \u044e\u043f\u0438\u0442\u0435\u0440 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u0441 \u043c\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u0442 \u0438\u0436 \u044e\u043f\u0438\u0442\u0435\u0440, \u0432\u0438\u0434 \u0441\u0437\u0430\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b \u0441 \u043c\u043e\u0442\u043e\u0440\u043e\u043c \u0438 \u043c\u043e\u0442\u043e\u0440\u043e\u043c \u0441 \u043c\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u0442 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b\u0430, \u0432\u0438\u0434 \u0441\u0431\u043e\u043a\u0443\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b \u0441 \u043a\u0443\u0437\u043e\u0432\u043e\u043c \u0438\u0437 \u0444\u0438\u043b\u044c\u043c\u0430 \u00ab\u0431\u044d\u0442\u043c\u0435\u043d \u043f\u0440\u043e\u0442\u0438\u0432 \u0441\u0443\u043f\u0435\u0440\u043c\u0435\u043d\u0430\u00bb, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434 \u0441 \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434\u043e\u043c \u0432 \u0433\u0430\u0440\u0430\u0436\u0435, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b \u0441 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b\u043e\u043c \u00ab\u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b\u00bb \u0432\u0438\u0434 \u0441\u0437\u0430\u0434\u0438, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434 \u0441 \u043a\u043e\u0440\u0437\u0438\u043d\u043e\u0439 \u0434\u043b\u044f \u043f\u043e\u043a\u0443\u043f\u043e\u043a, \u0432\u0438\u0434 \u0441\u0437\u0430\u0434\u0438\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u0432\u0435\u043b\u043e\u0441\u0438\u043f\u0435\u0434 \u0441 \u043c\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u0442 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b\u0430 \u0438\u0436 \u044e\u043f\u0438\u0442\u0435\u0440 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 2 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430, \u0432\u0438\u0434 \u0441\u0431\u043e\u043a\u0443\n-\u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0435 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b \u0441 \u043c\u043e\u0442\u043e\u0446\u0438\u043a\u043b\u043e\u043c \u00ab \u00bb, \u0432\u0438\u0434 \u0441\u043f\u0435\u0440\u0435\u0434\u0438\n```\n\n### Zero-Shot Image Classification using PPL\n```python\nimport base64\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\nbs4_urls = requests.get('https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/pipelines/cats_vs_dogs_bs4.json').json()\n\nf, ax = plt.subplots(2,4, figsize=(12,6))\n\nfor i, bs4_url in enumerate(bs4_urls):\n    pil_img = Image.open(BytesIO(base64.b64decode(bs4_url)))\n    \n    classes = ['\u043a\u043e\u0448\u043a\u0430', '\u0441\u043e\u0431\u0430\u043a\u0430']\n    preds = zs_clf(\n        pil_img, \n        classes,\n        model, \n        tokenizer,\n        vae,\n        template = '{}', \n    )\n    ax[i//4, i%4].imshow(pil_img)\n    ax[i//4, i%4].set_title(preds['class'])\n```\n![](./pics/pipelines/zs_clf.png)\n\n### Linear Probe (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))\n\n# Authors: \n\n+ Alex Shonenkov: [Github](https://github.com/shonenkov), [Kaggle GM](https://www.kaggle.com/shonenkov)\n+ Michael Konstantinov: [Mishin Learning](https://t.me/mishin_learning), [Transformer Community](https://transformer.community/)\n\n<img src='https://habrastorage.org/webt/2w/5k/2r/2w5k2reyf6yqa4s7ywmmioaaieg.png' alt=\"Drawing\" width=\"200\" />  <img src='https://habrastorage.org/webt/eq/ft/g3/eqftg3_8l1b_fpimhiof7knytzk.png' alt=\"Drawing\" width=\"200\" />\n\n# Citation\n\n```\n@article{shonenkov2022ruDolph,\n  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},\n  author        = {Alex Shonenkov and Michael Konstantinov},\n  year          = {2022},\n  eprint        = {...},\n  archivePrefix = {arXiv},\n  primaryClass  = {cs.CL}\n}\n```\n\n```\n@misc{github2022ruDolph,\n  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},\n  author        = {Alex Shonenkov and Michael Konstantinov},\n  year          = {2022},\n  howpublished  = {\\url{https://github.com/sberbank-ai/ru-dolph}},\n}\n```\n\n# Supported by\n\n[<img src=\"https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberai-logo.png\" height=\"115\"/>](https://github.com/sberbank-ai) \\\n[<img src=\"https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberdevices-logo.png\" height=\"40\"/>](https://sberdevices.ru)\n\n[<img src=\"https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sbercloud-logo.png\" height=\"80\"/>](https://sbercloud.ru/) \\\n[<img src=\"https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/airi-logo.png\" height=\"50\"/>](https://airi.net)\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "rudolph",
            "package_url": "https://pypi.org/project/rudolph/",
            "platform": "",
            "project_url": "https://pypi.org/project/rudolph/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/rudolph/0.0.1rc8/",
            "requires_dist": [
                "rudalle (==0.5.0rc1)",
                "taming-transformers (==0.0.1)",
                "more-itertools (>=8.10.0)",
                "transformers (~=4.10.2)",
                "youtokentome (>=1.0.6)",
                "omegaconf (>=2.0.0)",
                "einops (~=0.3.2)",
                "torch",
                "torchvision",
                "matplotlib"
            ],
            "requires_python": "",
            "summary": "RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP",
            "version": "0.0.1rc8",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15328167,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1bb07f8cd33381042379f2fab24be309",
                    "sha256": "6a6111932aa342ba5f07853a60fd7f9c4a5795fb7f2278787b3113dfd60f231b"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc8-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1bb07f8cd33381042379f2fab24be309",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": null,
                "size": 23901,
                "upload_time": "2022-02-04T17:27:04",
                "upload_time_iso_8601": "2022-02-04T17:27:04.938857Z",
                "url": "https://files.pythonhosted.org/packages/b1/17/6d557d773c98581442d69b7e75a8b0caf6df340232628f46e6ed4f43efd4/rudolph-0.0.1rc8-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "e7f737f00d26e93ac3011c85b875fdb0",
                    "sha256": "0102f9647f41d81dfd44e6a60ed8980edf829b4add6a7b559ed15f4dfb478ffe"
                },
                "downloads": -1,
                "filename": "rudolph-0.0.1rc8.tar.gz",
                "has_sig": false,
                "md5_digest": "e7f737f00d26e93ac3011c85b875fdb0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 25334,
                "upload_time": "2022-02-04T17:27:08",
                "upload_time_iso_8601": "2022-02-04T17:27:08.811117Z",
                "url": "https://files.pythonhosted.org/packages/81/eb/7f1bb8adca0b99a2a1be4e05596fb2b16c33fa7ab86e76158b015750ed7f/rudolph-0.0.1rc8.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
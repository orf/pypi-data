{
    "1.0.1": {
        "info": {
            "author": "Vis\u00e3o - FATEC - 6o sem ADS Noturno",
            "author_email": "matheus.silva263@fatec.sp.gov.br",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 4 - Beta",
                "Intended Audience :: Education",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: Portuguese (Brazilian)"
            ],
            "description": "Os programas deste pacote foram adaptados para rodar diretamente no Raspberry Pi 3 do projeto fatequino e, portanto, os pathsde refer\u00eancia dos arquivos de dados est\u00e3o vinculados ao usu\u00e1rio pi do sistema RaspbianEstes programas tamb\u00e9m foram testados no ambiente Windows e, neste caso, \u00e9 necess\u00e1rio criar pastas com a mesma estrutura.Em ambos os casos a pasta raiz usada \u00e9 a Desktop.Obs: No Raspberry Pi a pasta Desktop \u00e9 a \u00e1rea de trabalho do usu\u00e1rio pi mas no Windows \u00e9 apenas uma pasta comum.Pasta de imagens:Os programas foram adaptados para gravar e ler imagens na seguinte pasta:No Raspberry Pi:home pi Desktop reconhecimento DataNo Windows:C: home pi Desktop reconhecimento DataProgramas:1) capturandoRosto.pyEste programa pede a identifica\u00e7\u00e3o do aluno, pode ser um nome (n\u00e3o deve conter espa\u00e7os, barras, ou caracteres estranos) ou o RA do aluno, e cria uma subpasta com essa identifica\u00e7\u00e3o dentro da pasta de imagens.Ativa a c\u00e2mera do Raspberry Pi exibe um quadro de tamanho reduzido na tela, localiza um rostohumano baseado em um modelo padr\u00e3o haarcascade_frontalface_alt.xml  contido na pasta do projeto e captura automaticamenteat\u00e9 50 imagens do rosto do aluno fazendo um recorte de tamanho padr\u00e3o de 150 por 150 pixels e adaptando o tamanho para poderfazer a an\u00e1lise comparativa de imagens posterior. O aluno pode movimentar-se naturalmente em frente \u00e1 c\u00e2mera durante o processo de captura para que o sistema tenhadiversas imagens ligeiramente diferentes do mesmo rosto e possa criar um banco de dados com essas imagens.Um contador de imagens capturadas \u00e9 exibida no topo da tela que mostra o rosto do aluno durante o processo. Caso n\u00e3o queiraesperar a captura das 50 imagens o usu\u00e1rio pode teclar ESC (se houver teclado anexado) e abortar o programa.Pode-se reiniciar o processo posteriormente fornecendo a mesma identifica\u00e7\u00e3o do aluno dada inicialmente e as novas imagenscapturadas ser\u00e3o anexadas aquelas j\u00e1 existentes na pasta de imagens.Obs 1: No Windows a ativa\u00e7\u00e3o da c\u00e2mera, geralmente plugada via porta USB, pode requerer um par\u00e2metro complementar no comandode ativa\u00e7\u00e3oo da c\u00e2mera. Por este motivo foi usado nos programas a biblioteca platform que permite identificar se o programaest\u00e1 sendo executado no Windows para usar este par\u00e2metro adicional.2) treinandoRF.pyEste programa ir\u00e1 processar todas as imagens contidas na pasta de imagens do sistema e ir\u00e1 gerar um arquivo de parametriza\u00e7\u00e3omodeloLBPHFace.xml que ser\u00e1 usado no terceiro programa que faz o reconhecimento facial. Foi escolhido o m\u00e9todo LBPHFaceRecognizer Local Binary Patterns Histograms usado na biblioteca complementar do OpenCVchamada opencv-contrib-python.Ap\u00f3s o treinamento o programa dever\u00e1 gerar o arquivo XML com os par\u00e2metros de reconhecimento ajustadospara aquele conjunto de imagens. Obs: n\u00e3o misturar na mesma subpasta de imagens de um aluno fotos de outros alunos.3) ReconhecimentoFacial.pyEste programa ir\u00e1 ativar a c\u00e2mera do Raspberry Pi exibe um quadro de tamanho reduzido na ela,localiza um rosto humano baseado em um modelo padr\u00e3o haarcascade_frontalface_alt.xml  e usao m\u00e9todo LBPHFaceRecognizer com o arquivo de modelos gerado pelo programa de treinamentomodeloLBPHFace.xml para obter a identifica\u00e7\u00e3o prov\u00e1vel de um rosto capturado pela c\u00e2mera. Ao encontrar um ID sequencialcontido nesse arquivo de par\u00e2metros ele busca, pela ordem, o nome da pasta de imagens que corresponde ao ID encontrado edesenha um quadro ao redor do rosto que aparece na imagem da c\u00e2mera e imprime a identifica\u00e7\u00e3o do usu\u00e1rio no alto desse quadro. 4) HandGestureV(n).pyEst\u00e3o disponibilizados nesta edi\u00e7\u00e3o do projeto 2 vers\u00f5es do programa de reconhecimento de gestos das m\u00e3os.A primeira vers\u00e3o HandGestureV3.py \u00e9 apenas uma corre\u00e7\u00e3o do programa publicado pelas equipes anteriores para poder rodar,relativamente sem erros de execu\u00e7\u00e3o e com um pouco mais de velocidade, no ambiente do Raspberry Pi pois este programa,originalmente, foi desenvolvidor fora do ambiente deste equipamento provavelmente num PC e continha chamadas para exibi\u00e7\u00e3ode telas de depura\u00e7\u00e3o de imagens e grava\u00e7\u00e3o de um arquivo de video  que deixavam a aplica\u00e7\u00e3o mais lenta. Al\u00e9m disso, foi inclu\u00eddo um bloco de tratamento de excess\u00f5es pois, em determinadas situa\u00e7\u00f5es, a biblioteca de reconhecimentode padr\u00f5es usada gerava um erro interno que parava o programa completamente.Embora tenha havido alguma melhora e permita executar este programa no Raspberry Pi o modelo usado neste programa (V3) tentainferir o contorno da m\u00e3o e \u00e2ngulos entre os dedos usando um m\u00e9todo que \u00e9 altamente dependente de ilumina\u00e7\u00e3o adequada epode confundir outros elementos do ambiente como fazendo parte da an\u00e1lise. Gera muitos falsos positivos e erros deidentifica\u00e7\u00e3o com resultados imprevis\u00edveis.Dados os problemas relatados na vers\u00e3o V3 foi criada uma nova vers\u00e3o (V4) com uma abordagem totalmente diferente da anteriore que utiliza a biblioteca mediapipe (Google) com um algoritmo baseado no TensorFlow que consegue extrair das imagens aposi\u00e7\u00e3o exata de cada dedo das m\u00e3os que permitiria at\u00e9 criar um modelo 3D se necess\u00e1rio.A biblioteca mediapipe foi instalada no Raspberry Pi e nos testes realizados diretamente no equipamento conseguiu lercom precis\u00e3o a posi\u00e7\u00e3o de todos os dedos da m\u00e3o. Entretanto, devido ao equipamento ser de reduzido poder de processamento,a velocidade de reconhecimento ficou reduzida a 1 frame por segundo mas, mesmo assim, sem erros devido a presen\u00e7a de outroselementos visuais na imagem e com baixa ilumina\u00e7\u00e3o.Foram acrescentados neste programa rotinas que permitem identificar a posi\u00e7\u00e3o de apenas 1 dedo (se necess\u00e1rio) ou de v\u00e1rios(ou todos) de uma m\u00e3o ou at\u00e9 duas ao mesmo tempo. A posi\u00e7\u00e3o dos dedos \u00e9 desenhada virtualmente sobre a imagem da c\u00e2merapermitindo mostrar em destaque a posi\u00e7\u00e3o de cada ponto de refer\u00eancia (4 por dedo e 1 na base da m\u00e3o) com cores diferentes.Esta vers\u00e3o ainda est\u00e1 em desenvolvimento para permitir calcular os \u00e2ngulos dos dedos (em rela\u00e7\u00e3o \u00e1 base da imagem e entre os dedos) e, eventualmente, determinar se est\u00e3o abertos, fechados, curvados, etc. Entretanto, at\u00e9 essa vers\u00e3o, n\u00e3o foicriado um dicion\u00e1rio de posi\u00e7\u00f5es que permite, por exemplo, obter uma letra da linguagem brasileira de sinais (libras) mascom as fun\u00e7\u00f5es implementadas at\u00e9 o momento isso ser\u00e1 plenamente poss\u00edvel numa futura vers\u00e3o.5) Faces.pyEste \u00e9 um programa exemplo de uma poss\u00edvel interface visual que pode ser implementada no Fatequino (futuramente) no qual,usando-se um display de LCD acoplado no equipamento, \u00e9 exibido um par de olhos que ficam piscando quando o equipamento,atrav\u00e9s da c\u00e2mera, consegue encontrar um rosto nas imagens capturadas e, ao identificar um aluno, \ufffd exibida sua identifica\u00e7\u00e3o no alto da tela. Foram reunidos, num c\u00f3digo s\u00f3, rotinas que desenham olhos (com base em imagens que est\u00e3o na subpasta imagens) em v\u00e1riasposi\u00e7\u00f5es (abertos, cerrados, fechados, piscando) e os programas de captura de rostro (item 1) que localiza nas imagens da c\u00e2mera um rosto gen\u00e9rico e, neste caso, mostra os olhos em posi\u00e7\u00f5es cerrada (como se estivesse tentando reconhecer algu\u00e9m)e o programa de reconhecimento facial (item 3) que, quando consegue encontrar um ID correspondente ao rosto, pisca um dosolhos e exibe no alto da tela a identifica\u00e7\u00e3o do aluno. Os olhos ficam piscando na tela de tempos em tempos como acontececom uma pessoa mostrando que o programa est\u00e1 em funcionamento normal e gerando uma maior empatia com o usu\u00e1rio.Al\u00e9m disso, caso as imagens do aluno estejam na pasta com nome especial chamada DEMO durante o processo de treinamento, ser\u00e1 exibida uma figura de fundo com uma imagem de terror (zumbi). Isso \u00e9 um exemplo de uma aplica\u00e7ao l\u00fadica que pode sercriada acoplando-se um display no Fatequino e permita uma maior intera\u00e7\u00e3o com o usu\u00e1rio.Pode-se tamb\u00e9m aprimorar essa interface gr\u00e1fica com um rosto e com acesso, pela internet, a outros dados relativos aoaluno identificado exibindo-se, em forma adequada, tais informa\u00e7\u00f5es na tela tornando o projeto mais interativo e simp\u00e1tico ao ser humano.",
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/MatheusCarpe/Fatequino-robotic-vision",
            "keywords": "VISAO,FATEC,PROFESSORES,TURMAS",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "fatequino-robotic-vision",
            "package_url": "https://pypi.org/project/fatequino-robotic-vision/",
            "platform": "",
            "project_url": "https://pypi.org/project/fatequino-robotic-vision/",
            "project_urls": {
                "Homepage": "https://github.com/MatheusCarpe/Fatequino-robotic-vision"
            },
            "release_url": "https://pypi.org/project/fatequino-robotic-vision/1.0.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Este c\u00f3digo \u00e9 responsavel pela estrutura de vis\u00e3o rob\u00f3tica.",
            "version": "1.0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 12053766,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "97080785c0ec5abf283b250514fe53d0",
                    "sha256": "ccb7c39fd7833a8aaa6bc11bd093cdfede2fee1ac68f1db7c2de47f8092a28a6"
                },
                "downloads": -1,
                "filename": "fatequino_robotic_vision-1.0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "97080785c0ec5abf283b250514fe53d0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 4944,
                "upload_time": "2021-11-17T23:47:33",
                "upload_time_iso_8601": "2021-11-17T23:47:33.057898Z",
                "url": "https://files.pythonhosted.org/packages/65/ab/dbec27d3e86190f4866f01fbb936a79deac43205a830a609574eda7f1b4f/fatequino_robotic_vision-1.0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1": {
        "info": {
            "author": "Irvinfaith",
            "author_email": "irvinfaith@hotmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Irvinfaith/tinyCrawl",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tinyCrawl",
            "package_url": "https://pypi.org/project/tinyCrawl/",
            "platform": "python 3.6",
            "project_url": "https://pypi.org/project/tinyCrawl/",
            "project_urls": {
                "Homepage": "https://github.com/Irvinfaith/tinyCrawl"
            },
            "release_url": "https://pypi.org/project/tinyCrawl/0.1/",
            "requires_dist": null,
            "requires_python": "",
            "summary": "Very easy and tiny crawling framework, support multithread processing.",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 9111222,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "660e3bc8599062cbaf0d7e34e55e3fdd",
                    "sha256": "42b4089a2559dc1535245b1d663bbac59d6a22f61504f71061c23bd2c73176d6"
                },
                "downloads": -1,
                "filename": "tinyCrawl-0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "660e3bc8599062cbaf0d7e34e55e3fdd",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": null,
                "size": 10895516,
                "upload_time": "2021-01-10T10:27:11",
                "upload_time_iso_8601": "2021-01-10T10:27:11.205571Z",
                "url": "https://files.pythonhosted.org/packages/7f/0b/6b2c4a1409e80d84b317c478f3d79300a21386a1911c76915ca289364f0a/tinyCrawl-0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "Irvinfaith",
            "author_email": "waxiguan00@hotmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Irvinfaith/tinyCrawl",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tinyCrawl",
            "package_url": "https://pypi.org/project/tinyCrawl/",
            "platform": "python 3.6",
            "project_url": "https://pypi.org/project/tinyCrawl/",
            "project_urls": {
                "Homepage": "https://github.com/Irvinfaith/tinyCrawl"
            },
            "release_url": "https://pypi.org/project/tinyCrawl/0.1.1/",
            "requires_dist": null,
            "requires_python": ">=3.6,<4",
            "summary": "Very easy and tiny crawling framework, support multithread processing.",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 9111222,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b4113ae3259cdedbad35cd1a993ad4b0",
                    "sha256": "9181d2b1d24b3c668879c98b8ad45ea74691f11c1059563563fdc29ecf98d04b"
                },
                "downloads": -1,
                "filename": "tinyCrawl-0.1.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b4113ae3259cdedbad35cd1a993ad4b0",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6,<4",
                "size": 14419,
                "upload_time": "2021-01-11T07:46:25",
                "upload_time_iso_8601": "2021-01-11T07:46:25.271965Z",
                "url": "https://files.pythonhosted.org/packages/e6/4e/a2269c7f4257a9582287ad8c9f141be862aaf0a33fad3f001bdddd393d4f/tinyCrawl-0.1.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "6c611141970fabc1431cd1e204c86749",
                    "sha256": "a6f69b2e5a8befe5d48ac9685865ff782cf18f68d50ff8af025d5fc4bf117e7e"
                },
                "downloads": -1,
                "filename": "tinyCrawl-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "6c611141970fabc1431cd1e204c86749",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6,<4",
                "size": 10891417,
                "upload_time": "2021-01-11T07:47:19",
                "upload_time_iso_8601": "2021-01-11T07:47:19.887971Z",
                "url": "https://files.pythonhosted.org/packages/59/c0/6c33a110ca203fb56e33edb1c432fcb767e1d9c84231d872e578d59ebad8/tinyCrawl-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "Irvinfaith",
            "author_email": "waxiguan00@hotmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": "[![PyPI version](https://badge.fury.io/py/tinyCrawl.svg)](https://badge.fury.io/py/tinyCrawl)\n[![Build Status](https://travis-ci.com/Irvinfaith/tinyCrawl.svg?branch=master)](https://travis-ci.com/Irvinfaith/tinyCrawl)\n[![Documentation Status](https://readthedocs.org/projects/tinycrawl-irvinfaith/badge/?version=latest)](https://tinycrawl-irvinfaith.readthedocs.io/zh_CN/latest/?badge=latest)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/tinyCrawl)\n![GitHub](https://img.shields.io/github/license/irvinfaith/tinyCrawl)\n\n# Overview \u6982\u89c8\n\ntinyCrawl \u662f\u4e00\u4e2a\u5fae\u578b\u7684\u722c\u866b\u6846\u67b6\uff0c\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a\n\n- \u7b80\u5355\u8f7b\u5de7\uff0c\u6ca1\u6709\u4efb\u4f55\u7b2c\u4e09\u65b9\u5305\u7684\u4f9d\u8d56\n- checkpoint\u65ad\u70b9\u7eed\u722c\n- \u652f\u6301\u591a\u7ebf\u7a0b\u722c\u53d6\n- \u5185\u7f6e\u65e5\u5fd7\u529f\u80fd\n- \u4f7f\u7528\u7b80\u5355\n\n# Documentation \u6587\u6863\n\n[\u8bbf\u95ee\u5b98\u65b9\u8bf4\u660e\u6587\u6863](https://tinycrawl-irvinfaith.readthedocs.io/zh_CN/latest/)\n\n# Installation \u5b89\u88c5\n\n```\npip install tinyCrawl\n```\n\n\n# How to use \u5982\u4f55\u4f7f\u7528\ntinyCrawl \u652f\u63012\u79cd\u8fd0\u884c\u65b9\u6cd5\n\n- By using funciton \u51fd\u6570\u5f0f\uff1a\u5b9a\u4e49\u722c\u866b\u7684\u65b9\u6cd5 task()\uff0c\u5b9e\u4f8b\u5316 ``BaseCrawl(iter_url, iter_num_range, thread_num)``\uff0c\u8c03\u7528 ``run`` \u65b9\u6cd5\u6267\u884c\n- By inheritance \u7ee7\u627f\u5f0f\uff1a\u7ee7\u627f ``BaseCrawl(iter_url, iter_num_range, thread_num)`` \uff0c\u91cd\u5199 ``crawl()`` \u548c ``sink()`` \u65b9\u6cd5\uff0c\u5176\u4e2d ``crawl()``\u7c7b\u4f3c\u4e8e\u4e0a\u4e00\u65b9\u6cd5\u4e2d\u7684\u722c\u866b\u65b9\u6cd5task()\uff0c\u5b9a\u4e49\u722c\u53d6\u5355\u9875\u7684\u722c\u866b\u4ee3\u7801\uff0c ``sink()``\u662f\u5c06\u7ed3\u679c\u8f93\u51fa\u7684\u65b9\u6cd5\uff0c\u6700\u540e\u6267\u884c ``main()`` \u65b9\u6cd5\u6267\u884c\u603b\u7a0b\u5e8f\n\n\n## By using funciton \u51fd\u6570\u5f0f\n\n```python\n# -*- coding: utf-8 -*-\n\nfrom tinyCrawl import BaseCrawl, RowContainer\n\nfrom urllib.request import urlopen\nfrom lxml import etree\n\n# \u5b9a\u4e49xpath\nsong_name_xpath = '//div[@class=\"song-name\"]/a/text()'\nsinger_xpath = '//div[@class=\"singers\"]/a[1]/text()'\nalbum_xpath = '//div[@class=\"album\"]/a[1]/text()'\n\ndef task(url):\n    \"\"\"\n    \u5b9a\u4e49\u722c\u53d6\u5355\u9875\u7684\u722c\u866b\u4ee3\u7801\n\n    \"\"\"\n    # \u5b9a\u4e49\u6570\u636e\u5b58\u653e\u7684\u5bb9\u5668\uff0c\u5bb9\u5668\u540d\u5b57\u5c31\u662f\u6700\u540e\u722c\u53d6\u7ed3\u679c\u5b58\u653e\u5b57\u5178\u7684self.out\u7684key\n    song_name_list = RowContainer(\"song name\")\n    singer_list = RowContainer(\"singer\")\n    album_list = RowContainer(\"album\")\n\n    page = urlopen(url).read().decode(\"utf-8\", 'ignore')\n    parse = etree.HTML(page)\n    for _song_name, _singer, _album in zip(parse.xpath(song_name_xpath),\n                                           parse.xpath(singer_xpath),\n                                           parse.xpath(album_xpath)):\n       \t# \u5c06\u6570\u636eappend\u8fdb\u6307\u5b9a\u5bb9\u5668\u4e2d\n        song_name_list.append(str(_song_name))\n        singer_list.append(str(_singer))\n        album_list.append(str(_album))\n\n\n# \u7b2c\u4e00\u4e2a\u53c2\u6570\u662f\u94fe\u63a5\u5730\u5740\uff0c\u9700\u901a\u8fc7 %s \u5b9a\u4e49\u9875\u6570\u7b49\u8fed\u4ee3\u7684\u53c2\u6570\n# \u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u8fed\u4ee3\u7684\u8303\u56f4\uff0c\n# \u7b2c\u4e09\u4e2a\u53c2\u6570\u662f\u542f\u7528\u7684\u7ebf\u7a0b\u6570\uff0c\u5927\u4e8e1\u5c31\u662f\u591a\u7ebf\u7a0b\uff0c\u7b49\u4e8e1\u5c31\u662f\u5355\u7ebf\u7a0b\nbc = BaseCrawl(\"http://example.com/?page=%s\", range(1, 5), 3)\n# \u8f93\u5165task\u7684\u5bf9\u8c61\uff0c\u5f00\u59cb\u6267\u884c\u7a0b\u5e8f\nbc.run(task)\n# \u6267\u884c\u5b8c\u6bd5\u540e\uff0c\u901a\u8fc7out\u5c5e\u6027\uff0c\u83b7\u53d6\u7ed3\u679c\nprint(bc.out)\n```\n\n## By inheritance \u7ee7\u627f\u5f0f\n\n```python\nfrom tinyCrawl import BaseCrawl, RowContainer\nfrom urllib.request import urlopen\nfrom lxml import etree\nimport pandas as pd\n\n# \u9700\u7ee7\u627fBaseCrawl\u7c7b\uff0c\u8986\u5199crawl\u548csink\u65b9\u6cd5\nclass Scratch(BaseCrawl):\n    def __init__(self, iter_url, iter_num_range, thread_num):\n        super().__init__(iter_url, iter_num_range, thread_num)\n\n    # \u8986\u5199crawl\u65b9\u6cd5\n    def crawl(self, url):\n    # \u5b9a\u4e49\u6570\u636e\u5b58\u653e\u7684\u5bb9\u5668\uff0c\u5bb9\u5668\u540d\u5b57\u5c31\u662f\u6700\u540e\u722c\u53d6\u7ed3\u679c\u5b58\u653e\u5b57\u5178\u7684self.out\u7684key\n    song_name_list = RowContainer(\"song name\")\n    singer_list = RowContainer(\"singer\")\n    album_list = RowContainer(\"album\")\n\n    page = urlopen(url).read().decode(\"utf-8\", 'ignore')\n    parse = etree.HTML(page)\n    for _song_name, _singer, _album in zip(parse.xpath(song_name_xpath),\n                                           parse.xpath(singer_xpath),\n                                           parse.xpath(album_xpath)):\n       \t# \u5c06\u6570\u636eappend\u8fdb\u6307\u5b9a\u5bb9\u5668\u4e2d\n        song_name_list.append(str(_song_name))\n        singer_list.append(str(_singer))\n        album_list.append(str(_album))\n\n    # \u8986\u5199sink\u65b9\u6cd5\uff0c\u5c06\u722c\u53d6\u7684\u7ed3\u679c\u8f93\u51fa\n    def sink(self):\n        # self.out\u662f\u5b57\u5178\u7ed3\u6784\u7684\u7ed3\u679c\uff0c\u53ef\u4ee5\u76f4\u63a5\u8f93\u5165pandas\u5b58\u4e3adataframe\n        recent_music = pd.DataFrame(self.out)\n        recent_music.to_csv(\"D:/tmptest.csv\", index=0)\n\n\nif __name__ == '__main__':\n    mc = Scratch(\"http://example.com/?page=%s\", range(1, 5), 3)\n    # \u8c03\u7528main\u51fd\u6570\u6267\u884c\u7a0b\u5e8f\n    mc.main()\n```\n\noutput\uff1a\n\n```shell\n2021-01-10 16:18:36,944 - base.py - __init__ - [line:30] - INFO: Checkpoint path: D:\\breakpoint_page.txt\n2021-01-10 16:18:38,539 - base.py - __source - [line:119] - INFO: Now is running on multithread mode, total thread num is `3`\n2021-01-10 16:18:38,539 - base.py - __source - [line:126] - INFO: Total iteration num: 4\n2021-01-10 16:18:38,541 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_0 now is processing: http://example.com/?page=1\n2021-01-10 16:18:38,541 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_1 now is processing: http://example.com/?page=2\n2021-01-10 16:18:38,542 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_2 now is processing: http://example.com/?page=3\n2021-01-10 16:18:41,544 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_1 task finished; (Time took: 3.0009s)\n2021-01-10 16:18:41,544 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_0 task finished; (Time took: 3.0019s)\n2021-01-10 16:18:41,544 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_2 task finished; (Time took: 3.0009s)\n2021-01-10 16:18:41,545 - base.py - _multi_thread_wrap - [line:59] - INFO: ThreadPoolExecutor-1_1 now is processing: http://example.com/?page=4\n2021-01-10 16:18:44,551 - base.py - __task_done - [line:115] - INFO: ThreadPoolExecutor-1_1 task finished; (Time took: 3.0022s)\n2021-01-10 16:18:44,551 - base.py - __source - [line:151] - INFO: All done. (Time took: 6.0102s)\n```\n\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Irvinfaith/tinyCrawl",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "tinyCrawl",
            "package_url": "https://pypi.org/project/tinyCrawl/",
            "platform": "python 3.6",
            "project_url": "https://pypi.org/project/tinyCrawl/",
            "project_urls": {
                "Homepage": "https://github.com/Irvinfaith/tinyCrawl"
            },
            "release_url": "https://pypi.org/project/tinyCrawl/0.1.2/",
            "requires_dist": null,
            "requires_python": ">=3.6,<4",
            "summary": "Very easy and tiny crawling framework, support multithread processing.",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 9111222,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ba5f3a663d6a9959f57ac5861d9c99fe",
                    "sha256": "894fee57ac9c5509c199f8a3505553ad744d876eba0b39fa963fe41b84d2b8f5"
                },
                "downloads": -1,
                "filename": "tinyCrawl-0.1.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ba5f3a663d6a9959f57ac5861d9c99fe",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6,<4",
                "size": 14939,
                "upload_time": "2021-01-12T03:44:14",
                "upload_time_iso_8601": "2021-01-12T03:44:14.918927Z",
                "url": "https://files.pythonhosted.org/packages/39/95/be2ce841221dc2a55887101ab6abc6af6ed64adc5f0382d74f53cab3643a/tinyCrawl-0.1.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "e90de4d5ad9e549f3c1c26df8205459c",
                    "sha256": "fa9bafb0920fc429ff473fa0fd6fe7a6fdfd7562c84723d5d5ebaade9c1f8634"
                },
                "downloads": -1,
                "filename": "tinyCrawl-0.1.2.tar.gz",
                "has_sig": false,
                "md5_digest": "e90de4d5ad9e549f3c1c26df8205459c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6,<4",
                "size": 10913458,
                "upload_time": "2021-01-12T03:45:48",
                "upload_time_iso_8601": "2021-01-12T03:45:48.393819Z",
                "url": "https://files.pythonhosted.org/packages/d5/15/d695fba55a999a710c6a527d70911da3bb4411cd8e5d17e02a9734634afc/tinyCrawl-0.1.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
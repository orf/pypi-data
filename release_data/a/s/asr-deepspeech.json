{
    "0.3.2": {
        "info": {
            "author": "CADIC Jean-Maximilien",
            "author_email": "git@zakuro.ai",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3.8"
            ],
            "description": "<h1 align=\"center\">\n  <br>\n  <img src=\"https://drive.google.com/uc?id=17SeD6ijR7DV_EnZGJqavHxVbNHs8n4EQ\">\n  <br>\n    ASRDeepspeech x Sakura-ML \n    (English/Japanese)\n  <br>\n</h1>\n\n<p align=\"center\">\n  <a href=\"#modules\">Modules</a> \u2022\n  <a href=\"#code-structure\">Code structure</a> \u2022\n  <a href=\"#installing-the-application\">Installing the application</a> \u2022\n  <a href=\"#makefile-commands\">Makefile commands</a> \u2022\n  <a href=\"#environments\">Environments</a> \u2022\n  <a href=\"#dataset\">Dataset</a>\u2022\n  <a href=\"#running-the-application\">Running the application</a>\u2022\n  <a href=\"#notes\">Notes</a>\u2022\n</p>\n\n\nThis repository offers a clean code version of the original repository from SeanNaren with classes and modular\ncomponents (eg trainers, models, loggers...).\n\nI have added a configuration file to manage the parameters set in the model. You will also find a pretrained model in japanese performing a `CER = 34` on JSUT test set .\n\n# Modules\n\nAt a granular level, ASRDeepSpeech is a library that consists of the following components:\n\n| Component | Description |\n| ---- | --- |\n| **asr_deepspeech** | Speech Recognition package |\n| **asr_deepspeech.data** | Data related module |\n| **asr_deepspeech.data.dataset** | Build the dataset |\n| **asr_deepspeech.data.loaders** | Load the dataset |\n| **asr_deepspeech.data.parsers** | Parse the dataset |\n| **asr_deepspeech.data.samplers** | Sample the dataset |\n| **asr_deepspeech.decoders** | Decode the generated text |\n| **asr_deepspeech.loggers** | Loggers |\n| **asr_deepspeech.modules** | Components of the network |\n| **asr_deepspeech.parsers** | Arguments parser |\n| **asr_deepspeech.tests** | Test units |\n| **asr_deepspeech.trainers** | Trainers |\n\n\n# Code structure\n```python\nfrom setuptools import setup\nfrom asr_deepspeech import __version__\n\nsetup(\n    name=\"asr_deepspeech\",\n    version=__version__,\n    short_description=\"ASRDeepspeech (English / Japanese)\",\n    long_description=\"\".join(open(\"README.md\", \"r\").readlines()),\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/zakuro-ai/asr\",\n    license=\"MIT Licence\",\n    author=\"CADIC Jean-Maximilien\",\n    python_requires=\">=3.8\",\n    packages=[\n        \"asr_deepspeech\",\n        \"asr_deepspeech.audio\",\n        \"asr_deepspeech.data\",\n        \"asr_deepspeech.data.dataset\",\n        \"asr_deepspeech.data.loaders\",\n        \"asr_deepspeech.data.manifests\",\n        \"asr_deepspeech.data.parsers\",\n        \"asr_deepspeech.data.samplers\",\n        \"asr_deepspeech.decoders\",\n        \"asr_deepspeech.etl\",\n        \"asr_deepspeech.loggers\",\n        \"asr_deepspeech.models\",\n        \"asr_deepspeech.modules\",\n        \"asr_deepspeech.parsers\",\n        \"asr_deepspeech.tests\",\n        \"asr_deepspeech.trainers\",\n    ],\n    include_package_data=True,\n    package_data={\"\": [\"*.yml\"]},\n    install_requires=[r.rsplit()[0] for r in open(\"requirements.txt\")],\n    author_email=\"git@zakuro.ai\",\n    description=\"ASRDeepspeech (English / Japanese)\",\n    platforms=\"linux_debian_10_x86_64\",\n    classifiers=[\n        \"Programming Language :: Python :: 3.8\",\n        \"License :: OSI Approved :: MIT License\",\n    ],\n)\n\n```\n\n\n# Installing the application\nTo clone and run this application, you'll need the following installed on your computer:\n- [Git](https://git-scm.com)\n- Docker Desktop\n   - [Install Docker Desktop on Mac](https://docs.docker.com/docker-for-mac/install/)\n   - [Install Docker Desktop on Windows](https://docs.docker.com/desktop/install/windows-install/)\n   - [Install Docker Desktop on Linux](https://docs.docker.com/desktop/install/linux-install/)\n- [Python](https://www.python.org/downloads/)\n\nInstall bpd:\n```bash\n# Clone this repository and install the code\ngit clone https://github.com/zakuro-ai/asr\n\n# Go into the repository\ncd asr\n```\n\n\n# Makefile commands\nExhaustive list of make commands:\n```\npull                # Download the docker image\nsandbox             # Launch the sandox image \ninstall_wheels      # Install the wheel\ntests               # Test the code\n```\n# Environments\nWe are providing a support for local or docker setup. However we recommend to use docker to avoid any difficulty to run\n the code. \nIf you decide to run the code locally you will need python3.6 with cuda>=10.1.\nSeveral libraries are needed to be installed for training to work. I will assume that everything is being installed in\nan Anaconda installation on Ubuntu, with Pytorch 1.0.\nInstall [PyTorch](https://github.com/pytorch/pytorch#installation) if you haven't already.\n\n## Docker\n\n> **Note**\n> \n> Running this application by using Docker is recommended.\n\nTo build and run the docker image\n```\nmake pull\nmake sandbox\n```\n\n## PythonEnv\n\n> **Warning**\n> \n> Running this application by using PythonEnv is possible but *not* recommended.\n```\nmake install_wheels\n```\n\n## Test\n```\nmake tests\n```\nYou should be able to get an output like\n```python\n=1= TEST PASSED : asr_deepspeech\n=1= TEST PASSED : asr_deepspeech.data\n=1= TEST PASSED : asr_deepspeech.data.dataset\n=1= TEST PASSED : asr_deepspeech.data.loaders\n=1= TEST PASSED : asr_deepspeech.data.parsers\n=1= TEST PASSED : asr_deepspeech.data.samplers\n=1= TEST PASSED : asr_deepspeech.decoders\n=1= TEST PASSED : asr_deepspeech.loggers\n=1= TEST PASSED : asr_deepspeech.modules\n=1= TEST PASSED : asr_deepspeech.parsers\n=1= TEST PASSED : asr_deepspeech.test\n=1= TEST PASSED : asr_deepspeech.trainers\n```\n\n# Datasets\n\nBy default we process the JSUT dataset. See the `config` section to know how to process a custom dataset.\n```python\nfrom gnutools.remote import gdrive\nfrom asr_deepspech import  cfg\n\n# This will download the JSUT dataset in your /tmp\ngdrive(cfg.gdrive_uri)\n```\n## ETL\n\n```\npython -m asr_deepspeech.etl\n```\n\n# Running the application\n\n## Training a Model\n\nTo train on a single gpu\n```bash\nsakura -m asr_deepspeech.trainers\n```\n\n## Pretrained model\n```bash\npython -m asr_deepspeech\n```\n\n\n# Notes\n<li> Clean verbose during training \n\n```\n================ VARS ===================\nmanifest: clean\ndistributed: True\ntrain_manifest: __data__/manifests/train_clean.json\nval_manifest: __data__/manifests/val_clean.json\nmodel_path: /data/ASRModels/deepspeech_jp_500_clean.pth\ncontinue_from: None\noutput_file: /data/ASRModels/deepspeech_jp_500_clean.txt\nmain_proc: True\nrank: 0\ngpu_rank: 0\nworld_size: 2\n==========================================\n```\n<li> Progress bar\n\n```\n...\nclean - 0:00:46 >> 2/1000 (1) | Loss 95.1626 | Lr 0.30e-3 | WER/CER 98.06/95.16 - (98.06/[95.16]): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:46<00:00,  2.59s/it]\nclean - 0:00:47 >> 3/1000 (1) | Loss 96.3579 | Lr 0.29e-3 | WER/CER 97.55/97.55 - (98.06/[95.16]): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:47<00:00,  2.61s/it]\nclean - 0:00:47 >> 4/1000 (1) | Loss 97.5705 | Lr 0.29e-3 | WER/CER 100.00/100.00 - (98.06/[95.16]): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:47<00:00,  2.66s/it]\nclean - 0:00:48 >> 5/1000 (1) | Loss 97.8628 | Lr 0.29e-3 | WER/CER 98.74/98.74 - (98.06/[95.16]): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:50<00:00,  2.78s/it]\nclean - 0:00:50 >> 6/1000 (5) | Loss 97.0118 | Lr 0.29e-3 | WER/CER 96.26/93.61 - (96.26/[93.61]): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:49<00:00,  2.76s/it]\nclean - 0:00:50 >> 7/1000 (5) | Loss 97.2341 | Lr 0.28e-3 | WER/CER 98.35/98.35 - (96.26/[93.61]):  17%|\u2588\u2588\u2588\u258a                   | 3/18 [00:10<00:55,  3.72s/it]\n...\n```\n\n<li> Separated text file to check wer/cer with histogram on CER values (best/last/worst result)\n\n```\n================= 100.00/34.49 =================\n----- BEST -----\nRef:\u826f\u3042\u308b\u4eba\u306a\u3089\u305d\u3093\u306a\u98a8\u306b\u306b\u8a71\u3057\u304b\u3051\u306a\u3044\u3060\u308d\u3046\nHyp:\u7528\u3042\u308b\u4eba\u306a\u3089\u305d\u3093\u306a\u98a8\u306b\u306b\u8a71\u3057\u304b\u3051\u306a\u3044\u3060\u308d\u3046\nWER:100.0  - CER:4.761904761904762\n----- LAST -----\nRef:\u3059\u307f\u307e\u305b\u3093\u304c\u30aa\u30fc\u30b9\u30c1\u30f3\u3055\u3093\u306f5\u65e5\u306b\u306f\u3067\u3059\nHyp:\u3059\u307f\u307e\u305b\u3093\u304c\u30fc\u30b9\u30f3\u3055\u3093\u306f\u4e00\u3064\u304b\u306b\u306f\u3067\u3059\nWER:100.0  - CER:25.0\n----- WORST -----\nRef:\u5c0f\u5207\u306b\u306f\u5185\u304c\u307f\u3089\u308c\u308b\nHyp:\u30b3\u306b\u306f\u5185\u5148\u91d1\u5730\u3064\u4f5c\u307f\u304c\u898b\u3089\u308c\u308b\nWER:100.0  - CER:90.0\nCER histogram\n|###############################################################################\n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                           6  0-10  \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                          15  10-20 \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  36  20-30 \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    35  30-40 \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                   27  40-50 \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                        16  50-60 \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                             5  60-70 \n|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                           6  70-80 \n|                                                                      0  80-90 \n|\u2588                                                                     1  90-100\n=============================================\n```\n\n\n## Acknowledgements\n\nThanks to [Egor](https://github.com/EgorLakomkin) and [Ryan](https://github.com/ryanleary) for their contributions!\n\nThis is a fork from https://github.com/SeanNaren/deepspeech.pytorch. The code has been improved for the readability only.\n\nFor any question please contact me at j.cadic[at]protonmail.ch\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/zakuro-ai/asr",
            "keywords": "",
            "license": "MIT Licence",
            "maintainer": "",
            "maintainer_email": "",
            "name": "asr-deepspeech",
            "package_url": "https://pypi.org/project/asr-deepspeech/",
            "platform": "linux_debian_10_x86_64",
            "project_url": "https://pypi.org/project/asr-deepspeech/",
            "project_urls": {
                "Homepage": "https://github.com/zakuro-ai/asr"
            },
            "release_url": "https://pypi.org/project/asr-deepspeech/0.3.2/",
            "requires_dist": [
                "audioread",
                "scipy",
                "appdirs",
                "gnutools-python (>=2.3.2)",
                "python-levenshtein",
                "torch",
                "visdom",
                "wget",
                "librosa",
                "tqdm",
                "matplotlib",
                "ascii-graph",
                "tensorboardX",
                "numba",
                "numpy (>=1.23.3)",
                "PyYaml",
                "zakuro-ai",
                "sakura-ml (>=0.1.1)",
                "ipywidgets",
                "pandas",
                "bpd"
            ],
            "requires_python": ">=3.8",
            "summary": "ASRDeepspeech (English / Japanese)",
            "version": "0.3.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15187026,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7a7059be48a53494c838f8dd1923535b",
                    "sha256": "16e65eaef9b435f7edbb473b00cc04fb681e4d44e346d3fd6a343df088484e4e"
                },
                "downloads": -1,
                "filename": "asr_deepspeech-0.3.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7a7059be48a53494c838f8dd1923535b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8",
                "size": 42037,
                "upload_time": "2022-09-23T06:17:48",
                "upload_time_iso_8601": "2022-09-23T06:17:48.382525Z",
                "url": "https://files.pythonhosted.org/packages/5f/25/c0008cd5fe2c99eb36915eedbc48a56d4538312b8d465c7cc0a761f9fd73/asr_deepspeech-0.3.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
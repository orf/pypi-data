{
    "0.1.0": {
        "info": {
            "author": "Jaackson Cakes",
            "author_email": "jacksonkek257@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "Intended Audience :: Developers",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.6",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9",
                "Topic :: Scientific/Engineering :: Artificial Intelligence"
            ],
            "description": "# Chinese_keyBERT\nChinese_keyBERT is a minimal Chinese keywords extraction library that leverage the contextual embeddings generated from BERT models to extract relevant keywords from the given texts.\n\n## Installation\n```\npip install chinese_keybert\n```\n\n## Get started\n```\nfrom chinese_keybert import Chinese_Extractor\nkw_extractor = Chinese_Extractor()\ntext = [\n   '''\n\u6e3e\u6c34\u5275\u59cb\u4eba\uff1a\u4e03\u6708\u958b\u59cb\u8abf\u67e5\u8c9d\u6bbc\uff0c\u56e0\u70ba\u201c\u597d\u5f97\u96e3\u4ee5\u7f6e\u4fe1\u201d 2021\u5e7412\u670816\u65e5\uff0c\u505a\u7a7a\u6a5f\u69cb\u6e3e\u6c34\u5728\u793e\u4ea4\u5a92\u9ad4\u4e0a\u516c\u958b\u8868\u793a\uff0c\u6b63\u5728\u505a\u7a7a\u7f8e\u80a1\u4e0a\u5e02\u516c\u53f8\u8c9d\u6bbc...\n'''\n]\nresult = kw_extractor.generate_keywords(text,top_k=5,rank_methods=\"mmr\")\n```\n\n## How it works\nThe core idea behind chinese_keyBERT is to utilize a word segmentation models to segments a piece of text into smaller n-grams and filter the n-grams according to the defined part-of-speech (as some pos are not suitable to be used as a keyword). Then, an embedding model (eg. BERT) is used to encode the text and filtered n_grams into embeddings and using some ranking methods (eg. maximun sum/maximun marginal relevance) to compute the cosine distances betweens the text and n-grams embeddings and rank the keywords according to the scores.\n\n## To-do\n- [ ] Documentations\n- [ ] Vectorization operations to speed-up processing of multiple documents\n- [ ] Add support for other word segmentation, part-of-speech and embeddings model\n\n## Credit\nChinese_keyBERT was largely inspired by [KeyBERT](https://github.com/MaartenGr/KeyBERT), a minimal library for embedding based keywords extractions. Besides, Chinese_keyBERT is also heavily relies on Chinese word segmentation and POS library from [CKIP](https://github.com/ckiplab/ckip-transformers) as well as [sentence-transformer](https://github.com/UKPLab/sentence-transformers) for generating quality embeddings. \n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/JacksonCakes/chinese_keybert",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "chinese-keybert",
            "package_url": "https://pypi.org/project/chinese-keybert/",
            "platform": null,
            "project_url": "https://pypi.org/project/chinese-keybert/",
            "project_urls": {
                "Homepage": "https://github.com/JacksonCakes/chinese_keybert"
            },
            "release_url": "https://pypi.org/project/chinese-keybert/0.1.0/",
            "requires_dist": [
                "ckip-transformers (>=0.3.2)",
                "numpy (>=1.20.1)",
                "sentence-transformers (>=2.2.2)"
            ],
            "requires_python": ">=3.6",
            "summary": "Chinese keyword extraction using transformer-based language models",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15611887,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "cd690b060f4c8e7cd0883a8d5fcf7486",
                    "sha256": "bedfb59adbfeb84936f0f72386a955973d3096151d609c52fa503a9c858f6407"
                },
                "downloads": -1,
                "filename": "chinese_keybert-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "cd690b060f4c8e7cd0883a8d5fcf7486",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.6",
                "size": 10122,
                "upload_time": "2022-11-01T14:46:27",
                "upload_time_iso_8601": "2022-11-01T14:46:27.850292Z",
                "url": "https://files.pythonhosted.org/packages/05/43/b389f81eece163a83777cf7a537d19e91e1551a07b5941e8f42ee63c86b8/chinese_keybert-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "ad638e69d34421ce83f3a287aa9236ce",
                    "sha256": "505358bcd300fc78900dfe189e4b13f6dc6d4b8314e5f3bb6c11bf6e3375013f"
                },
                "downloads": -1,
                "filename": "chinese_keybert-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "ad638e69d34421ce83f3a287aa9236ce",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 8713,
                "upload_time": "2022-11-01T14:46:29",
                "upload_time_iso_8601": "2022-11-01T14:46:29.817414Z",
                "url": "https://files.pythonhosted.org/packages/78/99/db56f3aef86c2d7fa7cf9d670ba1448b90ee5a4194da9dd7cd11ab5cc68f/chinese_keybert-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
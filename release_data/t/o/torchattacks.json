{
    "1.3": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/1.3/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "15ab126863786b26f2662c911c6cdd1f",
                    "sha256": "4c11eb4a9849e18f2f8a111f980abf73b3299411c79e49109b770b1851a7aa36"
                },
                "downloads": -1,
                "filename": "torchattacks-1.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "15ab126863786b26f2662c911c6cdd1f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 15949,
                "upload_time": "2020-04-20T00:56:26",
                "upload_time_iso_8601": "2020-04-20T00:56:26.050423Z",
                "url": "https://files.pythonhosted.org/packages/3a/15/43d6010be0ef23ce21633749dae17cc264e8fbae1590c941c0b66ab6de50/torchattacks-1.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.4": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/1.4/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "1.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1a6a366e2554f66cb0ccf097c7bbe6a2",
                    "sha256": "59a143dcdd9954945f9ebee59d9f9cff1540129fd844800a0f192fddf1d924ff"
                },
                "downloads": -1,
                "filename": "torchattacks-1.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1a6a366e2554f66cb0ccf097c7bbe6a2",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 15312,
                "upload_time": "2020-05-08T14:27:15",
                "upload_time_iso_8601": "2020-05-08T14:27:15.461637Z",
                "url": "https://files.pythonhosted.org/packages/c5/7b/635c264f0bd43b409ffecfb32e9828134883933b78d9971c3d006b145f00/torchattacks-1.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "1.5": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/1.5/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "1.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "793ab984a0526926cad60a3af348668b",
                    "sha256": "375db95e56da2f3981e3603dfed015385e2a50296c36abbbeaad40143c360b0e"
                },
                "downloads": -1,
                "filename": "torchattacks-1.5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "793ab984a0526926cad60a3af348668b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 17230,
                "upload_time": "2020-06-04T16:03:40",
                "upload_time_iso_8601": "2020-06-04T16:03:40.087208Z",
                "url": "https://files.pythonhosted.org/packages/8c/27/dd815a5182eee243d5d5fc7c788b6a90347903c93a4af40c660b1ab9763e/torchattacks-1.5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.10": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.10/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.10",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e62b3758d5918b3395ffc13b40580629",
                    "sha256": "fa7988cb51c879d431e049caf9626fe819c29faa15050166a1d48d3e4b9137ef"
                },
                "downloads": -1,
                "filename": "torchattacks-2.10-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "e62b3758d5918b3395ffc13b40580629",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 21972,
                "upload_time": "2020-12-04T05:55:25",
                "upload_time_iso_8601": "2020-12-04T05:55:25.696579Z",
                "url": "https://files.pythonhosted.org/packages/9c/78/84390e943cf16924700c43b4cf05d3b92300aa3a8dcd1a82c3ef4856cb65/torchattacks-2.10-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.10.1": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.10.1/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.10.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "cc98a5ffc26b50e42c4b09f347bcb27a",
                    "sha256": "174385922d6f22604b57d3e032fcc7f631b2888c3ffe694c6854663b898a31a2"
                },
                "downloads": -1,
                "filename": "torchattacks-2.10.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "cc98a5ffc26b50e42c4b09f347bcb27a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 21991,
                "upload_time": "2020-12-04T15:27:33",
                "upload_time_iso_8601": "2020-12-04T15:27:33.546906Z",
                "url": "https://files.pythonhosted.org/packages/0a/4e/dc99b35900757437cd1a9c0d0c1d552a2612bc00a0d1c3612f58df467a67/torchattacks-2.10.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.10.2": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.10.2/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.10.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7729e0136ce95163061e558a915bd204",
                    "sha256": "a3da0d04203a2c53184529e2b6777b2ea732506a6a418a1b34ca31153580be3a"
                },
                "downloads": -1,
                "filename": "torchattacks-2.10.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7729e0136ce95163061e558a915bd204",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 21994,
                "upload_time": "2020-12-04T15:33:14",
                "upload_time_iso_8601": "2020-12-04T15:33:14.183998Z",
                "url": "https://files.pythonhosted.org/packages/62/ae/22c97a1163f63ef31c31a479d3e06566ab09ae96eb155352c88d4216b465/torchattacks-2.10.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.10.3": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.10.3/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.10.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9a3538bae303ec768a55c970bae5395a",
                    "sha256": "cbd48de580e4cfcaa05bd40cef8357be043422ba1c30901e4edcb9d368cce0bc"
                },
                "downloads": -1,
                "filename": "torchattacks-2.10.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "9a3538bae303ec768a55c970bae5395a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 22059,
                "upload_time": "2020-12-07T13:09:05",
                "upload_time_iso_8601": "2020-12-07T13:09:05.531411Z",
                "url": "https://files.pythonhosted.org/packages/9e/0e/c5a3e5c12d2048de35067e200ca77f4899f4e55d79ffc5b945011d9b31e7/torchattacks-2.10.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.10.4": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.10.4/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.10.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1e647ecceff16f35861493a50e394469",
                    "sha256": "841419d228354862f045e968982e847ee0ab9380b99018d1956009b23d142897"
                },
                "downloads": -1,
                "filename": "torchattacks-2.10.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1e647ecceff16f35861493a50e394469",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 22104,
                "upload_time": "2020-12-07T13:48:21",
                "upload_time_iso_8601": "2020-12-07T13:48:21.290527Z",
                "url": "https://files.pythonhosted.org/packages/cf/c1/2df3691f58443655b37fb743f6b2eb51e47763c56a845f70eb062bd51142/torchattacks-2.10.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.11.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.11.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.11.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7f098a4dd35d24b633e3050c9c0237fc",
                    "sha256": "8ed0e59375310e39f5f42bb44ff4342493ec66e5fe347d215d3309dd66e6cc74"
                },
                "downloads": -1,
                "filename": "torchattacks-2.11.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7f098a4dd35d24b633e3050c9c0237fc",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 34122,
                "upload_time": "2020-12-12T16:15:11",
                "upload_time_iso_8601": "2020-12-12T16:15:11.638783Z",
                "url": "https://files.pythonhosted.org/packages/a8/e0/6834075fc05b8fcfed20105e744c1000e6b8368d7da2d4554fdf0400db1b/torchattacks-2.11.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.12.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.12.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.12.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "25e492aea475a204c1aee4e9862c3943",
                    "sha256": "9a9d695bcd46135bc6818f56d71349c05c505be7af237c5169a63cf790e348f3"
                },
                "downloads": -1,
                "filename": "torchattacks-2.12.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "25e492aea475a204c1aee4e9862c3943",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 32770,
                "upload_time": "2021-01-04T06:21:25",
                "upload_time_iso_8601": "2021-01-04T06:21:25.908981Z",
                "url": "https://files.pythonhosted.org/packages/33/45/e7ffd60f4d338e04346701130091e7d9a361855c411aa983358faca0814a/torchattacks-2.12.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.12.1": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.12.1/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.12.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c800825e82795011b82b095a7250525e",
                    "sha256": "133f75406a2f25ed671009b34df7a3768525e69855f5224ff6205d5ace2bdc65"
                },
                "downloads": -1,
                "filename": "torchattacks-2.12.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "c800825e82795011b82b095a7250525e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 32870,
                "upload_time": "2021-01-04T07:00:23",
                "upload_time_iso_8601": "2021-01-04T07:00:23.510544Z",
                "url": "https://files.pythonhosted.org/packages/e1/2d/4a32155c0b9eacae33549daedb79bb4dbf4c739fc15dc02e4b8881b04ca8/torchattacks-2.12.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.12.2": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.12.2/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.12.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "fadf2bd7cc136458708203ac970422a4",
                    "sha256": "bbbb6758052f28b4db76329026d4e1f8498aaabf991d56a8d90fc0bc9302aaba"
                },
                "downloads": -1,
                "filename": "torchattacks-2.12.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "fadf2bd7cc136458708203ac970422a4",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 34361,
                "upload_time": "2021-01-14T12:19:03",
                "upload_time_iso_8601": "2021-01-14T12:19:03.825495Z",
                "url": "https://files.pythonhosted.org/packages/64/f9/65912801a5d111ec9f47427a713f45a38bb0f23c50899d405b7beb8046d3/torchattacks-2.12.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.12.3": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.12.3/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.12.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "50672d26986cf2a7035a70e28d596580",
                    "sha256": "7044ae15e04ddda4126408e0dbde0ba6a2ffa63b90aed1bf29bd0c69c16b4e84"
                },
                "downloads": -1,
                "filename": "torchattacks-2.12.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "50672d26986cf2a7035a70e28d596580",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 34459,
                "upload_time": "2021-02-08T15:01:29",
                "upload_time_iso_8601": "2021-02-08T15:01:29.016281Z",
                "url": "https://files.pythonhosted.org/packages/e6/c2/2f4bbc08bf3e229008b61c679f04172d57c7bb3ca97da680dc579f3e31fc/torchattacks-2.12.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.13.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.13.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.13.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "cf0fe5753e4ab19299132a258a296ecf",
                    "sha256": "26337a3d9e9c63e760c55233afb7a10f317ca919c5e63dd091019806bab54c1c"
                },
                "downloads": -1,
                "filename": "torchattacks-2.13.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "cf0fe5753e4ab19299132a258a296ecf",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 78183,
                "upload_time": "2021-02-19T11:19:34",
                "upload_time_iso_8601": "2021-02-19T11:19:34.285821Z",
                "url": "https://files.pythonhosted.org/packages/d9/30/a0906014de4f72c2c64242b973e9e6e7ce74148ae20647a8e19d0a8a67d0/torchattacks-2.13.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.13.1": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.13.1/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.13.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "dd19e8554e4d525385c7d18ba4f0facc",
                    "sha256": "89cbbc0f04024f9f4105a17613a90d109a4beb7cd6c0787b2bacc36b46157b71"
                },
                "downloads": -1,
                "filename": "torchattacks-2.13.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "dd19e8554e4d525385c7d18ba4f0facc",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 78187,
                "upload_time": "2021-02-19T11:22:24",
                "upload_time_iso_8601": "2021-02-19T11:22:24.101744Z",
                "url": "https://files.pythonhosted.org/packages/54/20/aefeba57085a887be5c5b02b08b2df4d8dc1f1c842671aeb60d6077923d0/torchattacks-2.13.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.13.2": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.13.2/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.13.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5e24dcaff9c91789865e1c391e82abf2",
                    "sha256": "332674cba78f196b3820d0d1b172184da86af6f6c54cd1571c742f7c65ce34e8"
                },
                "downloads": -1,
                "filename": "torchattacks-2.13.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "5e24dcaff9c91789865e1c391e82abf2",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 78212,
                "upload_time": "2021-03-02T01:47:29",
                "upload_time_iso_8601": "2021-03-02T01:47:29.050787Z",
                "url": "https://files.pythonhosted.org/packages/15/8f/0cf57e21d5e12e25218df6a23de3e140f396e148be5c45a0c29cbac0e21d/torchattacks-2.13.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.13.3": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.13.3/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.13.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b2b0d46418e7416b46c53ca8e3252961",
                    "sha256": "df8bd2468e50d115bd84bacdcc3ed4732f7fa5996fcb19be57cb944452b4ff04"
                },
                "downloads": -1,
                "filename": "torchattacks-2.13.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b2b0d46418e7416b46c53ca8e3252961",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 78397,
                "upload_time": "2021-03-29T11:05:41",
                "upload_time_iso_8601": "2021-03-29T11:05:41.829971Z",
                "url": "https://files.pythonhosted.org/packages/78/10/b381053ca29da9cc248e28e68897760a0f72e74b47128265c1c45c688dc0/torchattacks-2.13.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.14.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.14.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.14.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ebcfd3f3d5b1ef37ca94989eb6808326",
                    "sha256": "a2a903dc0e09065b19828307072a66d330d34ab38aa91f2081008537240406a5"
                },
                "downloads": -1,
                "filename": "torchattacks-2.14.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ebcfd3f3d5b1ef37ca94989eb6808326",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 92686,
                "upload_time": "2021-04-11T14:11:46",
                "upload_time_iso_8601": "2021-04-11T14:11:46.162890Z",
                "url": "https://files.pythonhosted.org/packages/c3/12/2e09d6668cbbe66b51f9afa5d7629ba0d7d3e09030dce70db0cfeada9777/torchattacks-2.14.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.14.1": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.14.1/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.14.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "38f23b6e4c9d1a3a6a7443a06748ff03",
                    "sha256": "cd68194d6407ae90dc7c7f532dcd59da6f30ed4d9d1b4c5b65478e02e073836e"
                },
                "downloads": -1,
                "filename": "torchattacks-2.14.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "38f23b6e4c9d1a3a6a7443a06748ff03",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 92828,
                "upload_time": "2021-04-11T23:56:37",
                "upload_time_iso_8601": "2021-04-11T23:56:37.044857Z",
                "url": "https://files.pythonhosted.org/packages/bd/a8/559ba77713a870f3d288833455091753435daad414de5ccce64812199654/torchattacks-2.14.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.14.2": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.14.2/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.14.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "7551b959380d685db13971e033ae4768",
                    "sha256": "0b32cece50530b26c8a62731ced9722df82552f3273071792a1cc7b954085519"
                },
                "downloads": -1,
                "filename": "torchattacks-2.14.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "7551b959380d685db13971e033ae4768",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 92839,
                "upload_time": "2021-05-03T06:07:21",
                "upload_time_iso_8601": "2021-05-03T06:07:21.551400Z",
                "url": "https://files.pythonhosted.org/packages/a5/55/91c60b07daa4538090db811f75a1ab99b6d3db8342965027d76fab361dc7/torchattacks-2.14.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.14.4": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.14.4/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.14.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "4055845f250f3394bd00f7eee8bc786a",
                    "sha256": "01cc95857a94ab3f5693531e7beabd8b77493719f7b883ec0a3697b139b590bc"
                },
                "downloads": -1,
                "filename": "torchattacks-2.14.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "4055845f250f3394bd00f7eee8bc786a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 96889,
                "upload_time": "2021-06-18T00:16:41",
                "upload_time_iso_8601": "2021-06-18T00:16:41.123315Z",
                "url": "https://files.pythonhosted.org/packages/4b/59/65d4b9f30b1ba546bd6f7dc3538702e85edf4191d65753a35365d5dcfaa5/torchattacks-2.14.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.14.5": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.14.5/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.14.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ccedf52b850ce9b34798c2bf2c15d145",
                    "sha256": "c5a2912bddd98b91f7e06e42a6b2f8f265a8b2b87c3908f6646269cbc7714951"
                },
                "downloads": -1,
                "filename": "torchattacks-2.14.5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ccedf52b850ce9b34798c2bf2c15d145",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 96881,
                "upload_time": "2021-07-01T05:26:00",
                "upload_time_iso_8601": "2021-07-01T05:26:00.928768Z",
                "url": "https://files.pythonhosted.org/packages/f8/f1/612753505bc89ff67fa8f2c5ac6a0bf7e52cdb02c502a2570f27ca493cfe/torchattacks-2.14.5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.4": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.4/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "dfbf40b05f3bc1a0145a83ffb6a65926",
                    "sha256": "fd8f1606cf1575b3a46c3496ced8d1a8ce30ae4963b835939f51000b84c01b5f"
                },
                "downloads": -1,
                "filename": "torchattacks-2.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "dfbf40b05f3bc1a0145a83ffb6a65926",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 18950,
                "upload_time": "2020-07-21T08:55:44",
                "upload_time_iso_8601": "2020-07-21T08:55:44.723552Z",
                "url": "https://files.pythonhosted.org/packages/a8/28/205ed730c5a230d6f9fbaa2fd58cabd1ede582d72c7c2500ac93e5c7a9be/torchattacks-2.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.6": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.6/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "1f0cbf63def8de650b5b34933cdb6f1f",
                    "sha256": "6d2b025a224cbc917e523a2c7601e0a17188a0f8fea565fc855511164c27fe3a"
                },
                "downloads": -1,
                "filename": "torchattacks-2.6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "1f0cbf63def8de650b5b34933cdb6f1f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 19279,
                "upload_time": "2020-10-22T14:29:53",
                "upload_time_iso_8601": "2020-10-22T14:29:53.761587Z",
                "url": "https://files.pythonhosted.org/packages/e4/b4/df1f545c6cc86607f2bb7254f372550ee8a03f93d3ab49e71430116f9ab5/torchattacks-2.6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "2.9": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/2.9/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "2.9",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "e1f7bb833743f0f09a1d2eb0a5cabc29",
                    "sha256": "5031472314b2c0cc36ca94f8657003428bb1d8e63833ec1016658afaf79601f4"
                },
                "downloads": -1,
                "filename": "torchattacks-2.9-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "e1f7bb833743f0f09a1d2eb0a5cabc29",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 21261,
                "upload_time": "2020-11-30T04:58:50",
                "upload_time_iso_8601": "2020-11-30T04:58:50.878103Z",
                "url": "https://files.pythonhosted.org/packages/e1/d6/f609475bbadac8f79769b51f13a5ebd977188fa9506d3d69cbed016e81cd/torchattacks-2.9-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.0.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.0.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.0.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "500bccedc299a188bf88edc728faee94",
                    "sha256": "ed02b86bb39de018188f50a473722a65962ab7b157bfd34a3100f4c4167408f4"
                },
                "downloads": -1,
                "filename": "torchattacks-3.0.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "500bccedc299a188bf88edc728faee94",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 100465,
                "upload_time": "2021-07-08T06:00:36",
                "upload_time_iso_8601": "2021-07-08T06:00:36.167779Z",
                "url": "https://files.pythonhosted.org/packages/03/e3/a37ced3df6c01a53acdfe97e2c53d31df0653f8f4e2608cd3a4a9f89deb4/torchattacks-3.0.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.1.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.1.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b4c83bc6b6e9cb5d122108c3ca450dda",
                    "sha256": "173036b8e57fe34811b2b4c94702141d00c3042a331d21c2f446cc7002e3f0ff"
                },
                "downloads": -1,
                "filename": "torchattacks-3.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b4c83bc6b6e9cb5d122108c3ca450dda",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 100302,
                "upload_time": "2021-08-27T03:19:59",
                "upload_time_iso_8601": "2021-08-27T03:19:59.539217Z",
                "url": "https://files.pythonhosted.org/packages/d8/a1/ee9fa0cf7b6a5e9c40e7406f685b2f76de06ec7d6d5ac9ee68f9a5c70a2a/torchattacks-3.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ebb09f220e2abfb6fabffe6a03d4670d",
                    "sha256": "a0ba1dfc2436544ec42ea4bcfac748a45f1d68467d22cec5acf4cbf1b4bd229f"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "ebb09f220e2abfb6fabffe6a03d4670d",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 101892,
                "upload_time": "2021-10-07T12:38:41",
                "upload_time_iso_8601": "2021-10-07T12:38:41.666165Z",
                "url": "https://files.pythonhosted.org/packages/c5/11/cb244e1dc60c511fe6dfd4ba5a23940632da3ba224162b52f9ef92d96bc8/torchattacks-3.2.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.1": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.1/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b2eb595a1771d4a48957f8051035273b",
                    "sha256": "8cd66116720da4d347d9a6f7ca413782b2068ce88a3fd5c6af9a8227100244ed"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b2eb595a1771d4a48957f8051035273b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 101899,
                "upload_time": "2021-10-11T06:13:34",
                "upload_time_iso_8601": "2021-10-11T06:13:34.851646Z",
                "url": "https://files.pythonhosted.org/packages/36/e8/bd847e65c08d867ccb7b64370613950439d9b6f08d4fb0baf6f646a1f6ae/torchattacks-3.2.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.2": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.2/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "22866af3265b43ecf7b13ffcb6fa29d8",
                    "sha256": "90dbb04af7f0db63a8795c906ad53aa6a8eccb8e6a619c01881b4a51a536551c"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "22866af3265b43ecf7b13ffcb6fa29d8",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 102223,
                "upload_time": "2021-10-24T05:07:57",
                "upload_time_iso_8601": "2021-10-24T05:07:57.533054Z",
                "url": "https://files.pythonhosted.org/packages/95/2c/83a9bfcc14c1b4b06501b74818621b37c3c4a1e18517253a822a2fd87fbb/torchattacks-3.2.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.3": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.3/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "18f78c0603fc0f4bbd3e99d713b87cc9",
                    "sha256": "b5f7c6ae3b2c96123e54deb93e6ef8946cde9619ad5ec9ff1453a739f596eb51"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "18f78c0603fc0f4bbd3e99d713b87cc9",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 102322,
                "upload_time": "2021-12-09T07:14:57",
                "upload_time_iso_8601": "2021-12-09T07:14:57.812638Z",
                "url": "https://files.pythonhosted.org/packages/32/6b/2159daace4bfc9725eb6aaaa56915e4a141e43bff2a2bf5159f7dff3d2be/torchattacks-3.2.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.4": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": "",
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.4/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "37447c760a0204a5b6792365daefb265",
                    "sha256": "7a63cea637e1418e3f51dd4938c37590510d565b9771ab1cadd1142da800fad2"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "37447c760a0204a5b6792365daefb265",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 102263,
                "upload_time": "2021-12-23T03:37:59",
                "upload_time_iso_8601": "2021-12-23T03:37:59.593503Z",
                "url": "https://files.pythonhosted.org/packages/ab/56/84f27600fffa8bc1645fcc15892771be0570030a93643d567a934235a6e2/torchattacks-3.2.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.5": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": null,
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.5/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f9f36b41b94f012e0c92c30b01996a38",
                    "sha256": "3841aaaf65264dd45bc2e3e0550171f0fb399091bfac6ce8df9eed89a4ade67c"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "f9f36b41b94f012e0c92c30b01996a38",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 105559,
                "upload_time": "2022-03-24T02:00:16",
                "upload_time_iso_8601": "2022-03-24T02:00:16.523471Z",
                "url": "https://files.pythonhosted.org/packages/f9/aa/88eb33e9a7545cb074ea972d13a83284963189c28468a95034138c02036f/torchattacks-3.2.5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.6": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": null,
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.6/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "57980c825737b65f693b10bf1830aafd",
                    "sha256": "7f95b456d02177062fa688573f0cb3c85e31ff0db9eba873f16c34474284b417"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "57980c825737b65f693b10bf1830aafd",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 105762,
                "upload_time": "2022-04-10T02:46:21",
                "upload_time_iso_8601": "2022-04-10T02:46:21.876541Z",
                "url": "https://files.pythonhosted.org/packages/b5/93/0c0d341bf971d2e506c0f4817eb6282ad46707de7b887f5ee4a88f548a16/torchattacks-3.2.6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.2.7": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": null,
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.2.7/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.2.7",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a564b86abf39fd73a17803b3df0e591a",
                    "sha256": "cdebadefd6b8ddcae1510efaee3d2b5a7f3f7f92abca47b40059d01d1a5240d9"
                },
                "downloads": -1,
                "filename": "torchattacks-3.2.7-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "a564b86abf39fd73a17803b3df0e591a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 208769,
                "upload_time": "2022-07-13T05:29:02",
                "upload_time_iso_8601": "2022-07-13T05:29:02.316582Z",
                "url": "https://files.pythonhosted.org/packages/e5/28/89d4985ac19c00ff3420f7910f80bf2f7cc265c3e5e36279c6510737bbfc/torchattacks-3.2.7-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "3.3.0": {
        "info": {
            "author": "Harry Kim <24k.harry@gmail.com>",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 5 - Production/Stable",
                "Intended Audience :: Developers",
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.6",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Scientific/Engineering :: Visualization"
            ],
            "description": "# Adversarial-Attacks-PyTorch\n\n<p>\n  <a href=\"https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/LICENSE\"><img alt=\"MIT License\" src=\"https://img.shields.io/github/license/Harry24k/adversarial-attacks-pytorch?&color=brightgreen\" /></a>\n  <a href=\"https://pypi.org/project/torchattacks/\"><img alt=\"Pypi\" src=\"https://img.shields.io/pypi/v/torchattacks.svg?&color=orange\" /></a>\n  <a href=\"https://github.com/Harry24k/adversarial-attacks-pytorch/releases\"><img alt=\"Latest Release\" src=\"https://img.shields.io/github/release/Harry24k/adversarial-attacks-pytorch.svg?&color=blue\" /></a>\n  <a href=\"https://arxiv.org/abs/2010.01950\"><img alt=\"arXiv\" src=\"https://img.shields.io/badge/arXiv-2010.01950-f9f107.svg\" /></a>\n  <a href=\"https://adversarial-attacks-pytorch.readthedocs.io/en/latest/\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/adversarial-attacks-pytorch/badge/?version=latest\" /></a>\n  <a href=\"https://codecov.io/gh/Harry24k/adversarial-attacks-pytorch\" > \n <img src=\"https://codecov.io/gh/Harry24k/adversarial-attacks-pytorch/branch/master/graph/badge.svg?token=00CQ79UTC2\"/> \n </a>\n</p>\n\n[Torchattacks](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/index.html) is a PyTorch library that provides *adversarial attacks* to generate *adversarial examples*. It contains *PyTorch-like* interface and functions that make it easier for PyTorch users to implement adversarial attacks ([README [KOR]](https://github.com/Harry24k/adversairal-attacks-pytorch/blob/master/README_KOR.md)).\n\n\n```python\nimport torchattacks\natk = torchattacks.PGD(model, eps=8/255, alpha=2/255, steps=4)\n# If, images are normalized:\n# atk.set_normalization_used(mean=[...], std=[...])\nadv_images = atk(images, labels)\n```\n\n\n\n## Table of Contents\n\n1. [Requirements and Installation](#Requirements-and-Installation)\n2. [Getting Started](#Getting-Started)\n3. [Performance Comparison](#Performance-Comparison)\n5. [Citation](#Citation)\n7. [Contribution](#Contribution)\n8. [Recommended Sites and Packages](#Recommended-Sites-and-Packages)\n\n\n\n## Requirements and Installation\n\n### :clipboard: Requirements\n\n- PyTorch version >=1.4.0\n- Python version >=3.6\n\n\n\n### :hammer: Installation\n\n```\npip install torchattacks\n```\n\n\n## Getting Started\n\n###  :warning: Precautions\n* **All models should return ONLY ONE vector of `(N, C)` where `C = number of classes`.** Considering most models in _torchvision.models_ return one vector of `(N,C)`, where `N` is the number of inputs and `C` is thenumber of classes, _torchattacks_ also only supports limited forms of output.  Please check the shape of the model\u2019s output carefully. \n* **`torch.backends.cudnn.deterministic = True` to get same adversarial examples with fixed random seed**. Some operations are non-deterministic with float tensors on GPU [[discuss]](https://discuss.pytorch.org/t/inconsistent-gradient-values-for-the-same-input/26179). If you want to get same results with same inputs, please run `torch.backends.cudnn.deterministic = True`[[ref]](https://stackoverflow.com/questions/56354461/reproducibility-and-performance-in-pytorch).\n\n\n\n### :rocket: Demos\n\n* **White-box Attack on CIFAR10** ([code](https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demo/White-box%20Attack%20on%20CIFAR10.ipynb), [nbviewer](https://nbviewer.jupyter.org/github/Harry24k/adversarial-attacks-pytorch/blob/master/demo/White-box%20Attack%20on%20CIFAR10.ipynb))\n* **White-box Attack on ImageNet** ([code](https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demo/White-box%20Attack%20on%20ImageNet.ipynb), [nbviewer](https://nbviewer.jupyter.org/github/Harry24k/adversarial-attacks-pytorch/blob/master/demo/White-box%20Attack%20on%20ImageNet.ipynb))\n* **Transfer Attack on CIFAR10** ([code](https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demo/Transfer%20Attack%20on%20CIFAR10.ipynb), [nbviewer](https://nbviewer.jupyter.org/github/Harry24k/adversarial-attacks-pytorch/blob/master/demo/Transfer%20Attack%20on%20CIFAR10.ipynb))\n\n\n#### Torchattacks supports following functions:\n\n<details><summary>Targeted mode</summary><p>\n\n* Random target label:\n```python\n# random labels as target labels.\natk.set_mode_targeted_random(n_classses)\n```\n\n* Least likely label:\n```python\n# label with the k-th smallest probability used as target labels.\natk.set_mode_targeted_least_likely(kth_min)\n```\n\n* By custom function:\n```python\n# label from mapping function\natk.set_mode_targeted_by_function(target_map_function=lambda images, labels:(labels+1)%10)\n```\n\n* Return to default:\n```python\natk.set_mode_default()\n```\n\n</p></details>\n\n<details><summary>Return type</summary><p>\n\n* Return adversarial images with integer value (0-255).\n```python\natk.set_return_type(type='int')\n```\n\n* Return adversarial images with float value (0-1).\n```python\natk.set_return_type(type='float')\n```\n\n</p></details>\n\n<details><summary>Save adversarial images</summary><p>\n\n```python\n# Save\natk.save(data_loader, save_path=\"./data.pt\", verbose=True)\n\n# Load\nadv_loader = atk.load(load_path=\"./data.pt\")\n```\n\n</p></details>\n\n<details><summary>Training/Eval during attack</summary><p>\n\n```python\n# For RNN-based models, we cannot calculate gradients with eval mode.\n# Thus, it should be changed to the training mode during the attack.\natk.set_training_mode(model_training=False, batchnorm_training=False, dropout_training=False)\n```\n\n</p></details>\n\n\n<details><summary>Make a set of attacks</summary><p>\n\n* Strong attacks\n```python\natk1 = torchattacks.FGSM(model, eps=8/255)\natk2 = torchattacks.PGD(model, eps=8/255, alpha=2/255, iters=40, random_start=True)\natk = torchattacks.MultiAttack([atk1, atk2])\n```\n\n* Binary search for CW\n```python\natk1 = torchattacks.CW(model, c=0.1, steps=1000, lr=0.01)\natk2 = torchattacks.CW(model, c=1, steps=1000, lr=0.01)\natk = torchattacks.MultiAttack([atk1, atk2])\n```\n\n* Random restarts\n```python\natk1 = torchattacks.PGD(model, eps=8/255, alpha=2/255, iters=40, random_start=True)\natk2 = torchattacks.PGD(model, eps=8/255, alpha=2/255, iters=40, random_start=True)\natk = torchattacks.MultiAttack([atk1, atk2])\n```\n\n</p></details>\n\n\n\n#### Torchattacks also supports collaboration with other attack packages.\n\n<details><summary>FoolBox</summary><p>\n\nhttps://github.com/bethgelab/foolbox\n\n```python\nfrom torchattacks.attack import Attack\nimport foolbox as fb\n\n# L2BrendelBethge\nclass L2BrendelBethge(Attack):\n    def __init__(self, model):\n        super(L2BrendelBethge, self).__init__(\"L2BrendelBethge\", model)\n        self.fmodel = fb.PyTorchModel(self.model, bounds=(0,1), device=self.device)\n        self.init_attack = fb.attacks.DatasetAttack()\n        self.adversary = fb.attacks.L2BrendelBethgeAttack(init_attack=self.init_attack)\n        self._attack_mode = 'only_default'\n\n    def forward(self, images, labels):\n        images, labels = images.to(self.device), labels.to(self.device)\n\n        # DatasetAttack\n        batch_size = len(images)\n        batches = [(images[:batch_size//2], labels[:batch_size//2]),\n                   (images[batch_size//2:], labels[batch_size//2:])]\n        self.init_attack.feed(model=self.fmodel, inputs=batches[0][0]) # feed 1st batch of inputs\n        self.init_attack.feed(model=self.fmodel, inputs=batches[1][0]) # feed 2nd batch of inputs\n        criterion = fb.Misclassification(labels)\n        init_advs = self.init_attack.run(self.fmodel, images, criterion)\n\n        # L2BrendelBethge\n        adv_images = self.adversary.run(self.fmodel, images, labels, starting_points=init_advs)\n        return adv_images\n\natk = L2BrendelBethge(model)\n```\n\n</p></details>\n\n<details><summary>Adversarial-Robustness-Toolbox (ART)</summary><p>\n\nhttps://github.com/IBM/adversarial-robustness-toolbox\n\n\n```python\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torchattacks.attack import Attack\n\nimport art.attacks.evasion as evasion\nfrom art.classifiers import PyTorchClassifier\n\n# SaliencyMapMethod (or Jacobian based saliency map attack)\nclass JSMA(Attack):\n    def __init__(self, model, theta=1/255, gamma=0.15, batch_size=128):\n        super(JSMA, self).__init__(\"JSMA\", model)\n        self.classifier = PyTorchClassifier(\n                            model=self.model, clip_values=(0, 1),\n                            loss=nn.CrossEntropyLoss(),\n                            optimizer=optim.Adam(self.model.parameters(), lr=0.01),\n                            input_shape=(1, 28, 28), nb_classes=10)\n        self.adversary = evasion.SaliencyMapMethod(classifier=self.classifier,\n                                                   theta=theta, gamma=gamma,\n                                                   batch_size=batch_size)\n        self.target_map_function = lambda labels: (labels+1)%10\n        self._attack_mode = 'only_default'\n\n    def forward(self, images, labels):\n        adv_images = self.adversary.generate(images, self.target_map_function(labels))\n        return torch.tensor(adv_images).to(self.device)\n\natk = JSMA(model)\n```\n\n</p></details>\n\n\n\n### :fire: List of implemented papers\n\nThe distance measure in parentheses.\n\n|              Name               | Paper                                                                                                                                                     | Remark                                                                                                                 |\n|:-------------------------------:|-----------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|\n|      **FGSM**<br />(Linf)       | Explaining and harnessing adversarial examples ([Goodfellow et al., 2014](https://arxiv.org/abs/1412.6572))                                               |                                                                                                                        |\n|       **BIM**<br />(Linf)       | Adversarial Examples in the Physical World ([Kurakin et al., 2016](https://arxiv.org/abs/1607.02533))                                                     | Basic iterative method or Iterative-FSGM                                                                               |\n|        **CW**<br />(L2)         | Towards Evaluating the Robustness of Neural Networks ([Carlini et al., 2016](https://arxiv.org/abs/1608.04644))                                           |                                                                                                                        |\n|      **RFGSM**<br />(Linf)      | Ensemble Adversarial Traning: Attacks and Defences ([Tram\u00e8r et al., 2017](https://arxiv.org/abs/1705.07204))                                              | Random initialization + FGSM                                                                                           |\n|       **PGD**<br />(Linf)       | Towards Deep Learning Models Resistant to Adversarial Attacks ([Mardry et al., 2017](https://arxiv.org/abs/1706.06083))                                   | Projected Gradient Method                                                                                              |\n|       **PGDL2**<br />(L2)       | Towards Deep Learning Models Resistant to Adversarial Attacks ([Mardry et al., 2017](https://arxiv.org/abs/1706.06083))                                   | Projected Gradient Method                                                                                              |\n|     **MIFGSM**<br />(Linf)      | Boosting Adversarial Attacks with Momentum ([Dong et al., 2017](https://arxiv.org/abs/1710.06081))                                                        | :heart_eyes: Contributor [zhuangzi926](https://github.com/zhuangzi926), [huitailangyz](https://github.com/huitailangyz) |\n|      **TPGD**<br />(Linf)       | Theoretically Principled Trade-off between Robustness and Accuracy ([Zhang et al., 2019](https://arxiv.org/abs/1901.08573))                               |                                                                                                                        |\n|     **EOTPGD**<br />(Linf)      | Comment on \"Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network\" ([Zimmermann, 2019](https://arxiv.org/abs/1907.00895))          | [EOT](https://arxiv.org/abs/1707.07397)+PGD                                                                            |\n|    **APGD**<br />(Linf, L2)     | Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks ([Croce et al., 2020](https://arxiv.org/abs/2001.03994)) |                                                                                                                        |\n|    **APGDT**<br />(Linf, L2)    | Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks ([Croce et al., 2020](https://arxiv.org/abs/2001.03994)) | Targeted APGD                                                                                                          |\n|   **FAB**<br />(Linf, L2, L1)   | Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack ([Croce et al., 2019](https://arxiv.org/abs/1907.02044))                    |                                                                                                                        |\n|   **Square**<br />(Linf, L2)    | Square Attack: a query-efficient black-box adversarial attack via random search ([Andriushchenko et al., 2019](https://arxiv.org/abs/1912.00049))         |                                                                                                                        |\n| **AutoAttack**<br />(Linf, L2)  | Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks ([Croce et al., 2020](https://arxiv.org/abs/2001.03994)) | APGD+APGDT+FAB+Square                                                                                                  |\n|     **DeepFool**<br />(L2)      | DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks ([Moosavi-Dezfooli et al., 2016](https://arxiv.org/abs/1511.04599))                   |                                                                                                                        |\n|     **OnePixel**<br />(L0)      | One pixel attack for fooling deep neural networks ([Su et al., 2019](https://arxiv.org/abs/1710.08864))                                                   |                                                                                                                        |\n|    **SparseFool**<br />(L0)     | SparseFool: a few pixels make a big difference ([Modas et al., 2019](https://arxiv.org/abs/1811.02248))                                                   |                                                                                                                        |\n|     **DIFGSM**<br />(Linf)      | Improving Transferability of Adversarial Examples with Input Diversity ([Xie et al., 2019](https://arxiv.org/abs/1803.06978))                             | :heart_eyes: Contributor [taobai](https://github.com/tao-bai)                                                          |\n|     **TIFGSM**<br />(Linf)      | Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks ([Dong et al., 2019](https://arxiv.org/abs/1904.02884))            | :heart_eyes: Contributor [taobai](https://github.com/tao-bai)                                                          |\n| **NIFGSM**<br />(Linf) | Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks ([Lin, et al., 2022](https://arxiv.org/abs/1908.06281))                 | :heart_eyes: Contributor [Zhijin-Ge](https://github.com/Zhijin-Ge)                               |\n| **SINIFGSM**<br />(Linf) | Nesterov Accelerated Gradient and Scale Invariance for Adversarial Attacks ([Lin, et al., 2022](https://arxiv.org/abs/1908.06281))                 | :heart_eyes: Contributor [Zhijin-Ge](https://github.com/Zhijin-Ge)                               |\n| **VMIFGSM**<br />(Linf) | Enhancing the Transferability of Adversarial Attacks through Variance Tuning ([Wang, et al., 2022](https://arxiv.org/abs/2103.15571))                 | :heart_eyes: Contributor [Zhijin-Ge](https://github.com/Zhijin-Ge)                               |\n| **VNIFGSM**<br />(Linf) | Enhancing the Transferability of Adversarial Attacks through Variance Tuning ([Wang, et al., 2022](https://arxiv.org/abs/2103.15571))                 | :heart_eyes: Contributor [Zhijin-Ge](https://github.com/Zhijin-Ge)                               |\n|     **Jitter**<br />(Linf)      | Exploring Misclassifications of Robust Neural Networks to Enhance Adversarial Attacks ([Schwinn, Leo, et al., 2021](https://arxiv.org/abs/2105.10304))    |                                                                                                                        |\n|       **Pixle**<br />(L0)       | Pixle: a fast and effective black-box attack based on rearranging pixels ([Pomponi, Jary, et al., 2022](https://arxiv.org/abs/2202.02236))                |                                                                                                                        |\n| **LGV**<br />(Linf, L2, L1, L0) | LGV: Boosting Adversarial Example Transferability from Large Geometric Vicinity ([Gubri, et al., 2022](https://arxiv.org/abs/2207.13129))                 | :heart_eyes: Contributor [Martin Gubri](https://github.com/Framartin)                               |\n\n\n\n## Performance Comparison\n\nFor a fair comparison, [Robustbench](https://github.com/RobustBench/robustbench) is used. As for the comparison packages, currently updated and the most cited methods were selected:\n\n* **Foolbox**: [505](https://scholar.google.com/scholar?q=Foolbox%3A%20A%20Python%20toolbox%20to%20benchmark%20the%20robustness%20of%20machine%20learning%20models.%20arXiv%202018) citations and last update 2022.10.\n* **ART**: [262](https://scholar.google.com/scholar?cluster=5391305326811305758&hl=ko&as_sdt=0,5&sciodt=0,5) citations and last update 2022.10.\n\nRobust accuracy against each attack and elapsed time on the first 50 images of CIFAR10. For L2 attacks, the average L2 distances between adversarial images and the original images are recorded. All experiments were done on GeForce RTX 2080. For the latest version, please refer to here ([code](https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demos/Performance%20Comparison%20(CIFAR10).ipynb), [nbviewer](https://nbviewer.jupyter.org/github/Harry24k/adversarial-attacks-pytorch/blob/master/demos/Performance%20Comparison%20(CIFAR10).ipynb)).\n\n|  **Attack**  |     **Package**     |     Standard |     [Wong2020Fast](https://arxiv.org/abs/2001.03994) |     [Rice2020Overfitting](https://arxiv.org/abs/2002.11569) |     **Remark**     |\n| :----------------: | :-----------------: | -------------------------------------------: | -------------------------------------------: | ---------------------------------------------: | :----------------: |\n|      **FGSM** (Linf)      |    Torchattacks     | 34% (54ms) |                                 **48% (5ms)** |                                    62% (82ms) |                    |\n|  | **Foolbox<sup>*</sup>** | **34% (15ms)** |                                     48% (8ms) |                  **62% (30ms)** |                    |\n|                    |         ART         | 34% (214ms) |                                     48% (59ms) |                                   62% (768ms) |                    |\n| **PGD** (Linf) |    **Torchattacks** | **0% (174ms)** |                               **44% (52ms)** |            **58% (1348ms)** | :crown: \u200b**Fastest** |\n|                    | Foolbox<sup>*</sup> | 0% (354ms) |                                  44% (56ms) |              58% (1856ms) |                    |\n|                    |         ART         | 0% (1384 ms) |                                   44% (437ms) |                58% (4704ms) |                    |\n| **CW<sup>\u2020\u00a0</sup>**(L2) |    **Torchattacks** | **0% / 0.40<br /> (2596ms)** |                **14% / 0.61 <br />(3795ms)** | **22% / 0.56<br />(43484ms)** | :crown: \u200b**Highest Success Rate** <br /> :crown: **Fastest** |\n|                    | Foolbox<sup>*</sup> | 0% / 0.40<br /> (2668ms) |                   32% / 0.41 <br />(3928ms) |                34% / 0.43<br />(44418ms) |  |\n|                    |         ART         | 0% / 0.59<br /> (196738ms) |                 24% / 0.70 <br />(66067ms) | 26% / 0.65<br />(694972ms) |  |\n| **PGD** (L2) |    **Torchattacks** | **0% / 0.41 (184ms)** |                  **68% / 0.5<br /> (52ms)** |                  **70% / 0.5<br />(1377ms)** | :crown: **Fastest** |\n|                    | Foolbox<sup>*</sup> | 0% / 0.41 (396ms) |                       68% / 0.5<br /> (57ms) |                     70% / 0.5<br /> (1968ms) |                    |\n|                    |         ART         | 0% / 0.40 (1364ms) |                       68% / 0.5<br /> (429ms) | 70% / 0.5<br /> (4777ms) |                           |\n\n<sup>*</sup> Note that Foolbox returns accuracy and adversarial images simultaneously, thus the *actual* time for generating adversarial images  might be shorter than the records.\n\n<sup>**\u2020**</sup>Considering that the binary search algorithm for const `c` can be time-consuming, torchattacks supports MutliAttack for grid searching `c`.\n\n\n\n## Citation\nIf you use this package, please cite the following BibTex ([SemanticScholar](https://www.semanticscholar.org/paper/Torchattacks-%3A-A-Pytorch-Repository-for-Adversarial-Kim/1f4b3283faf534ef92d7d7fa798b26480605ead9), [GoogleScholar](https://scholar.google.com/scholar?cluster=10203998516567946917&hl=ko&as_sdt=2005&sciodt=0,5)):\n\n```\n@article{kim2020torchattacks,\n  title={Torchattacks: A pytorch repository for adversarial attacks},\n  author={Kim, Hoki},\n  journal={arXiv preprint arXiv:2010.01950},\n  year={2020}\n}\n```\n\n\n\n##  Recommended Sites and Packages\n\n* **Adversarial Attack Packages:**\n\n    * [https://github.com/IBM/adversarial-robustness-toolbox](https://github.com/IBM/adversarial-robustness-toolbox): Adversarial attack and defense package made by IBM. **TensorFlow, Keras, Pyotrch available.**\n    * [https://github.com/bethgelab/foolbox](https://github.com/bethgelab/foolbox): Adversarial attack package made by [Bethge Lab](http://bethgelab.org/). **TensorFlow, Pyotrch available.**\n    * [https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans): Adversarial attack package made by Google Brain. **TensorFlow available.**\n    * [https://github.com/BorealisAI/advertorch](https://github.com/BorealisAI/advertorch): Adversarial attack package made by [BorealisAI](https://www.borealisai.com/en/). **Pytorch available.**\n    * [https://github.com/DSE-MSU/DeepRobust](https://github.com/DSE-MSU/DeepRobust): Adversarial attack (especially on GNN) package made by [BorealisAI](https://www.borealisai.com/en/). **Pytorch available.**\n    * https://github.com/fra31/auto-attack: Set of attacks that is believed to be the strongest in existence. **TensorFlow, Pyotrch available.**\n\n\n\n* **Adversarial Defense Leaderboard:**\n\n    * [https://github.com/MadryLab/mnist_challenge](https://github.com/MadryLab/mnist_challenge)\n    * [https://github.com/MadryLab/cifar10_challenge](https://github.com/MadryLab/cifar10_challenge)\n    * [https://www.robust-ml.org/](https://www.robust-ml.org/)\n    * [https://robust.vision/benchmark/leaderboard/](https://robust.vision/benchmark/leaderboard/)\n    * https://github.com/RobustBench/robustbench\n    * https://github.com/Harry24k/adversarial-defenses-pytorch\n\n\n\n* **Adversarial Attack and Defense Papers:**\n\n    * https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html: A Complete List of All (arXiv) Adversarial Example Papers made by Nicholas Carlini.\n    * https://github.com/chawins/Adversarial-Examples-Reading-List: Adversarial Examples Reading List made by Chawin Sitawarin.\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/HarryK24/adversairal-attacks-pytorch",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "torchattacks",
            "package_url": "https://pypi.org/project/torchattacks/",
            "platform": null,
            "project_url": "https://pypi.org/project/torchattacks/",
            "project_urls": {
                "Homepage": "https://github.com/HarryK24/adversairal-attacks-pytorch"
            },
            "release_url": "https://pypi.org/project/torchattacks/3.3.0/",
            "requires_dist": null,
            "requires_python": ">=3",
            "summary": "Adversarial Attacks for PyTorch",
            "version": "3.3.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15288160,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b76b5e79010338db23a6b70e0a6ffb48",
                    "sha256": "9065ab20c037ec1f2eab9fc0c44d32ec0961bffea11d8949fb1cb253010401fb"
                },
                "downloads": -1,
                "filename": "torchattacks-3.3.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b76b5e79010338db23a6b70e0a6ffb48",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3",
                "size": 155934,
                "upload_time": "2022-10-03T11:06:30",
                "upload_time_iso_8601": "2022-10-03T11:06:30.033341Z",
                "url": "https://files.pythonhosted.org/packages/41/75/a99caf6034d2bfed4f4c36d7f91054ae82dae5328f658864b238da2d31e5/torchattacks-3.3.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
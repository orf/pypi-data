{
    "0.0.6": {
        "info": {
            "author": "Shushant Pudasaini, Nitesh Ghimire , Sagar Lamichhane, Aakash Dumjan, Sujan Adhikari, Sajjan Adhikari, Janardan Karki",
            "author_email": "shusrulz@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "devanagari_nlp\n==============================\n\nNLP library for nepali textual dataset\n\nProject Organization\n------------\n\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 Makefile           <- Makefile with commands like `make data` or `make train`\n    \u251c\u2500\u2500 README.md          <- The top-level README for developers using this project.\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 external       <- Data from third party sources.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 interim        <- Intermediate data that has been transformed.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 processed      <- The final, canonical data sets for modeling.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 raw            <- The original, immutable data dump.\n    \u2502\n    \u251c\u2500\u2500 docs               <- A default Sphinx project; see sphinx-doc.org for details\n    \u2502\n    \u251c\u2500\u2500 models             <- Trained and serialized models, model predictions, or model summaries\n    \u2502\n    \u251c\u2500\u2500 notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n    \u2502                         the creator's initials, and a short `-` delimited description, e.g.\n    \u2502                         `1.0-jqp-initial-data-exploration`.\n    \u2502\n    \u251c\u2500\u2500 references         <- Data dictionaries, manuals, and all other explanatory materials.\n    \u2502\n    \u251c\u2500\u2500 reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        <- Generated graphics and figures to be used in reporting\n    \u2502\n    \u251c\u2500\u2500 requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n    \u2502                         generated with `pip freeze > requirements.txt`\n    \u2502\n    \u251c\u2500\u2500 setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n    \u251c\u2500\u2500 src                <- Source code for use in this project.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py    <- Makes src a Python module\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 data           <- Scripts to download or generate data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 make_dataset.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 features       <- Scripts to turn raw data into features for modeling\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 build_features.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 models         <- Scripts to train models and then use trained models to make\n    \u2502   \u2502   \u2502                 predictions\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 predict_model.py\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 train_model.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 visualization  <- Scripts to create exploratory and results oriented visualizations\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 visualize.py\n    \u2502\n    \u2514\u2500\u2500 tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n\n\n--------\n\n<p><small>Project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://gitlab.com/shusrulz/everest_nlp/-/archive/0.0.6/everest_nlp-0.0.6.tar.gz",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "devanagari-nlp",
            "package_url": "https://pypi.org/project/devanagari-nlp/",
            "platform": "",
            "project_url": "https://pypi.org/project/devanagari-nlp/",
            "project_urls": {
                "Homepage": "https://gitlab.com/shusrulz/everest_nlp/-/archive/0.0.6/everest_nlp-0.0.6.tar.gz"
            },
            "release_url": "https://pypi.org/project/devanagari-nlp/0.0.6/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "Package for applying NLP to devanagari datasets",
            "version": "0.0.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10275690,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "c4c16564748fcf1e1d3d7d22247876a0",
                    "sha256": "5549e078b4c8fa09058f5fe164aa4e81c9981744a964fb8871acc7fd6e196385"
                },
                "downloads": -1,
                "filename": "devanagari_nlp-0.0.6.tar.gz",
                "has_sig": false,
                "md5_digest": "c4c16564748fcf1e1d3d7d22247876a0",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 2747,
                "upload_time": "2021-05-06T13:23:33",
                "upload_time_iso_8601": "2021-05-06T13:23:33.546912Z",
                "url": "https://files.pythonhosted.org/packages/40/46/781fa72d12bb2a487fa385c31f51e2bb4b74a157b4dbc393e5d3b83ada05/devanagari_nlp-0.0.6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
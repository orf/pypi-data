{
    "0.1.0": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.0/",
            "requires_dist": null,
            "requires_python": ">=3.9,<4.0",
            "summary": "Module encoding and encrypting text by key",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "589d41055b109c5d3de921dbecc8e69f",
                    "sha256": "8606dd1afd200a1142900b8934f1c9e5d0a5e76bcc75eb32d3f01b6255009aaf"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "589d41055b109c5d3de921dbecc8e69f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9,<4.0",
                "size": 3638135,
                "upload_time": "2022-11-10T10:36:08",
                "upload_time_iso_8601": "2022-11-10T10:36:08.151241Z",
                "url": "https://files.pythonhosted.org/packages/65/23/82ef88d558c974f58daec8a67254840b41116145321cb1639e71b04db1cf/toxicityclassifier-0.1.0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "d14bfb46e5f6f43db456248609438912",
                    "sha256": "466a14d35b89ad929cedbf500bdf1c4f4fea63458156accaced3ee3187c67b7b"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "d14bfb46e5f6f43db456248609438912",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9,<4.0",
                "size": 3610755,
                "upload_time": "2022-11-10T10:36:10",
                "upload_time_iso_8601": "2022-11-10T10:36:10.458993Z",
                "url": "https://files.pythonhosted.org/packages/32/af/bdabb5971d09841dd17ef289f868e5a5863465587890bda881db727e8c06/toxicityclassifier-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.1": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": null,
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.1/",
            "requires_dist": null,
            "requires_python": ">=3.9,<4.0",
            "summary": "Module encoding and encrypting text by key",
            "version": "0.1.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "0700f9eaf9b1f7f9a54066f63621ca94",
                    "sha256": "198f1a56594a6b9d06059cbf7ff82feac64fc6b8f71f77073fe0808a8680dd53"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.1-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "0700f9eaf9b1f7f9a54066f63621ca94",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9,<4.0",
                "size": 3638136,
                "upload_time": "2022-11-10T10:37:25",
                "upload_time_iso_8601": "2022-11-10T10:37:25.420402Z",
                "url": "https://files.pythonhosted.org/packages/e5/26/85cd2b64718a26d263b2d3177bf1239d38f9f8aa9991a4d77a9df55ab968/toxicityclassifier-0.1.1-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "a871b0071bc7c11e1dcc90379033e600",
                    "sha256": "2e193716d0381022b6f70ad6c2dba93c2a1b5993cd8c368c4099a50ab61da941"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.1.tar.gz",
                "has_sig": false,
                "md5_digest": "a871b0071bc7c11e1dcc90379033e600",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9,<4.0",
                "size": 3610763,
                "upload_time": "2022-11-10T10:37:28",
                "upload_time_iso_8601": "2022-11-10T10:37:28.995309Z",
                "url": "https://files.pythonhosted.org/packages/44/72/c346fbdcfdc91bb678222ea842429df30ed73b58e1c29bd373abde599fd1/toxicityclassifier-0.1.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.2": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: Other/Proprietary License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "LICENCE.md",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.2/",
            "requires_dist": null,
            "requires_python": ">=3.9,<4.0",
            "summary": "",
            "version": "0.1.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6f104dd28285dd06aa1874f845bc17b7",
                    "sha256": "d26af6106fa3a375207a2546f930ca611cc765e82db5d810401fb4c78624c42d"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "6f104dd28285dd06aa1874f845bc17b7",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9,<4.0",
                "size": 3638207,
                "upload_time": "2022-11-12T12:25:49",
                "upload_time_iso_8601": "2022-11-12T12:25:49.234305Z",
                "url": "https://files.pythonhosted.org/packages/db/76/a546ddfd3e398eb71228ab4405515c998f5d12bb8cf18cdb2b4f9dc9285c/toxicityclassifier-0.1.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "1d2a79ac7143410e69e20c83461dd680",
                    "sha256": "5917e5fb4a70702dce2665180630fe136674b4a1011c4c97525f7bd52789beb4"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.2.tar.gz",
                "has_sig": false,
                "md5_digest": "1d2a79ac7143410e69e20c83461dd680",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9,<4.0",
                "size": 3610755,
                "upload_time": "2022-11-12T12:25:57",
                "upload_time_iso_8601": "2022-11-12T12:25:57.624206Z",
                "url": "https://files.pythonhosted.org/packages/71/74/fa5678537a3711983bdd0d4259fda81be83a09e0f30a3ef0fa80f624948d/toxicityclassifier-0.1.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.3": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": null,
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.3/",
            "requires_dist": null,
            "requires_python": ">=3.9,<4.0",
            "summary": "module for predicting toxicity messages in Russian and English",
            "version": "0.1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3d38b0ea4e3719e7c23ebc5381767d27",
                    "sha256": "8e8da56579b0043bb68d01af8d0068ff039af6cb9f0449063afbc3599f0b6472"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3d38b0ea4e3719e7c23ebc5381767d27",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9,<4.0",
                "size": 3638239,
                "upload_time": "2022-11-12T12:28:50",
                "upload_time_iso_8601": "2022-11-12T12:28:50.362001Z",
                "url": "https://files.pythonhosted.org/packages/21/dc/1c0d4a71b07164bcd4aa46827b6fa3675df00396ec1406f9a4c7579bbdbc/toxicityclassifier-0.1.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "70ace34a0a9c66d3865f7dc0dccd446a",
                    "sha256": "515f32358a48a4e3a159867c34b22ebc82bbf58e5c80856703695fecea2a3ff5"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.3.tar.gz",
                "has_sig": false,
                "md5_digest": "70ace34a0a9c66d3865f7dc0dccd446a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9,<4.0",
                "size": 3610817,
                "upload_time": "2022-11-12T12:29:01",
                "upload_time_iso_8601": "2022-11-12T12:29:01.305182Z",
                "url": "https://files.pythonhosted.org/packages/e7/a3/3035cbb97f1e6a91a73783a51660fd5976700eee631960a1e55488a4141b/toxicityclassifier-0.1.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.4": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/D1ffic00lt/toxicity-classification-module",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": {
                "Documentation": "https://github.com/D1ffic00lt/toxicity-classification-module",
                "Homepage": "https://github.com/D1ffic00lt/toxicity-classification-module",
                "Repository": "https://github.com/D1ffic00lt/toxicity-classification-module"
            },
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.4/",
            "requires_dist": null,
            "requires_python": ">=3.9,<4.0",
            "summary": "module for predicting toxicity messages in Russian and English",
            "version": "0.1.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "d8a419cc0bb9d4ac0eb77ae205d34436",
                    "sha256": "747f31aacce599a0b84ae61f9858b95eadee273676affe3d77fce4cd422e0673"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.4-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "d8a419cc0bb9d4ac0eb77ae205d34436",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9,<4.0",
                "size": 3638306,
                "upload_time": "2022-11-12T12:33:39",
                "upload_time_iso_8601": "2022-11-12T12:33:39.191388Z",
                "url": "https://files.pythonhosted.org/packages/40/43/98bead358b60523ba7d36fd5926d8fe83e228068a2ec814ab64c63f5fd22/toxicityclassifier-0.1.4-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "ffcb0669fcc39f543a43210710b72477",
                    "sha256": "01f2a62268ccc2e8c2fcfb692be06788adb367ecd246d252e4763d8c16c8b159"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.4.tar.gz",
                "has_sig": false,
                "md5_digest": "ffcb0669fcc39f543a43210710b72477",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9,<4.0",
                "size": 3610896,
                "upload_time": "2022-11-12T12:33:47",
                "upload_time_iso_8601": "2022-11-12T12:33:47.194362Z",
                "url": "https://files.pythonhosted.org/packages/7c/e4/f6c8d9aa3c76656c521b2ac2192f6340b48cf7850ff0049e0d7db9e5e85a/toxicityclassifier-0.1.4.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.5": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.9"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/D1ffic00lt/toxicity-classification-module",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": {
                "Documentation": "https://github.com/D1ffic00lt/toxicity-classification-module",
                "Homepage": "https://github.com/D1ffic00lt/toxicity-classification-module",
                "Repository": "https://github.com/D1ffic00lt/toxicity-classification-module"
            },
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.5/",
            "requires_dist": null,
            "requires_python": ">=3.9,<4.0",
            "summary": "module for predicting toxicity messages in Russian and English",
            "version": "0.1.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "144723a165975f0e8697a18261af1a3f",
                    "sha256": "b3ebf44eacda8691beff27412f00a246f2434f25a09ea61db32abc3514f7889c"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "144723a165975f0e8697a18261af1a3f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.9,<4.0",
                "size": 3638308,
                "upload_time": "2022-11-12T12:36:00",
                "upload_time_iso_8601": "2022-11-12T12:36:00.676592Z",
                "url": "https://files.pythonhosted.org/packages/43/78/82c9d74881ac9aa38f717ae53c3cb52921908455515b7a6c1e2b012ff676/toxicityclassifier-0.1.5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "48d83265fe0225be50285e86cc721e50",
                    "sha256": "858ef984bc7f42ecc7d79dfd75d01b569e72a52f2a8762959c98b2f1b237eeac"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.5.tar.gz",
                "has_sig": false,
                "md5_digest": "48d83265fe0225be50285e86cc721e50",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.9,<4.0",
                "size": 3610981,
                "upload_time": "2022-11-12T12:36:17",
                "upload_time_iso_8601": "2022-11-12T12:36:17.331716Z",
                "url": "https://files.pythonhosted.org/packages/26/5b/54dec45958b8c50ff7b2fbcc9322878bdec1322be330ba68274e0276ff49/toxicityclassifier-0.1.5.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.6": {
        "info": {
            "author": "D1ffic00lt",
            "author_email": "dm.filinov@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Programming Language :: Python :: 3",
                "Programming Language :: Python :: 3.10",
                "Programming Language :: Python :: 3.11",
                "Programming Language :: Python :: 3.8",
                "Programming Language :: Python :: 3.9"
            ],
            "description": "# ToxicityClassificator",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/D1ffic00lt/toxicity-classification-module",
            "keywords": "",
            "license": "MIT",
            "maintainer": "",
            "maintainer_email": "",
            "name": "toxicityclassifier",
            "package_url": "https://pypi.org/project/toxicityclassifier/",
            "platform": null,
            "project_url": "https://pypi.org/project/toxicityclassifier/",
            "project_urls": {
                "Documentation": "https://github.com/D1ffic00lt/toxicity-classification-module",
                "Homepage": "https://github.com/D1ffic00lt/toxicity-classification-module",
                "Repository": "https://github.com/D1ffic00lt/toxicity-classification-module"
            },
            "release_url": "https://pypi.org/project/toxicityclassifier/0.1.6/",
            "requires_dist": null,
            "requires_python": ">=3.8,<4.0",
            "summary": "module for predicting toxicity messages in Russian and English",
            "version": "0.1.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 15749803,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b71f7ad6f91f4c908aa1b8946052bb43",
                    "sha256": "ad5187d95cf68bd5f5d34ea416b4fb2650d3257003782b9ec94b9efbb4f39f9b"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.6-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "b71f7ad6f91f4c908aa1b8946052bb43",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.8,<4.0",
                "size": 3638312,
                "upload_time": "2022-11-13T08:05:50",
                "upload_time_iso_8601": "2022-11-13T08:05:50.081628Z",
                "url": "https://files.pythonhosted.org/packages/a3/5f/efd671258d0463871a86825d1571e7f7ba8640dfd2cdc21d1eeca18ec621/toxicityclassifier-0.1.6-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "e332808c600b36aba6969d950f692df3",
                    "sha256": "e65b71fef86a6e74802e6882952dbf37d27f933b491fdc3e00b951bdd886192a"
                },
                "downloads": -1,
                "filename": "toxicityclassifier-0.1.6.tar.gz",
                "has_sig": false,
                "md5_digest": "e332808c600b36aba6969d950f692df3",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.8,<4.0",
                "size": 3611004,
                "upload_time": "2022-11-13T08:05:59",
                "upload_time_iso_8601": "2022-11-13T08:05:59.473970Z",
                "url": "https://files.pythonhosted.org/packages/0a/3c/4764e1fce0ac69f8a453be06105e582c49207405c18c669fb648a0473abf/toxicityclassifier-0.1.6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
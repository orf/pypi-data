{
    "0.1": {
        "info": {
            "author": "Shushant Pudasaini, Nitesh Ghimire , Sagar Lamichhane, Aakash Dumjan, Sujan Adhikari, Sajjan Adhikari, Janardan Karki",
            "author_email": "shusrulz@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: MIT License",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3"
            ],
            "description": "devanagari\n==============================\n\nNLP library for nepali textual dataset\n\nProject Organization\n------------\n\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 Makefile           <- Makefile with commands like `make data` or `make train`\n    \u251c\u2500\u2500 README.md          <- The top-level README for developers using this project.\n    \u251c\u2500\u2500 data\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 external       <- Data from third party sources.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 interim        <- Intermediate data that has been transformed.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 processed      <- The final, canonical data sets for modeling.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 raw            <- The original, immutable data dump.\n    \u2502\n    \u251c\u2500\u2500 docs               <- A default Sphinx project; see sphinx-doc.org for details\n    \u2502\n    \u251c\u2500\u2500 models             <- Trained and serialized models, model predictions, or model summaries\n    \u2502\n    \u251c\u2500\u2500 notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n    \u2502                         the creator's initials, and a short `-` delimited description, e.g.\n    \u2502                         `1.0-jqp-initial-data-exploration`.\n    \u2502\n    \u251c\u2500\u2500 references         <- Data dictionaries, manuals, and all other explanatory materials.\n    \u2502\n    \u251c\u2500\u2500 reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 figures        <- Generated graphics and figures to be used in reporting\n    \u2502\n    \u251c\u2500\u2500 requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n    \u2502                         generated with `pip freeze > requirements.txt`\n    \u2502\n    \u251c\u2500\u2500 setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n    \u251c\u2500\u2500 src                <- Source code for use in this project.\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py    <- Makes src a Python module\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 data           <- Scripts to download or generate data\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 make_dataset.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 features       <- Scripts to turn raw data into features for modeling\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 build_features.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 models         <- Scripts to train models and then use trained models to make\n    \u2502   \u2502   \u2502                 predictions\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 predict_model.py\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 train_model.py\n    \u2502   \u2502\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 visualization  <- Scripts to create exploratory and results oriented visualizations\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 visualize.py\n    \u2502\n    \u2514\u2500\u2500 tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n\n\n--------\n\n<p><small>Project based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://gitlab.com/shusrulz/everest_nlp/-/archive/0.1/everest_nlp-0.1.tar.gz",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "devanagari",
            "package_url": "https://pypi.org/project/devanagari/",
            "platform": "",
            "project_url": "https://pypi.org/project/devanagari/",
            "project_urls": {
                "Homepage": "https://gitlab.com/shusrulz/everest_nlp/-/archive/0.1/everest_nlp-0.1.tar.gz"
            },
            "release_url": "https://pypi.org/project/devanagari/0.1/",
            "requires_dist": null,
            "requires_python": ">=3.6",
            "summary": "Package for applying NLP to devanagari datasets",
            "version": "0.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 10275724,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "79d25d835b4d46928a0795d346d06608",
                    "sha256": "c7cbbf7999dcb91dee7e4f763cabf62d6ae3a36fe83f7432bc40d8286f2be3dd"
                },
                "downloads": -1,
                "filename": "devanagari-0.1.tar.gz",
                "has_sig": false,
                "md5_digest": "79d25d835b4d46928a0795d346d06608",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.6",
                "size": 2670,
                "upload_time": "2021-05-06T13:29:07",
                "upload_time_iso_8601": "2021-05-06T13:29:07.983528Z",
                "url": "https://files.pythonhosted.org/packages/c6/46/49d52f748db2391a181344f93d28aab08e7e48b2e23da7ab7b2a79694532/devanagari-0.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
{
    "0.1.0": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.0/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the See19 dataset",
            "version": "0.1.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f6b04f1a8e1dd20784ce3a581edd1c4e",
                    "sha256": "a89d310d9ce8aac11ab7cb8d53a7fce721be0d9096a209d973daf2b3ece05bd3"
                },
                "downloads": -1,
                "filename": "see19-0.1.0.tar.gz",
                "has_sig": false,
                "md5_digest": "f6b04f1a8e1dd20784ce3a581edd1c4e",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 14428,
                "upload_time": "2020-06-13T21:49:11",
                "upload_time_iso_8601": "2020-06-13T21:49:11.157615Z",
                "url": "https://files.pythonhosted.org/packages/a2/36/dd4c78b118566eff54af99dcdde3b1b76247fcbac7a3bf62b0dfc400f534/see19-0.1.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.3": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.3/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the see19 dataset",
            "version": "0.1.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "0a7901da9f84ff2d6e711fddc5597fe6",
                    "sha256": "f5eca80b8312035095b8ae151f6281228b7911478f2a93f8222080018044b25a"
                },
                "downloads": -1,
                "filename": "see19-0.1.3.tar.gz",
                "has_sig": false,
                "md5_digest": "0a7901da9f84ff2d6e711fddc5597fe6",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 14522,
                "upload_time": "2020-05-04T04:17:36",
                "upload_time_iso_8601": "2020-05-04T04:17:36.921241Z",
                "url": "https://files.pythonhosted.org/packages/83/84/a99a1505d3596ddc06ff4afcb2c49b81ba4c31d2fddfefd5a29c1f414e18/see19-0.1.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.4": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.4/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the see19 dataset",
            "version": "0.1.4",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "dd02a5cf0299d5b344f5ac539b6add28",
                    "sha256": "65e8493b5825556b671aded6dbbe2f86e98466d4fd292ecc9a8cc5e58cb1388a"
                },
                "downloads": -1,
                "filename": "see19-0.1.4.tar.gz",
                "has_sig": false,
                "md5_digest": "dd02a5cf0299d5b344f5ac539b6add28",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 14525,
                "upload_time": "2020-05-04T05:07:54",
                "upload_time_iso_8601": "2020-05-04T05:07:54.556883Z",
                "url": "https://files.pythonhosted.org/packages/39/9c/c685873456d42300e5bcb4543f7dfb71856d25070ad4b8952b848d44c33b/see19-0.1.4.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.5": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.5/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the see19 dataset",
            "version": "0.1.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "ed32f6883c116373d33ba2da842a32ee",
                    "sha256": "d40c55847fa32abdafc03b47a4068e36233409f6f1628e72b433a789cc1d5f19"
                },
                "downloads": -1,
                "filename": "see19-0.1.5.tar.gz",
                "has_sig": false,
                "md5_digest": "ed32f6883c116373d33ba2da842a32ee",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 19988,
                "upload_time": "2020-05-04T08:11:58",
                "upload_time_iso_8601": "2020-05-04T08:11:58.993412Z",
                "url": "https://files.pythonhosted.org/packages/20/4b/0001a9b3b773bcf13a3fc886eea23e4c54b1f16f084ad752f2045230f4ba/see19-0.1.5.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.6": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.6/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the see19 dataset",
            "version": "0.1.6",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "f86973cbe20fb682a96665aa4ff79169",
                    "sha256": "3a013bd9218da4fc948ea94625996a105065709aa187e657ce13a947ef5d9d2c"
                },
                "downloads": -1,
                "filename": "see19-0.1.6.tar.gz",
                "has_sig": false,
                "md5_digest": "f86973cbe20fb682a96665aa4ff79169",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 19966,
                "upload_time": "2020-05-04T08:13:28",
                "upload_time_iso_8601": "2020-05-04T08:13:28.527026Z",
                "url": "https://files.pythonhosted.org/packages/fa/f4/c77fe00ba2c8debd4c08494da4b2c4b4e4b26df18607c03825c9aad6874b/see19-0.1.6.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.7": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.7/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the see19 dataset",
            "version": "0.1.7",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "400bed80c96523c1789040e571468ef8",
                    "sha256": "bd0595457934cfd2308364ab0859d6cb2ea031446651eecc1b833764bdd3bc8a"
                },
                "downloads": -1,
                "filename": "see19-0.1.7.tar.gz",
                "has_sig": false,
                "md5_digest": "400bed80c96523c1789040e571468ef8",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 16958,
                "upload_time": "2020-05-06T14:23:25",
                "upload_time_iso_8601": "2020-05-06T14:23:25.651597Z",
                "url": "https://files.pythonhosted.org/packages/ed/c6/68f51353cbf16a1114c90a487427b2cb9e3d1b7aa91f69e366aa965006d8/see19-0.1.7.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.1.8": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.1.8/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for the visualizing and analysing the see19 dataset",
            "version": "0.1.8",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "594755dda0c3e9adef78c30f7c06ddb2",
                    "sha256": "bf4419bd9b63be4b49303d1b09039d20dbcde9d4f2ade4548bbfbd11113d6495"
                },
                "downloads": -1,
                "filename": "see19-0.1.8.tar.gz",
                "has_sig": false,
                "md5_digest": "594755dda0c3e9adef78c30f7c06ddb2",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 18094,
                "upload_time": "2020-05-08T03:18:16",
                "upload_time_iso_8601": "2020-05-08T03:18:16.232091Z",
                "url": "https://files.pythonhosted.org/packages/0d/72/f1500c494c6119764c9f491b5336df2a2c213682cb90c205f5207e996960/see19-0.1.8.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.2.0": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.2.0/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.2.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "6c27e97dbfe859d74295a3ebb3626277",
                    "sha256": "67dbb5b2c7edc966d128a2221858012c5eb24b2c8bec4265e6ab3d3c288d082e"
                },
                "downloads": -1,
                "filename": "see19-0.2.0.tar.gz",
                "has_sig": false,
                "md5_digest": "6c27e97dbfe859d74295a3ebb3626277",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 22764,
                "upload_time": "2020-05-11T10:54:33",
                "upload_time_iso_8601": "2020-05-11T10:54:33.896435Z",
                "url": "https://files.pythonhosted.org/packages/53/e1/a874a8085e4f5a68eb0db965abdb697d4ef629f1a6b4ae71cf1edab535fe/see19-0.2.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.0": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.3.0/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.3.0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "a9208a0c259c69548f93e0446a199f54",
                    "sha256": "96f8f2f16d1120a64affd8750d199ef224dec2e43090c1b0876f5564bf682e42"
                },
                "downloads": -1,
                "filename": "see19-0.3.0.tar.gz",
                "has_sig": false,
                "md5_digest": "a9208a0c259c69548f93e0446a199f54",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 30570,
                "upload_time": "2020-05-31T21:04:05",
                "upload_time_iso_8601": "2020-05-31T21:04:05.456276Z",
                "url": "https://files.pythonhosted.org/packages/c5/7d/65692c5d9d64448af53612380e82d0e9492c5f37fb4915cdcd4765e29ee7/see19-0.3.0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.1": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.3.1/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.3.1",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "75f30e86d2e4141f27b17820d46b02a2",
                    "sha256": "b9b0ed4b796ae98b8b9e750f671e68806bb42df7a7a813a30d58f5f495d6b3a4"
                },
                "downloads": -1,
                "filename": "see19-0.3.1.tar.gz",
                "has_sig": false,
                "md5_digest": "75f30e86d2e4141f27b17820d46b02a2",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 29457,
                "upload_time": "2020-05-31T21:08:19",
                "upload_time_iso_8601": "2020-05-31T21:08:19.506424Z",
                "url": "https://files.pythonhosted.org/packages/ae/cf/24e3b430f4c071a82bd814756c74c17a4d6e884cdcd489c102a7bfbecc04/see19-0.3.1.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.2": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.3.2/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.3.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "9f798eda32888895934e5f3bfe966e35",
                    "sha256": "35db4d4a7567cd34f2014add9043de4f6f7888641a3ac8d6d727af0be6f29a7c"
                },
                "downloads": -1,
                "filename": "see19-0.3.2.tar.gz",
                "has_sig": false,
                "md5_digest": "9f798eda32888895934e5f3bfe966e35",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 29466,
                "upload_time": "2020-05-31T21:41:44",
                "upload_time_iso_8601": "2020-05-31T21:41:44.636980Z",
                "url": "https://files.pythonhosted.org/packages/6d/e0/a3748c35804dddc1c79f56b50c64b58294498a3537c10147428511ea5882/see19-0.3.2.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.3": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.3.3/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.3.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "b6f4546eef4a992c7cfb479823e64e9c",
                    "sha256": "d44971e6921d89dee635011f9a7b62806ccd278281441323294585182cb04fb2"
                },
                "downloads": -1,
                "filename": "see19-0.3.3.tar.gz",
                "has_sig": false,
                "md5_digest": "b6f4546eef4a992c7cfb479823e64e9c",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 29778,
                "upload_time": "2020-06-07T22:02:18",
                "upload_time_iso_8601": "2020-06-07T22:02:18.132679Z",
                "url": "https://files.pythonhosted.org/packages/85/c9/b51e989d636059b258fbdb43000270200ac39c42e4b321387042e02beb39/see19-0.3.3.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.5": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.3.5/",
            "requires_dist": null,
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.3.5",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "29238b2cf392f82c768de02d949c194f",
                    "sha256": "70258daf3c7c8cadc4bc4c0cb8e6a564b911d0f8c4e7e1e5d40ac3d3dbfc3c31"
                },
                "downloads": -1,
                "filename": "see19-0.3.5-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "29238b2cf392f82c768de02d949c194f",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 39357,
                "upload_time": "2020-06-13T21:49:10",
                "upload_time_iso_8601": "2020-06-13T21:49:10.226385Z",
                "url": "https://files.pythonhosted.org/packages/5c/93/875cfa46df8bb7a0a4f2842b48a7f222619f9f177874d56ad27ecb98898a/see19-0.3.5-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "362a18ab8591ee2d1f59328866fed9a5",
                    "sha256": "54580274c5309c711fa7ec7f84c35da2e768c29f66283cc9c409d276c0ed16b0"
                },
                "downloads": -1,
                "filename": "see19-0.3.5.tar.gz",
                "has_sig": false,
                "md5_digest": "362a18ab8591ee2d1f59328866fed9a5",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 29698,
                "upload_time": "2020-06-12T20:46:59",
                "upload_time_iso_8601": "2020-06-12T20:46:59.646286Z",
                "url": "https://files.pythonhosted.org/packages/af/00/57ecb0505ad881617e5af491d9f41e6dcf3deed6796afae7c3190811e946/see19-0.3.5.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4a0": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.4a0/",
            "requires_dist": [
                "bokeh (>=2.0.0)",
                "matplotlib (>=3.2.0)",
                "numpy (>=1.18.0)",
                "pandas (>=1.0.0)",
                "requests (>=2.23.0)",
                "numba (>=0.50.1)",
                "ray (>=0.8.6)"
            ],
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.4a0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "716fd7e40a8d9afdbf3b2db6ea06a46c",
                    "sha256": "1c0c6e69a9e1167852e1312aa6b496b1634812919a868b296321e75021e67d88"
                },
                "downloads": -1,
                "filename": "see19-0.4a0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "716fd7e40a8d9afdbf3b2db6ea06a46c",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 71281,
                "upload_time": "2020-08-02T09:21:26",
                "upload_time_iso_8601": "2020-08-02T09:21:26.194781Z",
                "url": "https://files.pythonhosted.org/packages/de/23/45c376e04f34c779fee06859f8e458fe4391221228008cee00289e1f23ba/see19-0.4a0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "de5c7820f902b1f228a494a020aeef0a",
                    "sha256": "b24881a69e1f62bc9a42a0ed42520183a4b63875564619271dda63776d6820d2"
                },
                "downloads": -1,
                "filename": "see19-0.4a0.tar.gz",
                "has_sig": false,
                "md5_digest": "de5c7820f902b1f228a494a020aeef0a",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 116746,
                "upload_time": "2020-08-02T09:24:02",
                "upload_time_iso_8601": "2020-08-02T09:24:02.918681Z",
                "url": "https://files.pythonhosted.org/packages/f7/d7/8872cab6471422d67ec024aba267e524ca5fac7841f66177f1094322e734/see19-0.4a0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4b0": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.4b0/",
            "requires_dist": [
                "bokeh (>=2.0.0)",
                "matplotlib (>=3.2.0)",
                "numpy (>=1.18.0)",
                "pandas (>=1.0.0)",
                "requests (>=2.23.0)",
                "numba (>=0.50.1)",
                "ray (>=0.8.6)"
            ],
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.4b0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "4d2d7ffbb2101437edaf13c9f402b47e",
                    "sha256": "e86c6b9ffb2a5ce3fb28c85443128d589fb66898f6e22dea0855c3bbcb5922c1"
                },
                "downloads": -1,
                "filename": "see19-0.4b0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "4d2d7ffbb2101437edaf13c9f402b47e",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 71284,
                "upload_time": "2020-08-02T16:39:25",
                "upload_time_iso_8601": "2020-08-02T16:39:25.557836Z",
                "url": "https://files.pythonhosted.org/packages/77/76/6fb9b9d07e78f136f350e55c1b7d199c489d86be09aca0929865ccac96f5/see19-0.4b0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f04d5fe3b1c101798fe41a47ea309272",
                    "sha256": "a0d21a9131343b9e90153fcf26a6e2f44e4d25270fbe12ed009cef46d697f927"
                },
                "downloads": -1,
                "filename": "see19-0.4b0.tar.gz",
                "has_sig": false,
                "md5_digest": "f04d5fe3b1c101798fe41a47ea309272",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 116745,
                "upload_time": "2020-08-02T16:39:28",
                "upload_time_iso_8601": "2020-08-02T16:39:28.218612Z",
                "url": "https://files.pythonhosted.org/packages/bc/8c/37771c2b3dd0481a1784834f6cc570a8cb58fd315587dd63b25796be99bf/see19-0.4b0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.4rc0": {
        "info": {
            "author": "Ryan Skene",
            "author_email": "rjskene83@gmail.com",
            "bugtrack_url": null,
            "classifiers": [
                "License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)",
                "Operating System :: OS Independent",
                "Programming Language :: Python :: 3.7"
            ],
            "description": "# see19 Guide\n\n**A dataset and interface for visualizing and analyzing the epidemiology of Coronavirus Disease 2019 aka COVID19 aka C19**\n\nCurrent with version 0.4.0\n\n# Analysis\n\nPlease read my various deep dives with `see19` exploring different aspects of COVID19.\n\n[How Effective Is Social Distancing?](https://ryanskene.github.io/see19/analysis/How%20Effective%20Is%20Social%20Distancing%3F.html)\n\n[What Factors Are Correlated With COVID19 Fatality Rates?](https://ryanskene.github.io/see19/analysis/What%20Factors%20Are%20Correlated%20With%20COVID19%20Fatality%20Rates%3F.html)\n\n[The COVID Dragons](https://ryanskene.github.io/see19/analysis/The%20COVID%20Dragons.html)\n\n# Contents\n\n1. [Purpose](#section1)\n2. [Getting Started](#section2)\n3. [the Data](#section3)  \n    3.1 [Data Sources](#section3.1)  \n    3.2 [Dataset Characteristics](#section3.2)  \n    3.3 [The Testset](#section3.3)  \n    3.4 [Disclaimer](#section3.4)\n4. [the CaseStudy Interface](#section4)    \n    4.1 [Basics](#section4.1)  \n    4.2 [Filtering](#section4.2)  \n    4.3 [Smoothing](#section4.3)  \n    4.4 [Available Factors](#section4.4)  \n    4.5 [Additional Flags](#section4.5)    \n    4.6 [RayStudy v BaseStudy](#section4.6)    \n    4.7 [Chart Objects](#section4.7)\n5. [compchart - Visualizing Regional Impacts](#section5)    \n    5.1 [Daily Fatalities Comparison - Italy](#section5.1)  \n    5.2 [Daily Fatalities Comparison - 10 Most Impacted Regions](#section5.2)  \n    5.3 [Varying the Categories](#section5.3)  \n6. [compchart4D - Visualizing Factors in 4D](#section6)    \n    6.1 [From 3D to 4D](#section6.1)  \n    6.2 [More on the X-Axis](#section6.2)  \n    6.3 [How Far Can We Take It?](#section6.3)\n7. [heatmap - Visualizing with Color Maps](#section7)    \n    7.1 [Count Category v Single Factor](#section7.1)  \n    7.2 [Count Category v Multiple Factors](#section7.2)  \n8. [barcharts - Comparing Regional Factors](#section8)\n9. [ScatterFlow for Large Sets](#section9)    \n    9.1 [substrinscat - for Strindex Sub-Categories](#section9.1)  \n    9.2 [scatterflow](#section9.2)  \n\n<h1><a id='section1'>1. Purpose</a></h1>\n\n**See19** is the single most comprehensive international COVID-19 dataset available.\n\nEase-of-use is paramount, thus, all data from all sources have been compiled into a single structure, readily consumed and manipulated in the ubiquitous `csv` format.\n\nAlong with the root data, a module is included with analysis and visualizations tools.\n\n<h1><a id='section2'>2. Getting Started</a></h1>\n\n**See19** is a dataset ***and*** a python package.\n\nThe dataset can be accessed directly **[here]('https://github.com/ryanskene/see19/tree/master/dataset')**. Files are timestamped with creation date.\n\nThe package can be installed via pip.\n\n`pip install see19`\n\n<h1><a id='section3'> 3. the Data</a></h1>\n\n3.1 [Data Sources](#section3.1)  \n3.2 [Dataset Characteristics](#section3.2)  \n3.3 [The Testset](#section3.3)  \n3.4 [Disclaimer](#section3.4)\n\nThe See19 dataset aggregates global data on COVID19 in various regions, as available data allows, and marries that data with available datasets on exogenous regional factors that might impact the epidemiology of the virus.\n\nThe dataset is compiled using `Selenium`, `Django`, `SQLite`, and `Pandas`.\n\n\n#### COVID19 Data Characteristics:\n* Cumulative Cases for each region on each date\n* Cumulative Fatalities for each region on each date\n* State / Provincial-level data available for:\n    * Australia\n    * Brazil\n    * Canada\n    * China\n    * Italy\n    * United States\n* Country-level available for all other regions\n\n**Factor Data Characteristics** available for most regions:\n* Longitude / Latitude\n    * I just wrote a script that searched the region name on [this website]('https://www.openstreetmap.org/') and pulled the coordinates from the resulting url\n* Population\n* Population demographic segmentation\n* Land Density\n* City Density (typically the density of the largest city in the region)\n* Climate Characteristics including:\n    * Average daily temperature\n    * Average daily dewpoint temperate\n    * Average daily relative humidity (derived from temperature and dewpoint temperature)\n    * Total daily UV-B Radiation\n* Air quality measures      \n* Historical Health Outcomes\n* Travel Popularity\n* Social Distancing Implementation\n\nUpdated each morning.\n\n<h2><a id='section3.1'>3.1 Data Sources</a></h2>\n\n#### COVID Case, Fatality, and Testing Data:\n* `cases` and `deaths` and `tests`\n    * [Brazil Regional Data compiled via the great from Wesley Cota and team.](https://github.com/wcota/covid19br)\n     * *Note*: Brazil data was previously available directly from the federal government, however, the fulsome CSV was removed from the site and a new source was required.\n    * [Italy Regional Data from the government github repo](https://github.com/pcm-dpc/COVID-19/blob/master/dati-regioni/dpc-covid19-ita-regioni-20200224.csv)\n        * *Note:* Italian testing has two categories that complicate the data somewhat\n            * `tamponi` refers to swabs. Swabs have been recorded since very early on. There are generally multiple swabs per individual whereas most test counts are one test per individual.\n            * `casi_testati` refers to the more standard one test per person. This metric was not reliably tract before mid-April\n            * for metrics prior to mid-April, `see19` adjusts the `tamponi` counts by finding the average `tamponi` per `case_testati` across the all data then dividing the tampons by the average to estimate casi_testati\n\n* `cases` and `deaths`\n    * [US Regional Data from the COVID Tracking Project](https://covidtracking.com)\n    * [Other Regions from Johns Hopkins via humdata.org](https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases)\n\n* `tests`\n    * [Country Level from myriad sources via humdata.org](https://data.humdata.org/dataset/total-covid-19-tests-performed-by-country)\n    * [Australia](https://services1.arcgis.com/vHnIGBHHqDR6y0CR/arcgis/rest/services/COVID19_Time_Series/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json)\n    * [Canada](https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection.html)\n    * [United States](https://covidtracking.com/)\n\nOther Data:\n* Longitude & Latitude\n    * I just wrote a script that searched each region name on this [site]('https://www.openstreetmap.org/')\n    * Any errors were fixed manually\n* [Population, Demographics, and Density from SEDAC](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-admin-unit-center-points-population-estimates-rev11)\n    * Matched to regional case data by name, often manually\n* [Climate Data from European Centre for Medium-Range Weather Forecasts](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview)\n    * Climate data pulled from nearest matching longitude & latitude coordinate in the dataset\n* [Air Quality Data from the World Air Quality Project](https://aqicn.org/data-platform/covid19/verify/1c09b43b-09f2-4244-a86f-24647e1fa3d9)\n    * Air quality data recorded at city-level, with limited number of cities available\n    * City data is aggregated to the regional or country-level\n    * So, where a region has mutiple cities reporting AQ data, the region value is aggregate of the cities\n    * Where a region has only a single city, that city represents the whole region\n    * Where a region has no cities, NADA\n* Social Distancing Stringency Index and Policy Indicators via [Oxford Covid Government Response Tracker](https://github.com/OxCGRT/covid-policy-tracker)\n* [Google Mobility Data](https://www.google.com/covid19/mobility/)\n* [Apple Mobility Index](https://www.apple.com/covid19/mobility)\n* GDP Per Capita via the [OECD](https://stats.oecd.org/Index.aspx?DataSetCode=REGION_ECONOM) and [WorldBank](https://data.worldbank.org/indicator/NY.GDP.MKTP.PP.CD?most_recent_year_desc=false)\n    * utilizing real 2016 Purchasing Power Parity figures indexed to 2015 US dollars\n* Causes of Death\n    * A fairly messy hodgepodge of data for [global](https://ourworldindata.org/causes-of-death), [US](https://wonder.cdc.gov/controller/datarequest/D76;jsessionid=7D21B11E6FF1F1059C184EE313E58875), and [Italy](http://dati.istat.it/Index.aspx?QueryId=26435&lang=en#)\n* Travel Popularity\n    * An even messier hodgepodge of data pulled from the World Tourism Organization via [indexmundi](https://www.indexmundi.com/facts/indicators/ST.INT.ARVL/rankings)\n    * State/Provincial data were derived from the country-level and other various sources in an ad-hoc fashion\n    * Good travel data is surprisingly difficult to come by. There are a number of services that offer data on flight statistics, however, it is prohibitively expensive\n\n<h2><a id='section3.2'>3.2 Dataset Characteristics</a></h2>\n\nWith `see19` installed, we can download the dataset via `get_baseframe`\n\n\n```python\nimport numpy as np\nimport pandas as pd\n```\n\n\n```python\n# from see19 import get_baseframe\nfrom casestudy.see19.see19 import get_baseframe\nbf = get_baseframe()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Find latest dataset...', layout=Layout(flex='2'), max=3.0\u2026\n\n\nThe dataset is arranged such that each row is a unique entry for each `region_id` on each `date`\n\nAll other columns are the value of that particular factor in that particular region on that particular date\n\n\n```python\nbf.head(3)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>genito</th>\n      <th>childbirth</th>\n      <th>perinatal</th>\n      <th>congenital</th>\n      <th>other</th>\n      <th>external</th>\n      <th>visitors</th>\n      <th>travel_year</th>\n      <th>gdp</th>\n      <th>gdp_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>282</td>\n      <td>110</td>\n      <td>ABR</td>\n      <td>Abruzzo</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-01-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>442.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n      <td>19.0</td>\n      <td>384.0</td>\n      <td>2059</td>\n      <td>181458.0</td>\n      <td>2017.0</td>\n      <td>4.560860e+10</td>\n      <td>2016.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>282</td>\n      <td>110</td>\n      <td>ABR</td>\n      <td>Abruzzo</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>442.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n      <td>19.0</td>\n      <td>384.0</td>\n      <td>2059</td>\n      <td>181458.0</td>\n      <td>2017.0</td>\n      <td>4.560860e+10</td>\n      <td>2016.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>282</td>\n      <td>110</td>\n      <td>ABR</td>\n      <td>Abruzzo</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-01-03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>442.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n      <td>19.0</td>\n      <td>384.0</td>\n      <td>2059</td>\n      <td>181458.0</td>\n      <td>2017.0</td>\n      <td>4.560860e+10</td>\n      <td>2016.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows \u00d7 132 columns</p>\n</div>\n\n\n\n_This could perhaps be more appropriately structured as a multi-index frame, however, I find such indexes cumbersome to work with._\n\n\n```python\n'There are {} unique regions in the dataset'.format(bf.region_id.unique().size)\n```\n\n\n\n\n    'There are 325 unique regions in the dataset'\n\n\n\n**Australia, Brazil, Canada, China, Italy, and the US** have state/provincial level data.\n\nFor example, regions within Italy and Brazil are as follows:\n\n\n```python\nbf[bf.country.isin(['Italy', 'Brazil'])].region_name.unique()\n```\n\n\n\n\n    array(['Abruzzo', 'Acre', 'Alagoas', 'Amapa', 'Amazonas', 'Bahia',\n           'Basilicata', 'Calabria', 'Campania', 'Ceara', 'Distrito Federal',\n           'Emilia-Romagna', 'Espirito Santo', 'Friuli Venezia Giulia',\n           'Goias', 'Lazio', 'Liguria', 'Lombardia', 'Maranhao', 'Marche',\n           'Mato Grosso', 'Mato Grosso Do Sul', 'Minas Gerais', 'Molise',\n           'P.A. Bolzano', 'P.A. Trento', 'Para', 'Paraiba', 'Parana',\n           'Pernambuco', 'Piaui', 'Piemonte', 'Puglia', 'Rio De Janeiro',\n           'Rio Grande Do Norte', 'Rio Grande Do Sul', 'Rondonia', 'Roraima',\n           'Santa Catarina', 'Sao Paulo', 'Sardegna', 'Sergipe', 'Sicilia',\n           'Tocantins', 'Toscana', 'Umbria', \"Valle d'Aosta\", 'Veneto'],\n          dtype=object)\n\n\n\n\n```python\n'Each region has {} dates in the dataset'.format(bf.date.unique().size)\n```\n\n\n\n\n    'Each region has 202 dates in the dataset'\n\n\n\n\n```python\n\"\"\"Thus, there are {:,.0f} rows in the dataset, with one row for each unique `region_id`-`date` combination\"\"\" \\\n.format(bf.date.shape[0])\n```\n\n\n\n\n    'Thus, there are 65,650 rows in the dataset, with one row for each unique `region_id`-`date` combination'\n\n\n\n\n```python\n\"\"\"There are currently {} columns in the dataset, most of which are observable factors\"\"\".format(bf.columns.size)\n```\n\n\n\n\n    'There are currently 132 columns in the dataset, most of which are observable factors'\n\n\n\nThe factors can be seen as split between two types:\n* **Time-static** factors, i.e. do not change by the date. \n    * population, density, population demographic ranges, cause of death outcomes, travel popularity\n\n* **Time-dynamic** factors, i.e. change with each date. \n    * fatalities, climate, pollution, mobility, and the Oxford stringency index\n\nThey can be found as follows:\n\n\n```python\nny = bf[bf.region_name == 'New York']\n\nstatic = []\ndynamic = []\nfor col in ny.columns:\n    if ny[col].unique().size > 1:\n        dynamic.append(col)\n    else:\n        static.append(col)\n\nbold = '\\033[1m'\nend = '\\033[0m'\nprint ('{}***STATIC***{}\\n'.format(bold, end), static)\nprint ('\\n')\nprint ('{}***DYNAMIC***{}\\n'.format(bold, end), dynamic)\n```\n\n    \u001b[1m***STATIC***\u001b[0m\n     ['region_id', 'country_id', 'region_code', 'region_name', 'country_code', 'country', 'population', 'land_KM2', 'land_dens', 'city_KM2', 'city_dens', 'A00_04B', 'A05_09B', 'A10_14B', 'A15_19B', 'A20_24B', 'A25_29B', 'A30_34B', 'A35_39B', 'A40_44B', 'A45_49B', 'A50_54B', 'A55_59B', 'A60_64B', 'A65_69B', 'A70_74B', 'A75_79B', 'A80_84B', 'A09UNDERB', 'A14UNDERB', 'A19UNDERB', 'A24UNDERB', 'A29UNDERB', 'A34UNDERB', 'A65PLUSB', 'A70PLUSB', 'A75PLUSB', 'A80PLUSB', 'A85PLUSB', 'A05_19B', 'A05_24B', 'A05_29B', 'A05_34B', 'A15_24B', 'A15_29B', 'A15_34B', 'A20_29B', 'A20_34B', 'A35_54B', 'A40_54B', 'A45_54B', 'A35_64B', 'A40_64B', 'A45_64B', 'pm10', 'precipitation', 'wd', 'uvi', 'aqi', 'pol', 'mepaqi', 'pm1', 'e3', 'e4', 'h4', 'h5', 'transit_apple', 'walking_apple', 'year', 'neoplasms', 'blood', 'endo', 'mental', 'nervous', 'circul', 'infectious', 'respir', 'digest', 'skin', 'musculo', 'genito', 'childbirth', 'perinatal', 'congenital', 'other', 'external', 'visitors', 'travel_year', 'gdp', 'gdp_year']\n\n\n    \u001b[1m***DYNAMIC***\u001b[0m\n     ['date', 'cases', 'deaths', 'tests', 'co', 'dew', 'humidity', 'no2', 'o3', 'pm25', 'pressure', 'so2', 'temperature', 'wind gust', 'wind speed', 'wind-gust', 'wind-speed', 'temp', 'dewpoint', 'uvb', 'rhum', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'e1', 'e2', 'h1', 'h2', 'h3', 'strindex', 'retail_n_rec', 'groc_n_pharm', 'parks', 'transit', 'workplaces', 'residential', 'driving_apple']\n\n\n\n```python\n'The entire set has {:,.0f} different data points'.format(bf.size)\n```\n\n\n\n\n    'The entire set has 8,665,800 different data points'\n\n\n\n<h2><a id='section3.3'>3.3 The Testset</a></h2>\n\nA separate dataset, referred to as the `testset`, is housed in the `see19` repo in the `testset` folder.\nThe `testset` will include new data (either additional factors or new regions) that has not yet been incorporated in the `see19` interface. The goal is to integrate the new data into the interface over time. The `testset` will be update concurrently with the main dataset on an adhoc basis.\n\nThe existing `see19` package is ***NOT*** be compatiable with the `testset`, **HOWEVER** you can download the `testset` via `get_baseframe` by setting `test=True`.\n\nSee the `readme` for additional data currently available in the `testset`.\n\n\n```python\nbf_test = get_baseframe(test=True)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Find latest testset...', layout=Layout(flex='2'), max=3.0\u2026\n\n\n<h2><a id='section3.4'>3.4 Disclaimer</a></h2>\n\nI have said before and it bears repeating: **This is an imperfect dataset.** Specific problems are highlighted here.\n\n**GENERAL ISSUES**\n* Not all factors have available measurements for each region or each date.\n    * These are typically expressed as `NaN`\n\n* Some factors are available at regional levels while others are not\n    * Measurements for a region are often compared to other measurements at the country level. This isn't necessarily problematic ... for large geographic and populous countries like the US, it is likely better that state-level data is used to compare to other smaller countries.\n    * State-level measurements are often estimate by mixing separate data sources. For instance, Visitor data for the provinces of Brazil was estimated by taking the country-level data from the World Tourism Organization and weighting it by the province's proportionate share in visitor travel from separate data from the Brazilian government.\n* Some data is outdated.\n    * GDP data lags signficantly particularly for large groups of countries, so 2016 figures have been used, presuming that the relative mix among countries has remained constant\n\n**DENSITY**\n\nPopulation density is oft-cited as a potential explanatory factor in COVID19 infection rates. And I couldn't agree more that it is important to consider. However, the study of density suffers from many issues.\n\n\n* Denisty is highly variable within regions. And case and fatality rates have been highly variable within regions and across densities. In New York City, for example, some of the least dense regions have had the highest infection rates.\n\n* With only regional data available, to be rigourous the safest option is to simple choose the density of the region. However, this is often a poor reflection of reality. New York State actually has signficant land mass despite most of its population residing on a tiny island on the southeastern edge.\n\n* To account for this, See19 includes a factor `city_dens`. `city_dens` is the density of the largest city in the region, so :\n    * for New York State, `city_dens` is the density of New York City,\n    * for Taiwan, `city_dens` is the density of Taipei, \n    * for Japan, `city_dens` is the density of Tokyo, and so on.\n\n    This approach results in its own issues. For instance, at present, for all of Russia, `city_dens` reflects the density of Moscow.\n\nOther geographic measurements, such as `temperature` and `uvb radiation` suffer from similar issues.\n\n\nThe only true way to address these shortcomings is for ***daily*** case and fatality statistics to be released at the county-level (or equivalent) in every country around the globe.\n\n**CASE DATA**\n\nAside from just the difficulties of aggregating data, there are well-documented issues with the underlying case and fatality counts as well.\n\n\n* Confirmed cases are likely well below actual cases given up to 50% of all COVID19 cases may be asymptomatic and limited testing in the early stages led to many symptomatic cases going unreported.\n\n\n* The rapid improvement in testing likely exaggerated the growth of infections over time\n\n\n* Fatalities were unreported at peak periods due to lack of health care capacity\n\n\n* Fatalities have been retroactively added to data, without adjusting back to the days the fatalities actually occured, so for regions like Hubei and New York state, there are massive spikes in fatalities that don't reflect the actual experience.\n\n\n* China has been heavily criticized for under-reporting, late-reporting, and recently added ~20% increase in cumulative fatalities on a random day in March. For these reasons, throughout this tutorial, you will see that China is often excluded from the dataset.\n\n\n**TESTING**\n\nTesting statistics are still a bit of a mess internationally. For instance, many European countries only report cumulative test counts on a weekly basis and many have only begun reporting in the vary recent past. Different methods of interpolation are available in the `CaseStudy` interface.\n\n* ***Brazil*** is not currently included in `tests` data. Brazil test counts are only currently available on the country level whereas case and fatality data is available on a regional level. Methods are being considered to allocate aggregate tests among the regions (perhaps simply as percentage of population or cases counts).\n\n\n\n<h1><a id='section4'>4. the Casestudy Interface</a></h1>\n\n4.1 [Basics](#section4.1)  \n4.2 [Filtering](#section4.2)  \n4.3 [Smoothing](#section4.3)  \n4.4 [Available Factors](#section4.4)  \n4.5 [Additional Flags](#section4.5)    \n4.6 [RayStudy v BaseStudy](#section4.6)    \n4.7 [Chart Objects](#section4.7)\n\nSee19 Visualization and Data analysis is completed via the `CaseStudy` class. `CaseStudy` provides attributes and methods for filtering, manipulating, appending, and visualizing data in the baseframe.\n\n`CaseStudy` can be accessed directly from the `see19` module. To initialize, simply pass the baseframe.\n\n\n```python\n# from see19 import CaseStudy\nfrom casestudy.see19.see19 import CaseStudy\ncasestudy = CaseStudy(bf)\n```\n\n<h2><a id='section4.1'>4.1 Basics</a></h2>\n\nThe original baseframe can be accessed via the `baseframe` attribute\n\n\n```python\ncasestudy.baseframe.head(2)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>genito</th>\n      <th>childbirth</th>\n      <th>perinatal</th>\n      <th>congenital</th>\n      <th>other</th>\n      <th>external</th>\n      <th>visitors</th>\n      <th>travel_year</th>\n      <th>gdp</th>\n      <th>gdp_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>282</td>\n      <td>110</td>\n      <td>ABR</td>\n      <td>Abruzzo</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-01-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>442.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n      <td>19.0</td>\n      <td>384.0</td>\n      <td>2059</td>\n      <td>181458.0</td>\n      <td>2017.0</td>\n      <td>4.560860e+10</td>\n      <td>2016.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>282</td>\n      <td>110</td>\n      <td>ABR</td>\n      <td>Abruzzo</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>442.0</td>\n      <td>1.0</td>\n      <td>16.0</td>\n      <td>19.0</td>\n      <td>384.0</td>\n      <td>2059</td>\n      <td>181458.0</td>\n      <td>2017.0</td>\n      <td>4.560860e+10</td>\n      <td>2016.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 132 columns</p>\n</div>\n\n\n\n`CaseStudy` automatically computes different adjustments including:\n\n1. Daily new cases, fatalities, and tests (called `count_types`)\n2. Daily Moving Average (DMA) for new and cumulative count_types\n3. Population and density adjustments for new and cumulative count_types\n4. Daily growth or change in 1. thru 3. above\n\nThese adjustments are referred to as `count_categories`. Additional adjustments are available via kwargs to be discussed below.\n\nAjustments are added to the dataset by calling the `make` method. The amended dataset is the accessible via the `df` attribute.\n\n\n```python\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=502.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\nThe amended dataframe can be accessed via the `df` attribute:\n\n\n```python\ncasestudy.df.head(2)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>growth_cases_per_person_per_city_KM2</th>\n      <th>growth_deaths_per_1K</th>\n      <th>growth_deaths_per_1M</th>\n      <th>growth_deaths_per_person_per_land_KM2</th>\n      <th>growth_deaths_per_person_per_city_KM2</th>\n      <th>growth_tests_per_1K</th>\n      <th>growth_tests_per_1M</th>\n      <th>growth_tests_per_person_per_land_KM2</th>\n      <th>growth_tests_per_person_per_city_KM2</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43906</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-13</td>\n      <td>216.699585</td>\n      <td>1.87999</td>\n      <td>803.712436</td>\n      <td>...</td>\n      <td>1.523364</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.426644</td>\n      <td>1.426644</td>\n      <td>1.426644</td>\n      <td>1.426644</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-14</td>\n      <td>273.865733</td>\n      <td>1.87999</td>\n      <td>955.714788</td>\n      <td>...</td>\n      <td>1.263804</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.189125</td>\n      <td>1.189125</td>\n      <td>1.189125</td>\n      <td>1.189125</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 140 columns</p>\n</div>\n\n\n\n*NOTE: [Ray](https://docs.ray.io/en/master/) and [Numba](https://numba.pydata.org/) are utilized to significantly improve the speed of `make`. Ray is not compatible with Windows. `CaseStudy` will attempt to detect incompatibility and revert to a single-process method where applicable.*\n\n*More in [Section 4.5](#section4.5)*\n\nFor ease of selection, `CaseStudy` has a number of class attributes with different groupings of count categories: `BASECOUNT_CATS`, `PER_CATS`, `LOGNAT_CATS`, `LOG_CATS`, `ALL_CATS`, `DMA_COUNT_CATS`, `PER_COUNT_CATS`.\n\n`DMA_COUNT_CATS` is shown as an example:\n\n\n```python\nCaseStudy.DMA_COUNT_CATS[:10]\n```\n\n\n\n\n    ['cases_dma',\n     'cases_new_dma',\n     'deaths_dma',\n     'deaths_new_dma',\n     'tests_dma',\n     'tests_new_dma',\n     'cases_dma_per_1K',\n     'cases_dma_per_1M',\n     'cases_dma_per_person_per_land_KM2',\n     'cases_dma_per_person_per_city_KM2']\n\n\n\nBoth the log10 and natural of each of 1. thru 3. above are available for presentation purposes. Simply provide `log=True` and/or `lognat=True` and/or .\n\n\n```python\ncasestudy.log = True\ncasestudy.lognat = True\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=502.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n```python\ncasestudy.df[['region_name', 'date'] + [col for col in casestudy.df if 'log' in col]].head(2)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_name</th>\n      <th>date</th>\n      <th>cases_dma_log</th>\n      <th>cases_new_log</th>\n      <th>cases_new_dma_log</th>\n      <th>deaths_dma_log</th>\n      <th>deaths_new_log</th>\n      <th>deaths_new_dma_log</th>\n      <th>tests_dma_log</th>\n      <th>tests_new_log</th>\n      <th>...</th>\n      <th>growth_cases_per_person_per_land_KM2_lognat</th>\n      <th>growth_cases_per_person_per_city_KM2_lognat</th>\n      <th>growth_deaths_per_1K_lognat</th>\n      <th>growth_deaths_per_1M_lognat</th>\n      <th>growth_deaths_per_person_per_land_KM2_lognat</th>\n      <th>growth_deaths_per_person_per_city_KM2_lognat</th>\n      <th>growth_tests_per_1K_lognat</th>\n      <th>growth_tests_per_1M_lognat</th>\n      <th>growth_tests_per_person_per_land_KM2_lognat</th>\n      <th>growth_tests_per_person_per_city_KM2_lognat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43906</th>\n      <td>P.A. Trento</td>\n      <td>2020-03-13</td>\n      <td>2.186879</td>\n      <td>1.871859</td>\n      <td>1.691872</td>\n      <td>-0.026874</td>\n      <td>-0.026874</td>\n      <td>-0.202966</td>\n      <td>2.794193</td>\n      <td>2.380851</td>\n      <td>...</td>\n      <td>-1.014299</td>\n      <td>-1.014299</td>\n      <td>0.890089</td>\n      <td>2.152714</td>\n      <td>0.867427</td>\n      <td>0.867427</td>\n      <td>4.976355</td>\n      <td>1.050782</td>\n      <td>1.304384</td>\n      <td>1.304384</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>P.A. Trento</td>\n      <td>2020-03-14</td>\n      <td>2.324156</td>\n      <td>1.757139</td>\n      <td>1.757139</td>\n      <td>0.194974</td>\n      <td>NaN</td>\n      <td>-0.202966</td>\n      <td>2.888888</td>\n      <td>2.181850</td>\n      <td>...</td>\n      <td>2.104604</td>\n      <td>2.104604</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.389530</td>\n      <td>1.023559</td>\n      <td>1.113758</td>\n      <td>1.113758</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 242 columns</p>\n</div>\n\n\n\n\n```python\n'In total, there are {} different `count_categories` to choose from.'.format(len(CaseStudy.ALL_COUNT_CATS))\n```\n\n\n\n\n    'In total, there are 180 different `count_categories` to choose from.'\n\n\n\n<h2><a id='section4.2'>4.2 Filtering</a></h2>\n\nThankfully, `casestudy.df` can be limited to specific count categories via the `count_categories` attribute:\n\n\n```python\ncasestudy.count_categories = ['tests_new_dma_per_person_per_land_KM2']\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=502.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>population</th>\n      <th>land_KM2</th>\n      <th>land_dens</th>\n      <th>city_KM2</th>\n      <th>city_dens</th>\n      <th>tests_new_dma_per_person_per_land_KM2</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43906</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-13</td>\n      <td>216.699585</td>\n      <td>1.87999</td>\n      <td>803.712436</td>\n      <td>515201.0</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>0.807438</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-14</td>\n      <td>273.865733</td>\n      <td>1.87999</td>\n      <td>955.714788</td>\n      <td>515201.0</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>0.865241</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n*When passing kwargs to CaseStudy at initialization, most kwargs will accept either a string for a single category or a list (or other iterable) for multiple. When assigning to an instance attribute, an interable must be passed*\n\n\n```python\ncasestudy = CaseStudy(bf, count_categories='tests_new_dma_per_person_per_land_KM2')\ncasestudy.make()\ncasestudy.df[['region_name', 'date', 'tests_new_dma_per_person_per_land_KM2']].head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=502.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_name</th>\n      <th>date</th>\n      <th>tests_new_dma_per_person_per_land_KM2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43906</th>\n      <td>P.A. Trento</td>\n      <td>2020-03-13</td>\n      <td>0.807438</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>P.A. Trento</td>\n      <td>2020-03-14</td>\n      <td>0.865241</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n\n```python\ncasestudy.count_categories = ['deaths_new_dma_per_person_per_land_KM2', 'growth_cases_new_per_1M']\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=502.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>population</th>\n      <th>land_KM2</th>\n      <th>land_dens</th>\n      <th>city_KM2</th>\n      <th>city_dens</th>\n      <th>deaths_new_dma_per_person_per_land_KM2</th>\n      <th>growth_cases_new_per_1M</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43906</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-13</td>\n      <td>216.699585</td>\n      <td>1.87999</td>\n      <td>803.712436</td>\n      <td>515201.0</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>0.003575</td>\n      <td>1.866667</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>43907</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-14</td>\n      <td>273.865733</td>\n      <td>1.87999</td>\n      <td>955.714788</td>\n      <td>515201.0</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>0.003575</td>\n      <td>0.767857</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n`CaseStudy` can further filter `baseframe` as follows:\n\n* `regions` to limit the frame to certain regions\n* `countries` to limit the frame to certain countries\n* `exclude_regions` to exclude certain regions\n* `exclude_countries` to exclude certain countries\n\nSpecific regions can be included or excluded by providing the `region_name`, `region_code`, or `region_id`.\nSpecific countries can be included or excluded by providing the `country`, `country_code`, or `country_id`.\n\nEach of the four parameters can accept a single region as a `str` object or multiple regions via several common iterables.\n\nBelow we select three regions:\n\n\n```python\nregions = ['New York', 'FL', 35]\ncasestudy = CaseStudy(\n    bf, regions=regions, count_categories=CaseStudy.BASECOUNT_CATS, \n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=5.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))\n\n\nWe can see that all three regions are indeed in the object by grouping:\n\n\n```python\npd.concat([df_group.iloc[:1] for region_id, df_group in casestudy.df.groupby('region_id')]).head(3)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>cases_dma</th>\n      <th>cases_new</th>\n      <th>cases_new_dma</th>\n      <th>deaths_dma</th>\n      <th>deaths_new</th>\n      <th>deaths_new_dma</th>\n      <th>tests_dma</th>\n      <th>tests_new</th>\n      <th>tests_new_dma</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53399</th>\n      <td>35</td>\n      <td>110</td>\n      <td>SIC</td>\n      <td>Sicilia</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-12</td>\n      <td>102.712067</td>\n      <td>2.000000</td>\n      <td>973.321711</td>\n      <td>...</td>\n      <td>77.406196</td>\n      <td>28.580749</td>\n      <td>15.778955</td>\n      <td>0.666667</td>\n      <td>2.000000</td>\n      <td>0.666667</td>\n      <td>796.493912</td>\n      <td>186.492921</td>\n      <td>140.803254</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>17846</th>\n      <td>64</td>\n      <td>236</td>\n      <td>FL</td>\n      <td>Florida</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-03-11</td>\n      <td>28.000000</td>\n      <td>2.526828</td>\n      <td>329.000000</td>\n      <td>...</td>\n      <td>21.666667</td>\n      <td>9.000000</td>\n      <td>3.666667</td>\n      <td>0.842276</td>\n      <td>2.526828</td>\n      <td>0.842276</td>\n      <td>242.666667</td>\n      <td>88.000000</td>\n      <td>64.666667</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>40070</th>\n      <td>75</td>\n      <td>236</td>\n      <td>NY</td>\n      <td>New York</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-03-15</td>\n      <td>729.000000</td>\n      <td>3.143533</td>\n      <td>6916.080830</td>\n      <td>...</td>\n      <td>558.000000</td>\n      <td>205.000000</td>\n      <td>171.000000</td>\n      <td>1.047844</td>\n      <td>3.143533</td>\n      <td>1.047844</td>\n      <td>5149.016931</td>\n      <td>2583.035500</td>\n      <td>2170.676861</td>\n      <td>0 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows \u00d7 25 columns</p>\n</div>\n\n\n\nThe region and country filters are important mechanisms for isolating data.\n\nHere, we focus on US regions only, but exclude some of the most impacted ones:\n\n\n```python\ncasestudy.countries = ['USA']\ncasestudy.excluded_regions = ['NY', 'NJ']\ncasestudy.regions = None\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=120.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))\n\n\n*Because certain regions were assigned in the previous CaseStudy instantiation, we must set `regions=None` above in order to ask ALL the regions of the baseframe.*\n\nAnd below we can see that we have various US states in the dataset and that New York or New Jersey are *not* included.\n\n\n```python\ncasestudy.df.region_name.unique()\n```\n\n\n\n\n    array(['Alabama', 'Wyoming', 'Alaska', 'Arkansas', 'Delaware', 'Idaho',\n           'Maine', 'Mississippi', 'Montana', 'New Mexico', 'North Dakota',\n           'South Dakota', 'West Virginia', 'Michigan', 'Vermont', 'Georgia',\n           'Colorado', 'Florida', 'Oregon', 'Texas', 'Illinois',\n           'Pennsylvania', 'Iowa', 'Maryland', 'North Carolina', 'Washington',\n           'California', 'Massachusetts', 'Oklahoma', 'Arizona',\n           'Connecticut', 'Minnesota', 'Virginia', 'New Hampshire', 'Hawaii',\n           'Nevada', 'Indiana', 'Kentucky', 'District of Columbia',\n           'Missouri', 'Louisiana', 'Ohio', 'Wisconsin', 'Kansas', 'Utah',\n           'Tennessee', 'South Carolina', 'Nebraska'], dtype=object)\n\n\n\n\n```python\npd.concat([df_group.iloc[:1] for region_id, df_group in casestudy.df.groupby('region_id')]).head(3)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>cases_dma</th>\n      <th>cases_new</th>\n      <th>cases_new_dma</th>\n      <th>deaths_dma</th>\n      <th>deaths_new</th>\n      <th>deaths_new_dma</th>\n      <th>tests_dma</th>\n      <th>tests_new</th>\n      <th>tests_new_dma</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>691</th>\n      <td>44</td>\n      <td>236</td>\n      <td>AL</td>\n      <td>Alabama</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-03-26</td>\n      <td>558.514091</td>\n      <td>1.26695</td>\n      <td>10468.861581</td>\n      <td>...</td>\n      <td>369.399307</td>\n      <td>246.143562</td>\n      <td>124.727455</td>\n      <td>0.422317</td>\n      <td>1.26695</td>\n      <td>0.422317</td>\n      <td>7859.521030</td>\n      <td>3287.002892</td>\n      <td>1929.975539</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>64339</th>\n      <td>48</td>\n      <td>236</td>\n      <td>WY</td>\n      <td>Wyoming</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-04-13</td>\n      <td>316.114653</td>\n      <td>1.00000</td>\n      <td>9715.352851</td>\n      <td>...</td>\n      <td>305.385913</td>\n      <td>16.093110</td>\n      <td>8.429724</td>\n      <td>0.333333</td>\n      <td>1.00000</td>\n      <td>0.333333</td>\n      <td>9166.923029</td>\n      <td>822.644733</td>\n      <td>529.424828</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>1094</th>\n      <td>49</td>\n      <td>236</td>\n      <td>AK</td>\n      <td>Alaska</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-03-25</td>\n      <td>53.977249</td>\n      <td>1.00000</td>\n      <td>3783.772189</td>\n      <td>...</td>\n      <td>42.839087</td>\n      <td>7.711036</td>\n      <td>8.567817</td>\n      <td>0.333333</td>\n      <td>1.00000</td>\n      <td>0.333333</td>\n      <td>2745.528371</td>\n      <td>1496.950677</td>\n      <td>539.260259</td>\n      <td>0 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows \u00d7 25 columns</p>\n</div>\n\n\n\n\n```python\ncasestudy.df[casestudy.df.region_name.isin(['NY', 'NJ'])]\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>cases_dma</th>\n      <th>cases_new</th>\n      <th>cases_new_dma</th>\n      <th>deaths_dma</th>\n      <th>deaths_new</th>\n      <th>deaths_new_dma</th>\n      <th>tests_dma</th>\n      <th>tests_new</th>\n      <th>tests_new_dma</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows \u00d7 25 columns</p>\n</div>\n\n\n\n### Limiting data via different start and tail hurdles\n\nParameters exist that allow you to filter the dataset such that regions and days appear only if they meet certain criteria.\n\n`start_factor` and `start_hurdle` provide the ability to effectively *crop* the beginning of region's period of data.\n\n`tail_factor` and `tail_hurdle` do the same for the end of a region's period.\n\n`start_factor` and `tail_factor` accept any *dynamic* factor in the dataset (including `date`).\n\nThe `hurdle` is the level of the specified factor the region must reach to be included. For instance, if `start_factor=cases_new_per_1M` and `start_hurdle=100`, each region's first row in `casestudy.df` will be the day that the region met or exceeded **100 new cases per 1 million people**.\n\nThese options are a convenient way to compare regions that have been impacted to a similar extent or, perhaps, to fairly compare regions that were impacted at different times.\n\nThe default parameters for `start_factor` and `start_hurdle` limit the data to regions with at least one cumulative fatality.\n\n**NOTE**: a `days` column is added to `casestudy.df`. This is a count of the number of days from the current date back to the first date in the casestudy.  When a `start_factor` is provided, this is the first date that the `start_hurdle` is met. When `start_factor` is not provided, this is the first date in the dataset.\n\nExamples are show below.\n\n\n```python\ncasestudy = CaseStudy(\n    bf, regions='Spain', count_categories=CaseStudy.BASECOUNT_CATS, \n    start_factor='cases', start_hurdle=1000\n)\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>cases_dma</th>\n      <th>cases_new</th>\n      <th>cases_new_dma</th>\n      <th>deaths_dma</th>\n      <th>deaths_new</th>\n      <th>deaths_new_dma</th>\n      <th>tests_dma</th>\n      <th>tests_new</th>\n      <th>tests_new_dma</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55820</th>\n      <td>491</td>\n      <td>209</td>\n      <td>ESP</td>\n      <td>Spain</td>\n      <td>ESP</td>\n      <td>Spain</td>\n      <td>2020-03-09</td>\n      <td>1057.840245</td>\n      <td>27.344784</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>738.089217</td>\n      <td>394.348647</td>\n      <td>221.163866</td>\n      <td>17.904323</td>\n      <td>10.742594</td>\n      <td>7.487262</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>55821</th>\n      <td>491</td>\n      <td>209</td>\n      <td>ESP</td>\n      <td>Spain</td>\n      <td>ESP</td>\n      <td>Spain</td>\n      <td>2020-03-10</td>\n      <td>1671.052390</td>\n      <td>34.180981</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1130.794744</td>\n      <td>613.212146</td>\n      <td>392.705527</td>\n      <td>26.042652</td>\n      <td>6.836196</td>\n      <td>8.138329</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 25 columns</p>\n</div>\n\n\n\n\n```python\ncasestudy = CaseStudy(\n    bf, countries='Sweden', \n    count_categories='deaths_new', start_factor='deaths_new', start_hurdle=100\n)\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>population</th>\n      <th>land_KM2</th>\n      <th>land_dens</th>\n      <th>city_KM2</th>\n      <th>city_dens</th>\n      <th>deaths_new</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>56656</th>\n      <td>495</td>\n      <td>214</td>\n      <td>SWE</td>\n      <td>Sweden</td>\n      <td>SWE</td>\n      <td>Sweden</td>\n      <td>2020-04-06</td>\n      <td>7438.936775</td>\n      <td>675.770207</td>\n      <td>NaN</td>\n      <td>9415570.0</td>\n      <td>415314.854224</td>\n      <td>22.67092</td>\n      <td>2150.411192</td>\n      <td>4378.497486</td>\n      <td>107.669886</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>56657</th>\n      <td>495</td>\n      <td>214</td>\n      <td>SWE</td>\n      <td>Sweden</td>\n      <td>SWE</td>\n      <td>Sweden</td>\n      <td>2020-04-07</td>\n      <td>7941.679240</td>\n      <td>837.275037</td>\n      <td>NaN</td>\n      <td>9415570.0</td>\n      <td>415314.854224</td>\n      <td>22.67092</td>\n      <td>2150.411192</td>\n      <td>4378.497486</td>\n      <td>161.504829</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nTo see the earliest dates in the dataframe, prior to any deaths being recorded, set `start_factor` to `''`.\n\n\n```python\ncasestudy.countries = None\ncasestudy.regions = ['RJ']\ncasestudy.count_categories = ['tests_new_dma']\ncasestudy.factors = ['temp', 'strindex']\ncasestudy.start_factor = ''\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=3.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>population</th>\n      <th>land_KM2</th>\n      <th>land_dens</th>\n      <th>city_KM2</th>\n      <th>city_dens</th>\n      <th>tests_new_dma</th>\n      <th>temp</th>\n      <th>strindex</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48480</th>\n      <td>557</td>\n      <td>31</td>\n      <td>RJ</td>\n      <td>Rio De Janeiro</td>\n      <td>BRA</td>\n      <td>Brazil</td>\n      <td>2020-01-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15962668.0</td>\n      <td>42269.311478</td>\n      <td>377.642016</td>\n      <td>2203.766328</td>\n      <td>7243.357792</td>\n      <td>NaN</td>\n      <td>294.134674</td>\n      <td>0.0</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>48481</th>\n      <td>557</td>\n      <td>31</td>\n      <td>RJ</td>\n      <td>Rio De Janeiro</td>\n      <td>BRA</td>\n      <td>Brazil</td>\n      <td>2020-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15962668.0</td>\n      <td>42269.311478</td>\n      <td>377.642016</td>\n      <td>2203.766328</td>\n      <td>7243.357792</td>\n      <td>NaN</td>\n      <td>294.375153</td>\n      <td>0.0</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n<h2><a id='section4.3'>4.3 Smoothing</a></h2>\n\nSmoothing is applied two ways within the `make` method.\n\nThe first addresses NaN values within the `count_type` time-series. Sometimes there are artifacts and one-offs within the set. Other times, as with `test` counts in many regions, the count is only update periodically and NaNs fill the gaps.\n\nIn these instances, `make` interpolates between the real values to fill in the gaps. The default method is linear interpolation, but this can be overriden by providing `interpolation_method` (see Pandas docs for options).\n\nFor instance, below we see that **Spain** testing data as follows:\n\n\n```python\ncasestudy = CaseStudy(bf, regions='Spain')\ncasestudy.make()\ncasestudy.df.tests.tail(20)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=3.0, st\u2026\n\n\n    2020-08-02 06:17:58,268\tINFO resource_spec.py:212 -- Starting Ray with 12.84 GiB memory available for workers and up to 6.44 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n    2020-08-02 06:17:58,495\tWARNING services.py:923 -- Redis failed to start, retrying now.\n    2020-08-02 06:17:58,792\tINFO services.py:1165 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n    55934    3.619554e+06\n    55935    3.644458e+06\n    55936    3.673778e+06\n    55937    3.703099e+06\n    55938    3.732419e+06\n    55939    3.761740e+06\n    55940    3.791060e+06\n    55941    3.820381e+06\n    55942    3.849701e+06\n    55943    3.881696e+06\n    55944    3.913690e+06\n    55945    3.945685e+06\n    55946    3.977680e+06\n    55947    4.009675e+06\n    55948    4.041669e+06\n    55949    4.073664e+06\n    55950    4.073664e+06\n    55951    4.073664e+06\n    55952    4.073664e+06\n    55953    4.073664e+06\n    Name: tests, dtype: float64\n\n\n\nBut when we set `interpolate=Flase`, we can see that in fact Spain updates its testing only weekly.\n\n\n```python\ncasestudy = CaseStudy(bf, regions='Spain', interpolate=False)\ncasestudy.make()\ncasestudy.df.tests.tail(20)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n    55934          NaN\n    55935    3644458.0\n    55936          NaN\n    55937          NaN\n    55938          NaN\n    55939          NaN\n    55940          NaN\n    55941          NaN\n    55942    3849701.0\n    55943          NaN\n    55944          NaN\n    55945          NaN\n    55946          NaN\n    55947          NaN\n    55948          NaN\n    55949    4073664.0\n    55950          NaN\n    55951          NaN\n    55952          NaN\n    55953          NaN\n    Name: tests, dtype: float64\n\n\n\nThe second approach is new in 0.3.6. CaseStudy *automatically applies smoothing* to <ins>negative values</ins> and <ins>large outliers</ins> in the main `count_categories` (cases, deaths, and tests). \n\nMany regions have chosen to \"adjust\" or \"catch up\" their case or fatality counts, not be adjusting the actual dates that the outcome occured, but instead on a seemingly random reporting date. This creates strange artifacts in the time series.\n\nFor example, Spain has dip in daily case counts to the negative in late April 2020:\n\n\n```python\ncasestudy = CaseStudy(bf, regions='Spain', smooth=False)\ncasestudy.make()\ncasestudy.compchart.make(x_category='date', y_category='deaths_new', figsize=(8,4))\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=1.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n    Daily Deaths\n\n\n\n![png](output_71_3.png)\n\n\nWith `smooth=True` (the default setting), this deep negative value is redistributed through prior dates according to the distribution of counts up to the date with the negative value.\n\nThis is a somewhat nieve approach but has the benefit of maintaining a consistent shape to the time-series.\n\n\n```python\ncasestudy = CaseStudy(bf, regions='Spain', smooth=True)\ncasestudy.make()\ncasestudy.compchart.make(x_category='date', y_category='deaths_new', figsize=(8,4))\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n    Daily Deaths\n\n\n\n![png](output_73_4.png)\n\n\nThe same adjustment is made for VERY large increases in counts relative to the cumulative total and to the daily rate. For example, see New York below:\n\n\n```python\ncasestudy = CaseStudy(bf, regions='NY', smooth=False)\ncasestudy.make()\ncasestudy.compchart.make(x_category='date', y_category='deaths_new', figsize=(8,4))\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=1.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n    Daily Deaths\n\n\n\n![png](output_75_3.png)\n\n\n\n```python\ncasestudy = CaseStudy(bf, regions='NY', smooth=True)\ncasestudy.make()\ncasestudy.compchart.make(x_category='date', y_category='deaths_new', figsize=(8,4))\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n    Daily Deaths\n\n\n\n![png](output_76_4.png)\n\n\n<h2><a id='section4.4'>4.4 Available Factors</a></h2>\n\nThe remaining columns in the `baseframe` can be included in a `CaseStudy` instance on an ***opt-in*** basis via the `factors` attribute:\n\n\n```python\ncasestudy = CaseStudy(bf, count_categories='cases_new_per_person_per_land_KM2', factors=['no2', 'strindex'])\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=659.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>population</th>\n      <th>land_KM2</th>\n      <th>land_dens</th>\n      <th>city_KM2</th>\n      <th>city_dens</th>\n      <th>cases_new_per_person_per_land_KM2</th>\n      <th>no2</th>\n      <th>strindex</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43905</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-12</td>\n      <td>131.523112</td>\n      <td>1.096661</td>\n      <td>652.429603</td>\n      <td>515201.0</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>0.210345</td>\n      <td>NaN</td>\n      <td>85.19</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-13</td>\n      <td>200.357639</td>\n      <td>2.193322</td>\n      <td>930.784897</td>\n      <td>515201.0</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>2938.79544</td>\n      <td>175.310262</td>\n      <td>0.392644</td>\n      <td>NaN</td>\n      <td>85.19</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nFor convenience, a number of factor groupings can be accessed via `CaseStudy` attributes:\n\n* `GMOBIS`, `AMOBIS`, `CAUSES`, `MAJOR_CAUSES`, `POLLUTS`, `TEMP_MSMTS`, `MSMTS`\n    * various groupings for factor data\n    * `GMOBIS` refer to Google Mobility data.\n    * `AMOBIS` refer to Apple Mobility data.\n* `STRINDEX_CATS`, `CONTAIN_CATS`, `ECON_CATS`, `HEALTH_CATS`\n    * groupings for the Oxford Stringency Index\n\n\n```python\nprint (CaseStudy.MSMTS)\nprint (CaseStudy.MAJOR_CAUSES)\n```\n\n    ['uvb', 'rhum', 'temp', 'dewpoint']\n    ['circul', 'infectious', 'respir', 'endo']\n\n\nDifferent demographic population age groupings can be accessed as well:\n* `ALL_RANGES` - all the possible demographic age ranges\n* `RANGES` - a dictionary of various groupings of age ranges\n\n\n```python\nfrom see19 import RANGES\nRANGES.keys()\n```\n\n\n\n\n    dict_keys(['UNDERS', 'OVERS', 'SCHOOL_GOERS', 'Y_MILLS', 'MILLS', 'MID', 'MID_PLUS'])\n\n\n\n\n```python\novers = RANGES['OVERS']['ranges']\ncasestudy = CaseStudy(bf, regions='Lombardia', count_categories='deaths_new_per_person_per_land_KM2', factors=overs)\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>A70PLUSB</th>\n      <th>A75PLUSB</th>\n      <th>A80PLUSB</th>\n      <th>A85PLUSB</th>\n      <th>A65PLUSB_%</th>\n      <th>A70PLUSB_%</th>\n      <th>A75PLUSB_%</th>\n      <th>A80PLUSB_%</th>\n      <th>A85PLUSB_%</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31566</th>\n      <td>36</td>\n      <td>110</td>\n      <td>LOM</td>\n      <td>Lombardia</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-02-24</td>\n      <td>216.225177</td>\n      <td>6.0</td>\n      <td>943.732875</td>\n      <td>...</td>\n      <td>1490749.0</td>\n      <td>963768.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.208224</td>\n      <td>0.154784</td>\n      <td>0.100068</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>31567</th>\n      <td>36</td>\n      <td>110</td>\n      <td>LOM</td>\n      <td>Lombardia</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-02-25</td>\n      <td>301.709549</td>\n      <td>9.0</td>\n      <td>2386.747531</td>\n      <td>...</td>\n      <td>1490749.0</td>\n      <td>963768.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.208224</td>\n      <td>0.154784</td>\n      <td>0.100068</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 27 columns</p>\n</div>\n\n\n\n\n```python\ncasestudy = CaseStudy(bf, regions='LOM', count_categories='deaths_new_per_person_per_land_KM2', factors=CaseStudy.MAJOR_CAUSES)\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=2.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>deaths_new_per_person_per_land_KM2</th>\n      <th>circul</th>\n      <th>infectious</th>\n      <th>respir</th>\n      <th>endo</th>\n      <th>circul_%</th>\n      <th>infectious_%</th>\n      <th>respir_%</th>\n      <th>endo_%</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31566</th>\n      <td>36</td>\n      <td>110</td>\n      <td>LOM</td>\n      <td>Lombardia</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-02-24</td>\n      <td>216.225177</td>\n      <td>6.0</td>\n      <td>943.732875</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>74695</td>\n      <td>4630</td>\n      <td>20185</td>\n      <td>6566.0</td>\n      <td>0.007756</td>\n      <td>0.000481</td>\n      <td>0.002096</td>\n      <td>0.000682</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>31567</th>\n      <td>36</td>\n      <td>110</td>\n      <td>LOM</td>\n      <td>Lombardia</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-02-25</td>\n      <td>301.709549</td>\n      <td>9.0</td>\n      <td>2386.747531</td>\n      <td>...</td>\n      <td>0.00507</td>\n      <td>74695</td>\n      <td>4630</td>\n      <td>20185</td>\n      <td>6566.0</td>\n      <td>0.007756</td>\n      <td>0.000481</td>\n      <td>0.002096</td>\n      <td>0.000682</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 25 columns</p>\n</div>\n\n\n\nSome factors are only available at a country level.\n\nBy setting `country_level=True`, `casestudy` will aggregate most data among the subregions up to the country level to allow for proper comparison across the broad range of countries.\n\nThe **Oxford Stringency Index** and its derivatives is one such data group only available at the country level.\n\n\n```python\ncasestudy = CaseStudy(bf, \n    count_categories='deaths_new_per_person_per_land_KM2', \n    factors='strindex',\n    country_level=True,\n)\ncasestudy.make()\ncasestudy.df.tail(2)\n```\n\n    /Users/spindicate/Documents/programming/zooscraper/casestudy/see19/see19/study/ray.py:16: UserWarning: smoothing is unavailable when country_level=True\n      super().__init__(*args, **kwargs)\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=155.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>population</th>\n      <th>land_KM2</th>\n      <th>land_dens</th>\n      <th>city_KM2</th>\n      <th>city_dens</th>\n      <th>deaths_new_per_person_per_land_KM2</th>\n      <th>strindex</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36560</th>\n      <td>id_for_USA</td>\n      <td>236</td>\n      <td>USA</td>\n      <td>name_for_USA</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-07-19</td>\n      <td>3725463.0</td>\n      <td>131737.0</td>\n      <td>45313502.0</td>\n      <td>307692971.0</td>\n      <td>9.087502e+06</td>\n      <td>33.858916</td>\n      <td>710152.024025</td>\n      <td>433.277609</td>\n      <td>15.446448</td>\n      <td>68.98</td>\n      <td>144 days</td>\n    </tr>\n    <tr>\n      <th>36561</th>\n      <td>id_for_USA</td>\n      <td>236</td>\n      <td>USA</td>\n      <td>name_for_USA</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-07-20</td>\n      <td>3782891.0</td>\n      <td>132095.0</td>\n      <td>46043131.0</td>\n      <td>307692971.0</td>\n      <td>9.087502e+06</td>\n      <td>33.858916</td>\n      <td>710152.024025</td>\n      <td>433.277609</td>\n      <td>10.573286</td>\n      <td>68.98</td>\n      <td>145 days</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\nAbove you can see that all US states have been aggregated into a single region with an region_id \n\nWith respect to the `STRINDEX_CATS` subgroups, if all the required categories are provided, `CaseStudy` will sum the individual category values. \n\nFor example, if `CONTAIN_CATS` are provided, the aggregate of the eight categories will be included in the `c_sum` column.\n\nNote if all five `h` indicators are provided, `CaseStudy` will also tabulate a `key3_sum`, which aggregates the scores on the `h1`, `h2`, and `h3` indicators.\n\n\n```python\ncasestudy = CaseStudy(bf, \n    count_categories='deaths_new_per_person_per_land_KM2', \n    factors=CaseStudy.CONTAIN_CATS,\n    country_level=True,\n)\ncasestudy.make()\ncasestudy.df.tail(2)\n```\n\n    /Users/spindicate/Documents/programming/zooscraper/casestudy/see19/see19/study/ray.py:16: UserWarning: smoothing is unavailable when country_level=True\n      super().__init__(*args, **kwargs)\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=155.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c4</th>\n      <th>c5</th>\n      <th>c6</th>\n      <th>c7</th>\n      <th>c8</th>\n      <th>c_sum</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36560</th>\n      <td>id_for_USA</td>\n      <td>236</td>\n      <td>USA</td>\n      <td>name_for_USA</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-07-19</td>\n      <td>3725463.0</td>\n      <td>131737.0</td>\n      <td>45313502.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>19.0</td>\n      <td>144 days</td>\n    </tr>\n    <tr>\n      <th>36561</th>\n      <td>id_for_USA</td>\n      <td>236</td>\n      <td>USA</td>\n      <td>name_for_USA</td>\n      <td>USA</td>\n      <td>United States of America (the)</td>\n      <td>2020-07-20</td>\n      <td>3782891.0</td>\n      <td>132095.0</td>\n      <td>46043131.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>19.0</td>\n      <td>145 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 26 columns</p>\n</div>\n\n\n\nAdditional computations can be added for each factor via the `factor_dmas` attribute. \n\nThe attribute is a dictionary of the form `str(factor_name): int(dma)`. \n\nWhen provided, `CaseStudy` will automatically add `_dma`, `_growth`, and `_growth_dma` computations\n\n\n```python\ncasestudy = CaseStudy(bf, count_categories='deaths_new_dma_per_1M', \n    factors=['temp', 'c1', 'strindex'], \n    factor_dmas={'temp': 7, 'c1': 14},\n    country_level=True,\n)\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n    /Users/spindicate/Documents/programming/zooscraper/casestudy/see19/see19/study/ray.py:16: UserWarning: smoothing is unavailable when country_level=True\n      super().__init__(*args, **kwargs)\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=155.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>temp</th>\n      <th>c1</th>\n      <th>strindex</th>\n      <th>temp_dma</th>\n      <th>temp_growth</th>\n      <th>temp_growth_dma</th>\n      <th>c1_dma</th>\n      <th>c1_growth</th>\n      <th>c1_growth_dma</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>81</th>\n      <td>293</td>\n      <td>1</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>2020-03-22</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>10.778741</td>\n      <td>3.0</td>\n      <td>41.67</td>\n      <td>7.908977</td>\n      <td>1.067747</td>\n      <td>1.384819</td>\n      <td>1.928571</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>293</td>\n      <td>1</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>2020-03-23</td>\n      <td>40.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>8.560785</td>\n      <td>3.0</td>\n      <td>41.67</td>\n      <td>8.784692</td>\n      <td>0.794229</td>\n      <td>1.150845</td>\n      <td>2.142857</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 26 columns</p>\n</div>\n\n\n\n***NOTE: When `country_level=True`, `smooth` is currently <ins>NOT</ins> available as per warning and Ray multi-processing is also <ins>NOT</ins> available.***\n\nTo provide a single dma for all the factors submitted, build the dictionary ahead of time:\n\n\n```python\nfactor_dmas = {msmt: 14 for msmt in CaseStudy.MSMTS}\ncasestudy = CaseStudy(\n    bf, count_categories='tests_new_per_1M', \n    factors=CaseStudy.MSMTS, factor_dmas=factor_dmas\n)\ncasestudy.make()\ncasestudy.df.head(2)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=659.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>country_id</th>\n      <th>region_code</th>\n      <th>region_name</th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>cases</th>\n      <th>deaths</th>\n      <th>tests</th>\n      <th>...</th>\n      <th>rhum_dma</th>\n      <th>rhum_growth</th>\n      <th>rhum_growth_dma</th>\n      <th>temp_dma</th>\n      <th>temp_growth</th>\n      <th>temp_growth_dma</th>\n      <th>dewpoint_dma</th>\n      <th>dewpoint_growth</th>\n      <th>dewpoint_growth_dma</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43905</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-12</td>\n      <td>131.523112</td>\n      <td>1.096661</td>\n      <td>652.429603</td>\n      <td>...</td>\n      <td>90.025840</td>\n      <td>1.050915</td>\n      <td>0.996733</td>\n      <td>3.513738</td>\n      <td>0.959184</td>\n      <td>1.105750</td>\n      <td>-3.142554</td>\n      <td>1.896068</td>\n      <td>-0.635699</td>\n      <td>0 days</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>32</td>\n      <td>110</td>\n      <td>TRE</td>\n      <td>P.A. Trento</td>\n      <td>ITA</td>\n      <td>Italy</td>\n      <td>2020-03-13</td>\n      <td>200.357639</td>\n      <td>2.193322</td>\n      <td>930.784897</td>\n      <td>...</td>\n      <td>89.967379</td>\n      <td>0.995192</td>\n      <td>1.001809</td>\n      <td>3.242550</td>\n      <td>1.053689</td>\n      <td>1.114479</td>\n      <td>-3.447804</td>\n      <td>1.026207</td>\n      <td>-0.735813</td>\n      <td>1 days</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows \u00d7 33 columns</p>\n</div>\n\n\n\nOther factors are adjusted to population. These factors are appended with `_%` and can be seen via the `pop_cats` attribute.\n\nThese are typically time-static factors.\n\n\n```python\ncasestudy = CaseStudy(bf, count_categories='deaths_new_dma_per_1M', factors=['visitors', 'gdp', 'A65PLUSB' ])\nprint (casestudy.pop_cats)\ncasestudy.make()\ncasestudy.df[['region_name', 'date', 'visitors_%', 'gdp_%', 'A65PLUSB_%']].head(2)\n```\n\n    ['A65PLUSB', 'visitors', 'gdp']\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=659.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_name</th>\n      <th>date</th>\n      <th>visitors_%</th>\n      <th>gdp_%</th>\n      <th>A65PLUSB_%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43905</th>\n      <td>P.A. Trento</td>\n      <td>2020-03-12</td>\n      <td>19.864474</td>\n      <td>54504.746691</td>\n      <td>0.203018</td>\n    </tr>\n    <tr>\n      <th>43906</th>\n      <td>P.A. Trento</td>\n      <td>2020-03-13</td>\n      <td>19.864474</td>\n      <td>54504.746691</td>\n      <td>0.203018</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n<h3><a id='section4.5'>4.5 Additional Flags</a></h3>\n\nThere are several additional flags and methods that will be touched on briefly, however, you are encouraged to read the analysis pages to see them in action.\n\n* `world_averages`: when set to `True`, averages each date in the dataset across all the regions, to provide a ***per_region*** statistic for each factor\n\n* `favor_earlier`: when set to `True`, scales any selected rows such that values earlier in the dataset receive more weight than later ones. A new column is added with the `_earlier` suffix. This is helpful when attempting to study the impacts of early moves to, say, social distance. Factors are selected by passing a list to the `factors_to_favor_earlier` parameter.\n\n<h3><a id='section4.6'>4.6 RayStudy v BaseStudy</a></h3>\n\nThe default implementation of `make` utilizes both [Ray](https://docs.ray.io/en/master/) and [Numba](https://numba.pydata.org/) to significantly improve the performance. \n\nRay is a 3rd party multi-processing package. For see19 purposes, Ray's key feature is the ability to share (albeit read-only) large objects among different live processes. Python's standard multi-processing module does not allow for simple access to the baseframe and, therefore, did not provide any performance benefits. \n\nNumba provides just-in-time compiling of certain numpy implementations. The custom Numba function typically provides 10x speed improvement versus the same built-in Pandas method.\n\nRay is not compatible with Windows. `CaseStudy` will attempt to detect incompatibility and revert to a single-process method where necessary.*\n\nTo support this, a root `BaseStudy` implementation provides single process functionality and a `RayStudy` child that implements Ray functionality. `CaseStudy` inherits from either class automatically based on operating system.\n\nYou can see which class is inherited as per below (this is on a Macbook)\n\n\n```python\nCaseStudy.__bases__\n```\n\n\n\n\n    (casestudy.see19.see19.study.ray.RayStudy,)\n\n\n\nTo use the non-Ray implementation, you can either import `BaseStudy` directly or set `use_ray=False` on `CaseStudy`.\n\nWe can see both approaches provide similar results below.\n\n\n```python\n# from see19.study.base import BaseStudy\nfrom casestudy.see19.see19.study.base import BaseStudy\nfrom datetime import datetime as dt\n```\n\n\n```python\ndef clockwrap(func):\n    def wrapper(*args, **kwargs):\n        start = dt.now()\n        func()\n        end = dt.now()\n\n        return end - start\n\n    return wrapper()\n```\n\n\n```python\ncasestudy = BaseStudy(bf)\ndur1 = clockwrap(casestudy.make)\nprint (dur1)\n```\n\n    /Users/spindicate/Documents/programming/envs/zooenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: It looks like you called BaseStudy directly. This is not recommended. Ray provides significant performance improvements and certain BaseStudy methods are not optimized.\n      \"\"\"Entry point for launching an IPython kernel.\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=537.0), HTML(value='')))\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=298.0), HTML(value='')))\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n    0:00:28.674439\n\n\n\n```python\ncasestudy = CaseStudy(bf, use_ray=False)\ndur2 = clockwrap(casestudy.make)\nprint (dur2)\n```\n\n    /Users/spindicate/Documents/programming/envs/zooenv/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: use_ray set to False. This is not recommended. Ray provides significant performance improvements and certain BaseStudy methods are not optimized.\n      \"\"\"Entry point for launching an IPython kernel.\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=537.0), HTML(value='')))\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=298.0), HTML(value='')))\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n    0:00:27.573194\n\n\nNow we'll compare that with the default Ray implemenation on an 8-core MacBook Pro.\n\n\n```python\ncasestudy = CaseStudy(bf)\ndur3 = clockwrap(casestudy.make)\nprint (dur3)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=659.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))\n\n\n    0:00:06.225569\n\n\n\n```python\ndiff = 1 - dur3 / (np.mean([dur1, dur2]))\nprint ('You can see that the Ray implementation is \\033[4m\\033[1m{:.2%}\\033[0m faster.'.format(diff))\n```\n\n    You can see that the Ray implementation is \u001b[4m\u001b[1m77.86%\u001b[0m faster.\n\n\n*Note: Both Numba and Ray perform caching on the first call of a function. Thus, on the first session call to make() method, there will be additional delay (due to many functions being cached). All subsequent calls will experience the significant performance improvements.*\n\n<h3><a id='section4.7'>4.7 Chart Objects</a></h3>\n\nEach casestudy object currently contains 6 different chart objects, that provide visual tools for analysising, assessing and comparing COVID-19s impact on different regions and factors. Each chart is created via matplotlib. Details of each chart object are provided in future sections.\n\nThe chart classes can be found in the `chart` module, along with the `BaseChart` root which provides common functionality.\n\n    compchart from CompChart2D\n    compchart4d from CompChart4D\n    heatmap from HeatMap\n    barcharts from BarCharts\n    scatterflow from ScatterFlow\n    substrinscat from SubStrindexScatter\n\nEach chart has been designed to align closely with the `CaseStudy` functionality and with the underlying functionality of matplotlib.\n\nFor instance, each chart is called via the `make` method.\n\n\n```python\ncasestudy.regions = ['NY', 'NJ']\ncasestudy.make()\nleg = {'fontsize': 12, 'handlelength': 1}\ncasestudy.compchart.make(x_category='days', y_category='cases', figsize=(8,4), legend_params=leg)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=5.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))\n\n\n    Cumulative Cases\n\n\n\n![png](output_110_4.png)\n\n\nEach chart object is automatically updated on each `make` call, so any changes to the `casestudy` object, will also be reflected in the charts.\n\n\n```python\ncasestudy.regions = ['AB', 'ON']\ncasestudy.make()\ncasestudy.compchart.make(x_category='days', y_category='cases', figsize=(8,4), legend_params=leg)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=4.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))\n\n\n    Cumulative Cases\n\n\n\n![png](output_112_4.png)\n\n\n*Note a prior version of see19 implemented compchart using Bokeh. This chart is deprecated and replaced with a matplotlib version but is still avialable under CompChart2DBokeh.*\n\n<h1><a id='section5'>5. compchart - Visualizing Regional Impacts</a></h1>\n\n5.1 [Daily Fatalities Comparison - Italy](#section5.1)  \n5.2 [Daily Fatalities Comparison - 5 Most Impacted Regions](#section5.2)  \n5.3 [Varying the Categories](#section5.3)  \n\n`compchart` attribute is an instance of the `CompChart2D` class and provides standard line graphs comparing regions on different categories provided to `x_category` & `y_category`. Time-series is supported when `x_category='date'`.\n\nCharts are available in **multi-line** format with optional overlay of a second factor on a separate y-axis.\n\n<h2><a id='section5.1'>5.1 Daily Fatalities Comparison - Italy</a></h2>\n\nWe will illustrate with an example, focusing on only the three most impacted regions in Italy.\n\n\n```python\nitaregs = bf[bf['country'] == 'Italy'] \\\n    .sort_values(by='deaths', ascending=False).region_name.unique().tolist()[:3]\n\ncasestudy = CaseStudy(bf, regions=itaregs, start_hurdle=3, start_factor='deaths', smooth=False)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=1.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))\n\n\nWhen `CaseStudy` is instantiated, `compchart` is also instantiated with its own attributes.\n\n\n```python\nprint (casestudy.compchart)\n```\n\n    <casestudy.see19.see19.charts.CompChart2D object at 0x32dee3950>\n\n\nIn particular, all the various available categories are automatically provided labels via the `label` attribute. A few are shown below for illustration purposes.\n\n\n```python\nfor k,v in casestudy.compchart.labels.items():\n    print ('{}: {}'.format(k, v))\n    if k == 'temp':\n        break\n```\n\n    cases_dma: Cumulative Cases (3DMA)\n    cases_new: Daily Cases\n    cases_new_dma: Daily Cases (3DMA)\n    deaths_dma: Cumulative Deaths (3DMA)\n    deaths_new: Daily Deaths\n    deaths_new_dma: Daily Deaths (3DMA)\n    tests_dma: Cumulative Tests (3DMA)\n    tests_new: Daily Tests\n    tests_new_dma: Daily Tests (3DMA)\n    cases: Cumulative Cases\n    deaths: Cumulative Deaths\n    tests: Cumulative Tests\n    cases_dma_per_1K: Cumulative Cases per 1K (3DMA)\n    cases_dma_per_1M: Cumulative Cases per 1M (3DMA)\n    cases_dma_per_person_per_land_KM2: Cumulative Cases / Person / Land KM\u00b2 (3DMA)\n    cases_dma_per_person_per_city_KM2: Cumulative Cases / Person / City KM\u00b2 (3DMA)\n    cases_new_per_1K: Daily Cases per 1K\n    cases_new_per_1M: Daily Cases per 1M\n    cases_new_per_person_per_land_KM2: Daily Cases / Person / Land KM\u00b2\n    cases_new_per_person_per_city_KM2: Daily Cases / Person / City KM\u00b2\n    cases_new_dma_per_1K: Daily Cases per 1K (3DMA)\n    cases_new_dma_per_1M: Daily Cases per 1M (3DMA)\n    cases_new_dma_per_person_per_land_KM2: Daily Cases / Person / Land KM\u00b2 (3DMA)\n    cases_new_dma_per_person_per_city_KM2: Daily Cases / Person / City KM\u00b2 (3DMA)\n    deaths_dma_per_1K: Cumulative Deaths per 1K (3DMA)\n    deaths_dma_per_1M: Cumulative Deaths per 1M (3DMA)\n    deaths_dma_per_person_per_land_KM2: Cumulative Deaths / Person / Land KM\u00b2 (3DMA)\n    deaths_dma_per_person_per_city_KM2: Cumulative Deaths / Person / City KM\u00b2 (3DMA)\n    deaths_new_per_1K: Daily Deaths per 1K\n    deaths_new_per_1M: Daily Deaths per 1M\n    deaths_new_per_person_per_land_KM2: Daily Deaths / Person / Land KM\u00b2\n    deaths_new_per_person_per_city_KM2: Daily Deaths / Person / City KM\u00b2\n    deaths_new_dma_per_1K: Daily Deaths per 1K (3DMA)\n    deaths_new_dma_per_1M: Daily Deaths per 1M (3DMA)\n    deaths_new_dma_per_person_per_land_KM2: Daily Deaths / Person / Land KM\u00b2 (3DMA)\n    deaths_new_dma_per_person_per_city_KM2: Daily Deaths / Person / City KM\u00b2 (3DMA)\n    tests_dma_per_1K: Cumulative Tests per 1K (3DMA)\n    tests_dma_per_1M: Cumulative Tests per 1M (3DMA)\n    tests_dma_per_person_per_land_KM2: Cumulative Tests / Person / Land KM\u00b2 (3DMA)\n    tests_dma_per_person_per_city_KM2: Cumulative Tests / Person / City KM\u00b2 (3DMA)\n    tests_new_per_1K: Daily Tests per 1K\n    tests_new_per_1M: Daily Tests per 1M\n    tests_new_per_person_per_land_KM2: Daily Tests / Person / Land KM\u00b2\n    tests_new_per_person_per_city_KM2: Daily Tests / Person / City KM\u00b2\n    tests_new_dma_per_1K: Daily Tests per 1K (3DMA)\n    tests_new_dma_per_1M: Daily Tests per 1M (3DMA)\n    tests_new_dma_per_person_per_land_KM2: Daily Tests / Person / Land KM\u00b2 (3DMA)\n    tests_new_dma_per_person_per_city_KM2: Daily Tests / Person / City KM\u00b2 (3DMA)\n    cases_per_1K: Cumulative Cases per 1K\n    cases_per_1M: Cumulative Cases per 1M\n    cases_per_person_per_land_KM2: Cumulative Cases / Person / Land KM\u00b2\n    cases_per_person_per_city_KM2: Cumulative Cases / Person / City KM\u00b2\n    deaths_per_1K: Cumulative Deaths per 1K\n    deaths_per_1M: Cumulative Deaths per 1M\n    deaths_per_person_per_land_KM2: Cumulative Deaths / Person / Land KM\u00b2\n    deaths_per_person_per_city_KM2: Cumulative Deaths / Person / City KM\u00b2\n    tests_per_1K: Cumulative Tests per 1K\n    tests_per_1M: Cumulative Tests per 1M\n    tests_per_person_per_land_KM2: Cumulative Tests / Person / Land KM\u00b2\n    tests_per_person_per_city_KM2: Cumulative Tests / Person / City KM\u00b2\n    cases_dma_lognat: Cumulative Cases (3DMA)\n    (Natural Log)\n    cases_new_lognat: Daily Cases\n    (Natural Log)\n    cases_new_dma_lognat: Daily Cases (3DMA)\n    (Natural Log)\n    deaths_dma_lognat: Cumulative Deaths (3DMA)\n    (Natural Log)\n    deaths_new_lognat: Daily Deaths\n    (Natural Log)\n    deaths_new_dma_lognat: Daily Deaths (3DMA)\n    (Natural Log)\n    tests_dma_lognat: Cumulative Tests (3DMA)\n    (Natural Log)\n    tests_new_lognat: Daily Tests\n    (Natural Log)\n    tests_new_dma_lognat: Daily Tests (3DMA)\n    (Natural Log)\n    cases_lognat: Cumulative Cases\n    (Natural Log)\n    deaths_lognat: Cumulative Deaths\n    (Natural Log)\n    tests_lognat: Cumulative Tests\n    (Natural Log)\n    cases_dma_per_1K_lognat: Cumulative Cases per 1K (3DMA)\n    (Natural Log)\n    cases_dma_per_1M_lognat: Cumulative Cases per 1M (3DMA)\n    (Natural Log)\n    cases_dma_per_person_per_land_KM2_lognat: Cumulative Cases / Person / Land KM\u00b2 (3DMA)\n    (Natural Log)\n    cases_dma_per_person_per_city_KM2_lognat: Cumulative Cases / Person / City KM\u00b2 (3DMA)\n    (Natural Log)\n    cases_new_per_1K_lognat: Daily Cases per 1K\n    (Natural Log)\n    cases_new_per_1M_lognat: Daily Cases per 1M\n    (Natural Log)\n    cases_new_per_person_per_land_KM2_lognat: Daily Cases / Person / Land KM\u00b2\n    (Natural Log)\n    cases_new_per_person_per_city_KM2_lognat: Daily Cases / Person / City KM\u00b2\n    (Natural Log)\n    cases_new_dma_per_1K_lognat: Daily Cases per 1K (3DMA)\n    (Natural Log)\n    cases_new_dma_per_1M_lognat: Daily Cases per 1M (3DMA)\n    (Natural Log)\n    cases_new_dma_per_person_per_land_KM2_lognat: Daily Cases / Person / Land KM\u00b2 (3DMA)\n    (Natural Log)\n    cases_new_dma_per_person_per_city_KM2_lognat: Daily Cases / Person / City KM\u00b2 (3DMA)\n    (Natural Log)\n    deaths_dma_per_1K_lognat: Cumulative Deaths per 1K (3DMA)\n    (Natural Log)\n    deaths_dma_per_1M_lognat: Cumulative Deaths per 1M (3DMA)\n    (Natural Log)\n    deaths_dma_per_person_per_land_KM2_lognat: Cumulative Deaths / Person / Land KM\u00b2 (3DMA)\n    (Natural Log)\n    deaths_dma_per_person_per_city_KM2_lognat: Cumulative Deaths / Person / City KM\u00b2 (3DMA)\n    (Natural Log)\n    deaths_new_per_1K_lognat: Daily Deaths per 1K\n    (Natural Log)\n    deaths_new_per_1M_lognat: Daily Deaths per 1M\n    (Natural Log)\n    deaths_new_per_person_per_land_KM2_lognat: Daily Deaths / Person / Land KM\u00b2\n    (Natural Log)\n    deaths_new_per_person_per_city_KM2_lognat: Daily Deaths / Person / City KM\u00b2\n    (Natural Log)\n    deaths_new_dma_per_1K_lognat: Daily Deaths per 1K (3DMA)\n    (Natural Log)\n    deaths_new_dma_per_1M_lognat: Daily Deaths per 1M (3DMA)\n    (Natural Log)\n    deaths_new_dma_per_person_per_land_KM2_lognat: Daily Deaths / Person / Land KM\u00b2 (3DMA)\n    (Natural Log)\n    deaths_new_dma_per_person_per_city_KM2_lognat: Daily Deaths / Person / City KM\u00b2 (3DMA)\n    (Natural Log)\n    tests_dma_per_1K_lognat: Cumulative Tests per 1K (3DMA)\n    (Natural Log)\n    tests_dma_per_1M_lognat: Cumulative Tests per 1M (3DMA)\n    (Natural Log)\n    tests_dma_per_person_per_land_KM2_lognat: Cumulative Tests / Person / Land KM\u00b2 (3DMA)\n    (Natural Log)\n    tests_dma_per_person_per_city_KM2_lognat: Cumulative Tests / Person / City KM\u00b2 (3DMA)\n    (Natural Log)\n    tests_new_per_1K_lognat: Daily Tests per 1K\n    (Natural Log)\n    tests_new_per_1M_lognat: Daily Tests per 1M\n    (Natural Log)\n    tests_new_per_person_per_land_KM2_lognat: Daily Tests / Person / Land KM\u00b2\n    (Natural Log)\n    tests_new_per_person_per_city_KM2_lognat: Daily Tests / Person / City KM\u00b2\n    (Natural Log)\n    tests_new_dma_per_1K_lognat: Daily Tests per 1K (3DMA)\n    (Natural Log)\n    tests_new_dma_per_1M_lognat: Daily Tests per 1M (3DMA)\n    (Natural Log)\n    tests_new_dma_per_person_per_land_KM2_lognat: Daily Tests / Person / Land KM\u00b2 (3DMA)\n    (Natural Log)\n    tests_new_dma_per_person_per_city_KM2_lognat: Daily Tests / Person / City KM\u00b2 (3DMA)\n    (Natural Log)\n    cases_per_1K_lognat: Cumulative Cases per 1K\n    (Natural Log)\n    cases_per_1M_lognat: Cumulative Cases per 1M\n    (Natural Log)\n    cases_per_person_per_land_KM2_lognat: Cumulative Cases / Person / Land KM\u00b2\n    (Natural Log)\n    cases_per_person_per_city_KM2_lognat: Cumulative Cases / Person / City KM\u00b2\n    (Natural Log)\n    deaths_per_1K_lognat: Cumulative Deaths per 1K\n    (Natural Log)\n    deaths_per_1M_lognat: Cumulative Deaths per 1M\n    (Natural Log)\n    deaths_per_person_per_land_KM2_lognat: Cumulative Deaths / Person / Land KM\u00b2\n    (Natural Log)\n    deaths_per_person_per_city_KM2_lognat: Cumulative Deaths / Person / City KM\u00b2\n    (Natural Log)\n    tests_per_1K_lognat: Cumulative Tests per 1K\n    (Natural Log)\n    tests_per_1M_lognat: Cumulative Tests per 1M\n    (Natural Log)\n    tests_per_person_per_land_KM2_lognat: Cumulative Tests / Person / Land KM\u00b2\n    (Natural Log)\n    tests_per_person_per_city_KM2_lognat: Cumulative Tests / Person / City KM\u00b2\n    (Natural Log)\n    cases_dma_log: Cumulative Cases (3DMA)\n    (Log Base 10)\n    cases_new_log: Daily Cases\n    (Log Base 10)\n    cases_new_dma_log: Daily Cases (3DMA)\n    (Log Base 10)\n    deaths_dma_log: Cumulative Deaths (3DMA)\n    (Log Base 10)\n    deaths_new_log: Daily Deaths\n    (Log Base 10)\n    deaths_new_dma_log: Daily Deaths (3DMA)\n    (Log Base 10)\n    tests_dma_log: Cumulative Tests (3DMA)\n    (Log Base 10)\n    tests_new_log: Daily Tests\n    (Log Base 10)\n    tests_new_dma_log: Daily Tests (3DMA)\n    (Log Base 10)\n    cases_log: Cumulative Cases\n    (Log Base 10)\n    deaths_log: Cumulative Deaths\n    (Log Base 10)\n    tests_log: Cumulative Tests\n    (Log Base 10)\n    cases_dma_per_1K_log: Cumulative Cases per 1K (3DMA)\n    (Log Base 10)\n    cases_dma_per_1M_log: Cumulative Cases per 1M (3DMA)\n    (Log Base 10)\n    cases_dma_per_person_per_land_KM2_log: Cumulative Cases / Person / Land KM\u00b2 (3DMA)\n    (Log Base 10)\n    cases_dma_per_person_per_city_KM2_log: Cumulative Cases / Person / City KM\u00b2 (3DMA)\n    (Log Base 10)\n    cases_new_per_1K_log: Daily Cases per 1K\n    (Log Base 10)\n    cases_new_per_1M_log: Daily Cases per 1M\n    (Log Base 10)\n    cases_new_per_person_per_land_KM2_log: Daily Cases / Person / Land KM\u00b2\n    (Log Base 10)\n    cases_new_per_person_per_city_KM2_log: Daily Cases / Person / City KM\u00b2\n    (Log Base 10)\n    cases_new_dma_per_1K_log: Daily Cases per 1K (3DMA)\n    (Log Base 10)\n    cases_new_dma_per_1M_log: Daily Cases per 1M (3DMA)\n    (Log Base 10)\n    cases_new_dma_per_person_per_land_KM2_log: Daily Cases / Person / Land KM\u00b2 (3DMA)\n    (Log Base 10)\n    cases_new_dma_per_person_per_city_KM2_log: Daily Cases / Person / City KM\u00b2 (3DMA)\n    (Log Base 10)\n    deaths_dma_per_1K_log: Cumulative Deaths per 1K (3DMA)\n    (Log Base 10)\n    deaths_dma_per_1M_log: Cumulative Deaths per 1M (3DMA)\n    (Log Base 10)\n    deaths_dma_per_person_per_land_KM2_log: Cumulative Deaths / Person / Land KM\u00b2 (3DMA)\n    (Log Base 10)\n    deaths_dma_per_person_per_city_KM2_log: Cumulative Deaths / Person / City KM\u00b2 (3DMA)\n    (Log Base 10)\n    deaths_new_per_1K_log: Daily Deaths per 1K\n    (Log Base 10)\n    deaths_new_per_1M_log: Daily Deaths per 1M\n    (Log Base 10)\n    deaths_new_per_person_per_land_KM2_log: Daily Deaths / Person / Land KM\u00b2\n    (Log Base 10)\n    deaths_new_per_person_per_city_KM2_log: Daily Deaths / Person / City KM\u00b2\n    (Log Base 10)\n    deaths_new_dma_per_1K_log: Daily Deaths per 1K (3DMA)\n    (Log Base 10)\n    deaths_new_dma_per_1M_log: Daily Deaths per 1M (3DMA)\n    (Log Base 10)\n    deaths_new_dma_per_person_per_land_KM2_log: Daily Deaths / Person / Land KM\u00b2 (3DMA)\n    (Log Base 10)\n    deaths_new_dma_per_person_per_city_KM2_log: Daily Deaths / Person / City KM\u00b2 (3DMA)\n    (Log Base 10)\n    tests_dma_per_1K_log: Cumulative Tests per 1K (3DMA)\n    (Log Base 10)\n    tests_dma_per_1M_log: Cumulative Tests per 1M (3DMA)\n    (Log Base 10)\n    tests_dma_per_person_per_land_KM2_log: Cumulative Tests / Person / Land KM\u00b2 (3DMA)\n    (Log Base 10)\n    tests_dma_per_person_per_city_KM2_log: Cumulative Tests / Person / City KM\u00b2 (3DMA)\n    (Log Base 10)\n    tests_new_per_1K_log: Daily Tests per 1K\n    (Log Base 10)\n    tests_new_per_1M_log: Daily Tests per 1M\n    (Log Base 10)\n    tests_new_per_person_per_land_KM2_log: Daily Tests / Person / Land KM\u00b2\n    (Log Base 10)\n    tests_new_per_person_per_city_KM2_log: Daily Tests / Person / City KM\u00b2\n    (Log Base 10)\n    tests_new_dma_per_1K_log: Daily Tests per 1K (3DMA)\n    (Log Base 10)\n    tests_new_dma_per_1M_log: Daily Tests per 1M (3DMA)\n    (Log Base 10)\n    tests_new_dma_per_person_per_land_KM2_log: Daily Tests / Person / Land KM\u00b2 (3DMA)\n    (Log Base 10)\n    tests_new_dma_per_person_per_city_KM2_log: Daily Tests / Person / City KM\u00b2 (3DMA)\n    (Log Base 10)\n    cases_per_1K_log: Cumulative Cases per 1K\n    (Log Base 10)\n    cases_per_1M_log: Cumulative Cases per 1M\n    (Log Base 10)\n    cases_per_person_per_land_KM2_log: Cumulative Cases / Person / Land KM\u00b2\n    (Log Base 10)\n    cases_per_person_per_city_KM2_log: Cumulative Cases / Person / City KM\u00b2\n    (Log Base 10)\n    deaths_per_1K_log: Cumulative Deaths per 1K\n    (Log Base 10)\n    deaths_per_1M_log: Cumulative Deaths per 1M\n    (Log Base 10)\n    deaths_per_person_per_land_KM2_log: Cumulative Deaths / Person / Land KM\u00b2\n    (Log Base 10)\n    deaths_per_person_per_city_KM2_log: Cumulative Deaths / Person / City KM\u00b2\n    (Log Base 10)\n    tests_per_1K_log: Cumulative Tests per 1K\n    (Log Base 10)\n    tests_per_1M_log: Cumulative Tests per 1M\n    (Log Base 10)\n    tests_per_person_per_land_KM2_log: Cumulative Tests / Person / Land KM\u00b2\n    (Log Base 10)\n    tests_per_person_per_city_KM2_log: Cumulative Tests / Person / City KM\u00b2\n    (Log Base 10)\n    : January 2020\n    population: Population\n    land_dens: Density of Land Area\n    city_dens: Population Density of Largest City\n    uvb: UV-B Radiation in J / M\u00b2\n    rhum: Relative Humidity\n    strindex: Oxford Stringency Index\n    visitors: Annual Visitors\n    visitors_%: Annual Visitors as % of Population\n    gdp: Gross Domestic Product\n    gdp_%: Gross Domestic Product per Capita\n    retail_n_rec: Change in Retail n Recreation Mobility\n    transit: Change in Transit Mobility\n    workplaces: Change in WorkPlace Mobility\n    residential: Change in Residential Mobility\n    parks: Change in Parks Mobility\n    groc_n_pharm: Change in Grocery & Pharmacy Mobility\n    transit_apple: Change in Transit Mobility - Apple\n    driving_apple: Change in Driving Mobility - Apple\n    walking_apple: Change in Walking Mobility - Apple\n    c1: School Closing\n    c2: Workplace Closing\n    c3: Cancel Public Events\n    c4: Restrictions on Gatherings\n    c5: Close Public Transport\n    c6: Stay-at-Home Requirements\n    c7: Restrictions on Internal Movement\n    c8: International Travel Controls\n    e1: Income Support\n    e2: Debt / Contract Relief\n    e3: Fiscal Measures\n    e4: International Support\n    h1: Public Information Campaigns\n    h2: Testing Policy\n    h3: Contact Tracing\n    h4: Emergency Investment in Health Care\n    h5: Investment in Vaccines\n    key3_sum: Sum of Key 3 Categories\n    key3_sum_earlier: Sum of Key 3 Oxford Stingency Factor Weighted to Earlier Dates\n    make_sum: Custom Stringency Aggregate\n    neoplasms: NeoPlasms Fatalities\n    blood: Blood-based Fatalities\n    endo: Endocrine Fatalities\n    mental: Mental Fatalities\n    nervous: Nervous System Fatalities\n    circul: Circulatory Fatalities\n    infectious: Infectious Fatalities\n    respir: Respiratory Fatalities\n    digest: Digestive Fatalities\n    skin: Skin-related Fatalities\n    musculo: Musculo-skeletal Fatalities\n    genito: Genitourinary Fatalities\n    childbirth: Maternal and Childbirth Fatalities\n    perinatal: Perinatal Fatalities\n    congenital: Congenital Fatalities\n    other: Other Fatalities\n    external: External Fatalities\n    date: Date\n    temp: Temperature (\u00b0C)\n\n\n### make()\n\nSimilar to the main casestudy object, charts are rendered with the `make` method.\n\n`x_category` and `y_category` accept any column header in `casestudy.df`.\n\n`make` accepts many optional kwargs. Every effort is made to align these options with matplotlib standards. Appropriate options can be found via the matplotlib api. For example: \n* `title`:          https://matplotlib.org/api/_as_gen/matplotlib.pyplot.suptitle.html (except for CompCharts4D)\n* `line_params`: https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.plot.html\n* `legend_params`:    https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html\n* `xlabel_params`: https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html\n* `xtick_params`:  https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.tick_params.html\n* `palette_base`:  https://matplotlib.org/1.2.1/examples/pylab_examples/show_colormaps.html   \n\nAll of the above kwargs and many others are share amongst ALL the different see19 Chart Classes.\n\n\n```python\nkwargs = {\n    'x_category': 'days',\n    'y_category': 'cases_new',\n    'width': 12,\n    'height': 8,\n    'title': {'t': 'Most Impacted Regions in Italy', 'fontsize': 24, 'weight': 'demi'},\n    'line_params': {'lw': 4},\n    'legend_params': {'fontsize': 14, 'handlelength': 1},\n    'xlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'ylabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 14},\n    'ytick_params': {'labelsize': 14},\n    'colors': ['red', 'green', 'blue']\n}\n\ncasestudy.compchart.make(**kwargs)\n```\n\n    Daily Cases\n\n\n\n![png](output_124_1.png)\n\n\nAn optional `regions` parameter exists that allows you to further reduce the number of regions presented in the chart. `regions` accepts a list of `region_id`, `region_code`, or `region_name` in any combination.\n\nBelow, we also show that a matplotlib colormap can be provided via `palette_base` and that the x-axis label can be removed by setting `xlabel=False` \n\n\n```python\nkwargs = {\n    'regions': ['LOM', 'EMI'],\n    'x_category': 'date',\n    'y_category': 'deaths_new',\n    'width': 12,\n    'height': 8,\n    'title': {'t': 'Lombardia v Emilia-Romagna', 'fontsize': 24, 'weight': 'demi'},\n    'line_params': {'lw': 6},\n    'legend_params': {'fontsize': 14, 'handlelength': 1},\n    'xlabel': False,\n    'ylabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 14},\n    'ytick_params': {'labelsize': 14},\n    'palette_base': 'Accent',\n}\n\ncasestudy.compchart.make(**kwargs)\n```\n\n    Daily Deaths\n\n\n\n![png](output_126_1.png)\n\n\n<h2><a id='section5.2'>5.2 Daily Fatalities Comparison - 5 Most Impacted Regions</a></h2>\n\nNow we'll look at new cases in the 5 most impacted regions globally in terms of total fatalities.\n\n\n```python\nregions = list(bf.sort_values(by='deaths', ascending=False).region_name.unique())[:5]\n```\n\n\n```python\ncasestudy = CaseStudy(bf, regions=regions, start_hurdle=3, start_factor='deaths', count_dma=21, log=True)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=12.0, style=ProgressStyle(description_width\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))\n\n\n\n```python\ntitle='5 Most Impacted Regions'\n\nkwargs = {\n    'x_category': 'days',\n    'y_category': 'deaths_new',\n    'width': 12,\n    'height': 8,\n    'title': {'t': title, 'fontsize': 24, 'weight': 'demi'},\n    'line_params': {'lw': 3},\n    'legend_params': {'fontsize': 14},\n    'xlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'ylabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 14},\n    'ytick_params': {'labelsize': 14},\n    'palette_base': 'Accent',\n}\np = casestudy.compchart.make(**kwargs)\n```\n\n    Daily Deaths\n\n\n\n![png](output_131_1.png)\n\n\nThere are major outliers, certainly in the early days that make the graph difficult to read. The `lognat` adjusted category comes in handy here.\n\nBelow we also demonstrate that the `regions` parameter can be provided to each `make` to further reduce the regions covered in the chart (for convenience)\n\n\n```python\nkwargs['y_category']= 'deaths_new_dma_per_1M_log'\nkwargs['ylabel_params']= {'fontsize': 18, 'labelpad': 10}\nkwargs['regions'] = ['France', 'India', 'United Kingdom']\n\np = casestudy.compchart.make(**kwargs)\n```\n\n    Daily Deaths per 1M (21DMA)\n    (Log Base 10)\n\n\n\n![png](output_133_1.png)\n\n\n<h2><a id='section5.3'>5.3 Varying the Categories</a></h2>\n\n**Oxford Stringency Index**\n\n`compchart` can be used to compare any `category` or `factor` in `casestudy.df` with `days` or `date` on the x-axis.\n\nThe below chart compares the Oxford Stringency Index for each selected region\n\n\n```python\nregions = ['Germany', 'Spain', 'Taiwan']\n\ncasestudy = CaseStudy(\n    bf, count_categories='cases_new_per_1M', regions=regions, \n    start_factor='', factors=['strindex']\n)\ncasestudy.make()\nkwargs = {\n    'x_category': 'date',\n    'y_category': 'strindex',\n    'width': 12,\n    'height': 8,\n    'line_params': {'lw': 3},\n    'legend_params': {'fontsize': 14},\n    'xlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'ylabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 14},\n    'ytick_params': {'labelsize': 14},\n    'palette_base': 'Accent',\n}\np = casestudy.compchart.make(**kwargs)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=6.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))\n\n\n    Oxford Stringency Index\n\n\n\n![png](output_136_4.png)\n\n\nThese graphs work best as time-series but the `x_category` can also be any other category in `casestudy.df`. Below we can see that in New York, positive cases have steadily declined even as testing has increased. Texas and Arizona have not had the same success.\n\n\n```python\nregions = ['New York', 'Texas', 'Arizona']\n\ncasestudy = CaseStudy(bf, regions=regions, count_dma=21)\ncasestudy.make()\nkwargs = {\n    'x_category': 'tests_new_dma_per_1M',\n    'y_category': 'cases_new_dma_per_1M',\n    'width': 12,\n    'height': 8,\n    'line_params': {'lw': 3},\n    'legend_params': {'fontsize': 14},\n    'xlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'ylabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 14},\n    'ytick_params': {'labelsize': 14},\n    'palette_base': 'Accent',\n}\np = casestudy.compchart.make(**kwargs)\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=8.0, style=ProgressStyle(description_width=\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))\n\n\n    Daily Cases per 1M (21DMA)\n\n\n\n![png](output_138_4.png)\n\n\n### Saving Files\n\nAll chart instances in `see19` have a `save_file` option. Simply set that option to `True` and provide a `filename` and the file will be saved to yor location of choice.\n\n<h1><a id='section6'>6. compchart4D - Visualizing Factors in 4D</a></h1>\n\n6.1 [From 3D to 4D](#section6.1)  \n6.2 [More on the X-Axis](#section6.2)  \n6.3 [How Far Can We Take It?](#section6.3)\n\n3D charts with color-mapping can be used to explore the impact of various factors in different regions at different times.\n\nSuch '4D' maps are often criticized for lack of readability, but they have been a valuable tool for recognizing  patterns.\n\nThese charts are available in `CaseStudy` via the `compchart4d` attribute, which is an instance of the `CompChart4D` class. The 3D representation shows the `count_category` for each region on z-axis with each day from the `start_hurdle` on the y-axis and the individual regions separated on the x-axis.\n\nThe 3D chart is a cute trick, but the real power is derived from the `color_factor`. This maps the color of each 3D bar to the factor one wants to investigate.\n\n`CompChart4D` object utilizes `matplotlib` for chart creation.\n\n<h1><a id='section6.1'>6.1  From 3D to 4D</a></h1>\n\n### Most Impacted Regions - Brazil\n\nFirst, we get region names from the baseframe, sorting as required.\n\nThen we create the `casestudy` instance, including several factors that we'll cover in our analysis.\n\n\n```python\nfrom casestudy.see19.see19 import CaseStudy\n```\n\n\n```python\nregions = bf[bf['country'] == 'Brazil'] \\\n    .sort_values(by='population', ascending=False) \\\n    .region_name.unique().tolist()[:20]\n\nfactor_dmas={'temp': 3}\n\ncasestudy = CaseStudy(\n    bf, count_dma=5, \n    factors=['temp', 'c1', 'A65PLUSB', 'A75PLUSB'], factor_dmas=factor_dmas,\n    regions=regions, start_hurdle=10, start_factor='cases', lognat=True,\n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=59.0, style=ProgressStyle(description_width\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))\n\n\n4D charts are customizable in precisely the same way as `CompChart2D`, sharing many of the same keywords. `compchart4D` utilizes a couple of its own unique keywords as per below:\n* `z_category` is utilized to determine the z-axis (vertical). x- and y-axis are automatically set to regions and days.\n* `comp_size` will further trim the number of regions by ranking them on the `comp_category`. \n* a separate `rank_category` can be provided for this process if preferred\n\n\n```python\nkwargs = {\n    'title': {'s': 'Most Impacted Regions in Brazil', 'x': .47, 'y': .74, 'fontsize': 24, 'rotation': -9, 'weight': 'demi'},\n    'ylabel_params': {'fontsize': 18, 'labelpad': 12},\n    'zlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 18},\n    'ytick_params': {'labelsize': 12},\n    'tight': True, 'comp_size': 10,\n}\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\n```\n\n\n![png](output_148_0.png)\n\n\n***`df_chart`***: for most charts, the casestudy dataframe is morphed for presentation purposes. This morphed data is avaliable via the df_chart attribute.\n\n\n```python\ncasestudy.compchart4d.df_chart.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>region_name</th>\n      <th>region_code</th>\n      <th>country</th>\n      <th>date</th>\n      <th>days</th>\n      <th>deaths_new_dma_per_1M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10585</th>\n      <td>566</td>\n      <td>Ceara</td>\n      <td>CE</td>\n      <td>Brazil</td>\n      <td>2020-03-22</td>\n      <td>6 days</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10586</th>\n      <td>566</td>\n      <td>Ceara</td>\n      <td>CE</td>\n      <td>Brazil</td>\n      <td>2020-03-23</td>\n      <td>7 days</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10587</th>\n      <td>566</td>\n      <td>Ceara</td>\n      <td>CE</td>\n      <td>Brazil</td>\n      <td>2020-03-24</td>\n      <td>8 days</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10588</th>\n      <td>566</td>\n      <td>Ceara</td>\n      <td>CE</td>\n      <td>Brazil</td>\n      <td>2020-03-25</td>\n      <td>9 days</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10589</th>\n      <td>566</td>\n      <td>Ceara</td>\n      <td>CE</td>\n      <td>Brazil</td>\n      <td>2020-03-26</td>\n      <td>10 days</td>\n      <td>0.169566</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n### Adding a Color Factor\n\nBy adding the `color_factor` attribute, we can see the impact, if any, of an exogenous factor on the `comp_category` over time.\n\nWe will start with `A65PLUSB_%`. As this a time-static factor, the color for each region will be the same regardless of the day.\n\nYou must provide additional options to position the color bar.\n\n\n```python\nkwargs = {\n    **kwargs,\n    'color_category': 'A65PLUSB_%', \n    'xy_cbar': (0.09, .225), 'wh_cbar': (.015, 14),\n    'cblabel_params': {'labelpad': -55},\n}\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\n```\n\n\n![png](output_152_0.png)\n\n\nNow we'll use `temp`, which is a time-dynamic factor and will provide a different color for each region on each day.\n\n\n```python\nkwargs = {**kwargs, \n    'color_category': 'temp',\n}\n```\n\n\n```python\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\n```\n\n\n![png](output_155_0.png)\n\n\n### Fixing the Color Range\n\n***NOTE:*** The range of colors is automatically set by `make`. This can be somewhat misleading when:\n1. comparing multiple charts \n2. when a single chart has temperatures in a narrow range. In the above example, for instance, temperatures range only between 18C - 28C and, yet, the color map runs almost the entire red-blue spectrum.\n\nThus, there is a `color_interval` option that allows you to fix the color interval. `color_interval` expects a tuple, where the first item is the low-end of the range and the second item is the high-end.\n\nFixing the color interval provides a very different picture of Brazil's impacted regions.\n\n\n```python\nkwargs = {**kwargs, 'color_interval': (20,30)}\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\n```\n\n\n![png](output_157_0.png)\n\n\n<h1><a id='section6.2'>6.2 More on the X-Axis</a></h1>\n\n\n### Top 30 US States\n\nNow we investigate the Top 30 most impacted US states.\n\n\n```python\nregions = bf[bf['country_code'] == 'USA'] \\\n    .sort_values('cases', ascending='False') \\\n    .region_name.unique().tolist()[:50]\ncountries = 'USA'\n```\n\n\n```python\ncasestudy = CaseStudy(\n    bf, regions=regions, countries=countries, count_dma=14,\n    factors=['temp', 'uvb', 'rhum', 'A65PLUSB', 'A75PLUSB', 'A05_24B'], factor_dmas={'temp': 14, 'uvb': 14},\n    start_hurdle=10, start_factor='cases', \n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=139.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))\n\n\nHere 4 charts are prepared in quick succession.\n\nAdditional options are shown for editing the background grey and removing gridlines.\n\n**NOTE:** `CompChart4D` automatically sorts the regions on the x-axis such that the regions with the greatest z-axis values are furthest away. This improves readability.\n\n\n```python\nkwargs = {\n    'regions': '',\n    'ylabel_params': {'fontsize': 18, 'labelpad': 12},\n    'zlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 12},\n    'ytick_params': {'labelsize': 12},\n    'ztick_params': {'labelsize': 12},\n    'title': {'x': 0.58, 'y': 0.825,'s': 'Daily Deaths in Select US States', 'fontsize': 22, 'rotation': -10.7},\n    'xy_cbar': (0.09, .225), 'wh_cbar': (.01, 20),\n    'title': {'s': 'Most Impacted States in US', 'x': .47, 'y': .74, 'fontsize': 24, 'rotation': -9, 'weight': 'demi'},\n    'cblabel_params': {'labelpad': -55},\n    'color_category': 'temp_dma', 'color_interval': (20,30),\n    'tight': True,\n    'comp_size': 30,\n    'rank_category': 'deaths_new_dma_per_1M',    \n}\n\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_person_per_city_KM2', **kwargs)\n\nkwargs['color_category'] = 'uvb_dma'\nkwargs['color_interval'] = ()\nkwargs['gridlines'] = False\n\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_person_per_city_KM2', **kwargs)\n```\n\n\n![png](output_163_0.png)\n\n\n\n![png](output_163_1.png)\n\n\n\n![png](output_163_2.png)\n\n\n\n![png](output_163_3.png)\n\n\n<h1><a id='section6.3'>6.3 How Far Can We Take It?</a></h1>\n\n### 101 Most Impacted Regions Globally\n\nI acknowledge that using the chart in this way stretches its value, however, it is has been a great way for me to consider trends globally. Try not to look at each individual region ... look at it more like a scatter plot and see what patterns you can identify, if any.\n\n**NOTE:** If the number of regions exceeds **100**, the region labels are removed automatically.\n\nFirst, we sort the regions in the `baseframe` to find the 101 most populous.\n\nThen, those regions are ranked on the `comp_category`.\n\n\n```python\ncompsize = 102\nregions = bf[~(bf['country'] == 'China')].sort_values(by='population', ascending=False).region_name.unique().tolist()[:compsize]\n\nfactors = ['temp']\nfactor_dmas = {'temp': 7}\n\ncasestudy = CaseStudy(\n    bf, regions=regions, factors=factors, factor_dmas=factor_dmas,\n    start_hurdle=10, start_factor='cases', count_dma=3, lognat=True\n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=226.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=103.0), HTML(value='')))\n\n\n\n```python\nkwargs = {\n    'ylabel_params': {'fontsize': 18, 'labelpad': 12},\n    'zlabel_params': {'fontsize': 18, 'labelpad': 10},\n    'xtick_params': {'labelsize': 12},\n    'ytick_params': {'labelsize': 12},\n    'ztick_params': {'labelsize': 12},\n    'title': {'x': 0.58, 'y': 0.825,'s': 'Daily Deaths Globally', 'fontsize': 22, 'rotation': -10.7},\n    'xy_cbar': (0.09, .225), 'wh_cbar': (.01, 20),\n    'title': {'s': 'Most Impacted Regions Totally', 'x': .47, 'y': .74, 'fontsize': 24, 'rotation': -9, 'weight': 'demi'},\n    'cblabel_params': {'labelpad': -55},\n    'color_category': 'temp_dma', 'color_interval': (20,30),\n    'tight': True,\n    'comp_size': 102,\n    'rank_category': 'deaths_new_dma_per_1M', \n}\n\np = casestudy.compchart4d.make(z_category='deaths_new_dma_per_1M', **kwargs)\n```\n\n\n![png](output_166_0.png)\n\n\nNow, ***if*** temperature *for some reason* did impact the fatality rate associated with COVID19, what we would expect to see is regions at the far end of the x-axis would tend toward the **blue** end of the color spectrum and regions at the near end of the x-axis would tend towards **red**.\n\nWe would also expect to see regions with higher peaks to have more **blue** bars on the near-end of the y-axis, or at times earlier in the outbreak.\n\n<h1><a id='section7'>7. heatmap - Visualizing with Color Maps</a></h1>\n\n7.1 [Count Category v Single Factor](#section7.1)  \n7.2 [Count Category v Multiple Factors](#section7.2)  \n\n### Hexbins? ###\nSee19 utilizes the `hexbin` module of `matplotlib` to generate ***HeatMap***-style charts to investigate the impact of different factors on COVID19 virulence.\n\nThis is a bit of a repurpose or basterdization from `hexbin`'s intended usage. `hexbin` is more commonly used as a 2D histogram for very large datasets, counting the appearance of datapoints within a range of certain `(x,y)` coordinates (called `bins`) and then mapping a color scheme to the range of counts.\n\nFor our purposes, use of `hexbin` is a stylistic choice, with the patterns developed more interesting and a bit more revealing than a scatter plot. The intention is for each `bin` to contain only one datapoint and the color is mapped to either the x-axis values or a 3rd dimension of values. \n\n### Structure ###\n\nAs with previous charts, heatmaps are available in `CaseStudy` via the `heatmap` attribute, which is in turn an instance of the `HeatMap` class.\n\nCharts are generated via the `make` method, which further morphs `casestudy.df` to arrange data for visualization.\n\n### Average over Time v Daily Points ###\n\nAll of the analysis to this point has considered each daily datapoint for each region separately. `heatmap` is different. `heatmap` takes (at this point) a simple mean of the `x_category` and `y_category` in question. This is a sufficient method to explore potential relationships, but true time series analysis must also be considered to project COVID19 virulence forward.\n\nWhile the average is used, the timing of such average can still have an impact on the relevance of the analysis. At this stage, `heatmap` is capable of utilizing the *daily moving average* from the date of the peak of the `x_category` or from the date the region clears the `start_hurdle`.\n\nThis option is denoted as the `x_start` and `color_start` parameters in the `make` method.\n\nFor this analysis, we need a large dataset, so will start with the top **250** regions in terms of population and we will add many different factors.\n\n\n```python\nexcluded_countries = ['China']\nexcluded_regions = []\n\nframe_filter = (~bf['country'].isin(excluded_countries)) & (~bf['region_name'].isin(excluded_regions))\nregions = bf[frame_filter] \\\n    .sort_values('population', ascending=False) \\\n    .region_name.unique().tolist()[:250]\n\nfactors_with_dmas = CaseStudy.MSMTS + ['strindex']\nfactor_dmas = {factor: 28 for factor in factors_with_dmas}\nfactor_dmas['strindex'] = 14\nfactors = factors_with_dmas + CaseStudy.MAJOR_CAUSES + ['visitors', 'A75PLUSB', 'A65PLUSB', 'gdp']\n\ncasestudy = CaseStudy(\n    bf, regions=regions, count_dma=14, factors=factors, \n    factor_dmas=factor_dmas, start_hurdle=1, start_factor='deaths', log=True, lognat=True,\n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=548.0, style=ProgressStyle(description_widt\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=230.0), HTML(value='')))\n\n\n<h2><a id='section7.1'>7.1 Count Category v Single Factor</a></h2>\n`heatmap` takes a similar set of options as `comp_chart` and `comp_chart4d`. The biggest difference in approach relates to text annotations:\n\n* In `comp_chart` and `comp_chart4d`, specific variables for `title`, `subtitle`, etc. generate text boxes for specific purposes.\n* In `heatmap` this is replaced in favor of a more flexible approach of ad-hoc text annotations via the `annotations` parameter.\n* `heatmap` has tended to require more lengthy notations / explanations and so this approach seemed more appropriate.\n\nIn addition to the standard `comp_category`, the x-axis of `heatmap` is now provided by the `comp_factor` parameter.\n\nThe below chart is completed on a linear scale of daily fatalities. It hints at a potential relationship between fatalities and temperature for the most impacted regions, however, the scaling is negatively impacted by a handful of outliers.\n\n**NOTE:** `color_factor` is ***not*** provided, therefore, the color map is a function of the `comp_factor` values (on the x-axis).\n\n**Max Fatalities v Temperature**\n\n\n```python\ntitle = 'Max Daily Fatalities v Temperature by Region'\nsubtitle = '*Average temperature for two weeks prior to day of 3rd fatality'\nnote = '**{} Regions considered excluding mainland China'.format(casestudy.df.region_id.unique().shape[0])\nkwargs = {\n    'x_category': 'deaths_new_dma_per_1M',\n    'y_category': 'temp_dma',\n    'annotations': [\n        [0, 1.09, title, {'color': 'black', 'fontsize': 16, 'ha': 'left', 'va': 'center',}],\n        [0, 1.05, subtitle, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n        [0, 1.01, note, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n    ],\n    'xtick_params': {'size': 12},\n    'ytick_params': {'size': 12},\n    'xlabel_params': {'size': 12},\n    'ylabel_params': {'size': 16},\n    'width': 12, 'height': 8,\n}\nplt = casestudy.heatmap.make(**kwargs)\n```\n\n\n![png](output_176_0.png)\n\n\nThe root data for the chart is available via `df_chart` attribute.\n\n\n```python\ncasestudy.heatmap.df_chart.head()\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>region_name</th>\n      <th>temp_dma</th>\n      <th>deaths_new_dma_per_1M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>52</td>\n      <td>Idaho</td>\n      <td>20.192015</td>\n      <td>0.428860</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>312</td>\n      <td>Bahrain</td>\n      <td>33.111273</td>\n      <td>0.274820</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>98</td>\n      <td>Nebraska</td>\n      <td>26.321220</td>\n      <td>0.240344</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>563</td>\n      <td>Mato Grosso Do Sul</td>\n      <td>23.137148</td>\n      <td>0.224056</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>568</td>\n      <td>Sergipe</td>\n      <td>26.239815</td>\n      <td>0.215220</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n**Natural Log of Max Fatalities v Temperature**\n\nBy taking the natural log of the fatality rate, we can scale the figure to reveal a more *(potentially)* clear relationship.\n\nViewers often struggle to understand the scaling of a natural log, so an `hlines` option has been provided that will create horizontal lines at the y-values input. `hlines` requires a `list` of `y-values`. \n\nText annotations are then included to inform of the unscaled `comp_category` value at each `hline`.\n\nWe also provide `comp_factor_start:` as `max`, which puts to use the 28DMA on the day of **peak fatalitiy rate** for each region.\n\n\n```python\ntitle = 'Max Daily Fatalities v Temperature by Region'\nkwargs = {\n    'x_category': 'deaths_new_dma_per_1M_log',\n    'y_category': 'temp_dma',\n    'x_start': 'start_hurdle',\n    'annotations': [\n        [0, 1.09, title, {'color': 'black', 'fontsize': 16, 'ha': 'left', 'va': 'center',}],\n        [0, 1.05, subtitle, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n        [0, 1.01, note, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n    ],\n    'xtick_params': {'size': 12},\n    'ytick_params': {'size': 12},\n    'xlabel_params': {'size': 12, 'labelpad': 10},\n    'ylabel_params': {'size': 16},\n    'width': 12, 'height': 8,\n}\nplt = casestudy.heatmap.make(**kwargs)\n```\n\n\n![png](output_180_0.png)\n\n\nAs with the other chart instances, a chart-specific dataframe can be access for `heatmap` via the `df_hm` attribute.\n\n\n```python\ncasestudy.heatmap.df_chart.head(4)\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>region_id</th>\n      <th>region_name</th>\n      <th>temp_dma</th>\n      <th>deaths_new_dma_per_1M_log</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>52</td>\n      <td>Idaho</td>\n      <td>20.192015</td>\n      <td>-0.367684</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>312</td>\n      <td>Bahrain</td>\n      <td>33.111273</td>\n      <td>-0.560952</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>98</td>\n      <td>Nebraska</td>\n      <td>26.321220</td>\n      <td>-0.619168</td>\n    </tr>\n    <tr>\n      <th>214</th>\n      <td>563</td>\n      <td>Mato Grosso Do Sul</td>\n      <td>23.137148</td>\n      <td>-0.649644</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n**Lognat of Max Daily New Fatalities and UVB Radition**\n\n\n```python\ntitle = 'Max Daily Fatalities v UVB Radiation by Region'\nsubtitle = '*Color-mapped by average daily uvb radiation for two weeks prior to the day of max fatalities'\nkwargs = {\n    'x_category': 'cases_new_dma_per_person_per_city_KM2_log',\n    'y_category': 'uvb_dma',\n    'x_start': 'max',\n    'annotations': [\n        [0, 1.09,  title, {'color': 'black', 'fontsize': 16, 'ha': 'left', 'va': 'center',}],\n        [0, 1.05, subtitle, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n    ],\n    'xtick_params': {'size': 12},\n    'ytick_params': {'size': 12},\n    'xlabel_params': {'size': 12, 'labelpad': 10},\n    'ylabel_params': {'size': 16},\n    'width': 12, 'height': 8,\n}\nplt = casestudy.heatmap.make(**kwargs)\n```\n\n\n![png](output_184_0.png)\n\n\n<h2><a id='section7.2'>7.2 Count Category v Multiple Factors (w one factor color-mapped)</a></h2>\n\nThe `heatmap` is made all the more powerful when a second factor is used to map the color space of the chart.\n\nThis is done via the `color_factor` parameter, which can be adapted via the `color_factor_start` parameter to take place on the day the `start_hurdle` is cleared or the day of max count category.\n\n\n```python\ntitle = 'Max Daily Fatalities v UVB Radiation v Oxford Stringency Index'\nsubtitle = '*Average UVB radiation and Oxford Stringency Index for two weeks prior to day of 1st fatality'\nkwargs = {\n    'x_category': 'cases_new_dma_per_1M_lognat',\n    'color_category': 'strindex_dma',\n    'color_start': 'start_hurdle',\n    'y_category': 'uvb_dma',\n    'annotations': [\n        [0, 1.09, title, {'color': 'black', 'fontsize': 16, 'ha': 'left', 'va': 'center',}],\n        [0, 1.05, subtitle, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n    ],\n    'xtick_params': {'size': 12},\n    'ytick_params': {'size': 12},\n    'xlabel_params': {'size': 12, 'labelpad': 10},\n    'ylabel_params': {'size': 16},\n    'width': 12, 'height': 8,\n}\nplt = casestudy.heatmap.make(**kwargs)\n```\n\n\n![png](output_187_0.png)\n\n\nThe `heatmap` approach is even better suited to time-static variables like demographic age ranges, given they are not susceptible to issues around averages over time.\n\nBelow we compare `A75PLUBB_%` against the average `strindex` for the 14 days prior to the max fatalitiy rate.\n\nWe can see that social distancing stringency was quite common across the spectrum and that population age was a much more important variable impacting fatalities.\n\n\n```python\ntitle = 'Max Daily Fatalities v UVB Radiation v Oxford Stringency Index'\nsubtitle = '*Average UVB radiation and Oxford Stringency Index for two weeks prior to day of 1st fatality'\nnote = '**Excludes mainland China'\n\nkwargs = {\n    'x_category': 'deaths_new_dma_per_person_per_city_KM2_lognat',\n    'y_category': 'A75PLUSB_%',\n    'color_category': 'strindex_dma',\n    'color_start': 'max',\n    'annotations': [\n        [0, 1.095, title, {'color': 'black', 'fontsize': 16, 'ha': 'left', 'va': 'center',}],\n        [0, 1.055, subtitle, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n        [0, 1.015, note, {'color': 'black', 'fontsize': 12, 'ha': 'left', 'va': 'center', 'style': 'italic'}],\n    ],\n    'xtick_params': {'size': 12},\n    'ytick_params': {'size': 12},\n    'xlabel_params': {'size': 12, 'labelpad': 10},\n    'ylabel_params': {'size': 16},\n    'width': 12, 'height': 8,\n}\nplt = casestudy.heatmap.make(**kwargs)\n```\n\n\n![png](output_189_0.png)\n\n\n<h1><a id='section8'>8. barcharts - Comparing Regional Factors</a></h1>\n\nA `barcharts` attribute is available (via `BarCharts` class) as another handy feature for comparing the impact in different regions across different categories.\n\nThe object plots a single category on a single plot comparing multiple regions. You can provide multiple categories and multiple subplots will be returned!\n\n`barcharts` object utilizes `matplotlib`.\n\nFirst instantiate the casestudy. We will consider a couple of the more successful Asian regions.\n\n\n```python\ndragons = ['Hong Kong', 'Taiwan', 'Korea, South', 'Japan']\nnotables = [ 'Texas', 'New York', 'Lombardia', 'Sao Paulo']\nregions = notables + dragons\n\nfactors_with_dmas = ['uvb', 'temp'] + CaseStudy.STRINDEX_CATS\nfactor_dmas = {factor: 28 for factor in factors_with_dmas}\nmobi_dmas = {'transit': 28, 'retail_n_rec': 28, 'parks': 28, 'workplaces': 28}\nfactors = factors_with_dmas + CaseStudy.GMOBIS + ['A15_34B', 'A65PLUSB'] \\\n    + ['visitors', 'gdp'] + CaseStudy.MAJOR_CAUSES\n\ncasestudy = CaseStudy(\n    bf, regions=regions, count_dma=21, factors=factors, factor_dmas=factor_dmas, \n    mobi_dmas=mobi_dmas, start_hurdle=1, start_factor='deaths',\n    favor_earlier=True, factors_to_favor_earlier='key3_sum',\n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=20.0, style=ProgressStyle(description_width\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))\n\n\n`Barcharts` accepts any category in the see19 dataset `bar_colors` provides different coloring of groups in the chart. You can further indicate some feature regions. Below we see a start difference among the regions selected.\n\n\n```python\nfactors1 = ['cases_per_1M', 'deaths_per_1M']\nkwargs = {'categories': factors1, 'height': 5, 'bar_colors': ['#3D7068', '#D4AFB9', '#529FD7']}\nkwargs['feature_regions'] = ['HKG', 'TWN', 'KOR']\nplt = casestudy.barcharts.make(**kwargs)\n```\n\n\n![png](output_195_0.png)\n\n\nOnce again, the chart data is available via `df_chart`:\n\n\n```python\ncasestudy.barcharts.df_chart\n```\n\n\n\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>region_code</th>\n      <th>NY</th>\n      <th>SP</th>\n      <th>LOM</th>\n      <th>TX</th>\n      <th>JPN</th>\n      <th>KOR</th>\n      <th>HKG</th>\n      <th>TWN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>region_id</th>\n      <td>75</td>\n      <td>556</td>\n      <td>36</td>\n      <td>67</td>\n      <td>429</td>\n      <td>433</td>\n      <td>353</td>\n      <td>497</td>\n    </tr>\n    <tr>\n      <th>region_code</th>\n      <td>NY</td>\n      <td>SP</td>\n      <td>LOM</td>\n      <td>TX</td>\n      <td>JPN</td>\n      <td>KOR</td>\n      <td>HKG</td>\n      <td>TWN</td>\n    </tr>\n    <tr>\n      <th>cases</th>\n      <td>407326</td>\n      <td>416434</td>\n      <td>95548</td>\n      <td>332434</td>\n      <td>25706</td>\n      <td>13816</td>\n      <td>1655</td>\n      <td>451</td>\n    </tr>\n    <tr>\n      <th>deaths</th>\n      <td>25056</td>\n      <td>19788</td>\n      <td>16796</td>\n      <td>4020</td>\n      <td>988</td>\n      <td>296</td>\n      <td>10</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>tests</th>\n      <td>5.16481e+06</td>\n      <td>1.15885e+06</td>\n      <td>724365</td>\n      <td>2.98455e+06</td>\n      <td>639821</td>\n      <td>1.44335e+06</td>\n      <td>442256</td>\n      <td>79506</td>\n    </tr>\n    <tr>\n      <th>population</th>\n      <td>1.93781e+07</td>\n      <td>4.1142e+07</td>\n      <td>9.63118e+06</td>\n      <td>2.51456e+07</td>\n      <td>1.28057e+08</td>\n      <td>4.79908e+07</td>\n      <td>7.02728e+06</td>\n      <td>2.25314e+07</td>\n    </tr>\n    <tr>\n      <th>city_dens</th>\n      <td>13978.1</td>\n      <td>8184.1</td>\n      <td>2316.88</td>\n      <td>924.007</td>\n      <td>8440.43</td>\n      <td>5032.81</td>\n      <td>9261.85</td>\n      <td>7919.49</td>\n    </tr>\n    <tr>\n      <th>cases_per_1M</th>\n      <td>21019.9</td>\n      <td>10121.9</td>\n      <td>9920.7</td>\n      <td>13220.4</td>\n      <td>200.738</td>\n      <td>287.889</td>\n      <td>235.511</td>\n      <td>20.0165</td>\n    </tr>\n    <tr>\n      <th>deaths_per_1M</th>\n      <td>1293.01</td>\n      <td>480.969</td>\n      <td>1743.92</td>\n      <td>159.869</td>\n      <td>7.71529</td>\n      <td>6.16785</td>\n      <td>1.42303</td>\n      <td>0.310678</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n\n\n`barcharts` can compare daily case and fatality rates. When a daily figure is selected, `barcharts` will find the maximum value in the time-series.\n\n\n```python\nfactors2 = ['deaths_new_dma_per_1M', 'deaths_new_dma_per_person_per_city_KM2']\nkwargs = {'categories': factors2, 'height': 5, 'bar_colors': ['#3D7068', '#D4AFB9', '#529FD7']}\nkwargs['feature_regions'] = ['HKG', 'TWN', 'KOR']\nplt = casestudy.barcharts.make(**kwargs)\n```\n\n\n![png](output_199_0.png)\n\n\nAs a matter of convenience, `barcharts` will automatically structure a subplot grid for any number of categories greater than 2.\n\n\n```python\nfactors = [\n    'strindex_dma', 'tests_new_dma_per_1M', \n    'population', 'city_dens', \n    'A15_34B_%', 'A65PLUSB_%', \n    'temp_dma', 'uvb_dma',\n    'circul_%', 'endo_%',\n    'visitors_%'\n]\nfactors = factors1 + factors2 + factors\nkwargs = {'categories': factors, 'height': 50, 'bar_colors': ['#3D7068', '#D4AFB9', '#529FD7']}\nkwargs['title'] = {'t': 'COVID Dragons v Other Regions', 'y': .895, 'fontsize': 20, 'fontweight': 'demi'}\nkwargs['feature_regions'] = ['HKG', 'TWN', 'KOR']\nplt = casestudy.barcharts.make(**kwargs)\n```\n\n\n![png](output_201_0.png)\n\n\n<h1><a id='section9'>9. Scatterflow for Large Sets</a></h1>\n\n9.1 [SubStrindexScatter](#section9.1)  \n9.2 [ScatterFlow](#section9.2)  \n\nThe plots investigated above have limitations when investigating a large set of subjects. Multi-line plots tend to become unreadable when using more than, say, 5 lines, and bar charts have dimensionality limitations, etc.\n\nThe `scatterflow` and `substrinscat` charts were created to improve visualization in this case.\n\n<h2><a id='section9.1'>9.1 substrinscat - for Strindex Sub-Categories</a></h2>\n\nWe will start with `substrinscat`, which is a more specific case of a `scatterflow` that focuses on the Oxford Stringency Index (you can think of it as being short for \"Sub-Strindex Category Scatterflow\").\n\nWe can generate a single `substrinscat` for one region that shows each `stringency` indicator. The value of the indicator is denoted by the color at each point. \n\nThe `strindex` and its subcategories are tracked at the `country-level`, so we will instantiate a `casestudy` setting the `country_level` flag to `true`. This aggregates all the `see19` data up from the province/state level to the country level (where province/state data exists). As previously noted, `smoothing` is not available when `country_level=True`.\n\n**NOTE** we will also instantiate with `start_factor: ''`. This creates a dataset beginning on 2020-01-01.\n\n\n```python\nfactors = CaseStudy.STRINDEX_CATS\nfactor_dmas = {factor: 28 for factor in factors}\n\ncountries = ['United States of America (the)', 'Canada', 'Mexico', 'Brazil', 'Australia', 'Russia',\n 'Italy', 'Germany', 'Spain', 'Singapore', 'Japan', 'Hong Kong', 'TWN', 'KOR', 'Malaysia'\n]\ncustom_sum = ['h1', 'h2', 'h3', 'c1', 'c8']\ncasestudy = CaseStudy(\n    bf, countries=countries, count_dma=21, factors=factors, factor_dmas=factor_dmas, \n    start_hurdle=1, start_factor='', lognat=True, country_level=True, custom_sum=custom_sum,\n)\ncasestudy.make()\n```\n\n    /Users/spindicate/Documents/programming/zooscraper/casestudy/see19/see19/study/ray.py:16: UserWarning: smoothing is unavailable when country_level=True\n      super().__init__(*args, **kwargs)\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))\n\n\nFirst, we'll demonstrate a single region, using Japan.\n\n\n```python\nkwargs = {\n    'regions': 'Japan', 'width': 6, 'height': 4.5, \n    'title': {'t': 'Japan Stringency Categories', 'x': .57, 'y': 1.07, 'fontsize': 20},\n    'xlabel_params': {'fontsize': 18, 'labelpad': 12},\n    'cblabel_params': {'fontsize': 14, 'labelpad': 6},\n    'palette_base': 'RdPu',\n    'xy_cbar': (1.05, .15), 'wh_cbar': (.35, .5),\n}\nplt = casestudy.substrinscat.make(**kwargs)\n```\n\n\n![png](output_208_0.png)\n\n\nThe single plot above expands to multi-plot simply by adding more regions.\n\n\n```python\nkwargs = {\n    'regions': ['name_for_USA', 'Hong Kong', 'Taiwan', 'Korea, South', 'Malaysia'], \n    'width': 14, 'height': 8,\n    'palette_base': 'RdPu',\n    'xy_cbar': (1.05, .3), 'wh_cbar': (.35, .5),\n    'xy_legend': (-.04, .49),\n    'legend': {'title': {'fontsize': 12}, 'text': {'fontsize': 12}},\n}\nplt = casestudy.substrinscat.make(**kwargs)\n```\n\n\n![png](output_210_0.png)\n\n\nAnd the plot automatically rescales based on the number of regions considered:\n\n\n```python\nkwargs = {\n    'width': 20, 'height': 18, \n    'palette_base': 'RdPu',\n    'xy_cbar': (1.05, .3), 'wh_cbar': (.35, .5),\n    'xy_legend': (-.04, .51),\n    'legend': {'title': {'fontsize': 12}, 'text': {'fontsize': 12}},\n}\nplt = casestudy.substrinscat.make(**kwargs)\n```\n\n\n![png](output_212_0.png)\n\n\n<h2><a id='section9.2'>9.2 scatterflow</a></h2>\n\n`ScatterFlow`, available as the `scatterflow` attribute, is a generalization of the `SubStrinScatter` chart. It is best suited for comparing many regions along a single dimension. For example, we can compare countries on the core Oxford Stringency Index:\n\n\n```python\nkwargs = {\n    'y_category': 'strindex',\n    'title': {'t': 'Oxford Stringency Index Over Time', 'y': 0.94, 'fontsize': 16},\n    'width': 8, 'height': 6,\n    'xy_cbar': (.7, .24), 'wh_cbar': (.35, 1),\n    'palette_base': 'Blues',\n    'xlabel_params': {'fontsize': 15, 'labelpad': 12},\n}\n\nplt = casestudy.scatterflow.make(**kwargs)\n```\n\n\n![png](output_215_0.png)\n\n\nWe can very clearly above the trends in stringency in the different regions above and isolate quickly the outliers.\n\n`Scatterflow` accepts any category in the see19 database.\n\nHere we show the sum of the Key3 strindex subcategories. \n\n\n```python\nkwargs = {\n    'y_category': 'key3_sum',\n    'title': {\n        't': 'The Key 3: Information, Contact Tracing, and Testing Over Time',\n        'fontsize': 16,\n        'y': 0.94\n    },\n    'xlabel_params': {'fontsize': 14},\n    'width': 8, 'height': 6,\n    'xy_cbar': (.7, .24), 'wh_cbar': (.35, 1),\n    'palette_base': 'Blues'\n}\nplt = casestudy.scatterflow.make(**kwargs)\n```\n\n\n![png](output_217_0.png)\n\n\nAnd below we compare US states on new fatalities. \n\nFirst, we will select the 25 most impacted States in terms of total fatalities. Then, we instantiate a new CaseStudy to do so.\n\n\n```python\nregion_ids = bf[bf.country_code == 'USA'].groupby('region_id').deaths.max().sort_values(ascending=False).index.values[:25]\n```\n\n\n```python\ncasestudy = CaseStudy(bf, regions=region_ids, count_dma=3,\n    start_factor='date', start_hurdle=dt(2020, 3, 1)\n)\ncasestudy.make()\n```\n\n\n    HBox(children=(FloatProgress(value=0.0, description='Creating CaseStudy', layout=Layout(flex='2'), max=2.0, st\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, description='changes', max=66.0, style=ProgressStyle(description_width\u2026\n\n\n\n    HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))\n\n\n\n```python\nkwargs = {\n    'y_category': 'deaths_new_dma_per_1M',\n    'title': {\n        't': 'Daily Fatalities in US States',\n        'fontsize': 16,\n        'y': 0.94\n    },\n    'marker': 's',\n    'ms': 225,\n    'width': 5, \n    'height': 4,\n    'xlabel_params': {'fontsize': 14},\n    'width': 8, 'height': 6,\n    'xy_cbar': (.7, .24), 'wh_cbar': (.35, 1),\n    'palette_base': 'RdYlGn_r'\n}\ncasestudy.scatterflow.make(**kwargs)\n```\n\n\n![png](output_221_0.png)\n\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/ryanskene/see19",
            "keywords": "",
            "license": "",
            "maintainer": "",
            "maintainer_email": "",
            "name": "see19",
            "package_url": "https://pypi.org/project/see19/",
            "platform": "",
            "project_url": "https://pypi.org/project/see19/",
            "project_urls": {
                "Homepage": "https://github.com/ryanskene/see19"
            },
            "release_url": "https://pypi.org/project/see19/0.4rc0/",
            "requires_dist": [
                "bokeh (>=2.0.0)",
                "matplotlib (>=3.2.0)",
                "numpy (>=1.18.0)",
                "pandas (>=1.0.0)",
                "requests (>=2.23.0)",
                "numba (>=0.50.1)",
                "ray (>=0.8.6)"
            ],
            "requires_python": ">=3.7",
            "summary": "An interface for visualizing and analysing the see19 dataset",
            "version": "0.4rc0",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13178756,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "882d3d84e9ec80488a73e10504f0487a",
                    "sha256": "758f2507da614fc1b3f6a6f02867319aaea3912d0d11c32d19098a4707a07bbe"
                },
                "downloads": -1,
                "filename": "see19-0.4rc0-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "882d3d84e9ec80488a73e10504f0487a",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 85971,
                "upload_time": "2020-08-02T16:46:23",
                "upload_time_iso_8601": "2020-08-02T16:46:23.772551Z",
                "url": "https://files.pythonhosted.org/packages/24/61/b8627185b760be90ede57c08de19c1c48b6db483d42c0feaa8d57fb4cdb7/see19-0.4rc0-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            },
            {
                "comment_text": "",
                "digests": {
                    "md5": "f6570984d1d6c9edc2091527c34664da",
                    "sha256": "e3889f14d426d614c67ac5d1058b1d64f734f21f08a4f38180e8875d9430c2e2"
                },
                "downloads": -1,
                "filename": "see19-0.4rc0.tar.gz",
                "has_sig": false,
                "md5_digest": "f6570984d1d6c9edc2091527c34664da",
                "packagetype": "sdist",
                "python_version": "source",
                "requires_python": ">=3.7",
                "size": 128791,
                "upload_time": "2020-08-02T16:46:26",
                "upload_time_iso_8601": "2020-08-02T16:46:26.018872Z",
                "url": "https://files.pythonhosted.org/packages/9b/85/30568451ea1762cf31253f1059966d4dfa956acf6e7ddae7997e9a1f5a01/see19-0.4rc0.tar.gz",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}
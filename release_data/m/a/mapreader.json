{
    "0.3.2": {
        "info": {
            "author": "kasra-hosseini",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: End Users/Desktop",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: English",
                "Operating System :: MacOS",
                "Operating System :: Microsoft :: Windows",
                "Operating System :: OS Independent",
                "Operating System :: Unix",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Software Development",
                "Topic :: Software Development :: Libraries :: Python Modules"
            ],
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/Living-with-machines/MapReader/archive/refs/heads/main.zip",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Living-with-machines/MapReader",
            "keywords": "Computer Vision,Classification,Deep Learning,living with machines",
            "license": "MIT License",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mapreader",
            "package_url": "https://pypi.org/project/mapreader/",
            "platform": "OS Independent",
            "project_url": "https://pypi.org/project/mapreader/",
            "project_urls": {
                "Download": "https://github.com/Living-with-machines/MapReader/archive/refs/heads/main.zip",
                "Homepage": "https://github.com/Living-with-machines/MapReader"
            },
            "release_url": "https://pypi.org/project/mapreader/0.3.2/",
            "requires_dist": [
                "pytest (<7.0.0,>=6.2.5)",
                "matplotlib (<4.0.0,>=3.5.0)",
                "numpy (<2.0.0,>=1.21.5)",
                "pandas (<2.0.0,>=1.3.4)",
                "pyproj (<4.0.0,>=3.2.0)",
                "azure-storage-blob (<13.0.0,>=12.9.0)",
                "aiohttp (<4.0.0,>=3.8.1)",
                "Shapely (<2.0.0,>=1.8.0)",
                "nest-asyncio (<2.0.0,>=1.5.1)",
                "scikit-image (<0.19.0,>=0.18.3)",
                "scikit-learn (<2.0.0,>=1.0.1)",
                "torch (<2.0.0,>=1.10.0)",
                "torchvision (<0.12.1,>=0.11.1)",
                "jupyter (<2.0.0,>=1.0.0)",
                "ipykernel (<7.0.0,>=6.5.1)",
                "ipyannotate (==0.1.0-beta.0)",
                "Cython (<0.30.0,>=0.29.24)",
                "proj (<0.3.0,>=0.2.0)",
                "PyYAML (<7.0,>=6.0)",
                "tensorboard (<3.0.0,>=2.7.0)",
                "parhugin (<0.0.4,>=0.0.3)",
                "geopy (==2.1.0) ; extra == 'geo'",
                "rasterio (<2.0.0,>=1.2.10) ; extra == 'geo'",
                "keplergl (<0.4.0,>=0.3.2) ; extra == 'geo'",
                "simplekml (<2.0.0,>=1.3.6) ; extra == 'geo'"
            ],
            "requires_python": ">=3.7",
            "summary": "A computer vision pipeline for the semantic exploration of maps/images at scale",
            "version": "0.3.2",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13641676,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "3c00396357a122ba22617e41400e0a7b",
                    "sha256": "30a5ab7da114ce4570ce4cfd019e25b070b7599cff22a08d634577f9ad75e31f"
                },
                "downloads": -1,
                "filename": "mapreader-0.3.2-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "3c00396357a122ba22617e41400e0a7b",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 67554,
                "upload_time": "2022-04-27T16:03:21",
                "upload_time_iso_8601": "2022-04-27T16:03:21.896620Z",
                "url": "https://files.pythonhosted.org/packages/9d/5d/fbeb9a45ae8a605a31717dbc8b6e6a0ac32c2572322f53f6743372763374/mapreader-0.3.2-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    },
    "0.3.3": {
        "info": {
            "author": "kasra-hosseini",
            "author_email": "",
            "bugtrack_url": null,
            "classifiers": [
                "Development Status :: 3 - Alpha",
                "Intended Audience :: Developers",
                "Intended Audience :: Education",
                "Intended Audience :: End Users/Desktop",
                "Intended Audience :: Science/Research",
                "License :: OSI Approved :: MIT License",
                "Natural Language :: English",
                "Operating System :: MacOS",
                "Operating System :: Microsoft :: Windows",
                "Operating System :: OS Independent",
                "Operating System :: Unix",
                "Programming Language :: Python :: 3.7",
                "Programming Language :: Python :: 3.8",
                "Topic :: Scientific/Engineering :: Artificial Intelligence",
                "Topic :: Software Development",
                "Topic :: Software Development :: Libraries :: Python Modules"
            ],
            "description": "<div align=\"center\">\n    <br>\n    <p align=\"center\">\n    <h1>MapReader</h1>\n    <h2>A computer vision pipeline for exploring and analyzing images at scale</h2>\n    </p>\n</div>\n\n<p align=\"center\">\n    <a href=\"https://pypi.org/project/mapreader/\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/MapReader\">\n    </a>\n    <a href=\"https://mybinder.org/v2/gh/Living-with-machines/MapReader/main?labpath=examples%2Fquick_start%2Fquick_start.ipynb\">\n        <img alt=\"Binder\" src=\"https://mybinder.org/badge_logo.svg\">\n    </a>\n    <a href=\"https://github.com/Living-with-machines/MapReader/blob/main/LICENSE\">\n        <img alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg\">\n    </a>\n    <a href=\"https://github.com/Living-with-machines/MapReader/actions/workflows/mr_ci.yml/badge.svg\">\n        <img alt=\"Integration Tests badge\" src=\"https://github.com/Living-with-machines/MapReader/actions/workflows/mr_ci.yml/badge.svg\">\n    </a>\n    <br/>\n</p>\n\n## Gallery\n\n<div align=\"center\">\n\n|   |   |\n|:---:|:---:|\n| **classification_one_inch_maps_001**<br><a href=\"https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial/classification_one_inch_maps_001\"><img src=\"https://raw.githubusercontent.com/Living-with-machines/MapReader/main/figs/tutorial_classification_one_inch_maps_001.png\" alt=\"tutorial for classification_one_inch_maps_001\" width=\"300\" height=\"150\"></a><br><sup>**Tutorial:** train/fine-tune PyTorch CV classifiers on <ins>historical maps</ins> (Fig: rail infrastructure around London as predicted by a MapReader model).</sup> | **classification_plant_phenotype**<br><a href=\"https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial/classification_plant_phenotype\"><img src=\"https://raw.githubusercontent.com/Living-with-machines/MapReader/main/figs/tutorial_classification_plant_phenotype.png\" alt=\"tutorial for classification_plant_phenotype\" width=\"300\" height=\"150\"></a><br><sup>**Tutorial:** train/fine-tune PyTorch CV classifiers on <ins>plant patches</ins> in images (plant phenotyping example).</sup> |\n| **classification_mnist**<br><a href=\"https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial/classification_mnist\"><img src=\"https://raw.githubusercontent.com/Living-with-machines/MapReader/main/figs/tutorial_classification_mnist.png\" alt=\"tutorial for classification_mnist\" width=\"300\" height=\"150\"></a><br><sup>**Tutorial:** train/fine-tune PyTorch CV classifiers on whole <ins>MNIST</ins> images (not on patches/slices of those images).</sup> | |\n| | |\n**MapReader paper**<br><a href=\"https://arxiv.org/abs/2111.15592\"> <img src=\"https://raw.githubusercontent.com/Living-with-machines/MapReader/main/figs/mapreader_paper.png\" alt=\"MapReader's paper\" width=\"300\"> </a> \n</div>\n\n## What is MapReader?\n\nMapReader is an end-to-end computer vision (CV) pipeline for exploring and analyzing images at scale. \n\nMapReader was developed in the [Living with Machines](https://livingwithmachines.ac.uk/) project to analyze large collections of historical maps but is a _**generalisable**_ computer vision pipeline which can be applied to _**any images**_ in a wide variety of domains. See [Gallery](#gallery) for some examples.\n\nRefer to each tutorial/example in the [use cases](#use-cases) section for more details on MapReader's relevant functionalities for [<ins>non-geospatial</ins>](https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial) and [<ins>geospatial</ins>](https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial) images.\n\n## Contents\n\n- [Gallery](#gallery)\n- [What is MapReader?](#what-is-mapreader)\n- [Overview](#overview)\n- [Installation and setup](#installation)\n  - [Set up a conda environment](#set-up-a-conda-environment)\n  - [Method 1: pip](#method-1)\n  - [Method 2: source code (for developers)](#method-2)\n- [Use cases](#use-cases)\n- [How to contribute](#how-to-contribute)\n- [How to cite MapReader](#how-to-cite-mapreader)\n- [Credits and re-use terms](#credits-and-re-use-terms)\n  - [Digitized maps](#digitized-maps): MapReader can retrieve maps from NLS via tileserver. Read the re-use terms in this section.\n  - [Metadata](#metadata): the metadata files are stored at [mapreader/persistent_data](https://github.com/Living-with-machines/MapReader/tree/main/mapreader/persistent_data). Read the re-use terms in this section.\n  - [Acknowledgements](#acknowledgements)\n\n## Overview\n\nMapReader is a groundbreaking interdisciplinary tool that emerged from a specific set of geospatial historical research questions. It was inspired by methods in biomedical imaging and geographic information science, which were adapted for annotation and use by historians, for example in [JVC](https://doi.org/10.1093/jvcult/vcab009) and [MapReader](https://arxiv.org/abs/2111.15592) papers. The success of the tool subsequently generated interest from plant phenotype researchers working with large image datasets, and so MapReader is an example of cross-pollination between the humanities and the sciences made possible by reproducible data science.\n\nMapReader has two main components: preprocessing/annotation and training/inference as shown in this figure:\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Living-with-machines/MapReader/main/figs/MapReader_pipeline.png\" \n        alt=\"MapReader pipeline\" width=\"70%\" align=\"center\">\n</p>\n\nIt provides a set of tools to:\n\n- **load** images or maps stored locally or **retrieve** maps via web-servers (e.g., tileservers which can be used to retrieve maps from OpenStreetMap (OSM), the National Library of Scotland (NLS), or elsewhere). :warning: Refer to the [credits and re-use terms](#credits-and-re-use-terms) section if you are using digitized maps or metadata provided by NLS. \n- **preprocess** images or maps (e.g., divide them into patches, resampling the images, removing borders outside the neatline or reprojecting the map).\n- annotate images or maps or their patches (i.e. slices of an image or map) using an **interactive annotation tool**.\n- **train, fine-tune, and evaluate** various CV models.\n- **predict** labels (i.e., model inference) on large sets of images or maps.\n- Other functionalities include:\n    - various **plotting tools** using, e.g., *matplotlib*, *cartopy*, *Google Earth*, and [kepler.gl](https://kepler.gl/).\n    - compute mean/standard-deviation **pixel intensity** of image patches.\n\n## Installation\n\n### Set up a conda environment\n\nWe recommend installation via Anaconda (refer to [Anaconda website and follow the instructions](https://docs.anaconda.com/anaconda/install/)).\n\n* Create a new environment for `mapreader` called `mr_py38`:\n\n```bash\nconda create -n mr_py38 python=3.8\n```\n\n* Activate the environment:\n\n```bash\nconda activate mr_py38\n```\n\n### Method 1\n\n* Install `mapreader`:\n\n```bash\npip install mapreader \n```\n\nTo work with geospatial images (e.g., maps):\n\n```bash\npip install \"mapreader[geo]\" \n```\n\n* We have provided some [Jupyter Notebooks to showcase MapReader's functionalities](https://github.com/Living-with-machines/MapReader/tree/main/examples). To allow the newly created `mr_py38` environment to show up in the notebooks:\n\n```bash\npython -m ipykernel install --user --name mr_py38 --display-name \"Python (mr_py38)\"\n```\n\n* Continue with the examples in [Use cases](#use-cases)!\n\n* \u26a0\ufe0f On *Windows* and for *geospatial images* (e.g., maps), you might need to do:\n\n```bash\n# activate the environment\nconda activate mr_py38\n\n# install rasterio and fiona manually\nconda install -c conda-forge rasterio=1.2.10\nconda install -c conda-forge fiona=1.8.20\n\n# install git\nconda install git\n\n# install MapReader\npip install git+https://github.com/Living-with-machines/MapReader.git\n\n# open Jupyter Notebook (if you want to test/work with the notebooks in \"examples\" directory)\ncd /path/to/MapReader \njupyter notebook\n```\n\n### Method 2\n\n* Clone `mapreader` source code:\n\n```bash\ngit clone https://github.com/Living-with-machines/MapReader.git \n```\n\n* Install:\n\n```bash\ncd /path/to/MapReader\npip install -v -e .\n```\n\nTo work with geospatial images (e.g., maps):\n\n```bash\ncd /path/to/MapReader\npip install -e .\"[geo]\"\n```\n\n* We have provided some [Jupyter Notebooks to showcase MapReader's functionalities](https://github.com/Living-with-machines/MapReader/tree/main/examples). To allow the newly created `mr_py38` environment to show up in the notebooks:\n\n```bash\npython -m ipykernel install --user --name mr_py38 --display-name \"Python (mr_py38)\"\n```\n\n* Continue with the examples in [Use cases](#use-cases)!\n\n## Use cases\n\n[Tutorials](https://github.com/Living-with-machines/MapReader/tree/main/examples) are organized in Jupyter Notebooks. Follow the hyperlinks on input type names (\"Non-Geospatial\" or \"Geospatial\") to read guidance specific to those image types. \n\n  - [Non-Geospatial](https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial):\n      - [classification_plant_phenotype](https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial/classification_plant_phenotype)\n        * **Goal:** train/fine-tune PyTorch CV classifiers on plant patches in images (plant phenotyping example).\n        * **Dataset:** Example images taken from the openly accessible `CVPPP2014_LSV_training_data` dataset available from https://www.plant-phenotyping.org/datasets-download. \n        * **Data access:** locally stored\n        * **Annotations** are done on plant patches (i.e., slices of each plant image).\n        * **Classifier:** train/fine-tuned PyTorch CV models.\n      - [classification_mnist](https://github.com/Living-with-machines/MapReader/tree/main/examples/non-geospatial/classification_mnist)\n        * **Goal:** train/fine-tune PyTorch CV classifiers on MNIST.\n        * **Dataset:** Example images taken from http://yann.lecun.com/exdb/mnist/. \n        * **Data access:** locally stored\n        * **Annotations** are done on whole MNIST images, **not** on patches/slices of those images.\n        * **Classifier:** train/fine-tuned PyTorch CV models.\n  - [Geospatial](https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial):\n      - Maps:\n        - [classification_one_inch_maps_001](https://github.com/Living-with-machines/MapReader/tree/main/examples/geospatial/classification_one_inch_maps_001)\n          * **Goal:** train/fine-tune PyTorch CV classifiers on historical maps.\n          * **Dataset:** from National Library of Scotland: [OS one-inch, 2nd edition layer](https://mapseries-tilesets.s3.amazonaws.com/1inch_2nd_ed/index.html).\n          * **Data access:** tileserver\n          * **Annotations** are done on map patches (i.e., slices of each map).\n          * **Classifier:** train/fine-tuned PyTorch CV models.\n\n## How to contribute\n\nWe welcome contributions related to new applications, both with <ins>geospatial</ins> images (other maps, remote sensing data, aerial photography) and <ins>non-geospatial</ins> images (for example, other scientific image datasets).\n\n## How to cite MapReader\n\nPlease consider acknowledging MapReader if it helps you to obtain results and figures for publications or presentations, by citing:\n\nLink: https://arxiv.org/abs/2111.15592\n\n```text\nKasra Hosseini, Daniel C. S. Wilson, Kaspar Beelen and Katherine McDonough (2021), MapReader: A Computer Vision Pipeline for the Semantic Exploration of Maps at Scale, arXiv:2111.15592.\n```\n\nand in BibTeX:\n\n```bibtex\n@misc{hosseini2021mapreader,\n      title={MapReader: A Computer Vision Pipeline for the Semantic Exploration of Maps at Scale}, \n      author={Kasra Hosseini and Daniel C. S. Wilson and Kaspar Beelen and Katherine McDonough},\n      year={2021},\n      eprint={2111.15592},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV}\n}\n```\n\n## Credits and re-use terms \n\n### Digitized maps\n\nMapReader can retrieve maps from NLS (National Library of Scotland) via webservers. For all the digitized maps (retrieved or locally stored), please note the re-use terms:\n\n:warning: Use of the digitised maps for commercial purposes is currently restricted by contract. Use of these digitised maps for non-commercial purposes is permitted under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/) (CC-BY-NC-SA) licence. Please refer to https://maps.nls.uk/copyright.html#exceptions-os for details on copyright and re-use license.\n\n### Metadata\n\nWe have provided some metadata files in `mapreader/persistent_data`. For all these file, please note the re-use terms:\n\n:warning: Use of the metadata for commercial purposes is currently restricted by contract. Use of this metadata for non-commercial purposes is permitted under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/) (CC-BY-NC-SA) licence. Please refer to https://maps.nls.uk/copyright.html#exceptions-os for details on copyright and re-use license.\n\n### Acknowledgements\n\nThis work was supported by Living with Machines (AHRC grant AH/S01179X/1) and The Alan Turing Institute (EPSRC grant EP/N510129/1). \nLiving with Machines, funded by the UK Research and Innovation (UKRI) Strategic Priority Fund, is a multidisciplinary collaboration delivered by the Arts and Humanities Research Council (AHRC), with The Alan Turing Institute, the British Library and the Universities of Cambridge, East Anglia, Exeter, and Queen Mary University of London.\n\n\n",
            "description_content_type": "text/markdown",
            "docs_url": null,
            "download_url": "https://github.com/Living-with-machines/MapReader/archive/refs/heads/main.zip",
            "downloads": {
                "last_day": -1,
                "last_month": -1,
                "last_week": -1
            },
            "home_page": "https://github.com/Living-with-machines/MapReader",
            "keywords": "Computer Vision,Classification,Deep Learning,living with machines",
            "license": "MIT License",
            "maintainer": "",
            "maintainer_email": "",
            "name": "mapreader",
            "package_url": "https://pypi.org/project/mapreader/",
            "platform": "OS Independent",
            "project_url": "https://pypi.org/project/mapreader/",
            "project_urls": {
                "Download": "https://github.com/Living-with-machines/MapReader/archive/refs/heads/main.zip",
                "Homepage": "https://github.com/Living-with-machines/MapReader"
            },
            "release_url": "https://pypi.org/project/mapreader/0.3.3/",
            "requires_dist": [
                "pytest (<7.0.0,>=6.2.5)",
                "matplotlib (<4.0.0,>=3.5.0)",
                "numpy (<2.0.0,>=1.21.5)",
                "pandas (<2.0.0,>=1.3.4)",
                "pyproj (<4.0.0,>=3.2.0)",
                "azure-storage-blob (<13.0.0,>=12.9.0)",
                "aiohttp (<4.0.0,>=3.8.1)",
                "Shapely (<2.0.0,>=1.8.0)",
                "nest-asyncio (<2.0.0,>=1.5.1)",
                "scikit-image (<0.19.0,>=0.18.3)",
                "scikit-learn (<2.0.0,>=1.0.1)",
                "torch (<2.0.0,>=1.10.0)",
                "torchvision (<0.12.1,>=0.11.1)",
                "jupyter (<2.0.0,>=1.0.0)",
                "ipykernel (<7.0.0,>=6.5.1)",
                "ipyannotate (==0.1.0-beta.0)",
                "Cython (<0.30.0,>=0.29.24)",
                "proj (<0.3.0,>=0.2.0)",
                "PyYAML (<7.0,>=6.0)",
                "tensorboard (<3.0.0,>=2.7.0)",
                "parhugin (<0.0.4,>=0.0.3)",
                "geopy (==2.1.0) ; extra == 'geo'",
                "rasterio (<2.0.0,>=1.2.10) ; extra == 'geo'",
                "keplergl (<0.4.0,>=0.3.2) ; extra == 'geo'",
                "simplekml (<2.0.0,>=1.3.6) ; extra == 'geo'"
            ],
            "requires_python": ">=3.7",
            "summary": "A computer vision pipeline for the semantic exploration of maps/images at scale",
            "version": "0.3.3",
            "yanked": false,
            "yanked_reason": null
        },
        "last_serial": 13641676,
        "urls": [
            {
                "comment_text": "",
                "digests": {
                    "md5": "5c4c8620d007164b15b23ca06fe73cf1",
                    "sha256": "7335cc8aee41050b6e292cd8d347563687438fd817635b40a6613d49789e30d1"
                },
                "downloads": -1,
                "filename": "mapreader-0.3.3-py3-none-any.whl",
                "has_sig": false,
                "md5_digest": "5c4c8620d007164b15b23ca06fe73cf1",
                "packagetype": "bdist_wheel",
                "python_version": "py3",
                "requires_python": ">=3.7",
                "size": 67579,
                "upload_time": "2022-04-27T16:29:19",
                "upload_time_iso_8601": "2022-04-27T16:29:19.526448Z",
                "url": "https://files.pythonhosted.org/packages/bc/0b/7a33b113edab2e522c3472233b684f770438366f4d79d3546460847637f8/mapreader-0.3.3-py3-none-any.whl",
                "yanked": false,
                "yanked_reason": null
            }
        ],
        "vulnerabilities": []
    }
}